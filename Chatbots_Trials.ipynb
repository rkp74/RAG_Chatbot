{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkTu4mHRpzBVTWDgx/Zowx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bf9638be1d74a828a469e5121523e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a2b9b3e03f44631b1f2410bb77a15ab",
              "IPY_MODEL_cabad43eefb24bb58e67f214635cfae7",
              "IPY_MODEL_d2dcb48375e34e4084f7f9c2bca8c31a"
            ],
            "layout": "IPY_MODEL_8281d7a7a8704d26a706323ca8a423e3"
          }
        },
        "5a2b9b3e03f44631b1f2410bb77a15ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3e43c9c1923490699677dff198d402c",
            "placeholder": "​",
            "style": "IPY_MODEL_f34aa1af2d5f4dbe85d90680c7e23ef4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cabad43eefb24bb58e67f214635cfae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecba445d19ff4f4a90f81602989bfdf2",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2e119f7902e4e4683b3f7cb008566c2",
            "value": 28
          }
        },
        "d2dcb48375e34e4084f7f9c2bca8c31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e956b533c14861b8c808452c3494a4",
            "placeholder": "​",
            "style": "IPY_MODEL_5c1316f15e7c4d5fa5c2b082578e422c",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.14kB/s]"
          }
        },
        "8281d7a7a8704d26a706323ca8a423e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e43c9c1923490699677dff198d402c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34aa1af2d5f4dbe85d90680c7e23ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecba445d19ff4f4a90f81602989bfdf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e119f7902e4e4683b3f7cb008566c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7e956b533c14861b8c808452c3494a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1316f15e7c4d5fa5c2b082578e422c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac6a3967bb9c4821951c17765d813f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa6dd73422094ec98aa384fa0a8f1ea9",
              "IPY_MODEL_cee121985a7f4717b3538b9d1ab08ba7",
              "IPY_MODEL_a27aec7b67334a8fb7b3260541a965b7"
            ],
            "layout": "IPY_MODEL_8aa958c7142740f9993e73bec992e6f4"
          }
        },
        "fa6dd73422094ec98aa384fa0a8f1ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c56763ff384598b12458500df684c7",
            "placeholder": "​",
            "style": "IPY_MODEL_aab89a8cb45747aba990607e469e4b24",
            "value": "vocab.txt: 100%"
          }
        },
        "cee121985a7f4717b3538b9d1ab08ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b0eca2cc484c148e1bc11601207530",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_816fcf0d57f34989963910aec51c66ff",
            "value": 231508
          }
        },
        "a27aec7b67334a8fb7b3260541a965b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_060489664ced4268a358c0012f1b43e7",
            "placeholder": "​",
            "style": "IPY_MODEL_67c110c6540b43fabe4c4e2ebe902d79",
            "value": " 232k/232k [00:00&lt;00:00, 2.33MB/s]"
          }
        },
        "8aa958c7142740f9993e73bec992e6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c56763ff384598b12458500df684c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab89a8cb45747aba990607e469e4b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2b0eca2cc484c148e1bc11601207530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816fcf0d57f34989963910aec51c66ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "060489664ced4268a358c0012f1b43e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c110c6540b43fabe4c4e2ebe902d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81f4c752aed4cad8fbfa51d100373a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_165dbceab6e84299bf0fe37650319a84",
              "IPY_MODEL_059ba710a5564cd28b529c990ec84241",
              "IPY_MODEL_54c7df1d2f9b412b867b5f04f191ed91"
            ],
            "layout": "IPY_MODEL_fa5b8c1f2bbf483ca2654a6720e36a03"
          }
        },
        "165dbceab6e84299bf0fe37650319a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71c7e5005c874bc895db73f72599c3df",
            "placeholder": "​",
            "style": "IPY_MODEL_e7ff5a48c75b4231b294ab5ea486ad62",
            "value": "tokenizer.json: 100%"
          }
        },
        "059ba710a5564cd28b529c990ec84241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d223169e08542caaad03a7ccd1e4048",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2a61b02abb8457e99967eb9c32f2beb",
            "value": 466062
          }
        },
        "54c7df1d2f9b412b867b5f04f191ed91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002297d9dc334574a379a3a819707c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_3d346addb9d948abbee4c92724381310",
            "value": " 466k/466k [00:00&lt;00:00, 11.0MB/s]"
          }
        },
        "fa5b8c1f2bbf483ca2654a6720e36a03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c7e5005c874bc895db73f72599c3df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ff5a48c75b4231b294ab5ea486ad62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d223169e08542caaad03a7ccd1e4048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a61b02abb8457e99967eb9c32f2beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "002297d9dc334574a379a3a819707c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d346addb9d948abbee4c92724381310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9b9a045f54d478794ada90bfd742bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b52b1b31ab440399d8ab8cd8526800d",
              "IPY_MODEL_db0aec260d45424bbd1dbd8af669733a",
              "IPY_MODEL_8501f840d3b244aa99a1a104883bb127"
            ],
            "layout": "IPY_MODEL_db52867f9f71481187a05f5459c91191"
          }
        },
        "5b52b1b31ab440399d8ab8cd8526800d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5b0461a3c784b929f0eded7292d9364",
            "placeholder": "​",
            "style": "IPY_MODEL_1fe92344a5fd4a6d86962c0ce3b71370",
            "value": "config.json: 100%"
          }
        },
        "db0aec260d45424bbd1dbd8af669733a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f243e7bb05045229da57361f5de4a56",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_127b4dceb9b042e2b71c73adfaf6a369",
            "value": 570
          }
        },
        "8501f840d3b244aa99a1a104883bb127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff1c142e4e8422abd6e3c7ff3202309",
            "placeholder": "​",
            "style": "IPY_MODEL_2f0566d138b5445da3117ad0f4e54967",
            "value": " 570/570 [00:00&lt;00:00, 29.5kB/s]"
          }
        },
        "db52867f9f71481187a05f5459c91191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b0461a3c784b929f0eded7292d9364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe92344a5fd4a6d86962c0ce3b71370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f243e7bb05045229da57361f5de4a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127b4dceb9b042e2b71c73adfaf6a369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ff1c142e4e8422abd6e3c7ff3202309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0566d138b5445da3117ad0f4e54967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be98164834c143da837a6e0a977e618a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bdca7fc1b9545feb374b4d63ad890d6",
              "IPY_MODEL_4d1e7f2951994e399c951f081cd4cb5b",
              "IPY_MODEL_47c94da8ae21463cba5477553ddc4ccd"
            ],
            "layout": "IPY_MODEL_e52c54cbf991404fad815ffe72d46168"
          }
        },
        "7bdca7fc1b9545feb374b4d63ad890d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2c69d45bc04d95a42c7f7168b253f6",
            "placeholder": "​",
            "style": "IPY_MODEL_bae63fa01da34955b64bbae6fa260847",
            "value": "model.safetensors: 100%"
          }
        },
        "4d1e7f2951994e399c951f081cd4cb5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c4484b5cbe4f87b23dcae0089a0bd3",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77d84fe2a82146648b2436d1f0ef1ca2",
            "value": 440449768
          }
        },
        "47c94da8ae21463cba5477553ddc4ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1349c97f5bd44218a21a5123e9265990",
            "placeholder": "​",
            "style": "IPY_MODEL_15e5de95fce1483ca1bc002669298212",
            "value": " 440M/440M [00:06&lt;00:00, 91.4MB/s]"
          }
        },
        "e52c54cbf991404fad815ffe72d46168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2c69d45bc04d95a42c7f7168b253f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae63fa01da34955b64bbae6fa260847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c4484b5cbe4f87b23dcae0089a0bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d84fe2a82146648b2436d1f0ef1ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1349c97f5bd44218a21a5123e9265990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e5de95fce1483ca1bc002669298212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9e01dec418b4ab68bba1eedc2d20831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33a9191d161041af87c373de8e91e60f",
              "IPY_MODEL_c24cacc56bcd4347afa44fb9cf7f55da",
              "IPY_MODEL_0408dd4c89ea4fd9be8d29f8091af13e"
            ],
            "layout": "IPY_MODEL_8b3370be27964307a0dae24da416bc15"
          }
        },
        "33a9191d161041af87c373de8e91e60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc1692f2e4a44009c694422c95c62c1",
            "placeholder": "​",
            "style": "IPY_MODEL_58cd6122eae245548934e63f6ca15f0f",
            "value": ".gitattributes: 100%"
          }
        },
        "c24cacc56bcd4347afa44fb9cf7f55da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eba8f6725484e79af1d02d5fc450a10",
            "max": 491,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e8d1dc75fb74e5bbcc5204070d3ad18",
            "value": 491
          }
        },
        "0408dd4c89ea4fd9be8d29f8091af13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348fb0db82154b0289560294bbe22b27",
            "placeholder": "​",
            "style": "IPY_MODEL_f6a129489743421784ea8c01b07250fe",
            "value": " 491/491 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "8b3370be27964307a0dae24da416bc15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc1692f2e4a44009c694422c95c62c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58cd6122eae245548934e63f6ca15f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eba8f6725484e79af1d02d5fc450a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8d1dc75fb74e5bbcc5204070d3ad18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "348fb0db82154b0289560294bbe22b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a129489743421784ea8c01b07250fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fe7c3bc57b34a07a9496e8738fc4b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ec74561c0c64bc08808ffd3644b77e7",
              "IPY_MODEL_79298e7ac3c344f29cbab53005e8ccd6",
              "IPY_MODEL_6bdc71ffe9ab4af28732c9d7700828f1"
            ],
            "layout": "IPY_MODEL_4f4e8bd64d674b5a9cf541010ae38040"
          }
        },
        "4ec74561c0c64bc08808ffd3644b77e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b48c743696f4c61a4f0d138a59e1ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_85ad10d0812d484bb50c3f2e3fb79a82",
            "value": "LICENSE: 100%"
          }
        },
        "79298e7ac3c344f29cbab53005e8ccd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da1f990dbdc4274b3e3366cfb3f0539",
            "max": 11356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2371db566fe40d98cc3150c42d3b715",
            "value": 11356
          }
        },
        "6bdc71ffe9ab4af28732c9d7700828f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bee9f7fd960f491d89784e65688748f3",
            "placeholder": "​",
            "style": "IPY_MODEL_b1acfa20f09f4db583b67a25dc9a37db",
            "value": " 11.4k/11.4k [00:00&lt;00:00, 588kB/s]"
          }
        },
        "4f4e8bd64d674b5a9cf541010ae38040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b48c743696f4c61a4f0d138a59e1ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ad10d0812d484bb50c3f2e3fb79a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da1f990dbdc4274b3e3366cfb3f0539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2371db566fe40d98cc3150c42d3b715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bee9f7fd960f491d89784e65688748f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1acfa20f09f4db583b67a25dc9a37db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "932b8216f9804641a3801f3b499a0388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59b28708244f40329b8f00f045716073",
              "IPY_MODEL_2dbe5cfab23e46a8837ecdedc9c1111d",
              "IPY_MODEL_1baad3de9df34ff19fe1270f39310663"
            ],
            "layout": "IPY_MODEL_d5a89fe36a3140dbbf566dc1bdf406da"
          }
        },
        "59b28708244f40329b8f00f045716073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b37527b3874f6f828091cfa4dbac1d",
            "placeholder": "​",
            "style": "IPY_MODEL_5525d0c914694d318269ef6f3f97868f",
            "value": "README.md: 100%"
          }
        },
        "2dbe5cfab23e46a8837ecdedc9c1111d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e037c96116b643339137b176c60741c6",
            "max": 10517,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1be1bea91348422eb465068a41c7dc6d",
            "value": 10517
          }
        },
        "1baad3de9df34ff19fe1270f39310663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f5531fa2994c1eb1346b5405d3a5bf",
            "placeholder": "​",
            "style": "IPY_MODEL_bd7dea4edeec4d2eafb6842f19fa951f",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 654kB/s]"
          }
        },
        "d5a89fe36a3140dbbf566dc1bdf406da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b37527b3874f6f828091cfa4dbac1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5525d0c914694d318269ef6f3f97868f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e037c96116b643339137b176c60741c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be1bea91348422eb465068a41c7dc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f5531fa2994c1eb1346b5405d3a5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7dea4edeec4d2eafb6842f19fa951f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d9b1b5b4790487b894fd6ad0f44fec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da907327dd4e4882a6449f899c1efb5d",
              "IPY_MODEL_53d3cf974e6044c3b15b12552978e7cd",
              "IPY_MODEL_86428fb30c0c4b7dbe0a4783f81e0936"
            ],
            "layout": "IPY_MODEL_f02728bea1db46d68edd9d66fe24021a"
          }
        },
        "da907327dd4e4882a6449f899c1efb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a2012e4563465891bcf00394391459",
            "placeholder": "​",
            "style": "IPY_MODEL_072b7fd7db75449fa0992b145db22ca6",
            "value": "config.json: 100%"
          }
        },
        "53d3cf974e6044c3b15b12552978e7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_155cab89f1904e37902b57f943170e67",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90deb757fcf74182963734791c763675",
            "value": 570
          }
        },
        "86428fb30c0c4b7dbe0a4783f81e0936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_820217eba92d4968bb5ee16ae12abd59",
            "placeholder": "​",
            "style": "IPY_MODEL_5724ef6e30f24dcabfe7cafa8d96c151",
            "value": " 570/570 [00:00&lt;00:00, 17.7kB/s]"
          }
        },
        "f02728bea1db46d68edd9d66fe24021a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a2012e4563465891bcf00394391459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072b7fd7db75449fa0992b145db22ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "155cab89f1904e37902b57f943170e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90deb757fcf74182963734791c763675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "820217eba92d4968bb5ee16ae12abd59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5724ef6e30f24dcabfe7cafa8d96c151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b919792a8b443c7891c5b8b8d22a19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac2e6f76cc7d457f9ae44dfde59e93ce",
              "IPY_MODEL_39488c41c59f4536aec0aa414e94ade0",
              "IPY_MODEL_8bb5358736ba4eefb248f1ceabca9fa3"
            ],
            "layout": "IPY_MODEL_da61caef6eb848b6acf75d6e43409440"
          }
        },
        "ac2e6f76cc7d457f9ae44dfde59e93ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7847a32772974a4196e7cd76e085f01f",
            "placeholder": "​",
            "style": "IPY_MODEL_2eee880577b948e78b30b76e2c91cc81",
            "value": "(…)kage/Data/com.apple.CoreML/model.mlmodel: 100%"
          }
        },
        "39488c41c59f4536aec0aa414e94ade0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80072e6e30214157978153e1e8283602",
            "max": 164911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01ecf5b4bf1847388476394c76dd9576",
            "value": 164911
          }
        },
        "8bb5358736ba4eefb248f1ceabca9fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d99e3a3bda504caeb883452e49c95234",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d2f051e2c64faa9cd3a3031f3f8f45",
            "value": " 165k/165k [00:00&lt;00:00, 3.27MB/s]"
          }
        },
        "da61caef6eb848b6acf75d6e43409440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7847a32772974a4196e7cd76e085f01f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eee880577b948e78b30b76e2c91cc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80072e6e30214157978153e1e8283602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ecf5b4bf1847388476394c76dd9576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d99e3a3bda504caeb883452e49c95234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d2f051e2c64faa9cd3a3031f3f8f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37a1ec500d334adfb6c811bc990f8030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d4983407aa146a6afb5acbc67de2f0a",
              "IPY_MODEL_ab1e63b1fe564b1995093327a1176340",
              "IPY_MODEL_30075978f75e42c998fa4f3e8168aedf"
            ],
            "layout": "IPY_MODEL_4677a22eb52943bdaf7cb59855d688db"
          }
        },
        "5d4983407aa146a6afb5acbc67de2f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729d86ea456a47bfbed8f0e9a31fa1d3",
            "placeholder": "​",
            "style": "IPY_MODEL_a14aee3c566546c7b70451b51bb5b11c",
            "value": "weight.bin: 100%"
          }
        },
        "ab1e63b1fe564b1995093327a1176340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9a9bca920d4c579423aba0a80232c3",
            "max": 531833856,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef81307de4594a32879ce658b863b160",
            "value": 531833856
          }
        },
        "30075978f75e42c998fa4f3e8168aedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be51057730f4f959f91fb6c49304b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_0176649e428f42329ed21bf7ba1b979a",
            "value": " 532M/532M [00:09&lt;00:00, 38.5MB/s]"
          }
        },
        "4677a22eb52943bdaf7cb59855d688db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729d86ea456a47bfbed8f0e9a31fa1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14aee3c566546c7b70451b51bb5b11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb9a9bca920d4c579423aba0a80232c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef81307de4594a32879ce658b863b160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4be51057730f4f959f91fb6c49304b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0176649e428f42329ed21bf7ba1b979a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07eff2e86876403ebbd454695d9d37ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e5e73f7d69d47dda8ac56dbe5f3543a",
              "IPY_MODEL_e29d1234c49f4dd4bd4a5dc3f9b117c9",
              "IPY_MODEL_fe62231902b64597b0907ae8305e7b62"
            ],
            "layout": "IPY_MODEL_87b9a37c4a9d4537b81afd100e05004e"
          }
        },
        "4e5e73f7d69d47dda8ac56dbe5f3543a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1745db7cdaac4b9dad78a036c49e9f5e",
            "placeholder": "​",
            "style": "IPY_MODEL_87e60351e5b040df9ce68fcdde28f72a",
            "value": "(…)sk/float32_model.mlpackage/Manifest.json: 100%"
          }
        },
        "e29d1234c49f4dd4bd4a5dc3f9b117c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d048b4d3d948edb70d08238b1ab6c4",
            "max": 617,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2976ca4f5f943fbbfa7a8d3e0ae2666",
            "value": 617
          }
        },
        "fe62231902b64597b0907ae8305e7b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e792330b1c4380a7fe83b8130cdb0a",
            "placeholder": "​",
            "style": "IPY_MODEL_46ab7eea93764b8db33c43e3048cf75c",
            "value": " 617/617 [00:00&lt;00:00, 24.9kB/s]"
          }
        },
        "87b9a37c4a9d4537b81afd100e05004e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1745db7cdaac4b9dad78a036c49e9f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e60351e5b040df9ce68fcdde28f72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68d048b4d3d948edb70d08238b1ab6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2976ca4f5f943fbbfa7a8d3e0ae2666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8e792330b1c4380a7fe83b8130cdb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ab7eea93764b8db33c43e3048cf75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e3d58929eed497d8b0015fa598745f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ed1e72ac97b488d8ea0e9f653d62861",
              "IPY_MODEL_1e3c24c9cd904fbcb171b47c69759150",
              "IPY_MODEL_1848e6ff3e62409a9570a4b2403873e6"
            ],
            "layout": "IPY_MODEL_2cfd71cc139d4158a84fab35ac47cda8"
          }
        },
        "8ed1e72ac97b488d8ea0e9f653d62861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4266b5828e4f318da8a66b3378d90d",
            "placeholder": "​",
            "style": "IPY_MODEL_25d5e704e727427ea6aa80df63a851a3",
            "value": "model.onnx: 100%"
          }
        },
        "1e3c24c9cd904fbcb171b47c69759150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e67159b0054994ac27d91797267262",
            "max": 532091246,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e59b65fff0d487cbbe9a3b74cc1bf08",
            "value": 532091246
          }
        },
        "1848e6ff3e62409a9570a4b2403873e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a1afd024c74e77bfac4753c6432055",
            "placeholder": "​",
            "style": "IPY_MODEL_2dd6978fd55c4f57831d2f6ffd4d7a9c",
            "value": " 532M/532M [00:10&lt;00:00, 38.4MB/s]"
          }
        },
        "2cfd71cc139d4158a84fab35ac47cda8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e4266b5828e4f318da8a66b3378d90d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d5e704e727427ea6aa80df63a851a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2e67159b0054994ac27d91797267262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e59b65fff0d487cbbe9a3b74cc1bf08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61a1afd024c74e77bfac4753c6432055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd6978fd55c4f57831d2f6ffd4d7a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ea07d545bee4217a324da0106c1c639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8bb82b7e49d43cf9b33d8e7fc2f21e5",
              "IPY_MODEL_7492d3fdc2c644c49338e53c896332d1",
              "IPY_MODEL_b0069b11a84b48a490dd5fa0f7ffae05"
            ],
            "layout": "IPY_MODEL_c7e755cb1c2942e99e52a18f7fe9f0e3"
          }
        },
        "d8bb82b7e49d43cf9b33d8e7fc2f21e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b47149eb10a41e9b08b828b2fb8808e",
            "placeholder": "​",
            "style": "IPY_MODEL_afe79dc613664db6b5bec7ed6f8f8fe1",
            "value": "model.safetensors: 100%"
          }
        },
        "7492d3fdc2c644c49338e53c896332d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758f680037c84a4f85991d285642afc9",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9922b72ccdf404a9731b567041479e6",
            "value": 440449768
          }
        },
        "b0069b11a84b48a490dd5fa0f7ffae05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd1a9ee935844d0b8c293f9fac775c0",
            "placeholder": "​",
            "style": "IPY_MODEL_9e045313d48147eaafbb8078292e9879",
            "value": " 440M/440M [00:02&lt;00:00, 193MB/s]"
          }
        },
        "c7e755cb1c2942e99e52a18f7fe9f0e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b47149eb10a41e9b08b828b2fb8808e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe79dc613664db6b5bec7ed6f8f8fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "758f680037c84a4f85991d285642afc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9922b72ccdf404a9731b567041479e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebd1a9ee935844d0b8c293f9fac775c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e045313d48147eaafbb8078292e9879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d036de511ec419ea2065e428da3cccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_614356073dc643a2af0141d79089e3bd",
              "IPY_MODEL_f75aeeae9c794374bf589d6cf13fd9e1",
              "IPY_MODEL_90d459428eed4326b7eba1afa1822684"
            ],
            "layout": "IPY_MODEL_957fd9bdd2404c7682cb000a1957bed2"
          }
        },
        "614356073dc643a2af0141d79089e3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ec06115959466f877a86a5826c8dd7",
            "placeholder": "​",
            "style": "IPY_MODEL_30b2f1f428a14d3bbd214e1b4d56232e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f75aeeae9c794374bf589d6cf13fd9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d0fcc812bd45ad82c44e9f5be72df4",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4751022230ed4f76b0c6c95ba6e52c48",
            "value": 440473133
          }
        },
        "90d459428eed4326b7eba1afa1822684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbb97ce96a442b48036fc8d05254c07",
            "placeholder": "​",
            "style": "IPY_MODEL_064a85c6eb99492590774d98a061c4fe",
            "value": " 440M/440M [00:04&lt;00:00, 135MB/s]"
          }
        },
        "957fd9bdd2404c7682cb000a1957bed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ec06115959466f877a86a5826c8dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b2f1f428a14d3bbd214e1b4d56232e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d0fcc812bd45ad82c44e9f5be72df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4751022230ed4f76b0c6c95ba6e52c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcbb97ce96a442b48036fc8d05254c07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064a85c6eb99492590774d98a061c4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f4a65b97cc346469356e6649be0ff89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2027f7c3f6314e0c94884f4ed4ecbcb4",
              "IPY_MODEL_de30b7bcb8e54298b63b68e2ef162138",
              "IPY_MODEL_f0e66c98927e4680a002eb64a8d0d8f3"
            ],
            "layout": "IPY_MODEL_beff2aaa198a484b83ccf1ec74a797ec"
          }
        },
        "2027f7c3f6314e0c94884f4ed4ecbcb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7975f71d5e4abb9daeacc0e89de384",
            "placeholder": "​",
            "style": "IPY_MODEL_33da93679d4f4d8192c359e21a21b681",
            "value": "tokenizer.json: 100%"
          }
        },
        "de30b7bcb8e54298b63b68e2ef162138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d657d333d46f43be8a3b105199d42ec6",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77dd3359f4e947e99e38e985b79426dc",
            "value": 466062
          }
        },
        "f0e66c98927e4680a002eb64a8d0d8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142587252f6d44829c8b64985358dcf7",
            "placeholder": "​",
            "style": "IPY_MODEL_ee4db58056e845bd8e6006ecea3a2a51",
            "value": " 466k/466k [00:00&lt;00:00, 14.1MB/s]"
          }
        },
        "beff2aaa198a484b83ccf1ec74a797ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7975f71d5e4abb9daeacc0e89de384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33da93679d4f4d8192c359e21a21b681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d657d333d46f43be8a3b105199d42ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77dd3359f4e947e99e38e985b79426dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "142587252f6d44829c8b64985358dcf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4db58056e845bd8e6006ecea3a2a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30eae81f318f4ab49a940e116951be3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fb65c9eb97c403696dd53084a3fe7db",
              "IPY_MODEL_9b0b2fcc69904541b86f2046fc64e18c",
              "IPY_MODEL_99dbfb1e3d4641cb9d5f7c43594a4fc2"
            ],
            "layout": "IPY_MODEL_5018f5f464714fdd9a64c976285dc82c"
          }
        },
        "0fb65c9eb97c403696dd53084a3fe7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48dc3b67caf3457693d28c1b23237c70",
            "placeholder": "​",
            "style": "IPY_MODEL_eddc8742a5824d0abac0f5961f8c0031",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9b0b2fcc69904541b86f2046fc64e18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e445cbb56e34b1f805066079e099b7b",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33b7524e2a424038959bb668f77b4b77",
            "value": 28
          }
        },
        "99dbfb1e3d4641cb9d5f7c43594a4fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a14aee1a26c45e5a7eec5c5e0f24839",
            "placeholder": "​",
            "style": "IPY_MODEL_848bf8779dec437ba6e6e3a7d5d6f8a5",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.65kB/s]"
          }
        },
        "5018f5f464714fdd9a64c976285dc82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48dc3b67caf3457693d28c1b23237c70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eddc8742a5824d0abac0f5961f8c0031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e445cbb56e34b1f805066079e099b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b7524e2a424038959bb668f77b4b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a14aee1a26c45e5a7eec5c5e0f24839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848bf8779dec437ba6e6e3a7d5d6f8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0efe12604df04b04bc019604fe2866dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_615fbd2dd2434590be38ab082fddb696",
              "IPY_MODEL_3d447735e1d447b49a88bbfc63288f59",
              "IPY_MODEL_6c8b49ea662d425780d3f414d7bca675"
            ],
            "layout": "IPY_MODEL_10522865624641d291ac68c056f0130d"
          }
        },
        "615fbd2dd2434590be38ab082fddb696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b38286de97a34c94ad5fd33215d2899c",
            "placeholder": "​",
            "style": "IPY_MODEL_51229f16589d4544b69a15f4ccad4b8d",
            "value": "vocab.txt: 100%"
          }
        },
        "3d447735e1d447b49a88bbfc63288f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbc9e127fc21437085e20b14c9119dd2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ef75f246c2e4b52bc0d379dccf2be42",
            "value": 231508
          }
        },
        "6c8b49ea662d425780d3f414d7bca675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d665ff349cf549669691b3170b4826cc",
            "placeholder": "​",
            "style": "IPY_MODEL_7e7639bd2d414beb91eeaaebbffdc978",
            "value": " 232k/232k [00:00&lt;00:00, 15.5MB/s]"
          }
        },
        "10522865624641d291ac68c056f0130d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38286de97a34c94ad5fd33215d2899c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51229f16589d4544b69a15f4ccad4b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbc9e127fc21437085e20b14c9119dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef75f246c2e4b52bc0d379dccf2be42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d665ff349cf549669691b3170b4826cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7639bd2d414beb91eeaaebbffdc978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkp74/RAG_Chatbot/blob/main/Chatbots_Trials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Downloading Wikipedia Texts"
      ],
      "metadata": {
        "id": "z-PFwIbNLWO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading 15 sub-related wikipedia pages"
      ],
      "metadata": {
        "id": "lECs_KNkuRJx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCOAQQ70LSrs",
        "outputId": "8be6b6f2-5da7-4e61-d8b2-62c4cd6a4815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia"
      ],
      "metadata": {
        "id": "6DnI8DKvLdPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_wikipedia_page(page_title):\n",
        "    wikipedia.set_lang(\"en\")\n",
        "    wikipedia.set_user_agent(\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\")\n",
        "\n",
        "    try:\n",
        "        page = wikipedia.page(page_title)\n",
        "        return page.content  # Retrieve only the first 200 characters\n",
        "    except wikipedia.exceptions.PageError:\n",
        "        return f\"Page '{page_title}' does not exist on Wikipedia.\"\n",
        "    except wikipedia.exceptions.DisambiguationError:\n",
        "        return f\"Page '{page_title}' is a disambiguation page.\""
      ],
      "metadata": {
        "id": "gFuXM5_YLqMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_titles = [\n",
        "    'Computer Science',\n",
        "    'Artificial Intelligence',\n",
        "    'Deep learning',\n",
        "    'Data Science',\n",
        "    'Algorithms',\n",
        "    'Programming Languages',\n",
        "    'Operating Systems',\n",
        "    'Computer Vision',\n",
        "    'Cryptography',\n",
        "    'Human-Computer Interaction',\n",
        "    'Software Engineering',\n",
        "    'Internet of Things',\n",
        "    'Computer Networks',\n",
        "    'Databases',\n",
        "    'Cybersecurity'\n",
        "]"
      ],
      "metadata": {
        "id": "pgI5RAHMLsiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sentences = []"
      ],
      "metadata": {
        "id": "S0RxN4VQ1kso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download text for each page title\n",
        "for title in page_titles:\n",
        "    text = download_wikipedia_page(title)\n",
        "    Sentences.append(text)\n",
        "    print(f\"Page Title: {title}\\nText: {text}...\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtVPtzwNMSWe",
        "outputId": "c4cf6ea7-f77b-4fe3-bac5-c96d4ece460a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page Title: Computer Science\n",
            "Text: Computer science is the study of computation, information, and automation. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). Though more often considered an academic discipline, computer science is closely related to computer programming.Algorithms and data structures are central to computer science.\n",
            "The theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.\n",
            "The fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\". \"A crucial step was the adoption of a punched card system derived from the Jacquard loom\" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1914, the Spanish engineer Leonardo Torres Quevedo published his Essays on Automatics, and designed, inspired by Babbage, a theoretical electromechanical calculating machine which was to be controlled by a read-only program. The paper also introduced the idea of floating-point arithmetic. In 1920, to celebrate the 100th anniversary of the invention of the arithmometer, Torres presented in Paris the  Electromechanical Arithmometer, a prototype that demonstrated the feasibility of an electromechanical analytical engine, on which commands could be typed and the results printed automatically. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as \"Babbage's dream come true\".\n",
            "During the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and Columbia University was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.\n",
            "\n",
            "\n",
            "== Etymology ==\n",
            "\n",
            "Although first proposed in 1956, the term \"computer science\" appears in a 1959 article in Communications of the ACM,\n",
            "in which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921. Louis justifies the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.\n",
            "His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.\n",
            "In the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. Three months later in the same journal, comptologist was suggested, followed next year by hypologist. The term computics has also been suggested. In Europe, terms derived from contracted translations of the expression \"automatic information\" (e.g. \"informazione automatica\" in Italian) or \"information and mathematics\" are often used, e.g. informatique (French), Informatik (German), informatica (Italian, Dutch), informática (Spanish, Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki (πληροφορική, which means informatics) in Greek. Similar words have also been adopted in the UK (as in the School of Informatics, University of Edinburgh). \"In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain.\"A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\" The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been exchange of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, Earth science, statistics, philosophy, and logic.\n",
            "Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.The relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term \"software engineering\" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.\n",
            "\n",
            "\n",
            "== Philosophy ==\n",
            "\n",
            "\n",
            "=== Epistemology of computer science ===\n",
            "Despite the word \"science\" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. Allen Newell and Herbert A. Simon argued in 1975, Computer science is an empirical discipline. We would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. Nonetheless, they are experiments. Each new machine that is built is an experiment. Actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. It has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. Proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. They also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.Proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.\n",
            "\n",
            "\n",
            "=== Paradigms of computer science ===\n",
            "A number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning's working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the \"rationalist paradigm\" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the \"technocratic paradigm\" (which might be found in engineering approaches, most prominently in software engineering), and the \"scientific paradigm\" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).\n",
            "Computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.\n",
            "\n",
            "\n",
            "== Fields ==\n",
            "\n",
            "As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.\n",
            "Computer science is no more about computers than astronomy is about telescopes.\n",
            "\n",
            "\n",
            "=== Theoretical computer science ===\n",
            "\n",
            "Theoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.\n",
            "\n",
            "\n",
            "==== Theory of computation ====\n",
            "\n",
            "According to Peter Denning, the fundamental question underlying computer science is, \"What can be automated?\" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.\n",
            "The famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.\n",
            "\n",
            "\n",
            "==== Information and coding theory ====\n",
            "\n",
            "Information theory, closely related to probability and statistics, is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.\n",
            "Coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.\n",
            "\n",
            "\n",
            "==== Data structures and algorithms ====\n",
            "Data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.\n",
            "\n",
            "\n",
            "==== Programming language theory and formal methods ====\n",
            "\n",
            "Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.\n",
            "Formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.\n",
            "\n",
            "\n",
            "=== Applied computer science ===\n",
            "\n",
            "\n",
            "==== Computer graphics and visualization ====\n",
            "\n",
            "Computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.\n",
            "\n",
            "\n",
            "==== Image and sound processing ====\n",
            "\n",
            "Information can take the form of images, sound, video or other multimedia. Bits of information can be streamed via signals. Its processing is the central notion of informatics, the European view on computing, which studies information processing algorithms independently of the type of information carrier – whether it is electrical, mechanical or biological. This field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. What is the lower bound on the complexity of fast Fourier transform algorithms? is one of unsolved problems in theoretical computer science.\n",
            "\n",
            "\n",
            "==== Computational science, finance and engineering ====\n",
            "\n",
            "Scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. A major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE, as well as software for physical realization of new (or modified) designs. The latter includes essential design software for integrated circuits.\n",
            "\n",
            "\n",
            "==== Social computing and human–computer interaction ====\n",
            "\n",
            "Social computing is an area that is concerned with the intersection of social behavior and computational systems. Human–computer interaction research develops theories, principles, and guidelines for user interface designers.\n",
            "\n",
            "\n",
            "==== Software engineering ====\n",
            "\n",
            "Software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it does not just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For example software testing, systems engineering, technical debt and software development processes.\n",
            "\n",
            "\n",
            "==== Artificial intelligence ====\n",
            "\n",
            "Artificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting point in the late 1940s was Alan Turing's question \"Can computers think?\", and the question remains effectively unanswered, although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.\n",
            "\n",
            "\n",
            "=== Computer systems ===\n",
            "\n",
            "\n",
            "==== Computer architecture and organization ====\n",
            "\n",
            "Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. Computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. The term \"architecture\" in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959.\n",
            "\n",
            "\n",
            "==== Concurrent, parallel and distributed computing ====\n",
            "\n",
            "Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.\n",
            "\n",
            "\n",
            "==== Computer networks ====\n",
            "\n",
            "This branch of computer science aims to manage networks between computers worldwide.\n",
            "\n",
            "\n",
            "==== Computer security and cryptography ====\n",
            "\n",
            "Computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.\n",
            "Historical cryptography is the art of writing and deciphering secret messages. Modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. Technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.\n",
            "\n",
            "\n",
            "==== Databases and data mining ====\n",
            "\n",
            "A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. Data mining is a process of discovering patterns in large data sets.\n",
            "\n",
            "\n",
            "== Discoveries ==\n",
            "The philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:\n",
            "Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's, and Samuel Morse's insight: there are only two objects that a computer has to deal with in order to represent \"anything\".All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as \"on/off\", \"magnetized/de-magnetized\", \"high-voltage/low-voltage\", etc.).\n",
            "Alan Turing's insight: there are only five actions that a computer has to perform in order to do \"anything\".Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;\n",
            "move right one location;\n",
            "read symbol at current location;\n",
            "print 0 at current location;\n",
            "print 1 at current location.\n",
            "Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do \"anything\".Only three rules are needed to combine any set of basic instructions into more complex ones:\n",
            "sequence: first do this, then do that;\n",
            " selection: IF such-and-such is the case, THEN do this, ELSE do that;\n",
            "repetition: WHILE such-and-such is the case, DO this.\n",
            "The three rules of Boehm's and Jacopini's insight can be further simplified with the use of goto (which means it is more elementary than structured programming).\n",
            "\n",
            "\n",
            "== Programming paradigms ==\n",
            "\n",
            "Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:\n",
            "\n",
            "Functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.\n",
            "Imperative programming, a programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.\n",
            "Object-oriented programming, a programming paradigm based on the concept of \"objects\", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.\n",
            "Service-oriented programming, a programming paradigm that uses \"services\" as the unit of computer work, to design and implement integrated business applications and mission critical software programsMany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.\n",
            "\n",
            "\n",
            "== Research ==\n",
            "\n",
            "Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.\n",
            "\n",
            "\n",
            "== Education ==\n",
            "\n",
            "Computer Science, known by its near synonyms, Computing, Computer Studies, has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science. According to a 2021 report, only 51% of high schools in the US offer computer science.Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== Notes ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "DBLP Computer Science Bibliography\n",
            "Association for Computing Machinery\n",
            "Institute of Electrical and Electronics Engineers...\n",
            "\n",
            "\n",
            "Page Title: Artificial Intelligence\n",
            "Text: Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science which develops and studies intelligent machines. Such machines may be called AIs.\n",
            "AI technology is widely used throughout industry, government, and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Google Assistant, Siri, and Alexa), self-driving cars (e.g., Waymo), generative and creative tools (ChatGPT and AI art), and superhuman play and analysis in strategy games (such as chess and Go).Alan Turing was the first person to carry out substantial research in the field that he called Machine Intelligence. Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture.The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to complete any task performable by a human) is among the field's long-term goals.\n",
            "To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.\n",
            "\n",
            "\n",
            "== Goals ==\n",
            "The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n",
            "\n",
            "\n",
            "=== Reasoning, problem-solving ===\n",
            "Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.\n",
            "Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\n",
            "Accurate and efficient reasoning is an unsolved problem.\n",
            "\n",
            "\n",
            "=== Knowledge representation ===\n",
            "Knowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as:\n",
            "objects, properties, categories and relations between objects;\n",
            "\n",
            "situations, events, states and time;\n",
            "causes and effects;\n",
            "knowledge about knowledge (what we know about what other people know);default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\n",
            "Among the most difficult problems in KR are: the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).Knowledge acquisition is the difficult problem of obtaining knowledge for AI applications. Modern AI gathers knowledge by \"scraping\" the internet (including Wikipedia). The knowledge itself was collected by the volunteers and professionals who published the information (who may or may not have agreed to provide their work to AI companies). This \"crowd sourced\" technique does not guarantee that the knowledge is correct or reliable. The knowledge of Large Language Models (such as ChatGPT) is highly unreliable—it generates misinformation and falsehoods (known as \"hallucinations\"). Providing accurate knowledge for these modern AI applications is an unsolved problem.\n",
            "\n",
            "\n",
            "=== Planning and decision making ===\n",
            "An \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.\n",
            "In automated planning, the agent has a specific goal. In automated decision making, the agent has preferences – there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.In classical planning, the agent knows exactly what the effect of any action will be.\n",
            "In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\n",
            "In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences.Information value theory can be used to weigh the value of exploratory or experimental actions.\n",
            "The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\n",
            "A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g. by iteration), be heuristic, or it can be learned.Game theory describes rational behavior of multiple interacting agents, and is used in AI programs that make decisions that involve other agents.\n",
            "\n",
            "\n",
            "=== Learning ===\n",
            "Machine learning is the study of programs that can improve their performance on a given task automatically.\n",
            "It has been a part of AI from the beginning.There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.Supervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\n",
            "In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n",
            "\n",
            "\n",
            "=== Natural language processing ===\n",
            "Natural language processing (NLP) allows programs to read, write and communicate in human languages such as English.\n",
            "Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation\n",
            "unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning, and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\n",
            "Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023 these models were able to get human-level scores on the bar exam, SAT, GRE, and many other real-world applications.\n",
            "\n",
            "\n",
            "=== Perception ===\n",
            "Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\n",
            "The field includes speech recognition,image classification,facial recognition, object recognition,\n",
            "and robotic perception.\n",
            "\n",
            "\n",
            "=== Social intelligence ===\n",
            "Affective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood.\n",
            "For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\n",
            "However, this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.\n",
            "\n",
            "\n",
            "=== General intelligence ===\n",
            "A machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\n",
            "\n",
            "\n",
            "== Tools ==\n",
            "AI research uses a wide variety of tools to accomplish the goals above.\n",
            "\n",
            "\n",
            "=== Search and optimization ===\n",
            "AI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\n",
            "\n",
            "\n",
            "==== State space search ====\n",
            "State space search searches through a tree of possible states to try to find a goal state.\n",
            "For example, Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.Simple exhaustive searches\n",
            "are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.\n",
            "\"Heuristics\" or \"rules of thumb\" can help to prioritize choices that are more likely to reach a goal.Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.\n",
            "\n",
            "\n",
            "==== Local search ====\n",
            "Local search uses mathematical optimization to find a numeric solution to a problem. It begins with some form of a guess and then refines the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. This process is called stochastic gradient descent.Evolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses).Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).Neural networks and statistical classifiers (discussed below), also use a form of local search, where the \"landscape\" to be searched is formed by learning.\n",
            "\n",
            "\n",
            "=== Logic ===\n",
            "Formal Logic is used for reasoning and knowledge representation.\n",
            "Formal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")\n",
            "and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").Logical inference (or deduction) is the process of proving a new statement (conclusion) from other statements that are already known to be true (the premises).\n",
            "A logical knowledge base also handles queries and assertions as a special case of inference.\n",
            "An inference rule describes what is a valid step in a proof. The most general inference rule is resolution.\n",
            "Inference can be reduced to performing a search to find a path that leads from premises to conclusions, where each step is the application of an inference rule.\n",
            "Inference performed this way is intractable except for short proofs in restricted domains. No efficient, powerful and general method has been discovered.Fuzzy logic assigns a \"degree of truth\" between 0 and 1 and handles uncertainty and probabilistic situations.Non-monotonic logics are designed to handle default reasoning.\n",
            "Other specialized versions of logic have been developed to describe many complex domains (see knowledge representation above).\n",
            "\n",
            "\n",
            "=== Probabilistic methods for uncertain reasoning ===\n",
            "Many problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.Bayesian networks\n",
            "are a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks)\n",
            "and perception (using dynamic Bayesian networks).Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,\n",
            "and information value theory.\n",
            "These tools include models such as Markov decision processes,\n",
            "dynamic decision networks, game theory and mechanism design.\n",
            "\n",
            "\n",
            "=== Classifiers and statistical learning methods ===\n",
            "The simplest AI applications can be divided into two types: classifiers (e.g. \"if shiny then diamond\"), on one hand, and controllers (e.g. \"if diamond then pick up\"), on the other hand. Classifiers\n",
            "are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.There are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\n",
            "The naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.Neural networks are also used as classifiers.\n",
            "\n",
            "\n",
            "=== Artificial neural networks ===\n",
            "Artificial neural networks were inspired by the design of the human brain: a simple \"neuron\" N accepts input from other neurons, each of which, when activated (or \"fired\"), casts a weighted \"vote\" for or against whether neuron N should itself activate. In practice, the input \"neurons\" are a list of numbers, the \"weights\" are a matrix, the next layer is the dot product (i.e., several weighted sums) scaled by an increasing function, such as the logistic function. \"The resemblance to real neural cells and structures is superficial\", according to Russell and Norvig.Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.\n",
            "Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.In feedforward neural networks the signal passes in only one direction.Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.Perceptrons\n",
            "use only a single layer of neurons, deep learning uses multiple layers.\n",
            "Convolutional neural networks strengthen the connection between neurons that are \"close\" to each other – this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.\n",
            "\n",
            "\n",
            "=== Deep learning ===\n",
            "Deep learning\n",
            "uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classification\n",
            "and others. The reason that deep learning performs so well in so many applications is not known as of 2023.\n",
            "The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)\n",
            "but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.\n",
            "\n",
            "\n",
            "=== Specialized hardware and software ===\n",
            "\n",
            "In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.\n",
            "Historically, specialized languages, such as Lisp, Prolog, Python and others, had been used.\n",
            "\n",
            "\n",
            "== Applications ==\n",
            "AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok).\n",
            "\n",
            "\n",
            "=== Health and Medicine ===\n",
            "\n",
            "The application of AI in medicine and medical research has the potential to increase patient care and quality of life.  Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\n",
            "For medical research, AI is an important tool for processing and integrating Big Data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. \n",
            "It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research, such as cardiovascular research which typically receives a disproportionately less funding that areas such as cancer research, relative to the morbidity and mortality of these diseases. New AI tools can deepen our understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.\n",
            "\n",
            "\n",
            "=== Games ===\n",
            "\n",
            "Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then it defeated Ke Jie in 2017, who at the time continuously held the world No. 1 ranking for two years. Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus and Cepheus. DeepMind in the 2010s developed a \"generalized artificial intelligence\" that could learn many diverse Atari games on its own.\n",
            "\n",
            "\n",
            "=== Military ===\n",
            "\n",
            "Various countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams. AI was incorporated into military operations in Iraq and Syria.\n",
            "\n",
            "\n",
            "=== Generative AI ===\n",
            "\n",
            "In the early 2020s, generative AI gained widespread prominence. ChatGPT, based on GPT-3, and other large language models, were tried by 14% of Americans adults. The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion sparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat, the fictional arrest of Donald Trump, and a hoax of an attack on the Pentagon, as well as the usage in professional creative arts.\n",
            "\n",
            "\n",
            "=== Industry Specific Tasks ===\n",
            "There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported they had incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\n",
            "In agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\n",
            "Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\n",
            "\n",
            "\n",
            "== Ethics ==\n",
            "AI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified.Anyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning.\n",
            "\n",
            "\n",
            "=== Risks and harm ===\n",
            "\n",
            "\n",
            "==== Privacy and copyright ====\n",
            "\n",
            "Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\n",
            "Technology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.\n",
            "For example, in order to build speech recognition algorithms, Amazon have recorded millions of private conversations and allowed temps to listen to and transcribe some of them.\n",
            "Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.AI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.\n",
            "Since 2016, some privacy experts, such as Cynthia Dwork, began to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\".Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under a rationale of \"fair use\". Experts disagree about how well, and under what circumstances, this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.\n",
            "\n",
            "\n",
            "==== Misinformation ====\n",
            "\n",
            "YouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\n",
            "In 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing.  It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\n",
            "\n",
            "\n",
            "==== Algorithmic bias and fairness ====\n",
            "\n",
            "Machine learning applications will be biased if they learn from biased data.\n",
            "The developers may not be aware that the bias exists.\n",
            "Bias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.Fairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \"fairness\" in a way that satisfies all stakeholders.On June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\n",
            "In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".\n",
            "Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"Criticism of COMPAS highlighted a deeper problem with the misuse of AI. Machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. Unfortunately, if an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022) the Association for Computing Machinery, in Seoul, South Korea, presented and published findings recommending that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.\n",
            "\n",
            "\n",
            "==== Lack of transparency ====\n",
            "\n",
            "Many AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.People who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are required to clearly and completely explain the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.DARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try and solve these problems.There are several potential solutions to the transparency problem. SHAP helps visualise the contribution of each feature to the output. LIME can locally approximate a model with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.\n",
            "\n",
            "\n",
            "==== Bad actors and weaponized AI ====\n",
            "\n",
            "A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. By 2015, over fifty countries were reported to be researching battlefield robots. These weapons are considered especially dangerous for several reasons: if they kill an innocent person it is not clear who should be held accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.AI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian centralized decision making more competitive with liberal and decentralized systems such as markets.AI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.Terrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons.\n",
            "Machine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.\n",
            "\n",
            "\n",
            "==== Technological unemployment ====\n",
            "\n",
            "From the early days of the development of artificial intelligence there have been arguments, for example those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.In April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.\n",
            "\n",
            "\n",
            "==== Existential risk ====\n",
            "\n",
            "It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\n",
            "First, AI does not require human-like \"sentience\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk have expressed concern about existential risk from AI.\n",
            "In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.\n",
            "However, after 2016, the study of current and future risks and possible solutions became a serious area of research.\n",
            "AI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI. In 2023, many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".\n",
            "\n",
            "\n",
            "=== Ethical machines and alignment ===\n",
            "\n",
            "Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\n",
            "The field of machine ethics is also called computational morality,\n",
            "and was founded at an AAAI symposium in 2005.Other approaches include Wendell Wallach's \"artificial moral agents\"\n",
            "and Stuart J. Russell's three principles for developing provably beneficial machines.\n",
            "\n",
            "\n",
            "=== Frameworks ===\n",
            "Artificial Intelligence projects can have their ethical permissibility tested while designing, developing, and implementing an AI system. An AI framework such as the SUM framework developed by the Alan Turing Institute tests projects in four main areas:\n",
            "RESPECT the dignity of individual people\n",
            "CONNECT with other people sincerely, openly and inclusively\n",
            "CARE for the wellbeing of everyone\n",
            "PROTECT social values, justice and the public interestOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others; however, these principles do not go without their criticisms, especially regards to the people chosen contributes to these frameworks.Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\n",
            "\n",
            "\n",
            "=== Regulation ===\n",
            "\n",
            "The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.\n",
            "The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.\n",
            "Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.\n",
            "Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, US and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.\n",
            "The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.\n",
            "In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics.In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.\n",
            "In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".In November 2023, a global AI safety summit was held in Bletchley Park to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis. This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \"electronic brain\".Alan Turing was thinking about machine intelligence at least as early as 1941, when he circulated a paper on machine intelligence which could be the earliest paper in the field of AI - though it is now lost. The first available paper generally recognized as \"AI\" was McCullouch and Pitts design for Turing-complete \"artificial neurons\" in 1943 - the first mathematical model of a neural network. The paper was influenced by Turing's earlier paper 'On Computable Numbers' from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function.The term 'Machine Intelligence' was used by Alan Turing during his life which was later often referred to as 'Artificial Intelligence' after his death in 1954. In 1950 Turing published the best known of his papers 'Computing Machinery and Intelligence', the paper introduced his concept of what is now known as the Turing test to the general public. Then followed three radio broadcasts on AI by Turing, the lectures: 'Intelligent Machinery, A Heretical Theory’, ‘Can Digital Computers Think’? and the panel discussion ‘Can Automatic Calculating Machines be Said to Think’. By 1956 computer intelligence had been actively pursued for more than a decade in Britain; the earliest AI programmes were written there in 1951–52.In 1951, using a Ferranti Mark 1 computer of the University of Manchester, checkers and chess programs were wrote where you could play against the computer. The field of American AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial Intelligence laboratories were set up at a number of British and US Universities in the latter 1950s and early 1960s.They had, however, underestimated the difficulty of the problem. Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.Many researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches. Robotics researchers, such as Rodney Brooks, rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).\n",
            "By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".Several academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\n",
            "For many specific tasks, other methods were abandoned.\n",
            "Deep learning's success was based on both hardware improvements (faster computers, graphics processing units, cloud computing)\n",
            "and access to large amounts of data (including curated datasets, such as ImageNet).\n",
            "Deep learning's success led to an enormous increase in interest and funding in AI.\n",
            "The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019,\n",
            "and WIPO reported that AI was the most prolific emerging technology in terms of the number of patent applications and granted patents.\n",
            "According to 'AI Impacts', about $50 billion annually was invested in \"AI\" around 2022 in the US alone and about 20% of new US Computer Science PhD graduates have specialized in \"AI\";\n",
            "about 800,000 \"AI\"-related US job openings existed in 2022. The large majority of the advances have occurred within the United States, with its companies, universities, and research labs leading artificial intelligence research.In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\n",
            "\n",
            "\n",
            "== Philosophy ==\n",
            "\n",
            "\n",
            "=== Defining artificial intelligence ===\n",
            "\n",
            "Alan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\"\n",
            "He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".\n",
            "He devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks\"Russell and Norvig agree with Turing that AI must be defined in terms of \"acting\" and not \"thinking\". However, they are critical that the test compares machines to people. \"Aeronautical engineering texts,\" they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world.\" Another AI founder, Marvin Minsky similarly defines it as \"the ability to solve hard problems\". These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible.\n",
            "Another definition has been adopted by Google, a major practitioner in the field of AI.\n",
            "This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\n",
            "\n",
            "\n",
            "=== Evaluating approaches to AI ===\n",
            "No established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\n",
            "\n",
            "\n",
            "==== Symbolic AI and its limits ====\n",
            "Symbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.\n",
            "Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.\n",
            "Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree.The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\n",
            "\n",
            "\n",
            "==== Neat vs. scruffy ====\n",
            "\n",
            "\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 70s and 80s,\n",
            "but eventually was seen as irrelevant. Modern AI has elements of both.\n",
            "\n",
            "\n",
            "==== Soft vs. hard computing ====\n",
            "\n",
            "Finding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 80s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\n",
            "\n",
            "\n",
            "==== Narrow vs. general AI ====\n",
            "\n",
            "AI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.\n",
            "General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\n",
            "\n",
            "\n",
            "=== Machine consciousness, sentience and mind ===\n",
            "\n",
            "The philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\n",
            "\n",
            "\n",
            "==== Consciousness ====\n",
            "\n",
            "David Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\n",
            "\n",
            "\n",
            "==== Computationalism and functionalism ====\n",
            "\n",
            "Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.Philosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"\n",
            "Searle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.\n",
            "\n",
            "\n",
            "==== Robot rights ====\n",
            "\n",
            "If a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.\n",
            "Any hypothetical robot rights would lie on a spectrum with animal rights and human rights.\n",
            "This issue has been considered in fiction for centuries,\n",
            "and is now being considered by, for example, California's Institute for the Future; however, critics argue that the discussion is premature.\n",
            "\n",
            "\n",
            "== Future ==\n",
            "\n",
            "\n",
            "=== Superintelligence and the singularity ===\n",
            "A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".However, technologies can't improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\n",
            "\n",
            "\n",
            "=== Transhumanism ===\n",
            "Robot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.Edward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.\n",
            "\n",
            "\n",
            "== In fiction ==\n",
            "\n",
            "Thought-capable artificial beings have appeared as storytelling devices since antiquity,\n",
            "and have been a persistent theme in science fiction.A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics;\n",
            "while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\n",
            "\n",
            "\n",
            "== See also ==\n",
            "AI effect\n",
            "Artificial intelligence detection software – Software to detect AI-generated contentPages displaying short descriptions of redirect targets\n",
            "Artificial intelligence in healthcare – Overview of the use of artificial intelligence in healthcare\n",
            "Behavior selection algorithm – Algorithm that selects actions for intelligent agents\n",
            "Business process automation – Technology-enabled automation of complex business processes\n",
            "Case-based reasoning – Process of solving new problems based on the solutions of similar past problems\n",
            "Emergent algorithm – Algorithm exhibiting emergent behavior\n",
            "Female gendering of AI technologies\n",
            "Glossary of artificial intelligence – List of definitions of terms and concepts commonly used in the study of artificial intelligence\n",
            "Robotic process automation – Form of business process automation technology\n",
            "Weak artificial intelligence – Form of artificial intelligence\n",
            "Wetware computer – Computer composed of organic material\n",
            "\n",
            "\n",
            "== Explanatory notes ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "=== AI textbooks ===\n",
            "The two most widely used textbooks in 2023. (See the Open Syllabus).\n",
            "\n",
            "Russell, Stuart J.; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0134610993. LCCN 20190474.\n",
            "Rich, Elaine; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0070087705.These were the four of the most widely used AI textbooks in 2008:\n",
            "\n",
            "\n",
            "=== History of AI ===\n",
            "\n",
            "\n",
            "=== Other sources ===\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.\n",
            "Thomason, Richmond. \"Logic and Artificial Intelligence\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\n",
            "Artificial Intelligence. BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander (In Our Time, 8 December 2005).\n",
            "Theranostics and AI—The Next Advance in Cancer Precision Medicine...\n",
            "\n",
            "\n",
            "Page Title: Deep learning\n",
            "Text: Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.Deep-learning architectures such as deep neural networks, deep belief networks, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog. ANNs are generally seen as low quality models for brain function.\n",
            "\n",
            "\n",
            "== Definition ==\n",
            "Deep learning is a class of machine learning algorithms that: 199–200  uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.\n",
            "From another angle to view deep learning, deep learning refers to \"computer-simulate\" or \"automate\" human learning processes from a source (e.g., an image of dogs) to a learned object (dogs). Therefore, a notion coined as \"deeper\" learning or \"deepest\" learning makes sense. The deepest learning refers to the fully automatic learning from a source to a final learned object. A deeper learning thus refers to a mixed learning process: a human learning process from a source to a learned semi-object, followed by a computer learning process from the human learned semi-object to a final learned object.\n",
            "\n",
            "\n",
            "== Overview ==\n",
            "Most modern deep learning models are based on multi-layered artificial neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\n",
            "Deep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.\n",
            "Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.Machine learning models are now adept at identifying complex patterns in financial market data. Due to the benefits of artificial intelligence, investors are increasingly utilizing deep learning techniques to forecast and analyze trends in stock and foreign exchange markets.\n",
            "\n",
            "\n",
            "== Interpretations ==\n",
            "Deep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima's rectified linear unit.The universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\n",
            "The probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.\n",
            "\n",
            "\n",
            "== History ==\n",
            "There are two types of neural networks: feedforward neural networks (FNNs) and recurrent neural networks (RNNs). RNNs have cycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst Ising created and analyzed the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this architecture adaptive. His learning RNN was popularised by John Hopfield in 1982. RNNs have become central for speech recognition and language processing.\n",
            "Charles Tappert writes that Frank Rosenblatt developed and explored all of the basic ingredients of the deep learning systems of today, referring to Rosenblatt's 1962 book which introduced a multilayer perceptron (MLP) with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. However, since only the output layer had learning connections, this was not yet deep learning. It was what later was called an extreme learning machine. In addition, term deep learning was proposed in 1986 by Rina Dechter Dechter (1986) although the history of its appearance is apparently more complicated.The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967. A 1971 paper described a deep network with eight layers trained by the group method of data handling.The first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari. In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned  internal representations to classify non-linearily separable pattern classes. In 1987 Matthew Brand reported that wide 12-layer nonlinear perceptrons could be fully end-to-end trained to reproduce logic functions of nontrivial circuit depth via gradient descent on small batches of random input/output samples, but concluded that training time on contemporary hardware (sub-megaflop computers) made the technique impractical, and proposed using fixed random early layers as an input hash for a single modifiable layer.  Instead, subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\n",
            "In 1970, Seppo Linnainmaa published the reverse mode of automatic differentiation of discrete connected networks of nested differentiable functions. This became known as backpropagation. It is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. \n",
            "The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation already in 1960 in the context of control theory. In 1982, Paul Werbos applied backpropagation to MLPs in the way that has become standard. In 1985, David E. Rumelhart et al. published an experimental analysis of the technique.Deep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1980. In 1969, he also introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for CNNs and deep learning in general. CNNs have become an essential tool for computer vision.\n",
            "The term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.In 1988, Wei Zhang et al. applied the backpropagation algorithm \n",
            "to a convolutional neural network (a simplified Neocognitron with convolutional interconnections between the image feature layers and the last fully connected layer) for alphabet recognition. They also proposed an implementation of the CNN with an optical computing system. \n",
            "In 1989, Yann LeCun et al. applied backpropagation to a CNN with the purpose of recognizing handwritten ZIP codes on mail. While the algorithm worked, training required 3 days. Subsequently, Wei Zhang, et al. modified their model by removing the last fully connected layer and applied it for medical image object segmentation in 1991 and breast cancer detection in mammograms in 1994. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.\n",
            "In the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, Jürgen Schmidhuber (1992) proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning. It uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by distilling a higher level chunker network into a lower level automatizer network. In 1993, a chunker solved a deep learning task whose depth exceeded 1000.In 1992, Jürgen Schmidhuber also published an alternative to RNNs which is now called a linear Transformer or a  Transformer with linearized self-attention (save for a normalization operator). It learns internal spotlights of attention: a slow feedforward neural network learns by gradient descent to control the fast weights of another neural network through outer products of self-generated activation patterns FROM and TO (which are now called key and value for self-attention). This fast weight attention mapping is applied to a query pattern.\n",
            "The modern Transformer was introduced by Ashish Vaswani et. al. in their 2017 paper \"Attention Is All You Need\". \n",
            "It combines this with a softmax operator and a projection matrix.\n",
            "Transformers have increasingly become the model of choice for natural language processing. Many modern large language models such as ChatGPT, GPT-4, and BERT use it. Transformers are also increasingly being used in computer vision.In 1991, Jürgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in a generative adversarial network (GAN) by Ian Goodfellow et al. Here the environmental reaction is 1 or 0 depending on whether the first network's output is in a given set. This can be used to create realistic deepfakes. Excellent image quality is achieved by Nvidia's StyleGAN (2018) based on the Progressive GAN by Tero Karras et. al. Here the GAN generator is grown from small to large scale in a pyramidal fashion.\n",
            "Sepp Hochreiter's diploma thesis (1991) was called \"one of the most important documents in the history of machine learning\" by his supervisor Schmidhuber. It not only tested the neural history compressor, but also identified and analyzed the vanishing gradient problem. Hochreiter proposed recurrent residual connections to solve this problem. This led to the deep learning method called long short-term memory (LSTM), published in 1997. LSTM recurrent neural networks can learn \"very deep learning\" tasks with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. The \"vanilla LSTM\" with forget gate was introduced in 1999 by Felix Gers, Schmidhuber and Fred Cummins. LSTM has become the  most cited neural network of the 20th century.\n",
            "In 2015, Rupesh Kumar Srivastava, Klaus Greff, and Schmidhuber used LSTM principles to create the Highway network, a feedforward neural network with hundreds of layers, much deeper than previous networks. 7 months later, Kaiming He, Xiangyu Zhang;  Shaoqing Ren, and Jian Sun won the ImageNet 2015 competition with an open-gated or gateless Highway network variant called Residual neural network. This has become the most cited neural network of the 21st century.In 1994, André de Carvalho, together with Mike Fairhurst and David Bisset, published experimental results of a multi-layer boolean neural network, also known as a weightless neural network, composed of a 3-layers self-organising feature extraction neural network module (SOFT) followed by a multi-layer classification neural network module (GSN), which were independently trained. Each layer in the feature extraction module extracted features with growing complexity regarding the previous layer.In 1995, Brendan Frey demonstrated that it was possible to train (over two days) a network containing six fully connected layers and several hundred hidden units using the wake-sleep algorithm, co-developed with Peter Dayan and Hinton.Since 1997, Sven Behnke extended the feed-forward hierarchical convolutional approach in the Neural Abstraction Pyramid by lateral and backward connections in order to flexibly incorporate context into decisions and iteratively resolve local ambiguities.\n",
            "Simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) were a popular choice in the 1990s and 2000s, because of artificial neural network's (ANN) computational cost and a lack of understanding of how the brain wires its biological networks.\n",
            "Both shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power. Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI studied deep neural networks in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 National Institute of Standards and Technology Speaker Recognition evaluation. The SRI deep neural network was then deployed in the Nuance Verifier, representing the first major industrial application of deep learning. The principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.Speech recognition was taken over by LSTM. In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks. In 2006, Alex Graves, Santiago Fernández, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC) in stacks of LSTM RNNs. In 2015, Google's speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through Google Voice Search.The impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.\n",
            "In 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh showed how a many-layered feedforward neural network could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then fine-tuning it using supervised backpropagation. The papers referred to learning for deep belief nets.\n",
            "The 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets (DNN) might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.  That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\n",
            "In 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks (CNNs) were superseded for ASR by CTC for LSTM. but are more successful in computer vision.\n",
            "Advances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the \"big bang\" of deep learning, \"as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs)\". That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times. In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.\n",
            "\n",
            "\n",
            "=== Deep learning revolution ===\n",
            "In the late 2000s, deep learning started to outperform other methods in machine learning competitions.\n",
            "In 2009, a long short-term memory trained by connectionist temporal classification (Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber, 2006) was the first RNN to win pattern recognition contests, winning three competitions in connected handwriting recognition. Google later used CTC-trained LSTM for speech recognition on the smartphone.Significant impacts in image or object recognition were felt from 2011 to 2012. Although CNNs trained by backpropagation had been around for decades, and GPU implementations of NNs for years, including CNNs, faster implementations of CNNs on GPUs were needed to progress on computer vision. In 2011, the DanNet by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. Also in 2011, DanNet won the ICDAR Chinese handwriting contest, and in May 2012, it won the ISBI image segmentation contest. Until 2011, CNNs did not play a major role at computer vision conferences, but in June 2012, a paper by Ciresan et al. at the leading conference CVPR showed how max-pooling CNNs on GPU can dramatically improve many vision benchmark records.  In September 2012, DanNet also won the ICPR contest on analysis of large medical images for cancer detection, and in the following year also the MICCAI Grand Challenge on the same topic. In October 2012, the similar AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. \n",
            "The VGG-16 network by Karen Simonyan and Andrew Zisserman further reduced the error rate and\n",
            "won the ImageNet 2014 competition, following a similar trend in large-scale speech recognition.\n",
            "Image classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.In 2012, a team led by George E. Dahl won the \"Merck Molecular Activity Challenge\" using multi-task deep neural networks to predict the biomolecular target of one drug. In 2014, Sepp Hochreiter's group used deep learning to detect off-target and toxic effects of environmental chemicals in nutrients, household products and drugs and won the \"Tox21 Data Challenge\" of NIH, FDA and NCATS.In 2016, Roger Parloff mentioned a \"deep learning revolution\" that has transformed the AI industry.In March 2019, Yoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.\n",
            "\n",
            "\n",
            "== Neural networks ==\n",
            "\n",
            "Artificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.\n",
            "An ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\n",
            "Typically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\n",
            "The original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\n",
            "Neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\n",
            "As of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\").\n",
            "\n",
            "\n",
            "=== Deep neural networks ===\n",
            "A deep neural network (DNN) is an artificial neural network (ANN) with multiple layers between the input and output layers. There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions. These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.For example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer, and complex DNN have many layers, hence the name \"deep\" networks.\n",
            "DNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives. The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network. For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.Deep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\n",
            "DNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights. That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\n",
            "Recurrent neural networks (RNNs), in which data can flow in any direction, are used for applications such as language modeling. Long short-term memory is particularly effective for this use.Convolutional deep neural networks (CNNs) are used in computer vision. CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).\n",
            "\n",
            "\n",
            "==== Challenges ====\n",
            "As with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time.\n",
            "DNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko's unit pruning or weight decay (\n",
            "  \n",
            "    \n",
            "      \n",
            "        \n",
            "          ℓ\n",
            "          \n",
            "            2\n",
            "          \n",
            "        \n",
            "      \n",
            "    \n",
            "    {\\displaystyle \\ell _{2}}\n",
            "  -regularization) or sparsity (\n",
            "  \n",
            "    \n",
            "      \n",
            "        \n",
            "          ℓ\n",
            "          \n",
            "            1\n",
            "          \n",
            "        \n",
            "      \n",
            "    \n",
            "    {\\displaystyle \\ell _{1}}\n",
            "  -regularization) can be applied during training to combat overfitting. Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies. Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.DNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples) speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.Alternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn't require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.\n",
            "\n",
            "\n",
            "== Hardware ==\n",
            "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.Special electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform. Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).Atomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\n",
            "In 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).In 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing. The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds. Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.\n",
            "\n",
            "\n",
            "== Applications ==\n",
            "\n",
            "\n",
            "=== Automatic speech recognition ===\n",
            "\n",
            "Large-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.The initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\n",
            "\n",
            "The debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003–2007, accelerated progress in eight major areas:\n",
            "Scale-up/out and accelerated DNN training and decoding\n",
            "Sequence discriminative training\n",
            "Feature processing by deep models with solid understanding of the underlying mechanisms\n",
            "Adaptation of DNNs and related deep models\n",
            "Multi-task and transfer learning by DNNs and related deep models\n",
            "CNNs and how to design them to best exploit domain knowledge of speech\n",
            "RNN and its rich LSTM variants\n",
            "Other types of deep models including tensor-based models and integrated deep generative/discriminative models.All major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.\n",
            "\n",
            "\n",
            "=== Image recognition ===\n",
            "\n",
            "A common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.Deep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.Deep learning-trained vehicles now interpret 360° camera views. Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\n",
            "\n",
            "\n",
            "=== Visual art processing ===\n",
            "Closely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\n",
            "\n",
            "identifying the style period of a given painting\n",
            "Neural Style Transfer –  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video\n",
            "generating striking imagery based on random visual input fields.\n",
            "\n",
            "\n",
            "=== Natural language processing ===\n",
            "\n",
            "Neural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.Other key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.Recent developments generalize word embedding to sentence embedding.\n",
            "Google Translate (GT) uses a large end-to-end long short-term memory (LSTM) network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\". It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages. The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\". GT uses English as an intermediate between most language pairs.\n",
            "\n",
            "\n",
            "=== Drug discovery and toxicology ===\n",
            "\n",
            "A large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects. Research has explored use of deep learning to predict the biomolecular targets, off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.AtomNet is a deep learning system for structure-based rational drug design. AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus and multiple sclerosis.In 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set. In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.\n",
            "\n",
            "\n",
            "=== Customer relationship management ===\n",
            "\n",
            "Deep reinforcement learning has been used to approximate the value of possible direct marketing actions, defined in terms of RFM variables. The estimated value function was shown to have a natural interpretation as customer lifetime value.\n",
            "\n",
            "\n",
            "=== Recommendation systems ===\n",
            "\n",
            "Recommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations. Multi-view deep learning has been applied for learning user preferences from multiple domains. The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\n",
            "\n",
            "\n",
            "=== Bioinformatics ===\n",
            "\n",
            "An autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.In medical informatics, deep learning was used to predict sleep quality based on data from wearables and predictions of health complications from electronic health record data.\n",
            "\n",
            "\n",
            "=== Deep Neural Network Estimations ===\n",
            "Deep neural networks (DNN) can be used to estimate the entropy of a stochastic process and called Neural Joint Entropy Estimator (NJEE). Such an estimation provides insights on the affects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in case of large alphabet sizes.\n",
            "\n",
            "\n",
            "=== Medical image analysis ===\n",
            "Deep learning has been shown to produce competitive results in medical application such as cancer cell classification, lesion detection, organ segmentation and image enhancement. Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.\n",
            "\n",
            "\n",
            "=== Mobile advertising ===\n",
            "Finding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server. Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\n",
            "\n",
            "\n",
            "=== Image restoration ===\n",
            "Deep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization. These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\" which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration.\n",
            "\n",
            "\n",
            "=== Financial fraud detection ===\n",
            "Deep learning is being successfully applied to financial fraud detection, tax evasion detection, and anti-money laundering.\n",
            "\n",
            "\n",
            "=== Military ===\n",
            "The United States Department of Defense applied deep learning to train robots in new tasks through observation.\n",
            "\n",
            "\n",
            "=== Partial differential equations ===\n",
            "Physics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner. One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods relies on.\n",
            "\n",
            "\n",
            "=== Image Reconstruction ===\n",
            "Image reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging  and ultrasound imaging.\n",
            "\n",
            "\n",
            "=== Epigenetic clock ===\n",
            "\n",
            "An epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.\n",
            "\n",
            "\n",
            "== Relation to human cognitive and brain development ==\n",
            "Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".A variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.Although a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.\n",
            "\n",
            "\n",
            "== Commercial activity ==\n",
            "Facebook's AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.Google's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.\n",
            "In 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.As of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".\n",
            "\n",
            "\n",
            "== Criticism and comment ==\n",
            "Deep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\n",
            "\n",
            "\n",
            "=== Theory ===\n",
            "\n",
            "A main criticism concerns the lack of theory surrounding some methods. Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear. (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.Others point out that deep learning should be looked at as a step towards realizing strong AI, not as an all-encompassing solution. Despite the power of deep learning methods, they still lack much of the functionality needed for realizing this goal entirely. Research psychologist Gary Marcus noted:\n",
            "\n",
            "Realistically, deep learning is only part of the larger challenge of building intelligent machines. Such techniques lack ways of representing causal relationships (...) have no obvious ways of performing logical inferences, and they are also still a long way from integrating abstract knowledge, such as information about what objects are, what they are for, and how they are typically used. The most powerful A.I. systems, like Watson (...) use techniques like deep learning as just one element in a very complicated ensemble of techniques, ranging from the statistical technique of Bayesian inference to deductive reasoning.\n",
            "\n",
            "In further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian's website.\n",
            "\n",
            "\n",
            "=== Errors ===\n",
            "Some deep learning architectures display problematic behaviors, such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014) and misclassifying minuscule perturbations of correctly classified images (2013). Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures. These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar decompositions of observed entities and events. Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition and artificial intelligence (AI).\n",
            "\n",
            "\n",
            "=== Cyber threat ===\n",
            "As deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception. By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".In 2016 researchers used one ANN to doctor images in trial and error fashion, identify another's focal points and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system. One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.Another group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.ANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.In 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".In \"data poisoning\", false data is continually smuggled into a machine learning system's training set to prevent it from achieving mastery.\n",
            "\n",
            "\n",
            "=== Data collection ethics ===\n",
            "Most Deep Learning systems rely on training and verification data that is generated and/or annotated by humans. It has been argued in media philosophy that not only low-paid clickwork (e.g. on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such. The philosopher Rainer Mühlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.Mühlhoff argues that in most commercial end-user applications of Deep Learning such as Facebook's face recognition system, the need for training data does not stop once an ANN is trained. Rather, there is a continued demand for human-generated verification data to constantly calibrate and update the ANN. For this purpose Facebook introduced the feature that once a user is automatically recognized in an image, they receive a notification. They can choose whether of not they like to be publicly labeled on the image, or tell Facebook that it is not them in the picture. This user interface is a mechanism to generate \"a constant stream of verification data\" to further train the network in real-time. As Mühlhoff argues, involvement of human users to generate training and verification data is so typical for most commercial end-user applications of Deep Learning that such systems may be referred to as \"human-aided artificial intelligence\".\n",
            "\n",
            "\n",
            "== See also ==\n",
            "Applications of artificial intelligence\n",
            "Comparison of deep learning software\n",
            "Compressed sensing\n",
            "Differentiable programming\n",
            "Echo state network\n",
            "List of artificial intelligence projects\n",
            "Liquid state machine\n",
            "List of datasets for machine-learning research\n",
            "Reservoir computing\n",
            "Scale space and deep learning\n",
            "Sparse coding\n",
            "Stochastic parrot\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Further reading ==...\n",
            "\n",
            "\n",
            "Page Title: Data Science\n",
            "Text: Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine). Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.A  data scientist is a professional who creates programming code and combines it with statistical knowledge to create insights from data.\n",
            "\n",
            "\n",
            "== Foundations ==\n",
            "Data science is an interdisciplinary field focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains. The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business. Statistician Nathan Yau, drawing on Ben Fry, also links data science to human–computer interaction: users should be able to intuitively control and explore data. In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.\n",
            "\n",
            "\n",
            "=== Relationship to statistics ===\n",
            "Many statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics. Others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data. Vasant Dhar writes that statistics emphasizes quantitative data and description. In contrast, data science deals with quantitative and qualitative data (e.g., from images, text, sensors, transactions, customer information, etc.) and emphasizes prediction and action. Andrew Gelman of Columbia University has described statistics as a non-essential part of data science.Stanford professor David Donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data-science program. He describes data science as an applied field growing out of traditional statistics.\n",
            "\n",
            "\n",
            "== Etymology ==\n",
            "\n",
            "\n",
            "=== Early usage ===\n",
            "In 1962, John Tukey described a field he called \"data analysis\", which resembles modern data science. In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C. F. Jeff Wu used the term \"data science\" for the first time as an alternative name for statistics. Later, attendees at a 1992 statistics symposium at the University of Montpellier  II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.The term \"data science\" has been traced back to 1974, when Peter Naur proposed it as an alternative name to computer science. In 1996, the International Federation of Classification Societies became the first conference to specifically feature data science as a topic. However, the definition was still in flux. After the 1985 lecture at the Chinese Academy of Sciences in Beijing, in 1997 C. F. Jeff Wu again suggested that statistics should be renamed data science. He reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting or limited to describing data. In 1998, Hayashi Chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.During the 1990s, popular terms for the process of finding patterns in datasets (which were increasingly large) included \"knowledge discovery\" and \"data mining\".\n",
            "\n",
            "\n",
            "=== Modern usage ===\n",
            "In 2012, technologists Thomas H. Davenport and DJ Patil declared \"Data Scientist: The Sexiest Job of the 21st Century\", a catchphrase that was picked up even by major-city newspapers like the New York Times and the Boston Globe. A decade later, they reaffirmed it, stating that \"the job is more in demand than ever with employers\".The modern conception of data science as an independent discipline is sometimes attributed to William S. Cleveland. In a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name. \"Data science\" became more widely used in the next few years: in 2002, the Committee on Data for Science and Technology launched the Data Science Journal. In 2003, Columbia University launched The Journal of Data Science. In 2014, the American Statistical Association's Section on Statistical Learning and Data Mining changed its name to the Section on Statistical Learning and Data Science, reflecting the ascendant popularity of data science.The professional title of \"data scientist\" has been attributed to DJ Patil and Jeff Hammerbacher in 2008. Though it was used by the National Science Board in their 2005 report \"Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century\", it referred broadly to any key role in managing a digital data collection.There is still no consensus on the definition of data science, and it is considered by some to be a buzzword. Big data is a related marketing term. Data scientists are responsible for breaking down big data into usable information and creating software and algorithms that help companies and organizations determine optimal operations.\n",
            "\n",
            "\n",
            "== Data Science and Data Analysis ==\n",
            "Data science and data analysis are both important disciplines in the field of data management and analysis, but they differ in several key ways. While both fields involve working with data, data science is more of an interdisciplinary field that involves the application of statistical, computational, and machine learning methods to extract insights from data and make predictions, while data analysis is more focused on the examination and interpretation of data to identify patterns and trends.Data analysis typically involves working with smaller, structured datasets to answer specific questions or solve specific problems. This can involve tasks such as data cleaning, data visualization, and exploratory data analysis to gain insights into the data and develop hypotheses about relationships between variables. Data analysts typically use statistical methods to test these hypotheses and draw conclusions from the data. For example, a data analyst might analyze sales data to identify trends in customer behavior and make recommendations for marketing strategies.Data science, on the other hand, is a more complex and iterative process that involves working with larger, more complex datasets that often require advanced computational and statistical methods to analyze. Data scientists often work with unstructured data such as text or images and use machine learning algorithms to build predictive models and make data-driven decisions. In addition to statistical analysis, data science often involves tasks such as data preprocessing, feature engineering, and model selection. For instance, a data scientist might develop a recommendation system for an e-commerce platform by analyzing user behavior patterns and using machine learning algorithms to predict user preferences.While data analysis focuses on extracting insights from existing data, data science goes beyond that by incorporating the development and implementation of predictive models to make informed decisions. Data scientists are often responsible for collecting and cleaning data, selecting appropriate analytical techniques, and deploying models in real-world scenarios. They work at the intersection of mathematics, computer science, and domain expertise to solve complex problems and uncover hidden patterns in large datasets.Despite these differences, data science and data analysis are closely related fields and often require similar skill sets. Both fields require a solid foundation in statistics, programming, and data visualization, as well as the ability to communicate findings effectively to both technical and non-technical audiences. Moreover, both fields benefit from critical thinking and domain knowledge, as understanding the context and nuances of the data is essential for accurate analysis and modeling.In summary, data analysis and data science are distinct yet interconnected disciplines within the broader field of data management and analysis. Data analysis focuses on extracting insights and drawing conclusions from structured data, while data science involves a more comprehensive approach that combines statistical analysis, computational methods, and machine learning to extract insights, build predictive models, and drive data-driven decision-making. Both fields play vital roles in leveraging the power of data to understand patterns, make informed decisions, and solve complex problems across various domains.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "\n",
            "== See also ==\n",
            "Open Data Science Conference\n",
            "Scientific Data\n",
            "Women in Data\n",
            "Python (programming language)\n",
            "R (programming language)\n",
            "Data engineering\n",
            "Big data\n",
            "Machine learning\n",
            "\n",
            "\n",
            "== References ==...\n",
            "\n",
            "\n",
            "Page Title: Algorithms\n",
            "Text: In mathematics and computer science, an algorithm ( ) is a finite sequence of rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning), achieving automation eventually. Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as \"memory\", \"search\" and \"stimulus\".In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "\n",
            "=== Ancient algorithms ===\n",
            "Since antiquity, step-by-step procedures for solving mathematical problems have been attested. This includes Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later; e.g. Shulba Sutras, Kerala School, and Brāhmasphuṭasiddhānta), The Ifa Oracle (around 500 BC), Greek mathematics (around 240 BC, e.g. sieve of Eratosthenes and Euclidean algorithm), and Arabic mathematics (9th century, e.g. cryptographic algorithms for code-breaking based on frequency analysis).\n",
            "\n",
            "\n",
            "=== Al-Khwārizmī and the term algorithm ===\n",
            "Around 825, Muḥammad ibn Mūsā al-Khwārizmī wrote kitāb al-ḥisāb al-hindī (\"Book of Indian computation\") and kitab al-jam' wa'l-tafriq al-ḥisāb al-hindī (\"Addition and subtraction in Indian arithmetic\"). Both of these texts are lost in the original Arabic at this time. (However, his other book on algebra remains.)In the early 12th century, Latin translations of said al-Khwarizmi texts involving the Hindu–Arabic numeral system and arithmetic appeared: Liber Alghoarismi de practica arismetrice (attributed to John of Seville) and Liber Algorismi de numero Indorum (attributed to Adelard of Bath). Hereby, alghoarismi or algorismi is the Latinization of Al-Khwarizmi's name; the text starts with the phrase Dixit Algorismi (\"Thus spoke Al-Khwarizmi\").In 1240, Alexander of Villedieu writes a Latin text titled Carmen de Algorismo. It begins with:\n",
            "\n",
            "Haec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris.\n",
            "which translates to:\n",
            "\n",
            "Algorism is the art by which at present we use those Indian figures, which number two times five.\n",
            "The poem is a few hundred lines long and summarizes the art of calculating with the new styled Indian dice (Tali Indorum), or Hindu numerals.\n",
            "\n",
            "\n",
            "=== English evolution of the word ===\n",
            "Around 1230, the English word algorism is attested and then by Chaucer in 1391. English adopted the French term.In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, \"number\"; cf. \"arithmetic\"), the Latin word was altered to algorithmus.\n",
            "In 1656, in the English dictionary Glossographia, it says:\n",
            "\n",
            "Algorism ([Latin] algorismus) the Art or use of Cyphers, or of numbering by Cyphers; skill in accounting.\n",
            "Augrime ([Latin] algorithmus) skil in accounting or numbring.\n",
            "\n",
            "In 1658, in the first edition of The New World of English Words, it says:\n",
            "\n",
            "Algorithme, (a word compounded of Arabick and Spanish,) the art of reckoning by Cyphers.\n",
            "\n",
            "In 1706, in the sixth edition of The New World of English Words, it says:\n",
            "\n",
            "Algorithm, the Art of computing or reckoning by numbers, which contains the five principle Rules of Arithmetick, viz. Numeration, Addition, Subtraction, Multiplication and Division; to which may be added Extraction of Roots: It is also call'd Logistica Numeralis.\n",
            "Algorism, the practical Operation in the several Parts of Specious Arithmetick or Algebra; sometimes it is taken for the Practice of Common Arithmetick by the ten Numeral Figures.\n",
            "\n",
            "In 1751, in the Young Algebraist's Companion, Daniel Fenning contrasts the terms algorism and algorithm as follows:\n",
            "\n",
            "Algorithm signifies the first Principles, and Algorism the practical Part, or knowing how to put the Algorithm in Practice.\n",
            "\n",
            "Since at least 1811, the term algorithm is attested to mean a \"step-by-step procedure\" in English.In 1842, in the Dictionary of Science, Literature and Art, it says:\n",
            "\n",
            "ALGORITHM, signifies the art of computing in reference to some particular subject, or in some particular way; as the algorithm of numbers; the algorithm of the differential calculus.\n",
            "\n",
            "\n",
            "=== Machine usage ===\n",
            "In 1928, a partial formalization of the modern concept of algorithms began with attempts to solve the Entscheidungsproblem (decision problem) posed by David Hilbert. Later formalizations were framed as attempts to define \"effective calculability\" or \"effective method\". Those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing machines of 1936–37 and 1939.\n",
            "\n",
            "\n",
            "== Informal definition ==\n",
            "\n",
            "One informal definition is \"a set of rules that precisely defines a sequence of operations\", which would include all computer programs (including programs that do not perform numeric calculations), and (for example) any prescribed bureaucratic procedure\n",
            "or cook-book recipe.In general, a program is an algorithm only if it stops eventually—even though infinite loops may sometimes prove desirable.\n",
            "A prototypical example of an algorithm is the Euclidean algorithm, which is used to determine the maximum common divisor of two integers; an example (there are others) is described by the flowchart above and as an example in a later section.\n",
            "Boolos, Jeffrey & 1974, 1999 offer an informal meaning of the word \"algorithm\" in the following quotation:\n",
            "\n",
            "No human being can write fast enough, or long enough, or small enough† ( †\"smaller and smaller without limit ... you'd be trying to write on molecules, on atoms, on electrons\") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols.\n",
            "An \"enumerably infinite set\" is one whose elements can be put into one-to-one correspondence with the integers. Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process that \"creates\" output integers from an arbitrary \"input\" integer or integers that, in theory, can be arbitrarily large. For example, an algorithm can be an algebraic equation such as y = m + n (i.e., two arbitrary \"input variables\" m and n that produce an output y), but various authors' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):\n",
            "\n",
            "Precise instructions (in a language understood by \"the computer\") for a fast, efficient, \"good\" process that specifies the \"moves\" of \"the computer\" (machine or human, equipped with the necessary internally contained information and capabilities) to find, decode, and then process arbitrary input integers/symbols m and n, symbols + and = ... and \"effectively\" produce, in a \"reasonable\" time, output-integer y at a specified place and in a specified format.The concept of algorithm is also used to define the notion of decidability—a notion that is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related to the customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.\n",
            "Most algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.\n",
            "\n",
            "\n",
            "== Formalization ==\n",
            "Algorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform—in a specific order—to carry out a specified task, such as calculating employees' paychecks or printing students' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987), and Gurevich (2000):\n",
            "\n",
            " Minsky: \"But we will also maintain, with Turing ... that any procedure which could \"naturally\" be called effective, can, in fact, be realized by a (simple) machine. Although this may seem extreme, the arguments ... in its favor are hard to refute\".\n",
            " Gurevich: \"… Turing's informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine … according to Savage [1987], an algorithm is a computational process defined by a Turing machine\".Turing machines can define computational processes that do not terminate. The informal definitions of algorithms generally require that the algorithm always terminates. This requirement renders the task of deciding whether a formal procedure is an algorithm impossible in the general case—due to a major theorem of computability theory known as the halting problem.\n",
            "Typically, when an algorithm is associated with processing information, data can be read from an input source, written to an output device and stored for further processing. Stored data is regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.\n",
            "For some of these computational processes, the algorithm must be rigorously defined and specified in the way it applies in all possible circumstances that could arise. This means that any conditional steps must be systematically dealt with, case by case; the criteria for each case must be clear (and computable).\n",
            "Because an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting \"from the top\" and going \"down to the bottom\"—an idea that is described more formally by flow of control.\n",
            "So far, the discussion on the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception—one that attempts to describe a task in discrete, \"mechanical\" terms. Associated with this conception of formalized algorithms is the assignment operation, which sets the value of a variable. It derives from the intuition of \"memory\" as a scratchpad. An example of such an assignment can be found below.\n",
            "For some alternate conceptions of what constitutes an algorithm, see functional programming and logic programming.\n",
            "\n",
            "\n",
            "== Expressing algorithms ==\n",
            "Algorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, drakon-charts, programming languages or control tables (processed by interpreters). Natural language expressions of algorithms tend to be verbose and ambiguous and are rarely used for complex or technical algorithms. Pseudocode, flowcharts, drakon-charts and control tables are structured ways to express algorithms that avoid many of the ambiguities common in statements based on natural language. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer, but they are also often used as a way to define or document algorithms.\n",
            "There is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see finite-state machine, state-transition table and control table for more), as flowcharts and drakon-charts (see state diagram for more), or as a form of rudimentary machine code or assembly code called \"sets of quadruples\" (see Turing machine for more).\n",
            "Representations of algorithms can be classified into three accepted levels of Turing machine description, as follows:\n",
            "1 High-level description\n",
            "\"...prose to describe an algorithm, ignoring the implementation details. At this level, we do not need to mention how the machine manages its tape or head.\"\n",
            "2 Implementation description\n",
            "\"...prose used to define the way the Turing machine uses its head and the way that it stores data on its tape. At this level, we do not give details of states or transition function.\"\n",
            "3 Formal description\n",
            "Most detailed, \"lowest level\", gives the Turing machine's \"state table\".For an example of the simple algorithm \"Add m+n\" described in all three levels, see Examples.\n",
            "\n",
            "\n",
            "== Design ==\n",
            "\n",
            "Algorithm design refers to a method or a mathematical process for problem-solving and engineering algorithms. The design of algorithms is part of many solution theories, such as divide-and-conquer or dynamic programming within operation research. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, with examples including the template method pattern and the decorator pattern.\n",
            "One of the most important aspects of algorithm design is resource (run-time, memory usage) efficiency; the big O notation is used to describe e.g., an algorithm's run-time growth as the size of its input increases.\n",
            "Typical steps in the development of algorithms:\n",
            "\n",
            "Problem definition\n",
            "Development of a model\n",
            "Specification of the algorithm\n",
            "Designing an algorithm\n",
            "Checking the correctness of the algorithm\n",
            "Analysis of algorithm\n",
            "Implementation of algorithm\n",
            "Program testing\n",
            "Documentation preparation\n",
            "\n",
            "\n",
            "== Computer algorithms ==\n",
            "\"Elegant\" (compact) programs, \"good\" (fast) programs: The notion of \"simplicity and elegance\" appears informally in Knuth and precisely in Chaitin:\n",
            "\n",
            "Knuth: \" ... we want good algorithms in some loosely defined aesthetic sense. One criterion ... is the length of time taken to perform the algorithm .... Other criteria are adaptability of the algorithm to computers, its simplicity, and elegance, etc.\"Chaitin: \" ... a program is 'elegant,' by which I mean that it's the smallest possible program for producing the output that it does\"Chaitin prefaces his definition with: \"I'll show you can't prove that a program is 'elegant'\"—such a proof would solve the Halting problem (ibid).\n",
            "Algorithm versus function computable by an algorithm: For a given function multiple algorithms may exist. This is true even without expanding the available instruction set available to the programmer. Rogers observes that \"It is ... important to distinguish between the notion of algorithm, i.e. procedure and the notion of function computable by algorithm, i.e. mapping yielded by procedure. The same function may have several different algorithms\".Unfortunately, there may be a tradeoff between goodness (speed) and elegance (compactness)—an elegant program may take more steps to complete a computation than one that is less elegant. An example that uses Euclid's algorithm appears below.\n",
            "Computers (and computors), models of computation: A computer (or human \"computer\") is a restricted type of machine, a \"discrete deterministic mechanical device\" that blindly follows its instructions. Melzak's and Lambek's primitive models reduced this notion to four elements: (i) discrete, distinguishable locations, (ii) discrete, indistinguishable counters (iii) an agent, and (iv) a list of instructions that are effective relative to the capability of the agent.Minsky describes a more congenial variation of Lambek's \"abacus\" model in his \"Very Simple Bases for Computability\". Minsky's machine proceeds sequentially through its five (or six, depending on how one counts) instructions unless either a conditional IF-THEN GOTO or an unconditional GOTO changes program flow out of sequence. Besides HALT, Minsky's machine includes three assignment (replacement, substitution) operations: ZERO (e.g. the contents of the location replaced by 0: L ← 0), SUCCESSOR (e.g. L ← L+1), and DECREMENT (e.g. L ← L − 1). Rarely must a programmer write \"code\" with such a limited instruction set. But Minsky shows (as do Melzak and Lambek) that his machine is Turing complete with only four general types of instructions: conditional GOTO, unconditional GOTO, assignment/replacement/substitution, and HALT. However, a few different assignment instructions (e.g. DECREMENT, INCREMENT, and ZERO/CLEAR/EMPTY for a Minsky machine) are also required for Turing-completeness; their exact specification is somewhat up to the designer. The unconditional GOTO is convenient; it can be constructed by initializing a dedicated location to zero e.g. the instruction \" Z ← 0 \"; thereafter the instruction IF Z=0 THEN GOTO xxx is unconditional.\n",
            "Simulation of an algorithm: computer (computor) language: Knuth advises the reader that \"the best way to learn an algorithm is to try it . . . immediately take pen and paper and work through an example\". But what about a simulation or execution of the real thing? The programmer must translate the algorithm into a language that the simulator/computer/computor can effectively execute. Stone gives an example of this: when computing the roots of a quadratic equation the computer must know how to take a square root. If they do not, then the algorithm, to be effective, must provide a set of rules for extracting a square root.This means that the programmer must know a \"language\" that is effective relative to the target computing agent (computer/computor).\n",
            "But what model should be used for the simulation? Van Emde Boas observes \"even if we base complexity theory on abstract instead of concrete machines, the arbitrariness of the choice of a model remains. It is at this point that the notion of simulation enters\". When speed is being measured, the instruction set matters. For example, the subprogram in Euclid's algorithm to compute the remainder would execute much faster if the programmer had a \"modulus\" instruction available rather than just subtraction (or worse: just Minsky's \"decrement\").\n",
            "Structured programming, canonical structures: Per the Church–Turing thesis, any algorithm can be computed by a model known to be Turing complete, and per Minsky's demonstrations, Turing completeness requires only four instruction types—conditional GOTO, unconditional GOTO, assignment, HALT. Kemeny and Kurtz observe that, while \"undisciplined\" use of unconditional GOTOs and conditional IF-THEN GOTOs can result in \"spaghetti code\", a programmer can write structured programs using only these instructions; on the other hand \"it is also possible, and not too hard, to write badly structured programs in a structured language\". Tausworthe augments the three Böhm-Jacopini canonical structures: SEQUENCE, IF-THEN-ELSE, and WHILE-DO, with two more: DO-WHILE and CASE. An additional benefit of a structured program is that it lends itself to proofs of correctness using mathematical induction.Canonical flowchart symbols: The graphical aid called a flowchart offers a way to describe and document an algorithm (and a computer program corresponding to it). Like the program flow of a Minsky machine, a flowchart always starts at the top of a page and proceeds down. Its primary symbols are only four: the directed arrow showing program flow, the rectangle (SEQUENCE, GOTO), the diamond (IF-THEN-ELSE), and the dot (OR-tie). The Böhm–Jacopini canonical structures are made of these primitive shapes. Sub-structures can \"nest\" in rectangles, but only if a single exit occurs from the superstructure. The symbols and their use to build the canonical structures are shown in the diagram.\n",
            "\n",
            "\n",
            "== Examples ==\n",
            "\n",
            "\n",
            "=== Algorithm example ===\n",
            "One of the simplest algorithms is to find the largest number in a list of numbers of random order. Finding the solution requires looking at every number in the list. From this follows a simple algorithm, which can be stated in a high-level description in English prose, as:\n",
            "High-level description:\n",
            "\n",
            "If there are no numbers in the set, then there is no highest number.\n",
            "Assume the first number in the set is the largest number in the set.\n",
            "For each remaining number in the set: if this number is larger than the current largest number, consider this number to be the largest number in the set.\n",
            "When there are no numbers left in the set to iterate over, consider the current largest number to be the largest number of the set.(Quasi-)formal description:\n",
            "Written in prose but much closer to the high-level language of a computer program, the following is the more formal coding of the algorithm in pseudocode or pidgin code:\n",
            "\n",
            "\n",
            "=== Euclid's algorithm ===\n",
            "\n",
            "In mathematics, the Euclidean algorithm or Euclid's algorithm, is an efficient method for computing the greatest common divisor (GCD) of two integers (numbers), the largest number that divides them both without a remainder. It is named after the ancient Greek mathematician Euclid, who first described it in his Elements (c. 300 BC). It is one of the oldest algorithms in common use. It can be used to reduce fractions to their simplest form, and is a part of many other number-theoretic and cryptographic calculations.\n",
            "\n",
            "Euclid poses the problem thus: \"Given two numbers not prime to one another, to find their greatest common measure\". He defines \"A number [to be] a multitude composed of units\": a counting number, a positive integer not including zero. To \"measure\" is to place a shorter measuring length s successively (q times) along longer length l until the remaining portion r is less than the shorter length s. In modern words, remainder r = l − q×s, q being the quotient, or remainder r is the \"modulus\", the integer-fractional part left over after the division.For Euclid's method to succeed, the starting lengths must satisfy two requirements: (i) the lengths must not be zero, AND (ii) the subtraction must be \"proper\"; i.e., a test must guarantee that the smaller of the two numbers is subtracted from the larger (or the two can be equal so their subtraction yields zero).\n",
            "Euclid's original proof adds a third requirement: the two lengths must not be prime to one another. Euclid stipulated this so that he could construct a reductio ad absurdum proof that the two numbers' common measure is in fact the greatest. While Nicomachus' algorithm is the same as Euclid's, when the numbers are prime to one another, it yields the number \"1\" for their common measure. So, to be precise, the following is really Nicomachus' algorithm.\n",
            "\n",
            "\n",
            "==== Computer language for Euclid's algorithm ====\n",
            "Only a few instruction types are required to execute Euclid's algorithm—some logical tests (conditional GOTO), unconditional GOTO, assignment (replacement), and subtraction.\n",
            "\n",
            "A location is symbolized by upper case letter(s), e.g. S, A, etc.\n",
            "The varying quantity (number) in a location is written in lower case letter(s) and (usually) associated with the location's name. For example, location L at the start might contain the number l = 3009.\n",
            "\n",
            "\n",
            "==== An inelegant program for Euclid's algorithm ====\n",
            "The following algorithm is framed as Knuth's four-step version of Euclid's and Nicomachus', but, rather than using division to find the remainder, it uses successive subtractions of the shorter length s from the remaining length r until r is less than s. The high-level description, shown in boldface, is adapted from Knuth 1973:2–4:\n",
            "INPUT:\n",
            "\n",
            "1 [Into two locations L and S put the numbers l and s that represent the two lengths]:\n",
            "INPUT L, S\n",
            "2 [Initialize R: make the remaining length r equal to the starting/initial/input length l]:\n",
            "R ← L\n",
            "\n",
            "E0: [Ensure r ≥ s.]\n",
            "\n",
            "3 [Ensure the smaller of the two numbers is in S and the larger in R]:\n",
            "IF R > S THEN\n",
            "the contents of L is the larger number so skip over the exchange-steps 4, 5 and 6:\n",
            "GOTO step 7\n",
            "ELSE\n",
            "swap the contents of R and S.\n",
            "4 L ← R (this first step is redundant, but is useful for later discussion).\n",
            "5 R ← S\n",
            "6 S ← L\n",
            "\n",
            "E1: [Find remainder]: Until the remaining length r in R is less than the shorter length s in S, repeatedly subtract the measuring number s in S from the remaining length r in R.\n",
            "\n",
            "7 IF S > R THEN\n",
            "done measuring so\n",
            "GOTO 10\n",
            "ELSE\n",
            "measure again,\n",
            "8 R ← R − S\n",
            "9 [Remainder-loop]:\n",
            "GOTO 7.\n",
            "\n",
            "E2: [Is the remainder zero?]: EITHER (i) the last measure was exact, the remainder in R is zero, and the program can halt, OR (ii) the algorithm must continue: the last measure left a remainder in R less than measuring number in S.\n",
            "\n",
            "10 IF R = 0 THEN\n",
            "done so\n",
            "GOTO step 15\n",
            "ELSE\n",
            "CONTINUE TO step 11,\n",
            "\n",
            "E3: [Interchange s and r]: The nut of Euclid's algorithm. Use remainder r to measure what was previously smaller number s; L serves as a temporary location.\n",
            "\n",
            "11 L ← R\n",
            "12 R ← S\n",
            "13 S ← L\n",
            "14 [Repeat the measuring process]:\n",
            "GOTO 7\n",
            "\n",
            "OUTPUT:\n",
            "\n",
            "15 [Done. S contains the greatest common divisor]:\n",
            "PRINT S\n",
            "\n",
            "DONE:\n",
            "\n",
            "16 HALT, END, STOP.\n",
            "\n",
            "\n",
            "==== An elegant program for Euclid's algorithm ====\n",
            "The following version of Euclid's algorithm requires only six core instructions to do what thirteen are required to do by \"Inelegant\"; worse, \"Inelegant\" requires more types of instructions. The flowchart of \"Elegant\" can be found at the top of this article. In the (unstructured) Basic language, the steps are numbered, and the instruction LET [] = [] is the assignment instruction symbolized by ←.\n",
            "\n",
            "How \"Elegant\" works: instead of an outer \"Euclid loop\", \"Elegant\" calculates the remainder of a division using modulo and shifts the variables A and B in each iteration. The following algorithm can be used with programming languages from the C-family:\n",
            "\n",
            "The standard function abs changes negative integer to positive integer\n",
            "When input A or B has the value 0, the algorithm stops and the result is 0\n",
            "If input A is greater than input B, the algorithm will automatically swap variables A and B during the first iteration via modulo\n",
            "The iteration (a do while loop) starts and only stops when the variable B is set to 0:\n",
            "% calculates the modulo of division A and B, which reduces the number (e.g.: 23 = 3 × 6 + remainder 5)\n",
            "A is equated with B\n",
            "B is equated with the modulo-result\n",
            "The iteration continues as long as B is greater than 0\n",
            "When the iteration stops, variable A always contains the greatest common divisor\n",
            "\n",
            "\n",
            "=== Testing the Euclid algorithms ===\n",
            "Does an algorithm do what its author wants it to do? A few test cases usually give some confidence in the core functionality. But tests are not enough. For test cases, one source uses 3009 and 884. Knuth suggested 40902, 24140. Another interesting case is the two relatively prime numbers 14157 and 5950.\n",
            "But \"exceptional cases\" must be identified and tested. Will \"Inelegant\" perform properly when R > S, S > R, R = S? Ditto for \"Elegant\": B > A, A > B, A = B? (Yes to all). What happens when one number is zero, both numbers are zero? (\"Inelegant\" computes forever in all cases; \"Elegant\" computes forever when A = 0.) What happens if negative numbers are entered? Fractional numbers? If the input numbers, i.e. the domain of the function computed by the algorithm/program, is to include only positive integers including zero, then the failures at zero indicate that the algorithm (and the program that instantiates it) is a partial function rather than a total function. A notable failure due to exceptions is the Ariane 5 Flight 501 rocket failure (June 4, 1996).\n",
            "Proof of program correctness by use of mathematical induction: Knuth demonstrates the application of mathematical induction to an \"extended\" version of Euclid's algorithm, and he proposes \"a general method applicable to proving the validity of any algorithm\". Tausworthe proposes that a measure of the complexity of a program be the length of its correctness proof.\n",
            "\n",
            "\n",
            "=== Measuring and improving the Euclid algorithms ===\n",
            "Elegance (compactness) versus goodness (speed): With only six core instructions, \"Elegant\" is the clear winner, compared to \"Inelegant\" at thirteen instructions. However, \"Inelegant\" is faster (it arrives at HALT in fewer steps). Algorithm analysis indicates why this is the case: \"Elegant\" does two conditional tests in every subtraction loop, whereas \"Inelegant\" only does one. As the algorithm (usually) requires many loop-throughs, on average much time is wasted doing a \"B = 0?\" test that is needed only after the remainder is computed.\n",
            "Can the algorithms be improved?: Once the programmer judges a program \"fit\" and \"effective\"—that is, it computes the function intended by its author—then the question becomes, can it be improved?\n",
            "The compactness of \"Inelegant\" can be improved by the elimination of five steps. But Chaitin proved that compacting an algorithm cannot be automated by a generalized algorithm; rather, it can only be done heuristically; i.e., by exhaustive search (examples to be found at Busy beaver), trial and error, cleverness, insight, application of inductive reasoning, etc. Observe that steps 4, 5 and 6 are repeated in steps 11, 12 and 13. Comparison with \"Elegant\" provides a hint that these steps, together with steps 2 and 3, can be eliminated. This reduces the number of core instructions from thirteen to eight, which makes it \"more elegant\" than \"Elegant\", at nine steps.\n",
            "The speed of \"Elegant\" can be improved by moving the \"B=0?\" test outside of the two subtraction loops. This change calls for the addition of three instructions (B = 0?, A = 0?, GOTO). Now \"Elegant\" computes the example-numbers faster; whether this is always the case for any given A, B, and R, S would require a detailed analysis.\n",
            "\n",
            "\n",
            "== Algorithmic analysis ==\n",
            "\n",
            "It is frequently important to know how much of a particular resource (such as time or storage) is theoretically required for a given algorithm. Methods have been developed for the analysis of algorithms to obtain such quantitative answers (estimates); for example, an algorithm which adds up the elements of a list of n numbers would have a time requirement of \n",
            "  \n",
            "    \n",
            "      \n",
            "        O\n",
            "        (\n",
            "        n\n",
            "        )\n",
            "      \n",
            "    \n",
            "    {\\displaystyle O(n)}\n",
            "  , using big O notation. At all times the algorithm only needs to remember two values: the sum of all the elements so far, and its current position in the input list. Therefore, it is said to have a space requirement of \n",
            "  \n",
            "    \n",
            "      \n",
            "        O\n",
            "        (\n",
            "        1\n",
            "        )\n",
            "      \n",
            "    \n",
            "    {\\displaystyle O(1)}\n",
            "  , if the space required to store the input numbers is not counted, or \n",
            "  \n",
            "    \n",
            "      \n",
            "        O\n",
            "        (\n",
            "        n\n",
            "        )\n",
            "      \n",
            "    \n",
            "    {\\displaystyle O(n)}\n",
            "   if it is counted.\n",
            "Different algorithms may complete the same task with a different set of instructions in less or more time, space, or 'effort' than others. For example, a binary search algorithm (with cost \n",
            "  \n",
            "    \n",
            "      \n",
            "        O\n",
            "        (\n",
            "        log\n",
            "        ⁡\n",
            "        n\n",
            "        )\n",
            "      \n",
            "    \n",
            "    {\\displaystyle O(\\log n)}\n",
            "  ) outperforms a sequential search (cost \n",
            "  \n",
            "    \n",
            "      \n",
            "        O\n",
            "        (\n",
            "        n\n",
            "        )\n",
            "      \n",
            "    \n",
            "    {\\displaystyle O(n)}\n",
            "   ) when used for table lookups on sorted lists or arrays.\n",
            "\n",
            "\n",
            "=== Formal versus empirical ===\n",
            "\n",
            "The analysis, and study of algorithms is a discipline of computer science, and is often practiced abstractly without the use of a specific programming language or implementation. In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. Usually pseudocode is used for analysis as it is the simplest and most general representation. However, ultimately, most algorithms are usually implemented on particular hardware/software platforms and their algorithmic efficiency is eventually put to the test using real code. For the solution of a \"one off\" problem, the efficiency of a particular algorithm may not have significant consequences (unless n is extremely large) but for algorithms designed for fast interactive, commercial or long life scientific usage it may be critical. Scaling from small n to large n frequently exposes inefficient algorithms that are otherwise benign.\n",
            "Empirical testing is useful because it may uncover unexpected interactions that affect performance. Benchmarks may be used to compare before/after potential improvements to an algorithm after program optimization.\n",
            "Empirical tests cannot replace formal analysis, though, and are not trivial to perform in a fair manner.\n",
            "\n",
            "\n",
            "=== Execution efficiency ===\n",
            "\n",
            "To illustrate the potential improvements possible even in well-established algorithms, a recent significant innovation, relating to FFT algorithms (used heavily in the field of image processing), can decrease processing time up to 1,000 times for applications like medical imaging. In general, speed improvements depend on special properties of the problem, which are very common in practical applications. Speedups of this magnitude enable computing devices that make extensive use of image processing (like digital cameras and medical equipment) to consume less power.\n",
            "\n",
            "\n",
            "== Classification ==\n",
            "There are various ways to classify algorithms, each with its own merits.\n",
            "\n",
            "\n",
            "=== By implementation ===\n",
            "One way to classify algorithms is by implementation means.\n",
            "\n",
            "Recursion\n",
            "A recursive algorithm is one that invokes (makes reference to) itself repeatedly until a certain condition (also known as termination condition) matches, which is a method common to functional programming. Iterative algorithms use repetitive constructs like loops and sometimes additional data structures like stacks to solve the given problems. Some problems are naturally suited for one implementation or the other. For example, towers of Hanoi is well understood using recursive implementation. Every recursive version has an equivalent (but possibly more or less complex) iterative version, and vice versa.\n",
            "Serial, parallel or distributed\n",
            "Algorithms are usually discussed with the assumption that computers execute one instruction of an algorithm at a time. Those computers are sometimes called serial computers. An algorithm designed for such an environment is called a serial algorithm, as opposed to parallel algorithms or distributed algorithms. Parallel algorithms are algorithms that take advantage of computer architectures where multiple processors can work on a problem at the same time. Distributed algorithms are algorithms that use multiple machines connected with a computer network. Parallel and distributed algorithms divide the problem into more symmetrical or asymmetrical subproblems and collect the results back together. For example, a CPU would be an example of a parallel algorithm. The resource consumption in such algorithms is not only processor cycles on each processor but also the communication overhead between the processors. Some sorting algorithms can be parallelized efficiently, but their communication overhead is expensive. Iterative algorithms are generally parallelizable, but some problems have no parallel algorithms and are called inherently serial problems.\n",
            "Deterministic or non-deterministic\n",
            "Deterministic algorithms solve the problem with exact decision at every step of the algorithm whereas non-deterministic algorithms solve problems via guessing although typical guesses are made more accurate through the use of heuristics.\n",
            "Exact or approximate\n",
            "While many algorithms reach an exact solution, approximation algorithms seek an approximation that is closer to the true solution. The approximation can be reached by either using a deterministic or a random strategy. Such algorithms have practical value for many hard problems. One of the examples of an approximate algorithm is the Knapsack problem, where there is a set of given items. Its goal is to pack the knapsack to get the maximum total value. Each item has some weight and some value. Total weight that can be carried is no more than some fixed number X. So, the solution must consider weights of items as well as their value.\n",
            "Quantum algorithm\n",
            "They run on a realistic model of quantum computation. The term is usually used for those algorithms which seem inherently quantum, or use some essential feature of Quantum computing such as quantum superposition or quantum entanglement.\n",
            "\n",
            "\n",
            "=== By design paradigm ===\n",
            "Another way of classifying algorithms is by their design methodology or paradigm. There is a certain number of paradigms, each different from the other. Furthermore, each of these categories includes many different types of algorithms. Some common paradigms are:\n",
            "\n",
            "Brute-force or exhaustive search\n",
            "Brute force is a method of problem-solving that involves systematically trying every possible option until the optimal solution is found. This approach can be very time consuming, as it requires going through every possible combination of variables. However, it is often used when other methods are not available or too complex. Brute force can be used to solve a variety of problems, including finding the shortest path between two points and cracking passwords.\n",
            "Divide and conquer\n",
            "A divide-and-conquer algorithm repeatedly reduces an instance of a problem to one or more smaller instances of the same problem (usually recursively) until the instances are small enough to solve easily. One such example of divide and conquer is merge sorting. Sorting can be done on each segment of data after dividing data into segments and sorting of entire data can be obtained in the conquer phase by merging the segments. A simpler variant of divide and conquer is called a decrease-and-conquer algorithm, which solves an identical subproblem and uses the solution of this subproblem to solve the bigger problem. Divide and conquer divides the problem into multiple subproblems and so the conquer stage is more complex than decrease and conquer algorithms. An example of a decrease and conquer algorithm is the binary search algorithm.\n",
            "Search and enumeration\n",
            "Many problems (such as playing chess) can be modeled as problems on graphs. A graph exploration algorithm specifies rules for moving around a graph and is useful for such problems. This category also includes search algorithms, branch and bound enumeration and backtracking.\n",
            "Randomized algorithm\n",
            "Such algorithms make some choices randomly (or pseudo-randomly). They can be very useful in finding approximate solutions for problems where finding exact solutions can be impractical (see heuristic method below). For some of these problems, it is known that the fastest approximations must involve some randomness. Whether randomized algorithms with polynomial time complexity can be the fastest algorithms for some problems is an open question known as the P versus NP problem. There are two large classes of such algorithms:Monte Carlo algorithms return a correct answer with high-probability. E.g. RP is the subclass of these that run in polynomial time.\n",
            "Las Vegas algorithms always return the correct answer, but their running time is only probabilistically bound, e.g. ZPP.Reduction of complexity\n",
            "This technique involves solving a difficult problem by transforming it into a better-known problem for which we have (hopefully) asymptotically optimal algorithms. The goal is to find a reducing algorithm whose complexity is not dominated by the resulting reduced algorithm's. For example, one selection algorithm for finding the median in an unsorted list involves first sorting the list (the expensive portion) and then pulling out the middle element in the sorted list (the cheap portion). This technique is also known as transform and conquer.\n",
            "Back tracking\n",
            "In this approach, multiple solutions are built incrementally and abandoned when it is determined that they cannot lead to a valid full solution.\n",
            "\n",
            "\n",
            "=== Optimization problems ===\n",
            "For optimization problems there is a more specific classification of algorithms; an algorithm for such problems may fall into one or more of the general categories described above as well as into one of the following:\n",
            "\n",
            "Linear programming\n",
            "When searching for optimal solutions to a linear function bound to linear equality and inequality constraints, the constraints of the problem can be used directly in producing the optimal solutions. There are algorithms that can solve any problem in this category, such as the popular simplex algorithm. Problems that can be solved with linear programming include the maximum flow problem for directed graphs. If a problem additionally requires that one or more of the unknowns must be an integer then it is classified in integer programming. A linear programming algorithm can solve such a problem if it can be proved that all restrictions for integer values are superficial, i.e., the solutions satisfy these restrictions anyway. In the general case, a specialized algorithm or an algorithm that finds approximate solutions is used, depending on the difficulty of the problem.\n",
            "Dynamic programming\n",
            "When a problem shows optimal substructures—meaning the optimal solution to a problem can be constructed from optimal solutions to subproblems—and overlapping subproblems, meaning the same subproblems are used to solve many different problem instances, a quicker approach called dynamic programming avoids recomputing solutions that have already been computed. For example, Floyd–Warshall algorithm, the shortest path to a goal from a vertex in a weighted graph can be found by using the shortest path to the goal from all adjacent vertices. Dynamic programming and memoization go together. The main difference between dynamic programming and divide and conquer is that subproblems are more or less independent in divide and conquer, whereas subproblems overlap in dynamic programming. The difference between dynamic programming and straightforward recursion is in caching or memoization of recursive calls. When subproblems are independent and there is no repetition, memoization does not help; hence dynamic programming is not a solution for all complex problems. By using memoization or maintaining a table of subproblems already solved, dynamic programming reduces the exponential nature of many problems to polynomial complexity.\n",
            "The greedy method\n",
            "A greedy algorithm is similar to a dynamic programming algorithm in that it works by examining substructures, in this case not of the problem but of a given solution. Such algorithms start with some solution, which may be given or have been constructed in some way, and improve it by making small modifications. For some problems they can find the optimal solution while for others they stop at local optima, that is, at solutions that cannot be improved by the algorithm but are not optimum. The most popular use of greedy algorithms is for finding the minimal spanning tree where finding the optimal solution is possible with this method. Huffman Tree, Kruskal, Prim, Sollin are greedy algorithms that can solve this optimization problem.\n",
            "The heuristic method\n",
            "In optimization problems, heuristic algorithms can be used to find a solution close to the optimal solution in cases where finding the optimal solution is impractical. These algorithms work by getting closer and closer to the optimal solution as they progress. In principle, if run for an infinite amount of time, they will find the optimal solution. Their merit is that they can find a solution very close to the optimal solution in a relatively short time. Such algorithms include local search, tabu search, simulated annealing, and genetic algorithms. Some of them, like simulated annealing, are non-deterministic algorithms while others, like tabu search, are deterministic. When a bound on the error of the non-optimal solution is known, the algorithm is further categorized as an approximation algorithm.\n",
            "\n",
            "\n",
            "=== By field of study ===\n",
            "\n",
            "Every field of science has its own problems and needs efficient algorithms. Related problems in one field are often studied together. Some example classes are search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, computational geometric algorithms, combinatorial algorithms, medical algorithms, machine learning, cryptography, data compression algorithms and parsing techniques.\n",
            "Fields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. For example, dynamic programming was invented for optimization of resource consumption in industry but is now used in solving a broad range of problems in many fields.\n",
            "\n",
            "\n",
            "=== By complexity ===\n",
            "\n",
            "Algorithms can be classified by the amount of time they need to complete compared to their input size:\n",
            "\n",
            "Constant time: if the time needed by the algorithm is the same, regardless of the input size. E.g. an access to an array element.\n",
            "Logarithmic time: if the time is a logarithmic function of the input size. E.g. binary search algorithm.\n",
            "Linear time: if the time is proportional to the input size. E.g. the traverse of a list.\n",
            "Polynomial time: if the time is a power of the input size. E.g. the bubble sort algorithm has quadratic time complexity.\n",
            "Exponential time: if the time is an exponential function of the input size. E.g. Brute-force search.Some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. There are also mappings from some problems to other problems. Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.\n",
            "\n",
            "\n",
            "=== Continuous algorithms ===\n",
            "The adjective \"continuous\" when applied to the word \"algorithm\" can mean:\n",
            "\n",
            "An algorithm operating on data that represents continuous quantities, even though this data is represented by discrete approximations—such algorithms are studied in numerical analysis; or\n",
            "An algorithm in the form of a differential equation that operates continuously on the data, running on an analog computer.\n",
            "\n",
            "\n",
            "== Algorithm = Logic + Control ==\n",
            "In logic programming, algorithms are viewed as having both \"a logic component, which specifies the knowledge to be  used in solving problems, and a control component, which determines the problem-solving strategies by means of which that knowledge is used.\"The Euclidean algorithm illustrates this view of an algorithm. Here is a logic programming representation, using :- to represent \"if\", and the relation gcd(A, B, C) to represent the function gcd(A, B) = C: \n",
            "\n",
            "In the logic programming language Ciao the gcd relation can be represented directly in functional notation:\n",
            "\n",
            "The Ciao implementation translates the functional notation into a relational representation in   Prolog, extracting the embedded subtractions, A-B and B-A, as separate conditions:\n",
            "\n",
            "The resulting program has a purely logical (and \"declarative\") reading, as a recursive (or inductive) definition, which is independent of how the logic is used to solve problems:\n",
            "\n",
            "Different problem-solving strategies turn the logic into different algorithms. In theory, given a pair of integers A and B, forward (or \"bottom-up\") reasoning could be used to generate all instances of the gcd relation, terminating when the desired gcd of A and B is generated. Of course, forward reasoning is entirely useless in this case. But in other cases, such as the definition of the Fibonacci sequence and Datalog, forward reasoning can be an efficient problem solving strategy. (See for example the logic program for computing fibonacci numbers in Algorithm = Logic + Control).\n",
            "In contrast with the inefficiency of forward reasoning in this example, backward (or \"top-down\") reasoning using SLD resolution turns the logic into the Euclidean algorithm:\n",
            "\n",
            "One of the advantages of the logic programming representation of the algorithm is that its purely logical reading makes it easier to verify that the algorithm is correct relative to the standard non-recursive definition of gcd. Here is the standard definition written in Prolog:\n",
            "\n",
            "This definition, which is the specification of the Euclidean algorithm, is also executable in Prolog: Backward reasoning treats the specification as the brute-force algorithm that iterates through all of the integers C between 1 and A, checking whether C divides both A and B, and then for each such C iterates again through all of the integers D between 1 and A, until it finds a C such that C is greater than or equal to all of the D that also divide both A and B. Although this algorithm is hopelessly inefficient, it shows that formal specifications can often be written in logic programming form, and they can be executed by Prolog, to check that they correctly represent informal requirements.\n",
            "\n",
            "\n",
            "== Legal issues ==\n",
            "\n",
            "Algorithms, by themselves, are not usually patentable. In the United States, a claim consisting solely of simple manipulations of abstract concepts, numbers, or signals does not constitute \"processes\" (USPTO 2006), so algorithms are not patentable (as in Gottschalk v. Benson). However practical applications of algorithms are sometimes patentable. For example, in Diamond v. Diehr, the application of a simple feedback algorithm to aid in the curing of synthetic rubber was deemed patentable. The patenting of software is controversial, and there are criticized patents involving algorithms, especially data compression algorithms, such as Unisys's LZW patent.\n",
            "Additionally, some cryptographic algorithms have export restrictions (see export of cryptography).\n",
            "\n",
            "\n",
            "== History: Development of the notion of \"algorithm\" ==\n",
            "\n",
            "\n",
            "=== Ancient Near East ===\n",
            "The earliest evidence of algorithms is found in the Babylonian mathematics of ancient Mesopotamia (modern Iraq). A Sumerian clay tablet found in Shuruppak near Baghdad and dated to c. 2500 BC described the earliest division algorithm. During the Hammurabi dynasty c. 1800 – c. 1600 BC, Babylonian clay tablets described algorithms for computing formulas. Algorithms were also used in Babylonian astronomy. Babylonian clay tablets describe and employ algorithmic procedures to compute the time and place of significant astronomical events.Algorithms for arithmetic are also found in ancient Egyptian mathematics, dating back to the Rhind Mathematical Papyrus c. 1550 BC. Algorithms were later used in ancient Hellenistic mathematics. Two examples are the Sieve of Eratosthenes, which was described in the Introduction to Arithmetic by Nicomachus,: Ch 9.2  and the Euclidean algorithm, which was first described in Euclid's Elements (c. 300 BC).: Ch 9.1 \n",
            "\n",
            "\n",
            "=== Discrete and distinguishable symbols ===\n",
            "Tally-marks: To keep track of their flocks, their sacks of grain and their money the ancients used tallying: accumulating stones or marks scratched on sticks or making discrete symbols in clay. Through the Babylonian and Egyptian use of marks and symbols, eventually Roman numerals and the abacus evolved (Dilson, p. 16–41). Tally marks appear prominently in unary numeral system arithmetic used in Turing machine and Post–Turing machine computations.\n",
            "\n",
            "\n",
            "=== Manipulation of symbols as \"place holders\" for numbers: algebra ===\n",
            "Muhammad ibn Mūsā al-Khwārizmī, a Persian mathematician, wrote the Al-jabr in the 9th century. The terms \"algorism\" and \"algorithm\" are derived from the name al-Khwārizmī, while the term \"algebra\" is derived from the book Al-jabr. In Europe, the word \"algorithm\" was originally used to refer to the sets of rules and techniques used by Al-Khwarizmi to solve algebraic equations, before later being generalized to refer to any set of rules or techniques. This eventually culminated in Leibniz's notion of the calculus ratiocinator (c. 1680):\n",
            "\n",
            "A good century and a half ahead of his time, Leibniz proposed an algebra of logic, an algebra that would specify the rules for manipulating logical concepts in the manner that ordinary algebra specifies the rules for manipulating numbers.\n",
            "\n",
            "\n",
            "=== Cryptographic algorithms ===\n",
            "The first cryptographic algorithm for deciphering encrypted code was developed by Al-Kindi, a 9th-century Arab mathematician, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest codebreaking algorithm.\n",
            "\n",
            "\n",
            "=== Mechanical contrivances with discrete states ===\n",
            "The clock: Bolter credits the invention of the weight-driven clock as \"The key invention [of Europe in the Middle Ages]\", in particular, the verge escapement that provides us with the tick and tock of a mechanical clock. \"The accurate automatic machine\" led immediately to \"mechanical automata\" beginning in the 13th century and finally to \"computational machines\"—the difference engine and analytical engines of Charles Babbage and Countess Ada Lovelace, mid-19th century. Lovelace is credited with the first creation of an algorithm intended for processing on a computer—Babbage's analytical engine, the first device considered a real Turing-complete computer instead of just a calculator—and is sometimes called \"history's first programmer\" as a result, though a full implementation of Babbage's second device would not be realized until decades after her lifetime.\n",
            "Logical machines 1870 – Stanley Jevons' \"logical abacus\" and \"logical machine\": The technical problem was to reduce Boolean equations when presented in a form similar to what is now known as Karnaugh maps. Jevons (1880) describes first a simple \"abacus\" of \"slips of wood furnished with pins, contrived so that any part or class of the [logical] combinations can be picked out mechanically ... More recently, however, I have reduced the system to a completely mechanical form, and have thus embodied the whole of the indirect process of inference in what may be called a Logical Machine\" His machine came equipped with \"certain moveable wooden rods\" and \"at the foot are 21 keys like those of a piano [etc.] ...\". With this machine he could analyze a \"syllogism or any other simple logical argument\".This machine he displayed in 1870 before the Fellows of the Royal Society. Another logician John Venn, however, in his 1881 Symbolic Logic, turned a jaundiced eye to this effort: \"I have no high estimate myself of the interest or importance of what are sometimes called logical machines ... it does not seem to me that any contrivances at present known or likely to be discovered really deserve the name of logical machines\"; see more at Algorithm characterizations. But not to be outdone he too presented \"a plan somewhat analogous, I apprehend, to Prof. Jevon's abacus ... [And] [a]gain, corresponding to Prof. Jevons's logical machine, the following contrivance may be described. I prefer to call it merely a logical-diagram machine ... but I suppose that it could do very completely all that can be rationally expected of any logical machine\".Jacquard loom, Hollerith punch cards, telegraphy and telephony – the electromechanical relay: Bell and Newell (1971) indicate that the Jacquard loom (1801), precursor to Hollerith cards (punch cards, 1887), and \"telephone switching technologies\" were the roots of a tree leading to the development of the first computers. By the mid-19th century the telegraph, the precursor of the telephone, was in use throughout the world, its discrete and distinguishable encoding of letters as \"dots and dashes\" a common sound. By the late 19th century the ticker tape (c. 1870s) was in use, as was the use of Hollerith cards in the 1890 U.S. census. Then came the teleprinter (c. 1910) with its punched-paper use of Baudot code on tape.\n",
            "Telephone-switching networks of electromechanical relays (invented 1835) was behind the work of George Stibitz (1937), the inventor of the digital adding device. As he worked in Bell Laboratories, he observed the \"burdensome' use of mechanical calculators with gears. \"He went home one evening in 1937 intending to test his idea... When the tinkering was over, Stibitz had constructed a binary adding device\".The mathematician Martin Davis observes the particular importance of the electromechanical relay (with its two \"binary states\" open and closed):\n",
            "\n",
            "It was only with the development, beginning in the 1930s, of electromechanical calculators using electrical relays, that machines were built having the scope Babbage had envisioned.\"\n",
            "\n",
            "\n",
            "=== Mathematics during the 19th century up to the mid-20th century ===\n",
            "Symbols and rules: In rapid succession, the mathematics of George Boole (1847, 1854), Gottlob Frege (1879), and Giuseppe Peano (1888–1889) reduced arithmetic to a sequence of symbols manipulated by rules. Peano's The principles of arithmetic, presented by a new method (1888) was \"the first attempt at an axiomatization of mathematics in a symbolic language\".But Heijenoort gives Frege (1879) this kudos: Frege's is \"perhaps the most important single work ever written in logic. ... in which we see a \"'formula language', that is a lingua characterica, a language written with special symbols, \"for pure thought\", that is, free from rhetorical embellishments ... constructed from specific symbols that are manipulated according to definite rules\". The work of Frege was further simplified and amplified by Alfred North Whitehead and Bertrand Russell in their Principia Mathematica (1910–1913).\n",
            "The paradoxes: At the same time a number of disturbing paradoxes appeared in the literature, in particular, the Burali-Forti paradox (1897), the Russell paradox (1902–03), and the Richard Paradox. The resultant considerations led to Kurt Gödel's paper (1931)—he specifically cites the paradox of the liar—that completely reduces rules of recursion to numbers.\n",
            "Effective calculability: In an effort to solve the Entscheidungsproblem defined precisely by Hilbert in 1928, mathematicians first set about to define what was meant by an \"effective method\" or \"effective calculation\" or \"effective calculability\" (i.e., a calculation that would succeed). In rapid succession the following appeared: Alonzo Church, Stephen Kleene and J.B. Rosser's λ-calculus a finely honed definition of \"general recursion\" from the work of Gödel acting on suggestions of Jacques Herbrand (cf. Gödel's Princeton lectures of 1934) and subsequent simplifications by Kleene. Church's proof that the Entscheidungsproblem was unsolvable, Emil Post's definition of effective calculability as a worker mindlessly following a list of instructions to move left or right through a sequence of rooms and while there either mark or erase a paper or observe the paper and make a yes-no decision about the next instruction. Alan Turing's proof of that the Entscheidungsproblem was unsolvable by use of his \"a- [automatic-] machine\"—in effect almost identical to Post's \"formulation\", J. Barkley Rosser's definition of \"effective method\" in terms of \"a machine\". Kleene's proposal of a precursor to \"Church thesis\" that he called \"Thesis I\", and a few years later Kleene's renaming his Thesis \"Church's Thesis\" and proposing \"Turing's Thesis\".\n",
            "\n",
            "\n",
            "=== Emil Post (1936) and Alan Turing (1936–37, 1939) ===\n",
            "Emil Post (1936) described the actions of a \"computer\" (human being) as follows:\n",
            "\n",
            "\"...two concepts are involved: that of a symbol space in which the work leading from problem to answer is to be carried out, and a fixed unalterable set of directions.His symbol space would be\n",
            "\n",
            "\"a two-way infinite sequence of spaces or boxes ... The problem solver or worker is to move and work in this symbol space, being capable of being in, and operating in but one box at a time. ... a box is to admit of but two possible conditions, i.e., being empty or unmarked, and having a single mark in it, say a vertical stroke.\"One box is to be singled out and called the starting point. ... a specific problem is to be given in symbolic form by a finite number of boxes [i.e., INPUT] being marked with a stroke. Likewise, the answer [i.e., OUTPUT] is to be given in symbolic form by such a configuration of marked boxes...\"A set of directions applicable to a general problem sets up a deterministic process when applied to each specific problem. This process terminates only when it comes to the direction of type (C ) [i.e., STOP]\". See more at Post–Turing machineAlan Turing's work preceded that of Stibitz (1937); it is unknown whether Stibitz knew of the work of Turing. Turing's biographer believed that Turing's use of a typewriter-like model derived from a youthful interest: \"Alan had dreamt of inventing typewriters as a boy; Mrs. Turing had a typewriter, and he could well have begun by asking himself what was meant by calling a typewriter 'mechanical'\". Given the prevalence at the time of Morse code, telegraphy, ticker tape machines, and teletypewriters, it is quite possible that all were influences on Turing during his youth.\n",
            "Turing—his model of computation is now called a Turing machine—begins, as did Post, with an analysis of a human computer that he whittles down to a simple set of basic motions and \"states of mind\". But he continues a step further and creates a machine as a model of computation of numbers.\n",
            "\"Computing is normally done by writing certain symbols on paper. We may suppose this paper is divided into squares like a child's arithmetic book...I assume then that the computation is carried out on one-dimensional paper, i.e., on a tape divided into squares. I shall also suppose that the number of symbols which may be printed is finite...\"The behavior of the computer at any moment is determined by the symbols which he is observing, and his \"state of mind\" at that moment. We may suppose that there is a bound B to the number of symbols or squares that the computer can observe at one moment. If he wishes to observe more, he must use successive observations. We will also suppose that the number of states of mind which need be taken into account is finite...\"Let us imagine that the operations performed by the computer to be split up into 'simple operations' which are so elementary that it is not easy to imagine them further divided.\"Turing's reduction yields the following:\n",
            "\n",
            "\"The simple operations must therefore include:\n",
            "\"(a) Changes of the symbol on one of the observed squares\n",
            "\"(b) Changes of one of the squares observed to another square within L squares of one of the previously observed squares.\"It may be that some of these change necessarily invoke a change of state of mind. The most general single operation must, therefore, be taken to be one of the following:\n",
            "\n",
            "\"(A) A possible change (a) of symbol together with a possible change of state of mind.\n",
            "\"(B) A possible change (b) of observed squares, together with a possible change of state of mind\"\"We may now construct a machine to do the work of this computer.\"A few years later, Turing expanded his analysis (thesis, definition) with this forceful expression of it:\n",
            "\n",
            "\"A function is said to be \"effectively calculable\" if its values can be found by some purely mechanical process. Though it is fairly easy to get an intuitive grasp of this idea, it is nevertheless desirable to have some more definite, mathematical expressible definition ... [he discusses the history of the definition pretty much as presented above with respect to Gödel, Herbrand, Kleene, Church, Turing, and Post] ... We may take this statement literally, understanding by a purely mechanical process one which could be carried out by a machine. It is possible to give a mathematical description, in a certain normal form, of the structures of these machines. The development of these ideas leads to the author's definition of a computable function, and to an identification of computability † with effective calculability...\n",
            "\"† We shall use the expression \"computable function\" to mean a function calculable by a machine, and we let \"effectively calculable\" refer to the intuitive idea without particular identification with any one of these definitions\".\n",
            "\n",
            "\n",
            "=== J. B. Rosser (1939) and S. C. Kleene (1943) ===\n",
            "J. Barkley Rosser defined an \"effective [mathematical] method\" in the following manner (italicization added):\n",
            "\n",
            "\"'Effective method' is used here in the rather special sense of a method each step of which is precisely determined and which is certain to produce the answer in a finite number of steps. With this special meaning, three different precise definitions have been given to date. [his footnote #5; see discussion immediately below]. The simplest of these to state (due to Post and Turing) says essentially that an effective method of solving certain sets of problems exists if one can build a machine which will then solve any problem of the set with no human intervention beyond inserting the question and (later) reading the answer. All three definitions are equivalent, so it doesn't matter which one is used. Moreover, the fact that all three are equivalent is a very strong argument for the correctness of any one.\" (Rosser 1939:225–226)Rosser's footnote No. 5 references the work of (1) Church and Kleene and their definition of λ-definability, in particular, Church's use of it in his An Unsolvable Problem of Elementary Number Theory (1936); (2) Herbrand and Gödel and their use of recursion, in particular, Gödel's use in his famous paper On Formally Undecidable Propositions of Principia Mathematica and Related Systems I (1931); and (3) Post (1936) and Turing (1936–37) in their mechanism-models of computation.\n",
            "Stephen C. Kleene defined as his now-famous \"Thesis I\" known as the Church–Turing thesis. But he did this in the following context (boldface in original):\n",
            "\n",
            "\"12. Algorithmic theories... In setting up a complete algorithmic theory, what we do is to describe a procedure, performable for each set of values of the independent variables, which procedure necessarily terminates and in such manner that from the outcome we can read a definite answer, \"yes\" or \"no,\" to the question, \"is the predicate value true?\"\" (Kleene 1943:273)\n",
            "\n",
            "\n",
            "=== History after 1950 ===\n",
            "A number of efforts have been directed toward further refinement of the definition of \"algorithm\", and activity is on-going because of issues surrounding, in particular, foundations of mathematics (especially the Church–Turing thesis) and philosophy of mind (especially arguments about artificial intelligence). For more, see Algorithm characterizations.\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== Notes ==\n",
            "\n",
            "\n",
            "== Bibliography ==\n",
            "\n",
            "Zaslavsky, C. (1970). Mathematics of the Yoruba People and of Their Neighbors in Southern Nigeria. The Two-Year College Mathematics Journal, 1(2), 76–99. https://doi.org/10.2307/3027363\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "\"Algorithm\". Encyclopedia of Mathematics. EMS Press. 2001 [1994].\n",
            "Algorithms at Curlie\n",
            "Weisstein, Eric W. \"Algorithm\". MathWorld.\n",
            "Dictionary of Algorithms and Data Structures – National Institute of Standards and TechnologyAlgorithm repositoriesThe Stony Brook Algorithm Repository – State University of New York at Stony Brook\n",
            "Collected Algorithms of the ACM – Associations for Computing Machinery\n",
            "The Stanford GraphBase Archived December 6, 2015, at the Wayback Machine – Stanford University...\n",
            "\n",
            "\n",
            "Page Title: Programming Languages\n",
            "Text: A programming language is a system of notation for writing computer programs.\n",
            "A programming language is usually described in terms of its syntax (form) and semantics (meaning). These are usually defined by a formal language.A language usually has at least one implementation in the form of a compiler or interpreter, allowing programs written in the language to be executed.\n",
            "Programming language theory is the subfield of computer science that studies the design, implementation, analysis, characterization, and classification of programming languages.\n",
            "\n",
            "\n",
            "== Definitions ==\n",
            "There are many considerations when defining what constitutes a programming language.\n",
            "\n",
            "\n",
            "=== Computer languages vs programming languages ===\n",
            "The term computer language is sometimes used interchangeably with programming language. However, the usage of both terms varies among authors, including the exact scope of each. One usage describes programming languages as a subset of computer languages. Similarly, languages used in computing that have a different goal than expressing computer programs are generically designated computer languages. For instance, markup languages are sometimes referred to as computer languages to emphasize that they are not meant to be used for programming.\n",
            "One way of classifying computer languages is by the computations they are capable of expressing, as described by the theory of computation. The majority of practical programming languages are Turing complete, and all Turing complete languages can implement the same set of algorithms. ANSI/ISO SQL-92 and Charity are examples of languages that are not Turing complete, yet are often called programming languages. However, some authors restrict the term \"programming language\" to Turing complete languages.Another usage regards programming languages as theoretical constructs for programming abstract machines and computer languages as the subset thereof that runs on physical computers, which have finite hardware resources. John C. Reynolds emphasizes that formal specification languages are just as much programming languages as are the languages intended for execution. He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats.\n",
            "\n",
            "\n",
            "=== Domain and target ===\n",
            "In most practical contexts, a programming language involves a computer; consequently, programming languages are usually defined and studied this way. Programming languages differ from natural languages in that natural languages are only used for interaction between people, while programming languages also allow humans to communicate instructions to machines.\n",
            "The domain of the language is also worth consideration. Markup languages like XML, HTML, or troff, which define structured data, are not usually considered programming languages. Programming languages may, however, share the syntax with markup languages if a computational semantics is defined. XSLT, for example, is a Turing complete language entirely using XML syntax. Moreover, LaTeX, which is mostly used for structuring documents, also contains a Turing complete subset.\n",
            "\n",
            "\n",
            "=== Abstractions ===\n",
            "Programming languages usually contain abstractions for defining and manipulating data structures or controlling the flow of execution. The practical necessity that a programming language support adequate abstractions is expressed by the abstraction principle. This principle is sometimes formulated as a recommendation to the programmer to make proper use of such abstractions.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "\n",
            "=== Early developments ===\n",
            "Very early computers, such as Colossus, were programmed without the help of a stored program, by modifying their circuitry or setting banks of physical controls.\n",
            "Slightly later, programs could be written in machine language, where the programmer writes each instruction in a numeric form the hardware can execute directly. For example, the instruction to add the value in two memory locations might consist of 3 numbers: an \"opcode\" that selects the \"add\" operation, and two memory locations. The programs, in decimal or binary form, were read in from punched cards, paper tape, magnetic tape or toggled in on switches on the front panel of the computer. Machine languages were later termed first-generation programming languages (1GL).\n",
            "The next step was the development of the so-called second-generation programming languages (2GL) or assembly languages, which were still closely tied to the instruction set architecture of the specific computer. These served to make the program much more human-readable and relieved the programmer of tedious and error-prone address calculations.\n",
            "The first high-level programming languages, or third-generation programming languages (3GL), were written in the 1950s. An early high-level programming language to be designed for a computer was Plankalkül, developed for the German Z3 by Konrad Zuse between 1943 and 1945. However, it was not implemented until 1998 and 2000.John Mauchly's Short Code, proposed in 1949, was one of the first high-level languages ever developed for an electronic computer. Unlike machine code, Short Code statements represented mathematical expressions in an understandable form. However, the program had to be translated into machine code every time it ran, making the process much slower than running the equivalent machine code.\n",
            "At the University of Manchester, Alick Glennie developed Autocode in the early 1950s. As a programming language, it used a compiler to automatically convert the language into machine code. The first code and compiler was developed in 1952 for the Mark 1 computer at the University of Manchester and is considered to be the first compiled high-level programming language.The second auto code was developed for the Mark 1 by R. A. Brooker in 1954 and was called the \"Mark 1 Autocode\". Brooker also developed an auto code for the Ferranti Mercury in the 1950s in conjunction with the University of Manchester. The version for the EDSAC 2 was devised by D. F. Hartley of University of Cambridge Mathematical Laboratory in 1961. Known as EDSAC 2 Autocode, it was a straight development from Mercury Autocode adapted for local circumstances and was noted for its object code optimization and source-language diagnostics which were advanced for the time. A contemporary but separate thread of development, Atlas Autocode was developed for the University of Manchester Atlas 1 machine.\n",
            "In 1954, FORTRAN was invented at IBM by John Backus. It was the first widely used high-level general-purpose programming language to have a functional implementation, as opposed to just a design on paper. It is still a popular language for high-performance computing and is used for programs that benchmark and rank the world's fastest supercomputers.Another early programming language was devised by Grace Hopper in the US, called FLOW-MATIC. It was developed for the UNIVAC I at Remington Rand during the period from 1955 until 1959. Hopper found that business data processing customers were uncomfortable with mathematical notation, and in early 1955, she and her team wrote a specification for an English programming language and implemented a prototype. The FLOW-MATIC compiler became publicly available in early 1958 and was substantially complete in 1959. FLOW-MATIC was a major influence in the design of COBOL, since only it and its direct descendant AIMACO were in actual use at the time.\n",
            "\n",
            "\n",
            "=== Refinement ===\n",
            "The increased use of high-level languages introduced a requirement for low-level programming languages or system programming languages. These languages, to varying degrees, provide facilities between assembly languages and high-level languages. They can be used to perform tasks that require direct access to hardware facilities but still provide higher-level control structures and error-checking.\n",
            "The period from the 1960s to the late 1970s brought the development of the major language paradigms now in use:\n",
            "\n",
            "APL introduced array programming and influenced functional programming.\n",
            "ALGOL refined both structured procedural programming and the discipline of language specification; the \"Revised Report on the Algorithmic Language ALGOL 60\" became a model for how later language specifications were written.\n",
            "Lisp, implemented in 1958, was the first dynamically-typed functional programming language.\n",
            "In the 1960s, Simula was the first language designed to support object-oriented programming; in the mid-1970s, Smalltalk followed with the first \"purely\" object-oriented language.\n",
            "C was developed between 1969 and 1973 as a system programming language for the Unix operating system and remains popular.\n",
            "Prolog, designed in 1972, was the first logic programming language.\n",
            "In 1978, ML built a polymorphic type system on top of Lisp, pioneering statically-typed functional programming languages.Each of these languages spawned descendants, and most modern programming languages count at least one of them in their ancestry.\n",
            "The 1960s and 1970s also saw considerable debate over the merits of structured programming, and whether programming languages should be designed to support it. Edsger Dijkstra, in a famous 1968 letter published in the Communications of the ACM, argued that Goto statements should be eliminated from all \"higher-level\" programming languages.\n",
            "\n",
            "\n",
            "=== Consolidation and growth ===\n",
            "The 1980s were years of relative consolidation. C++ combined object-oriented and systems programming. The United States government standardized Ada, a systems programming language derived from Pascal and intended for use by defense contractors. In Japan and elsewhere, vast sums were spent investigating the so-called \"fifth-generation\" languages that incorporated logic programming constructs. The functional languages community moved to standardize ML and Lisp. Rather than inventing new paradigms, all of these movements elaborated upon the ideas invented in the previous decades.\n",
            "One important trend in language design for programming large-scale systems during the 1980s was an increased focus on the use of modules or large-scale organizational units of code. Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs.The rapid growth of the Internet in the mid-1990s created opportunities for new languages. Perl, originally a Unix scripting tool first released in 1987, became common in dynamic websites. Java came to be used for server-side programming, and bytecode virtual machines became popular again in commercial settings with their promise of \"Write once, run anywhere\" (UCSD Pascal had been popular for a time in the early 1980s). These developments were not fundamentally novel; rather, they were refinements of many existing languages and paradigms (although their syntax was often based on the C family of programming languages).\n",
            "Programming language evolution continues, in both industry and research. Current directions include security and reliability verification, new kinds of modularity (mixins, delegates, aspects), and database integration such as Microsoft's LINQ.\n",
            "Fourth-generation programming languages (4GL) are computer programming languages that aim to provide a higher level of abstraction of the internal computer hardware details than 3GLs. Fifth-generation programming languages (5GL) are programming languages based on solving problems using constraints given to the program, rather than using an algorithm written by a programmer.\n",
            "\n",
            "\n",
            "== Elements ==\n",
            "All programming languages have some primitive building blocks for the description of data and the processes or transformations applied to them (like the addition of two numbers or the selection of an item from a collection). These primitives are defined by syntactic and semantic rules which describe their structure and meaning respectively.\n",
            "\n",
            "\n",
            "=== Syntax ===\n",
            "\n",
            "A programming language's surface form is known as its syntax. Most programming languages are purely textual; they use sequences of text including words, numbers, and punctuation, much like written natural languages. On the other hand, some programming languages are more graphical in nature, using visual relationships between symbols to specify a program.\n",
            "The syntax of a language describes the possible combinations of symbols that form a syntactically correct program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Since most languages are textual, this article discusses textual syntax.\n",
            "The programming language syntax is usually defined using a combination of regular expressions (for lexical structure) and Backus–Naur form (for grammatical structure). Below is a simple grammar, based on Lisp:\n",
            "\n",
            "This grammar specifies the following:\n",
            "\n",
            "an expression is either an atom or a list;\n",
            "an atom is either a number or a symbol;\n",
            "a number is an unbroken sequence of one or more decimal digits, optionally preceded by a plus or minus sign;\n",
            "a symbol is a letter followed by zero or more of any characters (excluding whitespace); and\n",
            "a list is a matched pair of parentheses, with zero or more expressions inside it.The following are examples of well-formed token sequences in this grammar: 12345, () and (a b c232 (1)).\n",
            "Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.\n",
            "Using natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:\n",
            "\n",
            "\"Colorless green ideas sleep furiously.\" is grammatically well-formed but has no generally accepted meaning.\n",
            "\"John is a married bachelor.\" is grammatically well-formed but expresses a meaning that cannot be true.The following C language fragment is syntactically correct, but performs operations that are not semantically defined (the operation *p >> 4 has no meaning for a value having a complex type and p->im is not defined because the value of p is the null pointer):\n",
            "\n",
            "If the type declaration on the first line were omitted, the program would trigger an error on the undefined variable p during compilation. However, the program would still be syntactically correct since type declarations provide only semantic information.\n",
            "The grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The syntax of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars. Some languages, including Perl and Lisp, contain constructs that allow execution during the parsing phase. Languages that have constructs that allow the programmer to alter the behavior of the parser make syntax analysis an undecidable problem, and generally blur the distinction between parsing and execution. In contrast to Lisp's macro system and Perl's BEGIN blocks, which may contain general computations, C macros are merely string replacements and do not require code execution.\n",
            "\n",
            "\n",
            "=== Semantics ===\n",
            "The term semantics refers to the meaning of languages, as opposed to their form (syntax).\n",
            "\n",
            "\n",
            "==== Static semantics ====\n",
            "A static semantics defines restrictions on the structure of valid texts that are hard or impossible to express in standard syntactic formalisms. For compiled languages, static semantics essentially include those semantic rules that can be checked at compile time. Examples include checking that every identifier is declared before it is used (in languages that require such declarations) or that the labels on the arms of a case statement are distinct. Many important restrictions of this type, like checking that identifiers are used in the appropriate context (e.g. not adding an integer to a function name), or that subroutine calls have the appropriate number and type of arguments, can be enforced by defining them as rules in a logic called a type system. Other forms of static analyses like data flow analysis may also be part of static semantics. Newer programming languages like Java and C# have definite assignment analysis, a form of data flow analysis, as part of their static semantics.\n",
            "\n",
            "\n",
            "==== Dynamic semantics ====\n",
            "\n",
            "Once data has been specified, the machine must be instructed to perform operations on the data. For example, the semantics may define the strategy by which expressions are evaluated to values, or the manner in which control structures conditionally execute statements. The dynamic semantics (also known as execution semantics) of a language defines how and when the various constructs of a language should produce a program behavior. There are many ways of defining execution semantics. Natural language is often used to specify the execution semantics of languages commonly used in practice. A significant amount of academic research went into formal semantics of programming languages, which allows execution semantics to be specified in a formal manner. Results from this field of research have seen limited application to programming language design and implementation outside academia.\n",
            "\n",
            "\n",
            "=== Type system ===\n",
            "\n",
            "A type system defines how a programming language classifies values and expressions into types, how it can manipulate those types and how they interact. The goal of a type system is to verify and usually enforce a certain level of correctness in programs written in that language by detecting certain incorrect operations. Any decidable type system involves a trade-off: while it rejects many incorrect programs, it can also prohibit some correct, albeit unusual programs. In order to bypass this downside, a number of languages have type loopholes, usually unchecked casts that may be used by the programmer to explicitly allow a normally disallowed operation between different types. In most typed languages, the type system is used only to type check programs, but a number of languages, usually functional ones, infer types, relieving the programmer from the need to write type annotations. The formal design and study of type systems is known as type theory.\n",
            "\n",
            "\n",
            "==== Typed versus untyped languages ====\n",
            "A language is typed if the specification of every operation defines types of data to which the operation is applicable. For example, the data represented by \"this text between the quotes\" is a string, and in many programming languages dividing a number by a string has no meaning and will not be executed. The invalid operation may be detected when the program is compiled (\"static\" type checking) and will be rejected by the compiler with a compilation error message, or it may be detected while the program is running (\"dynamic\" type checking), resulting in a run-time exception. Many languages allow a function called an exception handler to handle this exception and, for example, always return \"-1\" as the result.\n",
            "A special case of typed languages is the single-typed languages. These are often scripting or markup languages, such as REXX or SGML, and have only one data type–—most commonly character strings which are used for both symbolic and numeric data.\n",
            "In contrast, an untyped language, such as most assembly languages, allows any operation to be performed on any data, generally sequences of bits of various lengths. High-level untyped languages include BCPL, Tcl, and some varieties of Forth.\n",
            "In practice, while few languages are considered typed from the type theory (verifying or rejecting all operations), most modern languages offer a degree of typing. Many production languages provide means to bypass or subvert the type system, trading type safety for finer control over the program's execution (see casting).\n",
            "\n",
            "\n",
            "==== Static vis-à-vis dynamic typing ====\n",
            "In static typing, all expressions have their types determined before a program executes, typically at compile-time. For example, 1 and (2+2) are integer expressions; they cannot be passed to a function that expects a string or stored in a variable that is defined to hold dates.Statically-typed languages can be either manifestly typed or type-inferred. In the first case, the programmer must explicitly write types at certain textual positions (for example, at variable declarations). In the second case, the compiler infers the types of expressions and declarations based on context. Most mainstream statically-typed languages, such as C++, C#, and Java, are manifestly typed. Complete type inference has traditionally been associated with functional languages such as Haskell and ML. However, many manifestly-typed languages support partial type inference; for example, C++, Java, and C# all infer types in certain limited cases. Additionally, some programming languages allow for some types to be automatically converted to other types; for example, an int can be used where the program expects a float.\n",
            "Dynamic typing, also called latent typing, determines the type-safety of operations at run time; in other words, types are associated with run-time values rather than textual expressions. As with type-inferred languages, dynamically-typed languages do not require the programmer to write explicit type annotations on expressions. Among other things, this may permit a single variable to refer to values of different types at different points in the program execution. However, type errors cannot be automatically detected until a piece of code is actually executed, potentially making debugging more difficult. Lisp, Smalltalk, Perl, Python, JavaScript, and Ruby are all examples of dynamically-typed languages.\n",
            "\n",
            "\n",
            "==== Weak and strong typing ====\n",
            "Weak typing allows a value of one type to be treated as another, for example treating a string as a number. This can occasionally be useful, but it can also allow some kinds of program faults to go undetected at compile time and even at run time.\n",
            "Strong typing prevents these program faults. An attempt to perform an operation on the wrong type of value raises an error. Strongly-typed languages are often termed type-safe or safe.\n",
            "An alternative definition for \"weakly typed\" refers to languages, such as Perl and JavaScript, which permit a large number of implicit type conversions. In JavaScript, for example, the expression 2 * x implicitly converts x to a number, and this conversion succeeds even if x is null, undefined, an Array, or a string of letters. Such implicit conversions are often useful, but they can mask programming errors. Strong and static are now generally considered orthogonal concepts, but usage in the literature differs. Some use the term strongly typed to mean strongly, statically typed, or, even more confusingly, to mean simply statically typed. Thus C has been called both strongly typed and weakly, statically typed.It may seem odd to some professional programmers that C could be \"weakly, statically typed\". However, the use of the generic pointer, the void* pointer, does allow casting pointers to other pointers without needing to do an explicit cast. This is extremely similar to somehow casting an array of bytes to any kind of datatype in C without using an explicit cast, such as (int) or (char).\n",
            "\n",
            "\n",
            "=== Standard library and run-time system ===\n",
            "\n",
            "Most programming languages have an associated core library (sometimes known as the \"standard library\", especially if it is included as part of the published language standard), which is conventionally made available by all implementations of the language. Core libraries typically include definitions for commonly used algorithms, data structures, and mechanisms for input and output.\n",
            "The line between a language and its core library differs from language to language. In some cases, the language designers may treat the library as a separate entity from the language. However, a language's core library is often treated as part of the language by its users, and some language specifications even require that this library be made available in all implementations. Indeed, some languages are designed so that the meanings of certain syntactic constructs cannot even be described without referring to the core library. For example, in Java, a string literal is defined as an instance of the java.lang.String class; similarly, in Smalltalk, an anonymous function expression (a \"block\") constructs an instance of the library's BlockContext class. Conversely, Scheme contains multiple coherent subsets that suffice to construct the rest of the language as library macros, and so the language designers do not even bother to say which portions of the language must be implemented as language constructs, and which must be implemented as parts of a library.\n",
            "\n",
            "\n",
            "== Design and implementation ==\n",
            "\n",
            "Programming languages share properties with natural languages related to their purpose as vehicles for communication, having a syntactic form separate from its semantics, and showing language families of related languages branching one from another. But as artificial constructs, they also differ in fundamental ways from languages that have evolved through usage. A significant difference is that a programming language can be fully described and studied in its entirety since it has a precise and finite definition. By contrast, natural languages have changing meanings given by their users in different communities. While constructed languages are also artificial languages designed from the ground up with a specific purpose, they lack the precise and complete semantic definition that a programming language has.\n",
            "Many programming languages have been designed from scratch, altered to meet new needs, and combined with other languages. Many have eventually fallen into disuse. Although there have been attempts to design one \"universal\" programming language that serves all purposes, all of them have failed to be generally accepted as filling this role. The need for diverse programming languages arises from the diversity of contexts in which languages are used:\n",
            "\n",
            "Programs range from tiny scripts written by individual hobbyists to huge systems written by hundreds of programmers.\n",
            "Programmers range in expertise from novices who need simplicity above all else to experts who may be comfortable with considerable complexity.\n",
            "Programs must balance speed, size, and simplicity on systems ranging from microcontrollers to supercomputers.\n",
            "Programs may be written once and not change for generations, or they may undergo continual modification.\n",
            "Programmers may simply differ in their tastes: they may be accustomed to discussing problems and expressing them in a particular language.One common trend in the development of programming languages has been to add more ability to solve problems using a higher level of abstraction. The earliest programming languages were tied very closely to the underlying hardware of the computer. As new programming languages have developed, features have been added that let programmers express ideas that are more remote from simple translation into underlying hardware instructions. Because programmers are less tied to the complexity of the computer, their programs can do more computing with less effort from the programmer. This lets them write more functionality per time unit.\n",
            "Natural-language programming has been proposed as a way to eliminate the need for a specialized language for programming. However, this goal remains distant and its benefits are open to debate. Edsger W. Dijkstra took the position that the use of a formal language is essential to prevent the introduction of meaningless constructs, and dismissed natural-language programming as \"foolish\". Alan Perlis was similarly dismissive of the idea. Hybrid approaches have been taken in Structured English and SQL.\n",
            "A language's designers and users must construct a number of artifacts that govern and enable the practice of programming. The most important of these artifacts are the language specification and implementation.\n",
            "\n",
            "\n",
            "=== Specification ===\n",
            "\n",
            "The specification of a programming language is an artifact that the language users and the implementors can use to agree upon whether a piece of source code is a valid program in that language, and if so what its behavior shall be.\n",
            "A programming language specification can take several forms, including the following:\n",
            "\n",
            "An explicit definition of the syntax, static semantics, and execution semantics of the language. While syntax is commonly specified using a formal grammar, semantic definitions may be written in natural language (e.g., as in the C language), or a formal semantics (e.g., as in Standard ML and Scheme specifications).\n",
            "A description of the behavior of a translator for the language (e.g., the C++ and Fortran specifications). The syntax and semantics of the language have to be inferred from this description, which may be written in natural or formal language.\n",
            "A reference or model implementation, sometimes written in the language being specified (e.g., Prolog or ANSI REXX). The syntax and semantics of the language are explicit in the behavior of the reference implementation.\n",
            "\n",
            "\n",
            "=== Implementation ===\n",
            "\n",
            "An implementation of a programming language provides a way to write programs in that language and execute them on one or more configurations of hardware and software. There are, broadly, two approaches to programming language implementation: compilation and interpretation. It is generally possible to implement a language using either technique.\n",
            "The output of a compiler may be executed by hardware or a program called an interpreter. In some implementations that make use of the interpreter approach, there is no distinct boundary between compiling and interpreting. For instance, some implementations of BASIC compile and then execute the source one line at a time.\n",
            "Programs that are executed directly on the hardware usually run much faster than those that are interpreted in software.One technique for improving the performance of interpreted programs is just-in-time compilation. Here the virtual machine, just before execution, translates the blocks of bytecode which are going to be used to machine code, for direct execution on the hardware.\n",
            "\n",
            "\n",
            "== Proprietary languages ==\n",
            "Although most of the most commonly used programming languages have fully open specifications and implementations, many programming languages exist only as proprietary programming languages with the implementation available only from a single vendor, which may claim that such a proprietary language is their intellectual property. Proprietary programming languages are commonly domain-specific languages or internal scripting languages for a single product; some proprietary languages are used only internally within a vendor, while others are available to external users.Some programming languages exist on the border between proprietary and open; for example, Oracle Corporation asserts proprietary rights to some aspects of the Java programming language, and Microsoft's C# programming language, which has open implementations of most parts of the system, also has Common Language Runtime (CLR) as a closed environment.Many proprietary languages are widely used, in spite of their proprietary nature; examples include MATLAB, VBScript, and Wolfram Language. Some languages may make the transition from closed to open; for example, Erlang was originally Ericsson's internal programming language.\n",
            "\n",
            "\n",
            "== Use ==\n",
            "Thousands of different programming languages have been created, mainly in the computing field.\n",
            "Individual software projects commonly use five programming languages or more.Programming languages differ from most other forms of human expression in that they require a greater degree of precision and completeness. When using a natural language to communicate with other people, human authors and speakers can be ambiguous and make small errors, and still expect their intent to be understood. However, figuratively speaking, computers \"do exactly what they are told to do\", and cannot \"understand\" what code the programmer intended to write. The combination of the language definition, a program, and the program's inputs must fully specify the external behavior that occurs when the program is executed, within the domain of control of that program. On the other hand, ideas about an algorithm can be communicated to humans without the precision required for execution by using pseudocode, which interleaves natural language with code written in a programming language.\n",
            "A programming language provides a structured mechanism for defining pieces of data, and the operations or transformations that may be carried out automatically on that data. A programmer uses the abstractions present in the language to represent the concepts involved in a computation. These concepts are represented as a collection of the simplest elements available (called primitives). Programming is the process by which programmers combine these primitives to compose new programs, or adapt existing ones to new uses or a changing environment.\n",
            "Programs for a computer might be executed in a batch process without human interaction, or a user might type commands in an interactive session of an interpreter. In this case the \"commands\" are simply programs, whose execution is chained together. When a language can run its commands through an interpreter (such as a Unix shell or other command-line interface), without compiling, it is called a scripting language.\n",
            "\n",
            "\n",
            "=== Measuring language usage ===\n",
            "Determining which is the most widely used programming language is difficult since the definition of usage varies by context. One language may occupy the greater number of programmer hours, a different one has more lines of code, and a third may consume the most CPU time. Some languages are very popular for particular kinds of applications. For example, COBOL is still strong in the corporate data center, often on large mainframes; Fortran in scientific and engineering applications; Ada in aerospace, transportation, military, real-time, and embedded applications; and C in embedded applications and operating systems. Other languages are regularly used to write many different kinds of applications.\n",
            "Various methods of measuring language popularity, each subject to a different bias over what is measured, have been proposed:\n",
            "\n",
            "counting the number of job advertisements that mention the language\n",
            "the number of books sold that teach or describe the language\n",
            "estimates of the number of existing lines of code written in the language –  which may underestimate languages not often found in public searches\n",
            "counts of language references (i.e., to the name of the language) found using a web search engine.Combining and averaging information from various internet sites, stackify.com reported the ten most popular programming languages (in descending order by overall popularity): Java, C, C++, Python, C#, JavaScript, VB .NET, R, PHP, and MATLAB.\n",
            "\n",
            "\n",
            "== Dialects, flavors and implementations ==\n",
            "A dialect of a programming language or a data exchange language is a (relatively small) variation or extension of the language that does not change its intrinsic nature. With languages such as Scheme and Forth, standards may be considered insufficient, inadequate, or illegitimate by implementors, so often they will deviate from the standard, making a new dialect. In other cases, a dialect is created for use in a domain-specific language, often a subset. In the Lisp world, most languages that use basic S-expression syntax and Lisp-like semantics are considered Lisp dialects, although they vary wildly as do, say, Racket and Clojure. As it is common for one language to have several dialects, it can become quite difficult for an inexperienced programmer to find the right documentation. The BASIC language has many dialects.\n",
            "\n",
            "\n",
            "== Taxonomies ==\n",
            "\n",
            "There is no overarching classification scheme for programming languages. A given programming language does not usually have a single ancestor language. Languages commonly arise by combining the elements of several predecessor languages with new ideas in circulation at the time. Ideas that originate in one language will diffuse throughout a family of related languages, and then leap suddenly across familial gaps to appear in an entirely different family.\n",
            "The task is further complicated by the fact that languages can be classified along multiple axes. For example, Java is both an object-oriented language (because it encourages object-oriented organization) and a concurrent language (because it contains built-in constructs for running multiple threads in parallel). Python is an object-oriented scripting language.In broad strokes, programming languages are classified by programming paradigm and intended domain of use, with general-purpose programming languages distinguished from domain-specific programming languages. Traditionally, programming languages have been regarded as describing computation in terms of imperative sentences, i.e. issuing commands. These are generally called imperative programming languages. A great deal of research in programming languages has been aimed at blurring the distinction between a program as a set of instructions and a program as an assertion about the desired answer, which is the main feature of declarative programming. More refined paradigms include procedural programming, object-oriented programming, functional programming, and logic programming; some languages are hybrids of paradigms or multi-paradigmatic. An assembly language is not so much a paradigm as a direct model of an underlying machine architecture. By purpose, programming languages might be considered general purpose, system programming languages, scripting languages, domain-specific languages, or concurrent/distributed languages (or a combination of these). Some general purpose languages were designed largely with educational goals.A programming language may also be classified by factors unrelated to the programming paradigm. For instance, most programming languages use English language keywords, while a minority do not. Other languages may be classified as being deliberately esoteric or not.\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Further reading ==...\n",
            "\n",
            "\n",
            "Page Title: Operating Systems\n",
            "Text: An operating system (OS) is system software that manages computer hardware and software resources, and provides common services for computer programs.\n",
            "Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, peripherals, and other resources.\n",
            "For hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer –  from cellular phones and video game consoles to web servers and supercomputers.\n",
            "In the personal computer market, as of September 2023, Microsoft Windows holds a dominant market share of around 68%. macOS by Apple Inc. is in second place (20%), and the varieties of Linux, including ChromeOS, are collectively in third place (7%). In the mobile sector (including smartphones and tablets), as of September 2023, Android's share is 68.92%, followed by Apple's iOS and iPadOS with 30.42%, and other operating systems with .6%. Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications. Security-focused operating systems also exist. Some operating systems have low system requirements (e.g. light-weight Linux distribution). Others may have higher system requirements.\n",
            "Some operating systems require installation or may come pre-installed with purchased computers (OEM-installation), whereas others may run directly from media (i.e. live CD) or flash memory (i.e. USB stick).\n",
            "\n",
            "\n",
            "== Types of operating systems ==\n",
            "\n",
            "\n",
            "=== Single-tasking and multi-tasking ===\n",
            "A single-tasking system can only run one program at a time, while a multi-tasking operating system allows more than one program to be running concurrently. This is achieved by time-sharing, where the available processor time is divided between multiple processes. These processes are each interrupted repeatedly in time slices by a task-scheduling subsystem of the operating system. Multi-tasking may be characterized in preemptive and cooperative types. In preemptive multitasking, the operating system slices the CPU time and dedicates a slot to each of the programs. Unix-like operating systems, such as Linux—as well as non-Unix-like, such as AmigaOS—support preemptive multitasking. Cooperative multitasking is achieved by relying on each process to provide time to the other processes in a defined manner. 16-bit versions of Microsoft Windows used cooperative multi-tasking; 32-bit versions of both Windows NT and Win9x used preemptive multi-tasking.\n",
            "\n",
            "\n",
            "=== Single- and multi-user ===\n",
            "Single-user operating systems have no facilities to distinguish users but may allow multiple programs to run in tandem. A multi-user operating system extends the basic concept of multi-tasking with facilities that identify processes and resources, such as disk space, belonging to multiple users, and the system permits multiple users to interact with the system at the same time. Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources to multiple users.\n",
            "\n",
            "\n",
            "=== Distributed ===\n",
            "A distributed operating system manages a group of distinct, networked computers and makes them appear to be a single computer, as all computations are distributed (divided amongst the constituent computers).\n",
            "\n",
            "\n",
            "=== Embedded ===\n",
            "Embedded operating systems are designed to be used in embedded computer systems. They are designed to operate on small machines with less autonomy (e.g. PDAs). They are very compact and extremely efficient by design and are able to operate with a limited amount of resources. Windows CE and Minix 3 are some examples of embedded operating systems.\n",
            "\n",
            "\n",
            "=== Real-time ===\n",
            "A real-time operating system is an operating system that guarantees to process events or data by a specific moment in time. A real-time operating system may be single- or multi-tasking, but when multitasking, it uses specialized scheduling algorithms so that a deterministic nature of behavior is achieved. Such an event-driven system switches between tasks based on their priorities or external events, whereas time-sharing operating systems switch tasks based on clock interrupts.\n",
            "\n",
            "\n",
            "=== Library ===\n",
            "A library operating system is one in which the services that a typical operating system provides, such as networking, are provided in the form of libraries and composed with the application and configuration code to construct a unikernel: a specialized, single address space, machine image that can be deployed to cloud or embedded environments.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "Early computers were built to perform a series of single tasks, like a calculator. Basic operating system features were developed in the 1950s, such as resident monitor functions that could automatically run different programs in succession to speed up processing. Operating systems did not exist in their modern and more complex forms until the early 1960s. Hardware features were added, that enabled use of runtime libraries, interrupts, and parallel processing. When personal computers became popular in the 1980s, operating systems were made for them similar in concept to those used on larger computers.\n",
            "In the 1940s, the earliest electronic digital systems had no operating systems. Electronic systems of this time were programmed on rows of mechanical switches or by jumper wires on plugboards. These were special-purpose systems that, for example, generated ballistics tables for the military or controlled the printing of payroll checks from data on punched paper cards. After programmable general-purpose computers were invented, machine languages(consisting of strings of the binary digits 0 and 1 on punched paper tape) were introduced that sped up the programming process (Stern, 1981).\n",
            "In the early 1950s, a computer could execute only one program at a time.  Each user had sole use of the computer for a limited period and would arrive at a scheduled time with their program and data on punched paper cards or punched tape. The program would be loaded into the machine, and the machine would be set to work until the program completed or crashed. Programs could generally be debugged via a front panel using toggle switches and panel lights. It is said that Alan Turing was a master of this on the early Manchester Mark 1 machine, and he was already deriving the primitive conception of an operating system from the principles of the universal Turing machine.Later machines came with libraries of programs, which would be linked to a user's program to assist in operations such as input and output and compiling (generating machine code from human-readable symbolic code). This was the genesis of the modern-day operating system. However, machines still ran a single job at a time. At Cambridge University in England, the job queue was at one time a washing line (clothesline) from which tapes were hung with different colored clothes-pegs to indicate job priority.By the late 1950s, programs that one would recognize as an operating system were beginning to appear. Often pointed to as the earliest recognizable example is GM-NAA I/O, released in 1956 on the IBM 704. The first known example that actually referred to itself was the SHARE Operating System, a development of GM-NAA I/O, released in 1959. In a May 1960 paper describing the system, George Ryckman noted:\n",
            "\n",
            "The development of computer operating systems have materially aided the problem of getting a program or series of programs on and off the computer efficiently.\n",
            "One of the more famous examples that is often found in discussions of early systems is the Atlas Supervisor, running on the  Atlas in 1962. It was referred to as such in a December 1961 article describing the system, but the context of \"the Operating System\" is more along the lines of \"the system operates in the fashion\". The Atlas team itself used the term \"supervisor\", which was widely used along with \"monitor\". Brinch Hansen described it as \"the most significant breakthrough in the history of operating systems.\"\n",
            "\n",
            "\n",
            "=== Mainframes ===\n",
            "\n",
            "Through the 1950s, many major features were pioneered in the field of operating systems on mainframe computers, including batch processing, input/output interrupting, buffering, multitasking, spooling, runtime libraries, link-loading, and programs for sorting records in files. These features were included or not included in application software at the option of application programmers, rather than in a separate operating system used by all applications.  In 1959, the SHARE Operating System was released as an integrated utility for the IBM 704, and later in the 709 and 7090 mainframes, although it was quickly supplanted by IBSYS/IBJOB on the 709, 7090 and 7094, which in turn influenced the later 7040-PR-150 (7040/7044) and 1410-PR-155 (1410/7010) operating systems.\n",
            "During the 1960s, IBM's OS/360 introduced the concept of a single OS spanning an entire product line, which was crucial for the success of the System/360 machines. IBM's current mainframe operating systems are distant descendants of this original system and modern machines are backward compatible with applications written for OS/360.OS/360 also pioneered the concept that the operating system keeps track of all of the system resources that are used, including program and data space allocation in main memory and file space in secondary storage, and file locking during updates. When a process is terminated for any reason, all of these resources are re-claimed by the operating system.\n",
            "The alternative CP-67 system for the S/360-67 started a whole line of IBM operating systems focused on the concept of virtual machines. Other operating systems used on IBM S/360 series mainframes included systems developed by IBM: DOS/360 (Disk Operating System), TSS/360 (Time Sharing System), TOS/360 (Tape Operating System), BOS/360 (Basic Operating System), and ACP (Airline Control Program), as well as a few non-IBM systems: MTS (Michigan Terminal System), MUSIC (Multi-User System for Interactive Computing), and ORVYL (Stanford Timesharing System).\n",
            "Control Data Corporation developed the SCOPE operating system in the 1960s, for batch processing. In cooperation with the University of Minnesota, the Kronos and later the NOS operating systems were developed during the 1970s, which supported simultaneous batch and timesharing use. Like many commercial timesharing systems, its interface was an extension of the Dartmouth BASIC operating systems, one of the pioneering efforts in timesharing and programming languages. In the late 1970s, Control Data and the University of Illinois developed the PLATO operating system, which used plasma panel displays and long-distance time sharing networks. Plato was remarkably innovative for its time, featuring real-time chat, and multi-user graphical games.\n",
            "In 1961, Burroughs Corporation introduced the B5000 with the MCP (Master Control Program) operating system. The B5000 was a stack machine designed to exclusively support high-level languages with no assembler; indeed, the MCP was the first OS to be written exclusively in a high-level language (ESPOL, a dialect of ALGOL). MCP also introduced many other ground-breaking innovations, such as being the first commercial implementation of virtual memory. MCP is still in use today in the Unisys company's MCP/ClearPath line of computers.\n",
            "UNIVAC, the first commercial computer manufacturer, produced a series of EXEC operating systems. Like all early main-frame systems, this batch-oriented system managed magnetic drums, disks, card readers and line printers. In the 1970s, UNIVAC produced the Real-Time Basic (RTB) system to support large-scale time sharing, also patterned after the Dartmouth BC system.\n",
            "General Electric developed General Electric Comprehensive Operating Supervisor (GECOS), which primarily supported batch processing. After its acquisition by Honeywell, it was renamed General Comprehensive Operating System (GCOS).\n",
            "Bell Labs, General Electric and MIT developed Multiplexed Information and Computing Service (Multics), which introduced the concept of ringed security privilege levels.\n",
            "Digital Equipment Corporation developed many operating systems for its various computer lines, including TOPS-10 and TOPS-20 time-sharing systems for the 36-bit PDP-10 class systems. Before the widespread use of UNIX, TOPS-10 was a particularly popular system in universities, and in the early ARPANET community. RT-11 was a single-user real-time OS for the PDP-11 class minicomputer, and RSX-11 was the corresponding multi-user OS.\n",
            "From the late 1960s through the late 1970s, several hardware capabilities evolved that allowed similar or ported software to run on more than one system. Early systems had utilized microprogramming to implement features on their systems in order to permit different underlying computer architectures to appear to be the same as others in a series. In fact, most 360s after the 360/40 (except the 360/44, 360/75, 360/91, 360/95 and 360/195) were microprogrammed implementations.\n",
            "The enormous investment in software for these systems made since the 1960s caused most of the original computer manufacturers to continue to develop compatible operating systems along with the hardware. Notable supported mainframe operating systems include:\n",
            "\n",
            "Burroughs MCP –  B5000, 1961 to Unisys Clearpath/MCP, present\n",
            "IBM OS/360 –  IBM System/360, 1966 to IBM z/OS, present\n",
            "IBM CP-67 –  IBM System/360, 1967 to IBM z/VM, present\n",
            "UNIVAC EXEC 8 –  UNIVAC 1108, 1967, to OS 2200 Unisys Clearpath Dorado, present\n",
            "\n",
            "\n",
            "=== Microcomputers ===\n",
            "The first microcomputers did not have the capacity or need for the elaborate operating systems that had been developed for mainframes and minis; minimalistic operating systems were developed, often loaded from ROM and known as monitors. One notable early disk operating system was CP/M, which was supported on many early microcomputers and was closely imitated by Microsoft's MS-DOS, which became widely popular as the operating system chosen for the IBM PC (IBM's version of it was called IBM DOS or PC DOS). In the 1980s, Apple Computer Inc. (now Apple Inc.) abandoned its popular Apple II series of microcomputers to introduce the Apple Macintosh computer with an innovative graphical user interface (GUI); the Macintosh ran the operating system later known as the (classic) Mac OS.\n",
            "The introduction of the Intel 80386 CPU chip in October 1985, with 32-bit architecture and paging capabilities, provided personal computers with the ability to run multitasking operating systems like those of earlier superminicomputers and mainframes. Microsoft responded to this progress by hiring Dave Cutler, who had developed the VMS operating system for Digital Equipment Corporation. He would lead the development of the Windows NT operating system, which continues to serve as the basis for Microsoft's operating systems line. Steve Jobs, a co-founder of Apple Inc., started NeXT Computer Inc., which developed the NeXTSTEP operating system. NeXTSTEP would later be acquired by Apple Inc. and used, along with code from FreeBSD as the core of Mac OS X (macOS after latest name change).\n",
            "The GNU Project was started by activist and programmer Richard Stallman with the goal of creating a complete free software replacement to the proprietary UNIX operating system. While the project was highly successful in duplicating the functionality of various parts of UNIX, development of the GNU Hurd kernel proved to be unproductive. In 1991, Finnish computer science student Linus Torvalds, with cooperation from volunteers collaborating over the Internet, released the first version of the Linux kernel. It was soon merged with the GNU user space components and system software to form a complete operating system. Since then, the combination of the two major components has usually been referred to as simply \"Linux\" by the software industry, a naming convention that Stallman and the Free Software Foundation remain opposed to, preferring the name GNU/Linux. The Berkeley Software Distribution, known as BSD, is the UNIX derivative distributed by the University of California, Berkeley, starting in the 1970s. Freely distributed and ported to many minicomputers, it eventually also gained a following for use on PCs, mainly as FreeBSD, NetBSD and OpenBSD.\n",
            "\n",
            "\n",
            "== Examples ==\n",
            "\n",
            "\n",
            "=== Unix and Unix-like operating systems ===\n",
            "\n",
            "Unix was originally written in assembly language. Ken Thompson wrote B, mainly based on BCPL, based on his experience in the MULTICS project. B was replaced by C, and Unix, rewritten in C, developed into a large, complex family of inter-related operating systems which have been influential in every modern operating system (see History).\n",
            "The Unix-like family is a diverse group of operating systems, with several major sub-categories including System V, BSD, and Linux. The name \"UNIX\" is a trademark of The Open Group which licenses it for use with any operating system that has been shown to conform to their definitions. \"UNIX-like\" is commonly used to refer to the large set of operating systems which resemble the original UNIX.\n",
            "Unix-like systems run on a wide variety of computer architectures. They are used heavily for servers in business, as well as workstations in academic and engineering environments. Free UNIX variants, such as Linux and BSD, are popular in these areas.\n",
            "Five operating systems are certified by The Open Group (holder of the Unix trademark) as Unix. HP's HP-UX and IBM's AIX are both descendants of the original System V Unix and are designed to run only on their respective vendor's hardware. In contrast, Sun Microsystems's Solaris can run on multiple types of hardware, including x86 and SPARC servers, and PCs. Apple's macOS, a replacement for Apple's earlier (non-Unix) classic Mac OS, is a hybrid kernel-based BSD variant derived from NeXTSTEP, Mach, and FreeBSD. IBM's z/OS UNIX System Services includes a shell and utilities based on Mortice Kerns' InterOpen products.\n",
            "Unix interoperability was sought by establishing the POSIX standard. The POSIX standard can be applied to any operating system, although it was originally created for various Unix variants.\n",
            "\n",
            "\n",
            "==== BSD and its descendants ====\n",
            "\n",
            "A subgroup of the Unix family is the Berkeley Software Distribution family, which includes FreeBSD, NetBSD, and OpenBSD. These operating systems are most commonly found on webservers, although they can also function as a personal computer OS. The Internet owes much of its existence to BSD, as many of the protocols now commonly used by computers to connect, send and receive data over a network were widely implemented and refined in BSD. The World Wide Web was also first demonstrated on a number of computers running an OS based on BSD called NeXTSTEP.\n",
            "In 1974, University of California, Berkeley installed its first Unix system. Over time, students and staff in the computer science department there began adding new programs to make things easier, such as text editors. When Berkeley received new VAX computers in 1978 with Unix installed, the school's undergraduates modified Unix even more in order to take advantage of the computer's hardware possibilities. The Defense Advanced Research Projects Agency of the US Department of Defense took interest, and decided to fund the project. Many schools, corporations, and government organizations took notice and started to use Berkeley's version of Unix instead of the official one distributed by AT&T.\n",
            "Steve Jobs, upon leaving Apple Inc. in 1985, formed NeXT Inc., a company that manufactured high-end computers running on a variation of BSD called NeXTSTEP. One of these computers was used by Tim Berners-Lee as the first webserver to create the World Wide Web.\n",
            "Developers like Keith Bostic encouraged the project to replace any non-free code that originated with Bell Labs. Once this was done, however, AT&T sued. After two years of legal disputes, the BSD project spawned a number of free derivatives, such as NetBSD and FreeBSD (both in 1993), and OpenBSD (from NetBSD in 1995).\n",
            "\n",
            "\n",
            "==== macOS ====\n",
            "\n",
            "macOS (formerly \"Mac OS X\" and later \"OS X\")  is a line of open core graphical operating systems developed, marketed, and sold by Apple Inc., the latest of which is pre-loaded on all currently shipping Macintosh computers. macOS is the successor to the original classic Mac OS, which had been Apple's primary operating system since 1984. Unlike its predecessor, macOS is a UNIX operating system built on technology that had been developed at NeXT through the second half of the 1980s and up until Apple purchased the company in early 1997.\n",
            "The operating system was first released in 1999 as Mac OS X Server 1.0, followed in March 2001 by a client version (Mac OS X v10.0 \"Cheetah\"). Since then, six more distinct \"client\" and \"server\" editions of macOS have been released, until the two were merged in OS X 10.7 \"Lion\".\n",
            "Prior to its merging with macOS, the server edition –  macOS Server –  was architecturally identical to its desktop counterpart and usually ran on Apple's line of Macintosh server hardware. macOS Server included work group management and administration software tools that provide simplified access to key network services, including a mail transfer agent, a Samba server, an LDAP server, a domain name server, and others. With Mac OS X v10.7 Lion, all server aspects of Mac OS X Server have been integrated into the client version and the product re-branded as \"OS X\" (dropping \"Mac\" from the name). The server tools are now offered as an application.\n",
            "\n",
            "\n",
            "==== z/OS UNIX System Services ====\n",
            "First introduced as the OpenEdition upgrade to MVS/ESA System Product Version 4 Release 3, announced February 1993 with support for POSIX and other standards. z/OS UNIX System Services is built on top of MVS services and cannot run independently. While IBM initially introduced OpenEdition to satisfy FIPS requirements, several z/OS component now require UNIX services, e.g., TCP/IP.\n",
            "\n",
            "\n",
            "==== Linux ====\n",
            "\n",
            "The Linux kernel originated in 1991, as a project of Linus Torvalds, while a university student in Finland. He posted information about his project on a newsgroup for computer students and programmers, and received support and assistance from volunteers who succeeded in creating a complete and functional kernel.\n",
            "Linux is Unix-like, but was developed without any Unix code, unlike BSD and its variants. Because of its open license model, the Linux kernel code is available for study and modification, which resulted in its use on a wide range of computing machinery from supercomputers to smartwatches. Although estimates suggest that Linux is used on only 2.81% of all \"desktop\" (or laptop) PCs, it has been widely adopted for use in servers and embedded systems such as cell phones. \n",
            "Linux has superseded Unix on many platforms and is used on most supercomputers, including all 500 most powerful supercomputers on the TOP500 list — having displaced all competitors by 2017. Linux is also commonly used on other small energy-efficient computers, such as smartphones and smartwatches. The Linux kernel is used in some popular distributions, such as Red Hat, Debian, Ubuntu, Linux Mint and Google's Android, ChromeOS, and ChromiumOS.\n",
            "\n",
            "\n",
            "=== Microsoft Windows ===\n",
            "\n",
            "Microsoft Windows is a family of proprietary operating systems designed by Microsoft Corporation and primarily targeted to x86 architecture based computers.  As of 2022, its worldwide market share on all platforms was approximately 30%, and on the desktop/laptop platforms, its market share was approximately 75%.  The latest version is Windows 11.\n",
            "Microsoft Windows was first released in 1985, as an operating environment running on top of MS-DOS, which was the standard operating system shipped on most Intel architecture personal computers at the time. In 1995, Windows 95 was released which only used MS-DOS as a bootstrap. For backwards compatibility, Win9x could run real-mode MS-DOS and 16-bit Windows 3.x drivers. Windows ME, released in 2000, was the last version in the Win9x family. Later versions have all been based on the Windows NT kernel. Current client versions of Windows run on IA-32, x86-64 and Arm microprocessors. In the past, Windows NT supported additional architectures.\n",
            "Server editions of Windows are widely used, however, Windows' usage on servers is not as widespread as on personal computers as Windows competes against Linux and BSD for server market share.ReactOS is a Windows-alternative operating system, which is being developed on the principles of Windows –  without using any of Microsoft's code.\n",
            "\n",
            "\n",
            "=== Other ===\n",
            "There have been many operating systems that were significant in their day but are no longer so, such as AmigaOS; OS/2 from IBM and Microsoft; classic Mac OS, the non-Unix precursor to Apple's macOS; BeOS; XTS-300; RISC OS; MorphOS; Haiku; BareMetal and FreeMint. Some are still used in niche markets and continue to be developed as minority platforms for enthusiast communities and specialist applications.\n",
            "The z/OS operating system for IBM z/Architecture mainframe computers is still being used and developed, and \n",
            "OpenVMS, formerly from DEC, is still under active development by VMS Software Inc.  The IBM i operating system for IBM AS/400 and IBM Power Systems midrange computers is also still being used and developed.\n",
            "Yet other operating systems are used almost exclusively in academia, for operating systems education or to do research on operating system concepts. A typical example of a system that fulfills both roles is MINIX, while for example Singularity is used purely for research. Another example is the Oberon System designed at ETH Zürich by Niklaus Wirth, Jürg Gutknecht and a group of students at the former Computer Systems Institute in the 1980s. It was used mainly for research, teaching, and daily work in Wirth's group.\n",
            "Other operating systems have failed to win significant market share, but have introduced innovations that have influenced mainstream operating systems, not least Bell Labs' Plan 9.\n",
            "\n",
            "\n",
            "== Components ==\n",
            "The components of an operating system all exist in order to make the different parts of a computer work together. All user software needs to go through the operating system in order to use any of the hardware, whether it be as simple as a mouse or keyboard or as complex as an Internet component.\n",
            "\n",
            "\n",
            "=== Kernel ===\n",
            "\n",
            "With the aid of firmware and device drivers, the kernel provides the most basic level of control over all of the computer's hardware devices. It manages memory access for programs in the RAM, it determines which programs get access to which hardware resources, it sets up or resets the CPU's operating states for optimal operation at all times, and it organizes the data for long-term non-volatile storage with file systems on such media as disks, tapes, flash memory, etc.\n",
            "\n",
            "\n",
            "==== Program execution ====\n",
            "The operating system provides an interface between an application program and the computer hardware, so that an application program can interact with the hardware only by obeying rules and procedures programmed into the operating system.  The operating system is also a set of services which simplify development and execution of application programs. Executing an application program typically involves the creation of a process by the operating system kernel, which assigns memory space and other resources, establishes a priority for the process in multi-tasking systems, loads program binary code into memory, and initiates execution of the application program, which then interacts with the user and with hardware devices. However, in some systems an application can request that the operating system execute another application within the same process, either as a subroutine or in a separate thread, e.g., the LINK and ATTACH facilities of OS/360 and successors.\n",
            "\n",
            "\n",
            "==== Interrupts ====\n",
            "\n",
            "An interrupt (also known as abort, exception, fault, signal and trap) provides an efficient way for most operating systems to react to the environment. Interrupts cause the central processing unit (CPU) to have a control flow change away from the currently running program to an interrupt handler, also known as an interrupt service routine (ISR). An interrupt service routine may cause the central processing unit (CPU) to have a context switch. The details of how a computer processes an interrupt vary from architecture to architecture, and the details of how interrupt service routines behave vary from operating system to operating system. However, several interrupt functions are common. The architecture and operating system must:\n",
            "transfer control to an interrupt service routine.\n",
            "save the state of the currently running process.\n",
            "restore the state after the interrupt is serviced.\n",
            "\n",
            "\n",
            "===== Software interrupt =====\n",
            "A software interrupt is a message to a process that an event has occurred. This contrasts with a hardware interrupt — which is a message to the central processing unit (CPU) that an event has occurred. Software interrupts are similar to hardware interrupts — there is a change away from the currently running process. Similarly, both hardware and software interrupts execute an interrupt service routine.\n",
            "Software interrupts may be normally occurring events. It is expected that a time slice will occur, so the kernel will have to perform a context switch. A computer program may set a timer to go off after a few seconds in case too much data causes an algorithm to take too long.Software interrupts may be error conditions, such as a malformed machine instruction. However, the most common error conditions are division by zero and accessing an invalid memory address.Users can send messages to the kernel to modify the behavior of a currently running process. For example, in the command-line environment, pressing the interrupt character (usually Control-C) might terminate the currently running process.To generate software interrupts for x86 CPUs, the INT assembly language instruction is available. The syntax is INT X, where X is the offset number (in hexadecimal format) to the interrupt vector table.\n",
            "\n",
            "\n",
            "===== Signal =====\n",
            "To generate software interrupts in Unix-like operating systems, the kill(pid,signum) system call will send a signal to another process. pid is the process identifier of the receiving process. signum is the signal number (in mnemonic format) to be sent. (The abrasive name of kill was chosen because early implementations only terminated the process.)In Unix-like operating systems, signals inform processes of the occurrence of asynchronous events. To communicate asynchronously, interrupts are required. One reason a process needs to asynchronously communicate to another process solves a variation of the classic reader/writer problem. The writer receives a pipe from the shell for its output to be sent to the reader's input stream. The command-line syntax is alpha | bravo. alpha will write to the pipe when its computation is ready and then sleep in the wait queue. bravo will then be moved to the ready queue and soon will read from its input stream. The kernel will generate software interrupts to coordinate the piping.Signals may be classified into 7 categories. The categories are:\n",
            "\n",
            "when a process finishes normally.\n",
            "when a process has an error exception.\n",
            "when a process runs out of a system resource.\n",
            "when a process executes an illegal instruction.\n",
            "when a process sets an alarm event.\n",
            "when a process is aborted from the keyboard.\n",
            "when a process has a tracing alert for debugging.\n",
            "\n",
            "\n",
            "===== Hardware interrupt =====\n",
            "Input/Output (I/O) devices are slower than the CPU. Therefore, it would slow down the computer if the CPU had to wait for each I/O to finish. Instead, a computer may implement interrupts for I/O completion, avoiding the need for polling or busy waiting.Some computers require an interrupt for each character or word, costing a significant amount of CPU time. Direct memory access (DMA) is an architecture feature to allow devices to bypass the CPU and access main memory directly. (Separate from the architecture, a device may perform direct memory access to and from main memory either directly or via a bus.)\n",
            "\n",
            "\n",
            "==== Input/Output ====\n",
            "\n",
            "\n",
            "===== Interrupt-driven I/O =====\n",
            "When a computer user types a key on the keyboard, typically the character appears immediately on the screen. Likewise, when a user moves a mouse, the cursor immediately moves across the screen. Each keystroke and mouse movement generates an interrupt called Interrupt-driven I/O. An interrupt-driven I/O occurs when a process causes an interrupt for every character or word transmitted.\n",
            "\n",
            "\n",
            "===== Direct Memory Access =====\n",
            "Devices such as hard disk drives, solid state drives, and magnetic tape drives can transfer data at a rate high enough that interrupting the CPU for every byte or word transferred, and having the CPU transfer the byte or word between the device and memory, would require too much CPU time.  Data is, instead, transferred between the device and memory independently of the CPU by hardware such as a channel or a direct memory access controller; an interrupt is delivered only when all the data is transferred.If a computer program executes a system call to perform a block I/O write operation, then the system call might execute the following instructions:\n",
            "\n",
            "Set the contents of the CPU's registers (including the program counter) into the process control block.\n",
            "Create an entry in the device-status table. The operating system maintains this table to keep track of which processes are waiting for which devices. One field in the table is the memory address of the process control block.\n",
            "Place all the characters to be sent to the device into a memory buffer.\n",
            "Set the memory address of the memory buffer to a predetermined device register.\n",
            "Set the buffer size (an integer) to another predetermined register.\n",
            "Execute the machine instruction to begin the writing.\n",
            "Perform a context switch to the next process in the ready queue.While the writing takes place, the operating system will context switch to other processes as normal. When the device finishes writing, the device will interrupt the currently running process by asserting an interrupt request. The device will also place an integer onto the data bus. Upon accepting the interrupt request, the operating system will:\n",
            "\n",
            "Push the contents of the program counter (a register) followed by the status register onto the call stack.\n",
            "Push the contents of the other registers onto the call stack. (Alternatively, the contents of the registers may be placed in a system table.)\n",
            "Read the integer from the data bus. The integer is an offset to the interrupt vector table. The vector table's instructions will then:Access the device-status table.\n",
            "Extract the process control block.\n",
            "Perform a context switch back to the writing process.When the writing process has its time slice expired, the operating system will:\n",
            "Pop from the call stack the registers other than the status register and program counter.\n",
            "Pop from the call stack the status register.\n",
            "Pop from the call stack the address of the next instruction, and set it back into the program counter.With the program counter now reset, the interrupted process will resume its time slice.\n",
            "\n",
            "\n",
            "==== Modes ====\n",
            "\n",
            "Modern computers support multiple modes of operation. CPUs with this capability offer at least two modes: user mode and supervisor mode. In general terms, supervisor mode operation allows unrestricted access to all machine resources, including all MPU instructions.  User mode operation sets limits on instruction use and typically disallows direct access to machine resources. CPUs might have other modes similar to user mode as well, such as the virtual modes in order to emulate older processor types, such as 16-bit processors on a 32-bit one, or 32-bit processors on a 64-bit one.\n",
            "At power-on or reset, the system begins in supervisor mode. Once an operating system kernel has been loaded and started, the boundary between user mode and supervisor mode (also known as kernel mode) can be established.\n",
            "Supervisor mode is used by the kernel for low level tasks that need unrestricted access to hardware, such as controlling how memory is accessed, and communicating with devices such as disk drives and video display devices. User mode, in contrast, is used for almost everything else. Application programs, such as word processors and database managers, operate within user mode, and can only access machine resources by turning control over to the kernel, a process which causes a switch to supervisor mode.  Typically, the transfer of control to the kernel is achieved by executing a software interrupt instruction, such as the Motorola 68000 TRAP instruction.  The software interrupt causes the processor to switch from user mode to supervisor mode and begin executing code that allows the kernel to take control.\n",
            "In user mode, programs usually have access to a restricted set of processor instructions, and generally cannot execute any instructions that could potentially cause disruption to the system's operation.  In supervisor mode, instruction execution restrictions are typically removed, allowing the kernel unrestricted access to all machine resources.\n",
            "The term \"user mode resource\" generally refers to one or more CPU registers, which contain information that the running program is not allowed to alter. Attempts to alter these resources generally cause a switch to supervisor mode, where the operating system can deal with the illegal operation the program was attempting; for example, by forcibly terminating (\"killing\") the program.\n",
            "\n",
            "\n",
            "==== Memory management ====\n",
            "\n",
            "Among other things, a multiprogramming operating system kernel must be responsible for managing all system memory which is currently in use by the programs. This ensures that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory.\n",
            "Cooperative memory management, used by many early operating systems, assumes that all programs make voluntary use of the kernel's memory manager, and do not exceed their allocated memory. This system of memory management is almost never seen any more, since programs often contain bugs which can cause them to exceed their allocated memory. If a program fails, it may cause memory used by one or more other programs to be affected or overwritten. Malicious programs or viruses may purposefully alter another program's memory, or may affect the operation of the operating system itself. With cooperative memory management, it takes only one misbehaved program to crash the system.\n",
            "Memory protection enables the kernel to limit a process' access to the computer's memory. Various methods of memory protection exist, including memory segmentation and paging. All methods require some level of hardware support (such as the 80286 MMU), which does not exist in all computers.\n",
            "In both segmentation and paging, certain protected mode registers specify to the CPU what memory address it should allow a running program to access. Attempts to access other addresses trigger an interrupt, which causes the CPU to re-enter supervisor mode, placing the kernel in charge. This is called a segmentation violation or Seg-V for short, and since it is both difficult to assign a meaningful result to such an operation, and because it is usually a sign of a misbehaving program, the kernel generally resorts to terminating the offending program, and reports the error.\n",
            "Windows versions 3.1 through ME had some level of memory protection, but programs could easily circumvent the need to use it. A general protection fault would be produced, indicating a segmentation violation had occurred; however, the system would often crash anyway.\n",
            "\n",
            "\n",
            "==== Virtual memory ====\n",
            "\n",
            "The use of virtual memory addressing (such as paging or segmentation) means that the kernel can choose what memory each program may use at any given time, allowing the operating system to use the same memory locations for multiple tasks.\n",
            "If a program tries to access memory that is not in its current range of accessible memory, but nonetheless has been allocated to it, the kernel is interrupted in the same way as it would if the program were to exceed its allocated memory. (See section on memory management.) Under UNIX this kind of interrupt is referred to as a page fault.\n",
            "When the kernel detects a page fault it generally adjusts the virtual memory range of the program which triggered it, granting it access to the memory requested. This gives the kernel discretionary power over where a particular application's memory is stored, or even whether or not it has actually been allocated yet.\n",
            "In modern operating systems, memory which is accessed less frequently can be temporarily stored on a disk or other media to make that space available for use by other programs. This is called swapping, as an area of memory can be used by multiple programs, and what that memory area contains can be swapped or exchanged on demand.\n",
            "\"Virtual memory\" provides the programmer or the user with the perception that there is a much larger amount of RAM in the computer than is really there.\n",
            "\n",
            "\n",
            "==== Multitasking ====\n",
            "\n",
            "Multitasking refers to the running of multiple independent computer programs on the same computer, giving the appearance that it is performing the tasks at the same time. Since most computers can do at most one or two things at one time, this is generally done via time-sharing, which means that each program uses a share of the computer's time to execute.\n",
            "An operating system kernel contains a scheduling program which determines how much time each process spends executing, and in which order execution control should be passed to programs. Control is passed to a process by the kernel, which allows the program access to the CPU and memory. Later, control is returned to the kernel through some mechanism, so that another program may be allowed to use the CPU. This so-called passing of control between the kernel and applications is called a context switch.\n",
            "An early model which governed the allocation of time to programs was called cooperative multitasking. In this model, when control is passed to a program by the kernel, it may execute for as long as it wants before explicitly returning control to the kernel. This means that a malicious or malfunctioning program may not only prevent any other programs from using the CPU, but it can hang the entire system if it enters an infinite loop.\n",
            "Modern operating systems extend the concepts of application preemption to device drivers and kernel code, so that the operating system has preemptive control over internal run-times as well.\n",
            "The philosophy governing preemptive multitasking is that of ensuring that all programs are given regular time on the CPU. This implies that all programs must be limited in how much time they are allowed to spend on the CPU without being interrupted. To accomplish this, modern operating system kernels make use of a timed interrupt. A protected mode timer is set by the kernel which triggers a return to supervisor mode after the specified time has elapsed. (See above sections on Interrupts and Dual Mode Operation.)\n",
            "On many single user operating systems cooperative multitasking is perfectly adequate, as home computers generally run a small number of well tested programs. AmigaOS is an exception, having preemptive multitasking from its first version. Windows NT was the first version of Microsoft Windows which enforced preemptive multitasking, but it did not reach the home user market until Windows XP (since Windows NT was targeted at professionals).\n",
            "\n",
            "\n",
            "==== Disk access and file systems ====\n",
            "\n",
            "Access to data stored on disks is a central feature of all operating systems. Computers store data on disks using files, which are structured in specific ways in order to allow for faster access, higher reliability, and to make better use of the drive's available space. The specific way in which files are stored on a disk is called a file system, and enables files to have names and attributes. It also allows them to be stored in a hierarchy of directories or folders arranged in a directory tree.\n",
            "Early operating systems generally supported a single type of disk drive and only one kind of file system. Early file systems were limited in their capacity, speed, and in the kinds of file names and directory structures they could use. These limitations often reflected limitations in the operating systems they were designed for, making it very difficult for an operating system to support more than one file system.\n",
            "While many simpler operating systems support a limited range of options for accessing storage systems, operating systems like UNIX and Linux support a technology known as a virtual file system or VFS. An operating system such as UNIX supports a wide array of storage devices, regardless of their design or file systems, allowing them to be accessed through a common application programming interface (API). This makes it unnecessary for programs to have any knowledge about the device they are accessing. A VFS allows the operating system to provide programs with access to an unlimited number of devices with an infinite variety of file systems installed on them, through the use of specific device drivers and file system drivers.\n",
            "A connected storage device, such as a hard drive, is accessed through a device driver. The device driver understands the specific language of the drive and is able to translate that language into a standard language used by the operating system to access all disk drives. On UNIX, this is the language of block devices.\n",
            "When the kernel has an appropriate device driver in place, it can then access the contents of the disk drive in raw format, which may contain one or more file systems. A file system driver is used to translate the commands used to access each specific file system into a standard set of commands that the operating system can use to talk to all file systems. Programs can then deal with these file systems on the basis of filenames, and directories/folders, contained within a hierarchical structure. They can create, delete, open, and close files, as well as gather various information about them, including access permissions, size, free space, and creation and modification dates.\n",
            "Various differences between file systems make supporting all file systems difficult. Allowed characters in file names, case sensitivity, and the presence of various kinds of file attributes makes the implementation of a single interface for every file system a daunting task. Operating systems tend to recommend using (and so support natively) file systems specifically designed for them; for example, NTFS in Windows and ReiserFS, Reiser4, ext3, ext4 and Btrfs in Linux. However, in practice, third party drivers are usually available to give support for the most widely used file systems in most general-purpose operating systems (for example, NTFS is available in Linux through NTFS-3g, and ext2/3 and ReiserFS are available in Windows through third-party software).\n",
            "Support for file systems is highly varied among modern operating systems, although there are several common file systems which almost all operating systems include support and drivers for. Operating systems vary on file system support and on the disk formats they may be installed on. Under Windows, each file system is usually limited in application to certain media; for example, CDs must use ISO 9660 or UDF, and as of Windows Vista, NTFS is the only file system which the operating system can be installed on.  It is possible to install Linux onto many types of file systems. Unlike other operating systems, Linux and UNIX allow any file system to be used regardless of the media it is stored in, whether it is a hard drive, a disc (CD, DVD...), a USB flash drive, or even contained within a file located on another file system.\n",
            "\n",
            "\n",
            "==== Device drivers ====\n",
            "\n",
            "A device driver is a specific type of computer software developed to allow interaction with hardware devices. Typically this constitutes an interface for communicating with the device, through the specific computer bus or communications subsystem that the hardware is connected to, providing commands to or receiving data from the device, and on the other end, the requisite interfaces to the operating system and software applications. It is a specialized hardware-dependent computer program which is also operating system specific that enables another program, typically an operating system or applications software package or computer program running under the operating system kernel, to interact transparently with a hardware device, and usually provides the requisite interrupt handling necessary for any necessary asynchronous time-dependent hardware interfacing needs.\n",
            "The key design goal of device drivers is abstraction. Every model of hardware (even within the same class of device) is different. Newer models also are released by manufacturers that provide more reliable or better performance and these newer models are often controlled differently. Computers and their operating systems cannot be expected to know how to control every device, both now and in the future. To solve this problem, operating systems essentially dictate how every type of device should be controlled. The function of the device driver is then to translate these operating system mandated function calls into device specific calls. In theory a new device, which is controlled in a new manner, should function correctly if a suitable driver is available. This new driver ensures that the device appears to operate as usual from the operating system's point of view.\n",
            "Under versions of Windows before Vista and versions of Linux before 2.6, all driver execution was co-operative, meaning that if a driver entered an infinite loop it would freeze the system. More recent revisions of these operating systems incorporate kernel preemption, where the kernel interrupts the driver to give it tasks, and then separates itself from the process until it receives a response from the device driver, or gives it more tasks to do.\n",
            "\n",
            "\n",
            "=== Networking ===\n",
            "\n",
            "Currently most operating systems support a variety of networking protocols, hardware, and applications for using them. This means that computers running dissimilar operating systems can participate in a common network for sharing resources such as computing, files, printers, and scanners using either wired or wireless connections. Networks can essentially allow a computer's operating system to access the resources of a remote computer to support the same functions as it could if those resources were connected directly to the local computer. This includes everything from simple communication, to using networked file systems or even sharing another computer's graphics or sound hardware. Some network services allow the resources of a computer to be accessed transparently, such as SSH which allows networked users direct access to a computer's command line interface.\n",
            "Client/server networking allows a program on a computer, called a client, to connect via a network to another computer, called a server. Servers offer (or host) various services to other network computers and users. These services are usually provided through ports or numbered access points beyond the server's IP address. Each port number is usually associated with a maximum of one running program, which is responsible for handling requests to that port. A daemon, being a user program, can in turn access the local hardware resources of that computer by passing requests to the operating system kernel.\n",
            "Many operating systems support one or more vendor-specific or open networking protocols as well, for example, SNA on IBM systems, DECnet on systems from Digital Equipment Corporation, and Microsoft-specific protocols (SMB) on Windows. Specific protocols for specific tasks may also be supported such as NFS for file access. Protocols like ESound, or esd can be easily extended over the network to provide sound from local applications, on a remote system's sound hardware.\n",
            "\n",
            "\n",
            "=== Security ===\n",
            "\n",
            "A computer being secure depends on a number of technologies working properly. A modern operating system provides access to a number of resources, which are available to software running on the system, and to external devices like networks via the kernel.The operating system must be capable of distinguishing between requests which should be allowed to be processed, and others which should not be processed. While some systems may simply distinguish between \"privileged\" and \"non-privileged\", systems commonly have a form of requester identity, such as a user name. To establish identity there may be a process of authentication. Often a username must be quoted, and each username may have a password. Other methods of authentication, such as magnetic cards or biometric data, might be used instead. In some cases, especially connections from the network, resources may be accessed with no authentication at all (such as reading files over a network share). Also covered by the concept of requester identity is authorization; the particular services and resources accessible by the requester once logged into a system are tied to either the requester's user account or to the variously configured groups of users to which the requester belongs.In addition to the allow or disallow model of security, a system with a high level of security also offers auditing options. These would allow tracking of requests for access to resources (such as, \"who has been reading this file?\"). Internal security, or security from an already running program is only possible if all possibly harmful requests must be carried out through interrupts to the operating system kernel. If programs can directly access hardware and resources, they cannot be secured.External security involves a request from outside the computer, such as a login at a connected console or some kind of network connection. External requests are often passed through device drivers to the operating system's kernel, where they can be passed onto applications, or carried out directly. Security of operating systems has long been a concern because of highly sensitive data held on computers, both of a commercial and military nature. The United States Government Department of Defense (DoD) created the Trusted Computer System Evaluation Criteria (TCSEC) which is a standard that sets basic requirements for assessing the effectiveness of security. This became of vital importance to operating system makers, because the TCSEC was used to evaluate, classify and select trusted operating systems being considered for the processing, storage and retrieval of sensitive or classified information.\n",
            "Network services include offerings such as file sharing, print services, email, web sites, and file transfer protocols (FTP), most of which can have compromised security. At the front line of security are hardware devices known as firewalls or intrusion detection/prevention systems. At the operating system level, there are a number of software firewalls available, as well as intrusion detection/prevention systems. Most modern operating systems include a software firewall, which is enabled by default. A software firewall can be configured to allow or deny network traffic to or from a service or application running on the operating system. Therefore, one can install and be running an insecure service, such as Telnet or FTP, and not have to be threatened by a security breach because the firewall would deny all traffic trying to connect to the service on that port.\n",
            "An alternative strategy, and the only sandbox strategy available in systems that do not meet the Popek and Goldberg virtualization requirements, is where the operating system is not running user programs as native code, but instead either emulates a processor or provides a host for a p-code based system such as Java.\n",
            "Internal security is especially relevant for multi-user systems; it allows each user of the system to have private files that the other users cannot tamper with or read. Internal security is also vital if auditing is to be of any use, since a program can potentially bypass the operating system, inclusive of bypassing auditing.\n",
            "\n",
            "\n",
            "=== User interface ===\n",
            "\n",
            "Every computer that is to be operated by an individual requires a user interface. The user interface is usually referred to as a shell and is essential if human interaction is to be supported.  The user interface views the directory structure and requests services from the operating system that will acquire data from input hardware devices, such as a keyboard, mouse or credit card reader, and requests operating system services to display prompts, status messages and such on output hardware devices, such as a video monitor or printer. The two most common forms of a user interface have historically been the command-line interface, where computer commands are typed out line-by-line, and the graphical user interface, where a visual environment (most commonly a WIMP) is present.\n",
            "\n",
            "\n",
            "==== Graphical user interfaces ====\n",
            "Most of the modern computer systems support graphical user interfaces (GUI), and often include them. In some computer systems, such as the original implementation of the classic Mac OS, the GUI is integrated into the kernel.\n",
            "While technically a graphical user interface is not an operating system service, incorporating support for one into the operating system kernel can allow the GUI to be more responsive by reducing the number of context switches required for the GUI to perform its output functions. Other operating systems are modular, separating the graphics subsystem from the kernel and the Operating System. In the 1980s UNIX, VMS and many others had operating systems that were built this way. Linux and macOS are also built this way. Modern releases of Microsoft Windows such as Windows Vista implement a graphics subsystem that is mostly in user-space; however the graphics drawing routines of versions between Windows NT 4.0 and Windows Server 2003 exist mostly in kernel space. Windows 9x had very little distinction between the interface and the kernel.\n",
            "Many computer operating systems allow the user to install or create any user interface they desire. The X Window System in conjunction with GNOME or KDE Plasma 5 is a commonly found setup on most Unix and Unix-like (BSD, Linux, Solaris) systems. A number of Windows shell replacements have been released for Microsoft Windows, which offer alternatives to the included Windows shell, but the shell itself cannot be separated from Windows.\n",
            "Numerous Unix-based GUIs have existed over time, most derived from X11. Competition among the various vendors of Unix (HP, IBM, Sun) led to much fragmentation, though an effort to standardize in the 1990s to COSE and CDE failed for various reasons, and were eventually eclipsed by the widespread adoption of GNOME and K Desktop Environment. Prior to free software-based toolkits and desktop environments, Motif was the prevalent toolkit/desktop combination (and was the basis upon which CDE was developed).\n",
            "Graphical user interfaces evolve over time. For example, Windows has modified its user interface almost every time a new major version of Windows is released, and the Mac OS GUI changed dramatically with the introduction of Mac OS X in 1999.\n",
            "\n",
            "\n",
            "== Real-time operating systems ==\n",
            "\n",
            "A real-time operating system (RTOS) is an operating system intended for applications with fixed deadlines (real-time computing). Such applications include some small embedded systems, automobile engine controllers, industrial robots, spacecraft, industrial control, and some large-scale computing systems.\n",
            "An early example of a large-scale real-time operating system was Transaction Processing Facility developed by American Airlines and IBM for the Sabre Airline Reservations System.\n",
            "Embedded systems that have fixed deadlines use a real-time operating system such as VxWorks, PikeOS, eCos, QNX, MontaVista Linux and RTLinux. Windows CE is a real-time operating system that shares similar APIs to desktop Windows but shares none of desktop Windows' codebase. Symbian OS also has an RTOS kernel (EKA2) starting with version 8.0b.\n",
            "Some embedded systems use operating systems such as Palm OS, BSD, and Linux, although such operating systems do not support real-time computing.\n",
            "\n",
            "\n",
            "== Operating system development as a hobby ==\n",
            "\n",
            "A hobby operating system may be classified as one whose code has not been directly derived from an existing operating system, and has few users and active developers.In some cases, hobby development is in support of a \"homebrew\" computing device, for example, a simple single-board computer powered by a 6502 microprocessor.  Or, development may be for an architecture already in widespread use.  Operating system development may come from entirely new concepts, or may commence by modeling an existing operating system.  In either case, the hobbyist is her/his own developer, or may interact with a small and sometimes unstructured group of individuals who have like interests.\n",
            "Examples of a hobby operating system include Syllable and TempleOS.\n",
            "\n",
            "\n",
            "== Diversity of operating systems and portability ==\n",
            "If an application is written for use on a specific operating system, and is ported to another OS, the functionality required by that application may be implemented differently by that OS (the names of functions, meaning of arguments, etc.) requiring the application to be adapted, changed, or otherwise maintained.\n",
            "This cost in supporting operating systems diversity can be avoided by instead writing applications against software platforms such as Java or Qt. These abstractions have already borne the cost of adaptation to specific operating systems and their system libraries.\n",
            "Another approach is for operating system vendors to adopt standards. For example, POSIX and OS abstraction layers provide commonalities that reduce porting costs.\n",
            "\n",
            "\n",
            "== Market share ==\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== Notes ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "Operating Systems at Curlie\n",
            "Multics History and the history of operating systems...\n",
            "\n",
            "\n",
            "Page Title: Computer Vision\n",
            "Text: Page 'Computer Vision' does not exist on Wikipedia....\n",
            "\n",
            "\n",
            "Page Title: Cryptography\n",
            "Text: Cryptography, or cryptology (from Ancient Greek: κρυπτός, romanized: kryptós \"hidden, secret\"; and γράφειν graphein, \"to write\", or -λογία -logia, \"study\", respectively), is the practice and study of techniques for secure communication in the presence of adversarial behavior. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, information security, electrical engineering, digital signal processing, physics, and others. Core concepts related to  information security (data confidentiality, data integrity, authentication, and non-repudiation) are also central to cryptography. Practical applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.\n",
            "Cryptography prior to the modern age was effectively synonymous with encryption, converting readable information (plaintext) to unintelligible nonsense text (ciphertext), which can only be read by reversing the process (decryption). The sender of an encrypted (coded) message shares the decryption (decoding) technique only with the intended recipients to preclude access from adversaries. The cryptography literature often uses the names \"Alice\" (or \"A\") for the sender, \"Bob\" (or \"B\") for the intended recipient, and \"Eve\" (or \"E\") for the eavesdropping adversary. Since the development of rotor cipher machines in World War I and the advent of computers in World War II, cryptography methods have become increasingly complex and their applications more varied.\n",
            "Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary. While it is theoretically possible to break into a well-designed system, it is infeasible in actual practice to do so. Such schemes, if well designed, are therefore termed \"computationally secure\". Theoretical advances (e.g., improvements in integer factorization algorithms) and faster computing technology require these designs to be continually reevaluated and, if necessary, adapted. Information-theoretically secure schemes that provably cannot be broken even with unlimited computing power, such as the one-time pad, are much more difficult to use in practice than the best theoretically breakable but computationally secure schemes.\n",
            "The growth of cryptographic technology has raised a number of legal issues in the Information Age. Cryptography's potential for use as a tool for espionage and sedition has led many governments to classify it as a weapon and to limit or even prohibit its use and export. In some jurisdictions where the use of cryptography is legal, laws permit investigators to compel the disclosure of encryption keys for documents relevant to an investigation. Cryptography also plays a major role in digital rights management and copyright infringement disputes with regard to digital media.\n",
            "\n",
            "\n",
            "== Terminology ==\n",
            "The first use of the term \"cryptograph\" (as opposed to \"cryptogram\") dates back to the 19th century—originating from \"The Gold-Bug,\" a story by Edgar Allan Poe.Until modern times, cryptography referred almost exclusively to \"encryption\", which is the process of converting ordinary information (called plaintext) into an unintelligible form (called ciphertext). Decryption is the reverse, in other words, moving from the unintelligible ciphertext back to plaintext. A cipher (or cypher) is a pair of algorithms that carry out the encryption and the reversing decryption. The detailed operation of a cipher is controlled both by the algorithm and, in each instance, by a \"key\". The key is a secret (ideally known only to the communicants), usually a string of characters (ideally short so it can be remembered by the user), which is needed to decrypt the ciphertext.  In formal mathematical terms, a \"cryptosystem\" is the ordered list of elements of finite possible plaintexts, finite possible cyphertexts, finite possible keys, and the encryption and decryption algorithms that correspond to each key.  Keys are important both formally and in actual practice, as ciphers without variable keys can be trivially broken with only the knowledge of the cipher used and are therefore useless (or even counter-productive) for most purposes. Historically, ciphers were often used directly for encryption or decryption without additional procedures such as authentication or integrity checks.\n",
            "There are two main types of cryptosystems: symmetric and asymmetric. In symmetric systems, the only ones known until the 1970s, the same secret key encrypts and decrypts a message. Data manipulation in symmetric systems is significantly faster than in asymmetric systems. Asymmetric systems use a \"public key\" to encrypt a message and a related \"private key\" to decrypt it. The advantage of asymmetric systems is that the public key can be freely published, allowing parties to establish secure communication without having a shared secret key.  In practice, asymmetric systems are used to first exchange a secret key, and then secure communication proceeds via a more efficient symmetric system using that key. Examples of asymmetric systems include Diffie–Hellman key exchange, RSA (Rivest–Shamir–Adleman), ECC (Elliptic Curve Cryptography), and Post-quantum cryptography. Secure symmetric algorithms include the commonly used AES (Advanced Encryption Standard) which replaced the older DES (Data Encryption Standard).  Insecure symmetric algorithms include children's language tangling schemes such as Pig Latin or other cant, and all historical cryptographic schemes, however seriously intended, prior to the invention of the one-time pad early in the 20th century.\n",
            "In colloquial use, the term \"code\" is often used to mean any method of encryption or concealment of meaning. However, in cryptography, code has a more specific meaning: the replacement of a unit of plaintext (i.e., a meaningful word or phrase) with a code word (for example, \"wallaby\" replaces \"attack at dawn\").  A cypher, in contrast, is a scheme for changing or substituting an element below such a level (a letter, a syllable, or a pair of letters, etc.) in order to produce a cyphertext.\n",
            "Cryptanalysis is the term used for the study of methods for obtaining the meaning of encrypted information without access to the key normally required to do so; i.e., it is the study of how to \"crack\" encryption algorithms or their implementations.\n",
            "Some use the terms \"cryptography\" and \"cryptology\" interchangeably in English, while others (including US military practice generally) use \"cryptography\" to refer specifically to the use and practice of cryptographic techniques and \"cryptology\" to refer to the combined study of cryptography and cryptanalysis. English is more flexible than several other languages in which \"cryptology\" (done by cryptologists) is always used in the second sense above. RFC 2828 advises that steganography is sometimes included in cryptology.The study of characteristics of languages that have some application in cryptography or cryptology (e.g. frequency data, letter combinations, universal patterns, etc.) is called cryptolinguistics. Cryptolingusitics is especially used in military intelligence applications for deciphering foreign communications.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "Before the modern era, cryptography focused on message confidentiality (i.e., encryption)—conversion of messages from a comprehensible form into an incomprehensible one and back again at the other end, rendering it unreadable by interceptors or eavesdroppers without secret knowledge (namely the key needed for decryption of that message). Encryption attempted to ensure secrecy in communications, such as those of spies, military leaders, and diplomats. In recent decades, the field has expanded beyond confidentiality concerns to include techniques for message integrity checking, sender/receiver identity authentication, digital signatures, interactive proofs and secure computation, among others.\n",
            "\n",
            "\n",
            "=== Classic cryptography ===\n",
            "The main classical cipher types are transposition ciphers, which rearrange the order of letters in a message (e.g., 'hello world' becomes 'ehlol owrdl' in a trivially simple rearrangement scheme), and substitution ciphers, which systematically replace letters or groups of letters with other letters or groups of letters (e.g., 'fly at once' becomes 'gmz bu podf' by replacing each letter with the one following it in the Latin alphabet). Simple versions of either have never offered much confidentiality from enterprising opponents. An early substitution cipher was the Caesar cipher, in which each letter in the plaintext was replaced by a letter some fixed number of positions further down the alphabet. Suetonius reports that Julius Caesar used it with a shift of three to communicate with his generals. Atbash is an example of an early Hebrew cipher. The earliest known use of cryptography is some carved ciphertext on stone in Egypt (c. 1900 BCE), but this may have been done for the amusement of literate observers rather than as a way of concealing information.\n",
            "The Greeks of Classical times are said to have known of ciphers (e.g., the scytale transposition cipher claimed to have been used by the Spartan military). Steganography (i.e., hiding even the existence of a message so as to keep it confidential) was also first developed in ancient times. An early example, from Herodotus, was a message tattooed on a slave's shaved head and concealed under the regrown hair. More modern examples of steganography include the use of invisible ink, microdots, and digital watermarks to conceal information.\n",
            "In India, the 2000-year-old Kamasutra of Vātsyāyana speaks of two different kinds of ciphers called Kautiliyam and Mulavediya. In the Kautiliyam, the cipher letter substitutions are based on phonetic relations, such as vowels becoming consonants. In the Mulavediya, the cipher alphabet consists of pairing letters and using the reciprocal ones.In Sassanid Persia, there were two secret scripts, according to the Muslim author Ibn al-Nadim: the šāh-dabīrīya (literally \"King's script\") which was used for official correspondence, and the rāz-saharīya which was used to communicate secret messages with other countries.David Kahn notes in The Codebreakers that modern cryptology originated among the Arabs, the first people to systematically document cryptanalytic methods. Al-Khalil (717–786) wrote the Book of Cryptographic Messages, which contains the first use of permutations and combinations to list all possible Arabic words with and without vowels.\n",
            "Ciphertexts produced by a classical cipher (and some modern ciphers) will reveal statistical information about the plaintext, and that information can often be used to break the cipher. After the discovery of frequency analysis, perhaps by the Arab mathematician and polymath Al-Kindi (also known as Alkindus) in the 9th century, nearly all such ciphers could be broken by an informed attacker. Such classical ciphers still enjoy popularity today, though mostly as puzzles (see cryptogram). Al-Kindi wrote a book on cryptography entitled Risalah fi Istikhraj al-Mu'amma (Manuscript for the Deciphering Cryptographic Messages), which described the first known use of frequency analysis cryptanalysis techniques.\n",
            "Language letter frequencies may offer little help for some extended historical encryption techniques such as homophonic cipher that tend to flatten the frequency distribution. For those ciphers, language letter group (or n-gram) frequencies may provide an attack.\n",
            "Essentially all ciphers remained vulnerable to cryptanalysis using the frequency analysis technique until the development of the polyalphabetic cipher, most clearly by Leon Battista Alberti around the year 1467, though there is some indication that it was already known to Al-Kindi. Alberti's innovation was to use different ciphers (i.e., substitution alphabets) for various parts of a message (perhaps for each successive plaintext letter at the limit). He also invented what was probably the first automatic cipher device, a wheel that implemented a partial realization of his invention. In the Vigenère cipher, a polyalphabetic cipher, encryption uses a key word, which controls letter substitution depending on which letter of the key word is used. In the mid-19th century Charles Babbage showed that the Vigenère cipher was vulnerable to Kasiski examination, but this was first published about ten years later by Friedrich Kasiski.Although frequency analysis can be a powerful and general technique against many ciphers, encryption has still often been effective in practice, as many a would-be cryptanalyst was unaware of the technique. Breaking a message without using frequency analysis essentially required knowledge of the cipher used and perhaps of the key involved, thus making espionage, bribery, burglary, defection, etc., more attractive approaches to the cryptanalytically uninformed. It was finally explicitly recognized in the 19th century that secrecy of a cipher's algorithm is not a sensible nor practical safeguard of message security; in fact, it was further realized that any adequate cryptographic scheme (including ciphers) should remain secure even if the adversary fully understands the cipher algorithm itself. Security of the key used should alone be sufficient for a good cipher to maintain confidentiality under an attack. This fundamental principle was first explicitly stated in 1883 by Auguste Kerckhoffs and is generally called Kerckhoffs's Principle; alternatively and more bluntly, it was restated by Claude Shannon, the inventor of information theory and the fundamentals of theoretical cryptography, as Shannon's Maxim—'the enemy knows the system'.\n",
            "Different physical devices and aids have been used to assist with ciphers. One of the earliest may have been the scytale of ancient Greece, a rod supposedly used by the Spartans as an aid for a transposition cipher. In medieval times, other aids were invented such as the cipher grille, which was also used for a kind of steganography. With the invention of polyalphabetic ciphers came more sophisticated aids such as Alberti's own cipher disk, Johannes Trithemius' tabula recta scheme, and Thomas Jefferson's wheel cypher (not publicly known, and reinvented independently by Bazeries around 1900). Many mechanical encryption/decryption devices were invented early in the 20th century, and several patented, among them rotor machines—famously including the Enigma machine used by the German government and military from the late 1920s and during World War II. The ciphers implemented by better quality examples of these machine designs brought about a substantial increase in cryptanalytic difficulty after WWI.\n",
            "\n",
            "\n",
            "=== Early computer-era cryptography ===\n",
            "Cryptanalysis of the new mechanical ciphering devices proved to be both difficult and laborious. In the United Kingdom, cryptanalytic efforts at Bletchley Park during WWII spurred the development of more efficient means for carrying out repetitive tasks, such as military code breaking (decryption). This culminated in the development of the Colossus, the world's first fully electronic, digital, programmable computer, which assisted in the decryption of ciphers generated by the German Army's Lorenz SZ40/42 machine.\n",
            "Extensive open academic research into cryptography is relatively recent, beginning in the mid-1970s. In the early 1970s IBM personnel designed the Data Encryption Standard (DES) algorithm that became the first federal government cryptography standard in the United States. In 1976 Whitfield Diffie and Martin Hellman published the Diffie–Hellman key exchange algorithm. In 1977 the RSA algorithm was published in Martin Gardner's Scientific American column. Since then, cryptography has become a widely used tool in communications, computer networks, and computer security generally.\n",
            "Some modern cryptographic techniques can only keep their keys secret if certain mathematical problems are intractable, such as the integer factorization or the discrete logarithm problems, so there are deep connections with abstract mathematics. There are very few cryptosystems that are proven to be unconditionally secure. The one-time pad is one, and was proven to be so by Claude Shannon. There are a few important algorithms that have been proven secure under certain assumptions. For example, the infeasibility of factoring extremely large integers is the basis for believing that RSA is secure, and some other systems, but even so, proof of unbreakability is unavailable since the underlying mathematical problem remains open. In practice, these are widely used, and are believed unbreakable in practice by most competent observers.  There are systems similar to RSA, such as one by Michael O. Rabin that are provably secure provided factoring  n = pq is impossible;  it is quite unusable in practice. The discrete logarithm problem is the basis for believing some other cryptosystems are secure, and again, there are related, less practical systems that are provably secure relative to the solvability or insolvability discrete log problem.As well as being aware of cryptographic history, cryptographic algorithm and system designers must also sensibly consider probable future developments while working on their designs. For instance, continuous improvements in computer processing power have increased the scope of brute-force attacks, so when specifying key lengths, the required key lengths are similarly advancing. The potential impact of quantum computing are already being considered by some cryptographic system designers developing post-quantum cryptography. The announced imminence of small implementations of these machines may be making the need for preemptive caution rather more than merely speculative.\n",
            "\n",
            "\n",
            "=== Modern cryptography ===\n",
            "Prior to the early 20th century, cryptography was mainly concerned with linguistic and lexicographic patterns. Since then cryptography has broadened in scope, and now makes extensive use of mathematical subdisciplines, including information theory, computational complexity, statistics, combinatorics, abstract algebra, number theory, and finite mathematics. Cryptography is also a branch of engineering, but an unusual one since it deals with active, intelligent, and malevolent opposition; other kinds of engineering (e.g., civil or chemical engineering) need deal only with neutral natural forces. There is also active research examining the relationship between cryptographic problems and quantum physics.\n",
            "Just as the development of digital computers and electronics helped in cryptanalysis, it made possible much more complex ciphers. Furthermore, computers allowed for the encryption of any kind of data representable in any binary format, unlike classical ciphers which only encrypted written language texts; this was new and significant. Computer use has thus supplanted linguistic cryptography, both for cipher design and cryptanalysis. Many computer ciphers can be characterized by their operation on binary bit sequences (sometimes in groups or blocks), unlike classical and mechanical schemes, which generally manipulate traditional characters (i.e., letters and digits) directly. However, computers have also assisted cryptanalysis, which has compensated to some extent for increased cipher complexity. Nonetheless, good modern ciphers have stayed ahead of cryptanalysis; it is typically the case that use of a quality cipher is very efficient (i.e., fast and requiring few resources, such as memory or CPU capability), while breaking it requires an effort many orders of magnitude larger, and vastly larger than that required for any classical cipher, making cryptanalysis so inefficient and impractical as to be effectively impossible.\n",
            "\n",
            "\n",
            "== Modern cryptography ==\n",
            "\n",
            "\n",
            "=== Symmetric-key cryptography ===\n",
            "\n",
            "Symmetric-key cryptography refers to encryption methods in which both the sender and receiver share the same key (or, less commonly, in which their keys are different, but related in an easily computable way). This was the only kind of encryption publicly known until June 1976.\n",
            "Symmetric key ciphers are implemented as either block ciphers or stream ciphers. A block cipher enciphers input in blocks of plaintext as opposed to individual characters, the input form used by a stream cipher.\n",
            "The Data Encryption Standard (DES) and the Advanced Encryption Standard (AES) are block cipher designs that have been designated cryptography standards by the US government (though DES's designation was finally withdrawn after the AES was adopted). Despite its deprecation as an official standard, DES (especially its still-approved and much more secure triple-DES variant) remains quite popular; it is used across a wide range of applications, from ATM encryption to e-mail privacy and secure remote access. Many other block ciphers have been designed and released, with considerable variation in quality. Many, even some designed by capable practitioners, have been thoroughly broken, such as FEAL.Stream ciphers, in contrast to the 'block' type, create an arbitrarily long stream of key material, which is combined with the plaintext bit-by-bit or character-by-character, somewhat like the one-time pad. In a stream cipher, the output stream is created based on a hidden internal state that changes as the cipher operates. That internal state is initially set up using the secret key material. RC4 is a widely used stream cipher. Block ciphers can be used as stream ciphers by generating blocks of a keystream (in place of a Pseudorandom number generator) and applying an XOR operation to each bit of the plaintext with each bit of the keystream.Message authentication codes (MACs) are much like cryptographic hash functions, except that a secret key can be used to authenticate the hash value upon receipt; this additional complication blocks an attack scheme against bare digest algorithms, and so has been thought worth the effort. Cryptographic hash functions are a third type of cryptographic algorithm. They take a message of any length as input, and output a short, fixed-length hash, which can be used in (for example) a digital signature. For good hash functions, an attacker cannot find two messages that produce the same hash. MD4 is a long-used hash function that is now broken; MD5, a strengthened variant of MD4, is also widely used but broken in practice. The US National Security Agency developed the Secure Hash Algorithm series of MD5-like hash functions: SHA-0 was a flawed algorithm that the agency withdrew; SHA-1 is widely deployed and more secure than MD5, but cryptanalysts have identified attacks against it; the SHA-2 family improves on SHA-1, but is vulnerable to clashes as of 2011; and the US standards authority thought it \"prudent\" from a security perspective to develop a new standard to \"significantly improve the robustness of NIST's overall hash algorithm toolkit.\" Thus, a hash function design competition was meant to select a new U.S. national standard, to be called SHA-3, by 2012. The competition ended on October 2, 2012, when the NIST announced that Keccak would be the new SHA-3 hash algorithm. Unlike block and stream ciphers that are invertible, cryptographic hash functions produce a hashed output that cannot be used to retrieve the original input data. Cryptographic hash functions are used to verify the authenticity of data retrieved from an untrusted source or to add a layer of security.\n",
            "\n",
            "\n",
            "=== Public-key cryptography ===\n",
            "\n",
            "Symmetric-key cryptosystems use the same key for encryption and decryption of a message, although a message or group of messages can have a different key than others. A significant disadvantage of symmetric ciphers is the key management necessary to use them securely. Each distinct pair of communicating parties must, ideally, share a different key, and perhaps for each ciphertext exchanged as well. The number of keys required increases as the square of the number of network members, which very quickly requires complex key management schemes to keep them all consistent and secret.\n",
            "\n",
            "In a groundbreaking 1976 paper, Whitfield Diffie and Martin Hellman proposed the notion of public-key (also, more generally, called asymmetric key) cryptography in which two different but mathematically related keys are used—a public key and a private key. A public key system is so constructed that calculation of one key (the 'private key') is computationally infeasible from the other (the 'public key'), even though they are necessarily related. Instead, both keys are generated secretly, as an interrelated pair. The historian David Kahn described public-key cryptography as \"the most revolutionary new concept in the field since polyalphabetic substitution emerged in the Renaissance\".In public-key cryptosystems, the public key may be freely distributed, while its paired private key must remain secret. In a public-key encryption system, the public key is used for encryption, while the private or secret key is used for decryption. While Diffie and Hellman could not find such a system, they showed that public-key cryptography was indeed possible by presenting the Diffie–Hellman key exchange protocol, a solution that is now widely used in secure communications to allow two parties to secretly agree on a shared encryption key.\n",
            "The X.509 standard defines the most commonly used format for public key certificates.Diffie and Hellman's publication sparked widespread academic efforts in finding a practical public-key encryption system. This race was finally won in 1978 by Ronald Rivest, Adi Shamir, and Len Adleman, whose solution has since become known as the RSA algorithm.The Diffie–Hellman and RSA algorithms, in addition to being the first publicly known examples of high-quality public-key algorithms, have been among the most widely used. Other asymmetric-key algorithms include the Cramer–Shoup cryptosystem, ElGamal encryption, and various elliptic curve techniques.A document published in 1997 by the Government Communications Headquarters (GCHQ), a British intelligence organization, revealed that cryptographers at GCHQ had anticipated several academic developments. Reportedly, around 1970, James H. Ellis had conceived the principles of asymmetric key cryptography. In 1973, Clifford Cocks invented a solution that was very similar in design rationale to RSA. In 1974, Malcolm J. Williamson is claimed to have developed the Diffie–Hellman key exchange.\n",
            "Public-key cryptography is also used for implementing digital signature schemes. A digital signature is reminiscent of an ordinary signature; they both have the characteristic of being easy for a user to produce, but difficult for anyone else to forge. Digital signatures can also be permanently tied to the content of the message being signed; they cannot then be 'moved' from one document to another, for any attempt will be detectable. In digital signature schemes, there are two algorithms: one for signing, in which a secret key is used to process the message (or a hash of the message, or both), and one for verification, in which the matching public key is used with the message to check the validity of the signature. RSA and DSA are two of the most popular digital signature schemes. Digital signatures are central to the operation of public key infrastructures and many network security schemes (e.g., SSL/TLS, many VPNs, etc.).Public-key algorithms are most often based on the computational complexity of \"hard\" problems, often from number theory. For example, the hardness of RSA is related to the integer factorization problem, while Diffie–Hellman and DSA are related to the discrete logarithm problem. The security of elliptic curve cryptography is based on number theoretic problems involving elliptic curves. Because of the difficulty of the underlying problems, most public-key algorithms involve operations such as modular multiplication and exponentiation, which are much more computationally expensive than the techniques used in most block ciphers, especially with typical key sizes. As a result, public-key cryptosystems are commonly hybrid cryptosystems, in which a fast high-quality symmetric-key encryption algorithm is used for the message itself, while the relevant symmetric key is sent with the message, but encrypted using a public-key algorithm. Similarly, hybrid signature schemes are often used, in which a cryptographic hash function is computed, and only the resulting hash is digitally signed.\n",
            "\n",
            "\n",
            "=== Cryptographic hash functions ===\n",
            "Cryptographic hash functions are functions that take a variable-length input and return a fixed-length output, which can be used in, for example, a digital signature. For a hash function to be secure, it must be difficult to compute two inputs that hash to the same value (collision resistance) and to compute an input that hashes to a given output (preimage resistance). MD4 is a long-used hash function that is now broken; MD5, a strengthened variant of MD4, is also widely used but broken in practice. The US National Security Agency developed the Secure Hash Algorithm series of MD5-like hash functions: SHA-0 was a flawed algorithm that the agency withdrew; SHA-1 is widely deployed and more secure than MD5, but cryptanalysts have identified attacks against it; the SHA-2 family improves on SHA-1, but is vulnerable to clashes as of 2011; and the US standards authority thought it \"prudent\" from a security perspective to develop a new standard to \"significantly improve the robustness of NIST's overall hash algorithm toolkit.\" Thus, a hash function design competition was meant to select a new U.S. national standard, to be called SHA-3, by 2012. The competition ended on October 2, 2012, when the NIST announced that Keccak would be the new SHA-3 hash algorithm. Unlike block and stream ciphers that are invertible, cryptographic hash functions produce a hashed output that cannot be used to retrieve the original input data. Cryptographic hash functions are used to verify the authenticity of data retrieved from an untrusted source or to add a layer of security.\n",
            "\n",
            "\n",
            "=== Cryptanalysis ===\n",
            "\n",
            "The goal of cryptanalysis is to find some weakness or insecurity in a cryptographic scheme, thus permitting its subversion or evasion.\n",
            "It is a common misconception that every encryption method can be broken. In connection with his WWII work at Bell Labs, Claude Shannon proved that the one-time pad cipher is unbreakable, provided the key material is truly random, never reused, kept secret from all possible attackers, and of equal or greater length than the message. Most ciphers, apart from the one-time pad, can be broken with enough computational effort by brute force attack, but the amount of effort needed may be exponentially dependent on the key size, as compared to the effort needed to make use of the cipher. In such cases, effective security could be achieved if it is proven that the effort required (i.e., \"work factor\", in Shannon's terms) is beyond the ability of any adversary. This means it must be shown that no efficient method (as opposed to the time-consuming brute force method) can be found to break the cipher. Since no such proof has been found to date, the one-time-pad remains the only theoretically unbreakable cipher. Although well-implemented one-time-pad encryption cannot be broken, traffic analysis is still possible.\n",
            "There are a wide variety of cryptanalytic attacks, and they can be classified in any of several ways. A common distinction turns on what Eve (an attacker) knows and what capabilities are available. In a ciphertext-only attack, Eve has access only to the ciphertext (good modern cryptosystems are usually effectively immune to ciphertext-only attacks). In a known-plaintext attack, Eve has access to a ciphertext and its corresponding plaintext (or to many such pairs). In a chosen-plaintext attack, Eve may choose a plaintext and learn its corresponding ciphertext (perhaps many times); an example is gardening, used by the British during WWII. In a chosen-ciphertext attack, Eve may be able to choose ciphertexts and learn their corresponding plaintexts. Finally in a man-in-the-middle attack Eve gets in between Alice (the sender) and Bob (the recipient), accesses and modifies the traffic and then forwards it to the recipient. Also important, often overwhelmingly so, are mistakes (generally in the design or use of one of the protocols involved).\n",
            "\n",
            "Cryptanalysis of symmetric-key ciphers typically involves looking for attacks against the block ciphers or stream ciphers that are more efficient than any attack that could be against a perfect cipher. For example, a simple brute force attack against DES requires one known plaintext and 255 decryptions, trying approximately half of the possible keys, to reach a point at which chances are better than even that the key sought will have been found. But this may not be enough assurance; a linear cryptanalysis attack against DES requires 243 known plaintexts (with their corresponding ciphertexts) and approximately 243 DES operations. This is a considerable improvement over brute force attacks.\n",
            "Public-key algorithms are based on the computational difficulty of various problems. The most famous of these are the difficulty of integer factorization of semiprimes and the difficulty of calculating discrete logarithms, both of which are not yet proven to be solvable in polynomial time (P) using only a classical Turing-complete computer. Much public-key cryptanalysis concerns designing algorithms in P that can solve these problems, or using other technologies, such as quantum computers. For instance, the best-known algorithms for solving the elliptic curve-based version of discrete logarithm are much more time-consuming than the best-known algorithms for factoring, at least for problems of more or less equivalent size. Thus, to achieve an equivalent strength of encryption, techniques that depend upon the difficulty of factoring large composite numbers, such as the RSA cryptosystem, require larger keys than elliptic curve techniques. For this reason, public-key cryptosystems based on elliptic curves have become popular since their invention in the mid-1990s.\n",
            "While pure cryptanalysis uses weaknesses in the algorithms themselves, other attacks on cryptosystems are based on actual use of the algorithms in real devices, and are called side-channel attacks. If a cryptanalyst has access to, for example, the amount of time the device took to encrypt a number of plaintexts or report an error in a password or PIN character, they may be able to use a timing attack to break a cipher that is otherwise resistant to analysis. An attacker might also study the pattern and length of messages to derive valuable information; this is known as traffic analysis and can be quite useful to an alert adversary. Poor administration of a cryptosystem, such as permitting too short keys, will make any system vulnerable, regardless of other virtues. Social engineering and other attacks against humans (e.g., bribery, extortion, blackmail, espionage, rubber-hose cryptanalysis or torture) are usually employed due to being more cost-effective and feasible to perform in a reasonable amount of time compared to pure cryptanalysis by a high margin.\n",
            "\n",
            "\n",
            "=== Cryptographic primitives ===\n",
            "Much of the theoretical work in cryptography concerns cryptographic primitives—algorithms with basic cryptographic properties—and their relationship to other cryptographic problems. More complicated cryptographic tools are then built from these basic primitives. These primitives provide fundamental properties, which are used to develop more complex tools called cryptosystems or cryptographic protocols, which guarantee one or more high-level security properties. Note, however, that the distinction between cryptographic primitives and cryptosystems, is quite arbitrary; for example, the RSA algorithm is sometimes considered a cryptosystem, and sometimes a primitive. Typical examples of cryptographic primitives include pseudorandom functions, one-way functions, etc.\n",
            "\n",
            "\n",
            "=== Cryptosystems ===\n",
            "\n",
            "One or more cryptographic primitives are often used to develop a more complex algorithm, called a cryptographic system, or cryptosystem. Cryptosystems (e.g., El-Gamal encryption) are designed to provide particular functionality (e.g., public key encryption) while guaranteeing certain security properties (e.g., chosen-plaintext attack (CPA) security in the random oracle model). Cryptosystems use the properties of the underlying cryptographic primitives to support the system's security properties. As the distinction between primitives and cryptosystems is somewhat arbitrary, a sophisticated cryptosystem can be derived from a combination of several more primitive cryptosystems. In many cases, the cryptosystem's structure involves back and forth communication among two or more parties in space (e.g., between the sender of a secure message and its receiver) or across time (e.g., cryptographically protected backup data). Such cryptosystems are sometimes called cryptographic protocols.\n",
            "Some widely known cryptosystems include RSA, Schnorr signature, ElGamal encryption, and Pretty Good Privacy (PGP). More complex cryptosystems include electronic cash systems, signcryption systems, etc. Some more 'theoretical' cryptosystems include interactive proof systems, (like zero-knowledge proofs), systems for secret sharing, etc.\n",
            "\n",
            "\n",
            "=== Lightweight cryptography ===\n",
            "Lightweight cryptography (LWC) concerns cryptographic algorithms developed for a strictly constrained environment. The growth of Internet of Things (IoT) has spiked research into the development of lightweight algorithms that are better suited for the environment. An IoT environment requires strict constraints on power consumption, processing power, and security. Algorithms such as PRESENT, AES, and SPECK are examples of the many LWC algorithms that have been developed to achieve the standard set by the National Institute of Standards and Technology.\n",
            "\n",
            "\n",
            "== Applications ==\n",
            "\n",
            "Cryptography is widely used on the internet to help protect user-data and prevent eavesdropping. To ensure secrecy during transmission, many systems use private key cryptography to protect transmitted information. With public-key systems, one can maintain secrecy without a master key or a large number of keys. But, some algorithms like Bitlocker and Veracrypt are generally not private-public key cryptography. For example, Veracrypt uses a password hash to generate the single private key. However, it can be configured to run in public-private key systems. The C++ opensource encryption library OpenSSL provides free and opensource encryption software and tools. The most commonly used encryption cipher suit is AES, as it has hardware acceleration for all x86 based processors that has AES-NI. A close contender is ChaCha20-Poly1305, which is a stream cipher, however it is commonly used for mobile devices as they are ARM based which does not feature AES-NI instruction set extension.\n",
            "\n",
            "\n",
            "=== Cybersecurity ===\n",
            "Cryptography can be used to secure communications by encrypting them. Websites use encryption via HTTPS. \"End-to-end\" encryption, where only sender and receiver can read messages, is implemented for email in Pretty Good Privacy and for secure messaging in general in WhatsApp, Signal and Telegram.Operating systems use encryption to keep passwords secret, conceal parts of the system, and ensure that software updates are truly from the system maker. Instead of storing plaintext passwords, computer systems store hashes thereof; then, when a user logs in, the system passes the given password through a cryptographic hash function and compares it to the hashed value on file. In this manner, neither the system nor an attacker has at any point access to the password in plaintext.Encryption is sometimes used to encrypt one's entire drive. For example, University College London has implemented BitLocker (a program by Microsoft) to render drive data opaque without users logging in.\n",
            "\n",
            "\n",
            "=== Cryptocurrencies and cryptoeconomics ===\n",
            "Cryptographic techniques enable cryptocurrency technologies, such as distributed ledger technologies (e.g., blockchains), which finance cryptoeconomics applications such as decentralized finance (DeFi). Key cryptographic techniques that enable cryptocurrencies and cryptoeconomics include, but are not limited to: cryptographic keys, cryptographic hash function, asymmetric (public key) encryption, Multi-Factor Authentication (MFA), End-to-End Encryption (E2EE), and Zero Knowledge Proofs (ZKP).\n",
            "\n",
            "\n",
            "== Legal issues ==\n",
            "\n",
            "\n",
            "=== Prohibitions ===\n",
            "Cryptography has long been of interest to intelligence gathering and law enforcement agencies. Secret communications may be criminal or even treasonous. Because of its facilitation of privacy, and the diminution of privacy attendant on its prohibition, cryptography is also of considerable interest to civil rights supporters. Accordingly, there has been a history of controversial legal issues surrounding cryptography, especially since the advent of inexpensive computers has made widespread access to high-quality cryptography possible.\n",
            "In some countries, even the domestic use of cryptography is, or has been, restricted. Until 1999, France significantly restricted the use of cryptography domestically, though it has since relaxed many of these rules. In China and Iran, a license is still required to use cryptography. Many countries have tight restrictions on the use of cryptography. Among the more restrictive are laws in Belarus, Kazakhstan, Mongolia, Pakistan, Singapore, Tunisia, and Vietnam.In the United States, cryptography is legal for domestic use, but there has been much conflict over legal issues related to cryptography. One particularly important issue has been the export of cryptography and cryptographic software and hardware. Probably because of the importance of cryptanalysis in World War II and an expectation that cryptography would continue to be important for national security, many Western governments have, at some point, strictly regulated export of cryptography. After World War II, it was illegal in the US to sell or distribute encryption technology overseas; in fact, encryption was designated as auxiliary military equipment and put on the United States Munitions List. Until the development of the personal computer, asymmetric key algorithms (i.e., public key techniques), and the Internet, this was not especially problematic. However, as the Internet grew and computers became more widely available, high-quality encryption techniques became well known around the globe.\n",
            "\n",
            "\n",
            "=== Export controls ===\n",
            "\n",
            "In the 1990s, there were several challenges to US export regulation of cryptography. After the source code for Philip Zimmermann's Pretty Good Privacy (PGP) encryption program found its way onto the Internet in June 1991, a complaint by RSA Security (then called RSA Data Security, Inc.) resulted in a lengthy criminal investigation of Zimmermann by the US Customs Service and the FBI, though no charges were ever filed. Daniel J. Bernstein, then a graduate student at UC Berkeley, brought a lawsuit against the US government challenging some aspects of the restrictions based on free speech grounds. The 1995 case Bernstein v. United States ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.In 1996, thirty-nine countries signed the Wassenaar Arrangement, an arms control treaty that deals with the export of arms and \"dual-use\" technologies such as cryptography. The treaty stipulated that the use of cryptography with short key-lengths (56-bit for symmetric encryption, 512-bit for RSA) would no longer be export-controlled. Cryptography exports from the US became less strictly regulated as a consequence of a major relaxation in 2000; there are no longer very many restrictions on key sizes in US-exported mass-market software. Since this relaxation in US export restrictions, and because most personal computers connected to the Internet include US-sourced web browsers such as Firefox or Internet Explorer, almost every Internet user worldwide has potential access to quality cryptography via their browsers (e.g., via Transport Layer Security). The Mozilla Thunderbird and Microsoft Outlook E-mail client programs similarly can transmit and receive emails via TLS, and can send and receive email encrypted with S/MIME. Many Internet users do not realize that their basic application software contains such extensive cryptosystems. These browsers and email programs are so ubiquitous that even governments whose intent is to regulate civilian use of cryptography generally do not find it practical to do much to control distribution or use of cryptography of this quality, so even when such laws are in force, actual enforcement is often effectively impossible.\n",
            "\n",
            "\n",
            "=== NSA involvement ===\n",
            "\n",
            "Another contentious issue connected to cryptography in the United States is the influence of the National Security Agency on cipher development and policy. The NSA was involved with the design of DES during its development at IBM and its consideration by the National Bureau of Standards as a possible Federal Standard for cryptography. DES was designed to be resistant to differential cryptanalysis, a powerful and general cryptanalytic technique known to the NSA and IBM, that became publicly known only when it was rediscovered in the late 1980s. According to Steven Levy, IBM discovered differential cryptanalysis, but kept the technique secret at the NSA's request. The technique became publicly known only when Biham and Shamir re-discovered and announced it some years later. The entire affair illustrates the difficulty of determining what resources and knowledge an attacker might actually have.\n",
            "Another instance of the NSA's involvement was the 1993 Clipper chip affair, an encryption microchip intended to be part of the Capstone cryptography-control initiative. Clipper was widely criticized by cryptographers for two reasons. The cipher algorithm (called Skipjack) was then classified (declassified in 1998, long after the Clipper initiative lapsed). The classified cipher caused concerns that the NSA had deliberately made the cipher weak in order to assist its intelligence efforts. The whole initiative was also criticized based on its violation of Kerckhoffs's Principle, as the scheme included a special escrow key held by the government for use by law enforcement (i.e. wiretapping).\n",
            "\n",
            "\n",
            "=== Digital rights management ===\n",
            "\n",
            "Cryptography is central to digital rights management (DRM), a group of techniques for technologically controlling use of copyrighted material, being widely implemented and deployed at the behest of some copyright holders. In 1998, U.S. President Bill Clinton signed the Digital Millennium Copyright Act (DMCA), which criminalized all production, dissemination, and use of certain cryptanalytic techniques and technology (now known or later discovered); specifically, those that could be used to circumvent DRM technological schemes. This had a noticeable impact on the cryptography research community since an argument can be made that any cryptanalytic research violated the DMCA. Similar statutes have since been enacted in several countries and regions, including the implementation in the EU Copyright Directive. Similar restrictions are called for by treaties signed by World Intellectual Property Organization member-states.\n",
            "The United States Department of Justice and FBI have not enforced the DMCA as rigorously as had been feared by some, but the law, nonetheless, remains a controversial one. Niels Ferguson, a well-respected cryptography researcher, has publicly stated that he will not release some of his research into an Intel security design for fear of prosecution under the DMCA. Cryptologist Bruce Schneier has argued that the DMCA encourages vendor lock-in, while inhibiting actual measures toward cyber-security. Both Alan Cox (longtime Linux kernel developer) and Edward Felten (and some of his students at Princeton) have encountered problems related to the Act. Dmitry Sklyarov was arrested during a visit to the US from Russia, and jailed for five months pending trial for alleged violations of the DMCA arising from work he had done in Russia, where the work was legal. In 2007, the cryptographic keys responsible for Blu-ray and HD DVD content scrambling were discovered and released onto the Internet. In both cases, the Motion Picture Association of America sent out numerous DMCA takedown notices, and there was a massive Internet backlash triggered by the perceived impact of such notices on fair use and free speech.\n",
            "\n",
            "\n",
            "=== Forced disclosure of encryption keys ===\n",
            "\n",
            "In the United Kingdom, the Regulation of Investigatory Powers Act gives UK police the powers to force suspects to decrypt files or hand over passwords that protect encryption keys. Failure to comply is an offense in its own right, punishable on conviction by a two-year jail sentence or up to five years in cases involving national security. Successful prosecutions have occurred under the Act; the first, in 2009, resulted in a term of 13 months' imprisonment. Similar forced disclosure laws in Australia, Finland, France, and India compel individual suspects under investigation to hand over encryption keys or passwords during a criminal investigation.\n",
            "In the United States, the federal criminal case of United States v. Fricosu addressed whether a search warrant can compel a person to reveal an encryption passphrase or password. The Electronic Frontier Foundation (EFF) argued that this is a violation of the protection from self-incrimination given by the Fifth Amendment. In 2012, the court ruled that under the All Writs Act, the defendant was required to produce an unencrypted hard drive for the court.In many jurisdictions, the legal status of forced disclosure remains unclear.\n",
            "The 2016 FBI–Apple encryption dispute concerns the ability of courts in the United States to compel manufacturers' assistance in unlocking cell phones whose contents are cryptographically protected.\n",
            "As a potential counter-measure to forced disclosure some cryptographic software supports plausible deniability, where the encrypted data is indistinguishable from unused random data (for example such as that of a drive which has been securely wiped).\n",
            "\n",
            "\n",
            "== See also ==\n",
            "Collision attack\n",
            "Comparison of cryptography libraries\n",
            "Crypto Wars – Attempts to limit access to strong cryptography\n",
            "Encyclopedia of Cryptography and Security – Book by Technische Universiteit Eindhoven\n",
            "Global surveillance – Mass surveillance across national borders\n",
            "Indistinguishability obfuscation – Type of cryptographic software obfuscation\n",
            "Information theory – Scientific study of digital information\n",
            "Outline of cryptography – Overview of and topical guide to cryptography\n",
            "List of cryptographers\n",
            "List of important publications in cryptography\n",
            "List of multiple discoveries\n",
            "List of unsolved problems in computer science – List of unsolved computational problems\n",
            "Secure cryptoprocessor\n",
            "Strong cryptography – Term applied to cryptographic systems that are highly resistant to cryptanalysis\n",
            "Syllabical and Steganographical Table – Eighteenth-century work believed to be the first cryptography chart – first cryptography chart\n",
            "World Wide Web Consortium's Web Cryptography API – World Wide Web Consortium cryptography standard\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            " The dictionary definition of cryptography at Wiktionary\n",
            " Media related to Cryptography at Wikimedia Commons\n",
            "Cryptography on In Our Time at the BBC\n",
            "Crypto Glossary and Dictionary of Technical Cryptography\n",
            "A Course in Cryptography by Raphael Pass & Abhi Shelat – offered at Cornell in the form of lecture notes.\n",
            "For more on the use of cryptographic elements in fiction, see: Dooley, John F., William and Marilyn Ingersoll Professor of Computer Science, Knox College (23 August 2012). \"Cryptology in Fiction\". Archived from the original on 29 July 2020. Retrieved 20 February 2015.{{cite web}}:  CS1 maint: multiple names: authors list (link)\n",
            "The George Fabyan Collection at the Library of Congress has early editions of works of seventeenth-century English literature, publications relating to cryptography....\n",
            "\n",
            "\n",
            "Page Title: Human-Computer Interaction\n",
            "Text: Human–computer interaction (HCI) is research in the design and the use of computer technology, which focuses on the interfaces between people (users) and computers. HCI researchers observe the ways humans interact with computers and design technologies that allow humans to interact with computers in novel ways. A device that allows interaction between human being and a computer is known as a \"Human-computer Interface (HCI)\".\n",
            "As a field of research, human–computer interaction is situated at the intersection of computer science, behavioral sciences, design, media studies, and several other fields of study. The term was popularized by Stuart K. Card, Allen Newell, and Thomas P. Moran in their 1983 book, The Psychology of Human–Computer Interaction. The first known use was in 1975 by Carlisle. The term is intended to convey that, unlike other tools with specific and limited uses, computers have many uses which often involve an open-ended dialogue between the user and the computer. The notion of dialogue likens human–computer interaction to human-to-human interaction: an analogy that is crucial to theoretical considerations in the field.\n",
            "\n",
            "\n",
            "== Introduction ==\n",
            "Humans interact with computers in many ways, and the interface between the two is crucial to facilitating this interaction. HCI is also sometimes termed human–machine interaction (HMI), man-machine interaction (MMI) or computer-human interaction (CHI). Desktop applications, internet browsers, handheld computers, and computer kiosks make use of the prevalent graphical user interfaces (GUI) of today. Voice user interfaces (VUI) are used for speech recognition and synthesizing systems, and the emerging multi-modal and Graphical user interfaces (GUI) allow humans to engage with embodied character agents in a way that cannot be achieved with other interface paradigms. The growth in human–computer interaction field has led to an increase in the quality of interaction, and resulted in many new areas of research beyond. Instead of designing regular interfaces, the different research branches focus on the concepts of multimodality over unimodality, intelligent adaptive interfaces over command/action based ones, and active interfaces over passive interfaces.The Association for Computing Machinery (ACM) defines human–computer interaction as \"a discipline that is concerned with the design, evaluation, and implementation of interactive computing systems for human use and with the study of major phenomena surrounding them\". A key aspect of HCI is user satisfaction, also referred to as End-User Computing Satisfaction. It goes on to say:\n",
            "\"Because human–computer interaction studies a human and a machine in communication, it draws from supporting knowledge on both the machine and the human side. On the machine side, techniques in computer graphics, operating systems, programming languages, and development environments are relevant. On the human side, communication theory, graphic and industrial design disciplines, linguistics, social sciences, cognitive psychology, social psychology, and human factors such as computer user satisfaction are relevant. And, of course, engineering and design methods are relevant.\"Due to the multidisciplinary nature of HCI, people with different backgrounds contribute to its success.\n",
            "Poorly designed human-machine interfaces can lead to many unexpected problems. A classic example is the Three Mile Island accident, a nuclear meltdown accident, where investigations concluded that the design of the human-machine interface was at least partly responsible for the disaster. Similarly, accidents in aviation have resulted from manufacturers' decisions to use non-standard flight instruments or throttle quadrant layouts: even though the new designs were proposed to be superior in basic human-machine interaction, pilots had already ingrained the \"standard\" layout. Thus, the conceptually good idea had unintended results.\n",
            "\n",
            "\n",
            "== Human–computer interface ==\n",
            "\n",
            "The human–computer interface can be described as the point of communication between the human user and the computer. The flow of information between the human and computer is defined as the loop of interaction. The loop of interaction has several aspects to it, including:\n",
            "\n",
            "Visual Based: The visual-based human–computer interaction is probably the most widespread human–computer interaction (HCI) research area.\n",
            "Audio-Based: The audio-based interaction between a computer and a human is another important area of HCI systems. This area deals with information acquired by different audio signals.\n",
            "Task environment: The conditions and goals set upon the user.\n",
            "Machine environment: The computer's environment is connected to, e.g., a laptop in a college student's dorm room.\n",
            "Areas of the interface: Non-overlapping areas involve the processes related to humans and computers themselves, while the overlapping areas only involve the processes related to their interaction.\n",
            "Input flow: The flow of information begins in the task environment when the user has some tasks requiring using their computer.\n",
            "Output: The flow of information that originates in the machine environment.\n",
            "Feedback: Loops through the interface that evaluate, moderate, and confirm processes as they pass from the human through the interface to the computer and back.\n",
            "Fit: This matches the computer design, the user, and the task to optimize the human resources needed to accomplish the task.\n",
            "Visual- Based HCI ----\n",
            "Facial Expression Analysis: This area focuses on visually recognizing and analyzing emotions through facial expressions.\n",
            "Body Movement Tracking (Large-scale): Researchers in this area concentrate on tracking and analyzing large-scale body movements.\n",
            "Gesture Recognition: Gesture recognition involves identifying and interpreting gestures made by users, often used for direct interaction with computers in command and action scenarios.\n",
            "Gaze Detection (Eyes Movement Tracking): Gaze detection involves tracking the movement of a user's eyes and is primarily used to better understand the user's attention, intent, or focus in context-sensitive situations.  While the specific goals of each area vary based on applications, they collectively contribute to enhancing human-computer interaction. Notably, visual approaches have been explored as alternatives or aids to other types of interactions, such as audio- and sensor-based methods. For example, lip reading or lip movement tracking has proven influential in correcting speech recognition errors.\n",
            "Audio - Based HCI ----Audio-based interaction in human-computer interaction (HCI) is a crucial field focused on processing information acquired through various audio signals. While the nature of audio signals may be less diverse compared to visual signals, the information they provide can be highly reliable, valuable, and sometimes uniquely informative. The research areas within this domain include:\n",
            "Speech Recognition: This area centers on the recognition and interpretation of spoken language.\n",
            "Speaker Recognition: Researchers in this area concentrate on identifying and distinguishing different speakers.\n",
            "Auditory Emotion Analysis: Efforts have been made to incorporate human emotions into intelligent human-computer interaction by analyzing emotional cues in audio signals.\n",
            "Human-Made Noise/Sign Detections: This involves recognizing typical human auditory signs like sighs, gasps, laughs, cries, etc., which contribute to emotion analysis and the design of more intelligent HCI systems.\n",
            "Musical Interaction: A relatively new area in HCI, it involves generating and interacting with music, with applications in the art industry. This field is studied in both audio- and visual-based HCI systems.\n",
            "Sensor-Based HCI ----This section encompasses a diverse range of areas with broad applications, all of which involve the use of physical sensors to facilitate interaction between users and machines. These sensors can range from basic to highly sophisticated. The specific areas include:\n",
            "Pen-Based Interaction: Particularly relevant in mobile devices, focusing on pen gestures and handwriting recognition.\n",
            "Mouse & Keyboard: Well-established input devices discussed in Section 3.1, commonly used in computing.\n",
            "Joysticks: Another established input device for interactive control, commonly used in gaming and simulations.\n",
            "Motion Tracking Sensors and Digitizers: Cutting-edge technology that has revolutionized industries like film, animation, art, and gaming. These sensors, in forms like wearable cloth or joint sensors, enable more immersive interactions between computers and reality.\n",
            "Haptic Sensors: Particularly significant in applications related to robotics and virtual reality, providing feedback based on touch. They play a crucial role in enhancing sensitivity and awareness in humanoid robots, as well as in medical surgery applications.\n",
            "Pressure Sensors: Also important in robotics, virtual reality, and medical applications, providing information based on pressure exerted on a surface.\n",
            "Taste/Smell Sensors: Although less popular compared to other areas, research has been conducted in the field of sensors for taste and smell.  These sensors vary in their level of maturity, with some being well-established and others representing cutting-edge technologies.\n",
            "\n",
            "\n",
            "== Goals for computers ==\n",
            "Human–computer interaction studies the ways in which humans make—or do not make—use of computational artifacts, systems, and infrastructures. Much of the research in this field seeks to improve the human–computer interaction by improving the usability of computer interfaces. How usability is to be precisely understood, how it relates to other social and cultural values, and when it is, and when it may not be a desirable property of computer interfaces is increasingly debated.Much of the research in the field of human–computer interaction takes an interest in:\n",
            "\n",
            "Methods for designing new computer interfaces, thereby optimizing a design for a desired property such as learnability, findability, the efficiency of use.\n",
            "Methods for implementing interfaces, e.g., by means of software libraries.\n",
            "Methods for evaluating and comparing interfaces with respect to their usability and other desirable properties.\n",
            "Methods for studying human–computer use and its sociocultural implications more broadly.\n",
            "Methods for determining whether or not the user is human or computer.\n",
            "Models and theories of human–computer use as well as conceptual frameworks for the design of computer interfaces, such as cognitivist user models, Activity Theory, or ethnomethodological accounts of human–computer use.\n",
            "Perspectives that critically reflect upon the values that underlie computational design, computer use, and HCI research practice.Visions of what researchers in the field seek to achieve might vary. When pursuing a cognitivist perspective, researchers of HCI may seek to align computer interfaces with the mental model that humans have of their activities. When pursuing a post-cognitivist perspective, researchers of HCI may seek to align computer interfaces with existing social practices or existing sociocultural values.\n",
            "Researchers in HCI are interested in developing design methodologies, experimenting with devices, prototyping software, and hardware systems, exploring interaction paradigms, and developing models and theories of interaction.\n",
            "\n",
            "\n",
            "== Design ==\n",
            "\n",
            "\n",
            "=== Principles ===\n",
            "The following experimental design principles are considered, when evaluating a current user interface, or designing a new user interface:\n",
            "\n",
            "Early focus is placed on the user(s) and task(s): How many users are needed to perform the task(s) is established and who the appropriate users should be is determined (someone who has never used the interface, and will not use the interface in the future, is most likely not a valid user). In addition, the task(s) the users will be performing and how often the task(s) need to be performed is defined.\n",
            "Empirical measurement: the interface is tested with real users who come in contact with the interface daily. The results can vary with the performance level of the user and the typical human–computer interaction may not always be represented. Quantitative usability specifics, such as the number of users performing the task(s), the time to complete the task(s), and the number of errors made during the task(s) are determined.\n",
            "Iterative design: After determining what users, tasks, and empirical measurements to include, the following iterative design steps are performed:\n",
            "Design the user interface\n",
            "Test\n",
            "Analyze results\n",
            "RepeatThe iterative design process is repeated until a sensible, user-friendly interface is created.\n",
            "\n",
            "\n",
            "=== Methodologies ===\n",
            "Various strategies delineating methods for human–PC interaction design have developed since the conception of the field during the 1980s. Most plan philosophies come from a model for how clients, originators, and specialized frameworks interface. Early techniques treated clients' psychological procedures as unsurprising and quantifiable and urged plan specialists to look at subjective science to establish zones, (for example, memory and consideration) when structuring UIs. Present-day models, in general, center around a steady input and discussion between clients, creators, and specialists and push for specialized frameworks to be folded with the sorts of encounters clients need to have, as opposed to wrapping user experience around a finished framework.\n",
            "\n",
            "Activity theory: utilized in HCI to characterize and consider the setting where human cooperations with PCs occur. Action hypothesis gives a structure for reasoning about activities in these specific circumstances and illuminates the design of interactions from an action-driven perspective.\n",
            "User-centered design (UCD): a cutting-edge, broadly-rehearsed plan theory established on the possibility that clients must become the overwhelming focus in the plan of any PC framework. Clients, architects, and specialized experts cooperate to determine the requirements and restrictions of the client and make a framework to support these components. Frequently, client-focused plans are informed by ethnographic investigations of situations in which clients will associate with the framework. This training is like participatory design, which underscores the likelihood for end-clients to contribute effectively through shared plan sessions and workshops.\n",
            "Principles of UI design: these standards may be considered during the design of a client interface: resistance, effortlessness, permeability, affordance, consistency, structure, and feedback.\n",
            "Value sensitive design (VSD): a technique for building innovation that accounts for the individuals who utilize the design straightforwardly, and just as well for those who the design influences, either directly or indirectly. VSD utilizes an iterative planning process that includes three kinds of examinations: theoretical, exact, and specialized. Applied examinations target the understanding and articulation of the different parts of the design, and its qualities or any clashes that may emerge for the users of the design. Exact examinations are subjective or quantitative plans to explore things used to advise the creators' understanding regarding the clients' qualities, needs, and practices. Specialized examinations can include either investigation of how individuals use related advances or the framework plans.\n",
            "\n",
            "\n",
            "== Display designs ==\n",
            "Displays are human-made artifacts designed to support the perception of relevant system variables and facilitate further processing of that information. Before a display is designed, the task that the display is intended to support must be defined (e.g., navigating, controlling, decision making, learning, entertaining, etc.). A user or operator must be able to process whatever information a system generates and displays; therefore, the information must be displayed according to principles to support perception, situation awareness, and understanding.\n",
            "\n",
            "\n",
            "=== Thirteen principles of display design ===\n",
            "Christopher Wickens et al. defined 13 principles of display design in their book An Introduction to Human Factors Engineering.These human perception and information processing principles can be utilized to create an effective display design. A reduction in errors, a reduction in required training time, an increase in efficiency, and an increase in user satisfaction are a few of the many potential benefits that can be achieved by utilizing these principles.\n",
            "Certain principles may not apply to different displays or situations. Some principles may also appear to be conflicting, and there is no simple solution to say that one principle is more important than another. The principles may be tailored to a specific design or situation. Striking a functional balance among the principles is critical for an effective design.\n",
            "\n",
            "\n",
            "==== Perceptual principles ====\n",
            "1.\tMake displays legible (or audible). A display's legibility is critical and necessary for designing a usable display. If the characters or objects being displayed cannot be discernible, the operator cannot effectively use them.\n",
            "2.\tAvoid absolute judgment limits. Do not ask the user to determine the level of a variable based on a single sensory variable (e.g., color, size, loudness). These sensory variables can contain many possible levels.\n",
            "3.\tTop-down processing. Signals are likely perceived and interpreted by what is expected based on a user's experience. If a signal is presented contrary to the user's expectation, more physical evidence of that signal may need to be presented to assure that it is understood correctly.\n",
            "4.\tRedundancy gain. If a signal is presented more than once, it is more likely to be understood correctly. This can be done by presenting the signal in alternative physical forms (e.g., color and shape, voice and print, etc.), as redundancy does not imply repetition. A traffic light is a good example of redundancy, as color and position are redundant.\n",
            "5.\tSimilarity causes confusion: Use distinguishable elements. Signals that appear to be similar will likely be confused. The ratio of similar features to different features causes signals to be similar. For example, A423B9 is more similar to A423B8 than 92 is to 93. Unnecessarily similar features should be removed, and dissimilar features should be highlighted.\n",
            "\n",
            "\n",
            "==== Mental model principles ====\n",
            "6.\tPrinciple of pictorial realism. A display should look like the variable that it represents (e.g., the high temperature on a thermometer shown as a higher vertical level). If there are multiple elements, they can be configured in a manner that looks like they would in the represented environment.\n",
            "7.\tPrinciple of the moving part. Moving elements should move in a pattern and direction compatible with the user's mental model of how it actually moves in the system. For example, the moving element on an altimeter should move upward with increasing altitude.\n",
            "\n",
            "\n",
            "==== Principles based on attention ====\n",
            "8.\tMinimizing information access cost or interaction cost. When the user's attention is diverted from one location to another to access necessary information, there is an associated cost in time or effort. A display design should minimize this cost by allowing frequently accessed sources to be located at the nearest possible position. However, adequate legibility should not be sacrificed to reduce this cost.\n",
            "9.\tProximity compatibility principle. Divided attention between two information sources may be necessary for the completion of one task. These sources must be mentally integrated and are defined to have close mental proximity. Information access costs should be low, which can be achieved in many ways (e.g., proximity, linkage by common colors, patterns, shapes, etc.). However, close display proximity can be harmful by causing too much clutter.\n",
            "10.\tPrinciple of multiple resources. A user can more easily process information across different resources. For example, visual and auditory information can be presented simultaneously rather than presenting all visual or all auditory information.\n",
            "\n",
            "\n",
            "==== Memory principles ====\n",
            "11.\tReplace memory with visual information: knowledge in the world. A user should not need to retain important information solely in working memory or retrieve it from long-term memory. A menu, checklist, or another display can aid the user by easing the use of their memory. However, memory use may sometimes benefit the user by eliminating the need to reference some knowledge globally (e.g., an expert computer operator would rather use direct commands from memory than refer to a manual). The use of knowledge in a user's head and knowledge in the world must be balanced for an effective design.\n",
            "12.\tPrinciple of predictive aiding. Proactive actions are usually more effective than reactive actions. A display should eliminate resource-demanding cognitive tasks and replace them with simpler perceptual tasks to reduce the user's mental resources. This will allow the user to focus on current conditions and to consider possible future conditions. An example of a predictive aid is a road sign displaying the distance to a certain destination.\n",
            "13.\tPrinciple of consistency. Old habits from other displays will easily transfer to support the processing of new displays if they are designed consistently. A user's long-term memory will trigger actions that are expected to be appropriate. A design must accept this fact and utilize consistency among different displays.\n",
            "\n",
            "\n",
            "== Current research ==\n",
            "Topics in human–computer interaction include the following:\n",
            "\n",
            "\n",
            "=== Social computing ===\n",
            "\n",
            "Social computing is an interactive and collaborative behavior considered between technology and people. In recent years, there has been an explosion of social science research focusing on interactions as the unit of analysis, as there are a lot of social computing technologies that include blogs, emails,  social networking, quick messaging, and various others. Much of this research draws from psychology, social psychology, and sociology. For example, one study found out that people expected a computer with a man's name to cost more than a machine with a woman's name. Other research finds that individuals perceive their interactions with computers more negatively than humans, despite behaving the same way towards these machines.\n",
            "\n",
            "\n",
            "=== Knowledge-driven human–computer interaction ===\n",
            "In human and computer interactions, a semantic gap usually exists between human and computer's understandings towards mutual behaviors. Ontology, as a formal representation of domain-specific knowledge, can be used to address this problem by solving the semantic ambiguities between the two parties.\n",
            "\n",
            "\n",
            "=== Emotions and human–computer interaction ===\n",
            "\n",
            "In the interaction of humans and computers, research has studied how computers can detect, process, and react to human emotions to develop emotionally intelligent information systems. Researchers have suggested several 'affect-detection channels'. The potential of telling human emotions in an automated and digital fashion lies in improvements to the effectiveness of human–computer interaction. The influence of emotions in human–computer interaction has been studied in fields such as financial decision-making using ECG and organizational knowledge sharing using eye-tracking and face readers as affect-detection channels. In these fields, it has been shown that affect-detection channels have the potential to detect human emotions and those information systems can incorporate the data obtained from affect-detection channels to improve decision models.\n",
            "\n",
            "\n",
            "=== Brain–computer interfaces ===\n",
            "\n",
            "A brain–computer interface (BCI), is a direct communication pathway between an enhanced or wired brain and an external device. BCI differs from neuromodulation in that it allows for bidirectional information flow. BCIs are often directed at researching, mapping, assisting, augmenting, or repairing human cognitive or sensory-motor functions.\n",
            "\n",
            "\n",
            "=== Security interactions ===\n",
            "Security interactions are the study of interaction between humans and computers specifically as it pertains to information security.  Its aim, in plain terms, is to improve the usability of security features in end user applications.\n",
            "Unlike HCI, which has roots in the early days of Xerox PARC during the 1970s, HCISec is a nascent field of study by comparison. Interest in this topic tracks with that of Internet security, which has become an area of broad public concern only in very recent years.\n",
            "When security features exhibit poor usability, the following are common reasons:\n",
            "\n",
            "they were added in casual afterthought\n",
            "they were hastily patched in to address newly discovered security bugs\n",
            "they address very complex use cases without the benefit of a software wizard\n",
            "their interface designers lacked understanding of related security concepts\n",
            "their interface designers were not usability experts (often meaning they were the application developers themselves)\n",
            "\n",
            "\n",
            "== Factors of change ==\n",
            "Traditionally, computer use was modeled as a human–computer dyad in which the two were connected by a narrow explicit communication channel, such as text-based terminals. Much work has been done to make the interaction between a computing system and a human more reflective of the multidimensional nature of everyday communication. Because of potential issues, human–computer interaction shifted focus beyond the interface to respond to observations as articulated by D. Engelbart: \"If ease of use were the only valid criterion, people would stick to tricycles and never try bicycles.\"How humans interact with computers continues to evolve rapidly. Human–computer interaction is affected by developments in computing. These forces include:\n",
            "\n",
            "Decreasing hardware costs leading to larger memory and faster systems\n",
            "Miniaturization of hardware leading to portability\n",
            "Reduction in power requirements leading to portability\n",
            "New display technologies leading to the packaging of computational devices in new forms\n",
            "Specialized hardware leading to new functions\n",
            "Increased development of network communication and distributed computing\n",
            "Increasingly widespread use of computers, especially by people who are outside of the computing profession\n",
            "Increasing innovation in input techniques (e.g., voice, gesture, pen), combined with lowering cost, leading to rapid computerization by people formerly left out of the computer revolution.\n",
            "Wider social concerns leading to improved access to computers by currently disadvantaged groupsAs of 2010 the future for HCI is expected to include the following characteristics:\n",
            "\n",
            "Ubiquitous computing and communication. Computers are expected to communicate through high-speed local networks, nationally over wide-area networks, and portably via infrared, ultrasonic, cellular, and other technologies. Data and computational services will be portably accessible from many if not most locations to which a user travels.\n",
            "high-functionality systems. Systems can have large numbers of functions associated with them. There are so many systems that most users, technical or non-technical, do not have time to learn about traditionally (e.g., through thick user manuals).\n",
            "The mass availability of computer graphics. Computer graphics capabilities such as image processing, graphics transformations, rendering, and interactive animation become widespread as inexpensive chips become available for inclusion in general workstations and mobile devices.\n",
            "Mixed media. Commercial systems can handle images, voice, sounds, video, text, formatted data. These are exchangeable over communication links among users. The separate consumer electronics fields (e.g., stereo sets, DVD players, televisions) and computers are beginning to merge. Computer and print fields are expected to cross-assimilate.\n",
            "High-bandwidth interaction. The rate at which humans and machines interact is expected to increase substantially due to the changes in speed, computer graphics, new media, and new input/output devices. This can lead to qualitatively different interfaces, such as virtual reality or computational video.\n",
            "Large and thin displays. New display technologies are maturing, enabling huge displays and displays that are thin, lightweight, and low in power use. This has large effects on portability and will likely enable developing paper-like, pen-based computer interaction systems very different in feel from present desktop workstations.\n",
            "Information utilities. Public information utilities (such as home banking and shopping) and specialized industry services (e.g., weather for pilots) are expected to proliferate. The proliferation rate can accelerate with the introduction of high-bandwidth interaction and the improvement in the quality of interfaces.\n",
            "\n",
            "\n",
            "== Scientific conferences ==\n",
            "One of the main conferences for new research in human–computer interaction is the annually held Association for Computing Machinery's (ACM) Conference on Human Factors in Computing Systems, usually referred to by its short name CHI (pronounced kai, or Khai). CHI is organized by ACM Special Interest Group on Computer-Human Interaction (SIGCHI). CHI is a large conference, with thousands of attendants, and is quite broad in scope. It is attended by academics, practitioners, and industry people, with company sponsors such as Google, Microsoft, and PayPal.\n",
            "There are also dozens of other smaller, regional, or specialized HCI-related conferences held around the world each year, including:\n",
            "\n",
            "\n",
            "== See also ==\n",
            "CAPTCHA\n",
            "Digital Live Art\n",
            "Feminist HCI\n",
            "HCI Bibliography, a web-based project to provide a bibliography of Human Computer Interaction literature\n",
            "Information architecture\n",
            "Information design\n",
            "Mindfulness and technology\n",
            "Outline of human–computer interaction\n",
            "Turing test\n",
            "User experience design\n",
            " Human–computer interaction portal\n",
            "\n",
            "\n",
            "== Footnotes ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "Academic overviews of the fieldJulie A. Jacko (Ed.). (2012). Human–Computer Interaction Handbook (3rd Edition). CRC Press. ISBN 1-4398-2943-8\n",
            "Andrew Sears and Julie A. Jacko (Eds.). (2007). Human–Computer Interaction Handbook (2nd Edition). CRC Press. ISBN 0-8058-5870-9\n",
            "Julie A. Jacko and Andrew Sears (Eds.). (2003). Human–Computer Interaction Handbook. Mahwah: Lawrence Erlbaum & Associates. ISBN 0-8058-4468-6\n",
            "Dix, A. (2004). Human–computer interaction (3rd ed.). Pearson Education. ISBN 0-1304-6109-1Historically important classicStuart K. Card, Thomas P. Moran, Allen Newell (1983): The Psychology of Human–Computer Interaction. Erlbaum, Hillsdale 1983 ISBN 0-89859-243-7Overviews of history of the fieldJonathan Grudin: A moving target: The evolution of human–computer interaction. In Andrew Sears and Julie A. Jacko (Eds.). (2007). Human–Computer Interaction Handbook (2nd Edition). CRC Press. ISBN 0-8058-5870-9\n",
            "Myers, Brad (1998). \"A brief history of human–computer interaction technology\". Interactions. 5 (2): 44–54. CiteSeerX 10.1.1.23.2422. doi:10.1145/274430.274436. S2CID 8278771.\n",
            "John M. Carroll: Human–Computer Interaction: History and Status. Encyclopedia Entry at Interaction-Design.org\n",
            "Carroll, John M. (2010). \"Conceptualizing a possible discipline of human–computer interaction\". Interacting with Computers. 22 (1): 3–12. doi:10.1016/j.intcom.2009.11.008.\n",
            "Sara Candeias, S. and A. Veiga The dialogue between man and machine: the role of language theory and technology, Sandra M. Aluísio & Stella E. O. Tagnin, New Language Technologies, and Linguistic Research, A Two-Way Road: cap. 11. Cambridge Scholars Publishing. (ISBN 978-1-4438-5377-4)\n",
            "Social science and HCINass, Clifford; Fogg, B. J.; Moon, Youngme (1996). \"Can computers be teammates?\". International Journal of Human-Computer Studies. 45 (6): 669–678. doi:10.1006/ijhc.1996.0073.\n",
            "Nass, Clifford; Moon, Youngme (2000). \"Machines and mindlessness: Social responses to computers\". Journal of Social Issues. 56 (1): 81–103. doi:10.1111/0022-4537.00153. S2CID 15851410.\n",
            "Posard, Marek N (2014). \"Status processes in human–computer interactions: Does gender matter?\". Computers in Human Behavior. 37: 189–195. doi:10.1016/j.chb.2014.04.025.\n",
            "Posard, Marek N.; Rinderknecht, R. Gordon (2015). \"Do people like working with computers more than human beings?\". Computers in Human Behavior. 51: 232–238. doi:10.1016/j.chb.2015.04.057.Academic journalsACM Transactions on Computer-Human Interaction\n",
            "Behaviour & Information Technology [1]\n",
            "Interacting with Computers\n",
            "International Journal of Human-Computer Interaction\n",
            "International Journal of Human-Computer Studies\n",
            "Human–Computer Interaction [2] [3]Collection of papersRonald M. Baecker, Jonathan Grudin, William A. S. Buxton, Saul Greenberg (Eds.) (1995): Readings in human–computer interaction. Toward the Year 2000. 2. ed. Morgan Kaufmann, San Francisco 1995 ISBN 1-55860-246-1\n",
            "Mithun Ahamed, Developing a Message Interface Architecture for Android Operating Systems, (2015). [4]Treatments by one or few authors, often aimed at a more general audienceJakob Nielsen: Usability Engineering. Academic Press, Boston 1993 ISBN 0-12-518405-0\n",
            "Donald A. Norman: The Psychology of Everyday Things. Basic Books, New York 1988 ISBN 0-465-06709-3\n",
            "Jef Raskin: The Humane Interface. New directions for designing interactive systems. Addison-Wesley, Boston 2000 ISBN 0-201-37937-6\n",
            "Bruce Tognazzini: Tog on Interface. Addison-Wesley, Reading 1991 ISBN 0-201-60842-1TextbooksAlan Dix, Janet Finlay, Gregory Abowd, and Russell Beale (2003): Human–Computer Interaction. 3rd Edition. Prentice Hall, 2003. http://hcibook.com/e3/ ISBN 0-13-046109-1\n",
            "Yvonne Rogers, Helen Sharp & Jenny Preece: Interaction Design: Beyond Human–Computer Interaction, 3rd ed. John Wiley & Sons Ltd., 2011 ISBN 0-470-66576-9\n",
            "Helen Sharp, Yvonne Rogers & Jenny Preece: Interaction Design: Beyond Human–Computer Interaction, 2nd ed. John Wiley & Sons Ltd., 2007 ISBN 0-470-01866-6\n",
            "Matt Jones (interaction designer) and Gary Marsden (2006). Mobile Interaction Design, John Wiley and Sons Ltd.\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "Bad Human Factors Designs\n",
            "The HCI Wiki Bibliography with over 100,000 publications.\n",
            "The HCI Bibliography Over 100,000 publications about HCI.\n",
            "Human-Centered Computing Education Digital Library\n",
            "HCI Webliography...\n",
            "\n",
            "\n",
            "Page Title: Software Engineering\n",
            "Text: Software engineering is an engineering-based approach to software development.\n",
            "A software engineer is a person who applies the engineering design process to design, develop, test, maintain, and evaluate computer software. The term programmer is sometimes used as a synonym, but may emphasize software implementation over design and can also lack connotations of engineering education or skills.Engineering techniques are used to inform the software development process, which involves the definition, implementation, assessment, measurement, management, change, and improvement of the software life cycle process itself. It heavily uses software configuration management, which is about systematically controlling changes to the configuration, and maintaining the integrity and traceability of the configuration and code throughout the system life cycle. Modern processes use software versioning.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "Beginning in the 1960s, software engineering was seen as its own type of engineering. Additionally, the development of software engineering was seen as a struggle. It was difficult to keep up with the hardware which caused many problems for software engineers. Problems included software that was over budget, exceeded deadlines, required extensive debugging and maintenance, and unsuccessfully met the needs of consumers or was never even completed. In 1968 NATO held the first Software Engineering conference where issues related to software were addressed: guidelines and best practices for the development of software were established.The origins of the term software engineering have been attributed to various sources. The term  appeared in a list of services offered by companies in the June 1965 issue of \"Computers and Automation\" and was used more formally in the August 1966 issue of Communications of the ACM (Volume 9, number 8) \"letter to the ACM membership\" by the ACM President Anthony A. Oettinger. It is also associated with the title of a NATO conference in 1968 by Professor Friedrich L. Bauer. Margaret Hamilton described the discipline of \"software engineering\" during the Apollo missions to give what they were doing legitimacy.  At the time there was perceived to be a \"software crisis\". The 40th International Conference on Software Engineering (ICSE 2018) celebrates 50 years of \"Software Engineering\" with the Plenary Sessions' keynotes of Frederick Brooks and Margaret Hamilton.In 1984, the Software Engineering Institute (SEI) was established as a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania, United States. Watts Humphrey founded the SEI Software Process Program, aimed at understanding and managing the software engineering process.  The Process Maturity Levels introduced would become the Capability Maturity Model Integration for Development(CMMI-DEV), which has defined how the US Government evaluates the abilities of a software development team.\n",
            "Modern, generally accepted best-practices for software engineering have been collected by the ISO/IEC JTC 1/SC 7 subcommittee and published as the Software Engineering Body of Knowledge (SWEBOK). Software engineering is considered one of the major computing disciplines.\n",
            "\n",
            "\n",
            "== Definitions and terminology ==\n",
            "Notable definitions of software engineering include:\n",
            "\n",
            "\"The systematic application of scientific and technological knowledge, methods, and experience to the design, implementation, testing, and documentation of software\"—The Bureau of Labor Statistics—IEEE Systems and software engineering – Vocabulary\n",
            "\"The application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software\"—IEEE Standard Glossary of Software Engineering Terminology\n",
            "\"an engineering discipline that is concerned with all aspects of software production\"—Ian Sommerville\n",
            "\"the establishment and use of sound engineering principles in order to economically obtain software that is reliable and works efficiently on real machines\"—Fritz Bauer\n",
            "\"a branch of computer science that deals with the design, implementation, and maintenance of complex computer programs\"—Merriam-Webster\n",
            "\"'software engineering' encompasses not just the act of writing code, but all of the tools and processes an organization uses to build and maintain that code over time. [...] Software engineering can be thought of as 'programming integrated over time.'\"—Software Engineering at GoogleThe term has also been used less formally:\n",
            "\n",
            "as the informal contemporary term for the broad range of activities that were formerly called computer programming and systems analysis;\n",
            "as the broad term for all aspects of the practice of computer programming, as opposed to the theory of computer programming, which is formally studied as a sub-discipline of computer science;\n",
            "as the term embodying the advocacy of a specific approach to computer programming, one that urges that it be treated as an engineering discipline rather than an art or a craft, and advocates the codification of recommended practices.\n",
            "\n",
            "\n",
            "=== Etymology of \"software engineer\" ===\n",
            "Margaret Hamilton promoted the term \"software engineering\" during her work on the Apollo program. The term \"engineering\" was used to acknowledge that the work should be taken just as seriously as other contributions toward the advancement of technology. Hamilton details her use of the term:When I first came up with the term, no one had heard of it before, at least in our world. It was an ongoing joke for a long time. They liked to kid me about my radical ideas. It was a memorable day when one of the most respected hardware gurus explained to everyone in a meeting that he agreed with me that the process of building software should also be considered an engineering discipline, just like with hardware. Not because of his acceptance of the new \"term\" per se, but because we had earned his and the acceptance of the others in the room as being in an engineering field in its own right.\n",
            "\n",
            "\n",
            "=== Suitability of the term ===\n",
            "Individual commentators have disagreed sharply on how to define software engineering or its legitimacy as an engineering discipline. David Parnas has said that software engineering is, in fact, a form of engineering. Steve McConnell has said that it is not, but that it should be. Donald Knuth has said that programming is an art and a science. Edsger W. Dijkstra claimed that the terms software engineering and software engineer have been misused  and should be considered harmful, particularly in the United States.\n",
            "\n",
            "\n",
            "== Tasks in large scale projects ==\n",
            "\n",
            "\n",
            "=== Software requirements ===\n",
            "\n",
            "Requirements engineering is about the elicitation, analysis, specification, and validation of requirements for software. Software requirements can be of three different types. There are functional requirements, non-functional requirements, and domain requirements. The operation of the software should be performed and the proper output should be expected for the user to use. Non-functional requirements deal with issues like portability, security, maintainability, reliability, scalability, performance, reusability, and flexibility. They are classified into the following types: interface constraints, performance constraints (such as response time, security, storage space, etc.), operating constraints, life cycle constraints (maintainability, portability, etc.), and economic constraints. Knowledge of how the system or software works is needed when it comes to specifying non-functional requirements. Domain requirements have to do with the characteristic of a certain category or domain of projects.\n",
            "\n",
            "\n",
            "=== Software design ===\n",
            "\n",
            "Software design is about the process of defining the architecture, components, interfaces, and other characteristics of a system or component. This is also called software architecture. Software design is divided into three different levels of design. The three levels are interface design, architectural design, and detailed design. Interface design is the interaction between a system and its environment. This happens at a high level of abstraction along with the inner workings of the system. Architectural design has to do with the major components of a system and their responsibilities, properties, interfaces, and their relationships and interactions that occur between them. Detailed design is the internal elements of all the major system components, their properties, relationships, processing, and usually their algorithms and the data structures.\n",
            "\n",
            "\n",
            "=== Software construction ===\n",
            "\n",
            "Software construction, the main activity of software development, is the combination of programming, unit testing, integration testing, and debugging so as to implement the design. Testing during this phase is generally performed by the programmer while the software is under construction, to verify what was just written and decide when the code is ready to be sent to the next step.\n",
            "\n",
            "\n",
            "=== Software testing ===\n",
            "\n",
            "Software testing is an empirical, technical investigation conducted to provide stakeholders with information about the quality of the product or service under test, with different approaches such as unit testing and integration testing. It is one aspect of software quality. As a separate phase in software development, it is typically performed by quality assurance staff or a developer other than the one who wrote the code.\n",
            "\n",
            "\n",
            "=== Software analysis ===\n",
            "\n",
            "Software analysis is the process of analyzing the behavior of computer programs regarding a property such as performance, robustness, and security It can be performed without executing the program (static program analysis), during runtime (dynamic program analysis) or in a combination of both.\n",
            "\n",
            "\n",
            "=== Software maintenance ===\n",
            "\n",
            "Software maintenance refers to the activities required to provide cost-effective support after shipping the software product. Software maintenance is modifying and updating software applications after distribution to correct faults and to improve its performance. Software has a lot to do with the real world and when the real world changes, software maintenance is required. Software maintenance includes: error correction, optimization, deletion of unused and discarded features, and enhancement of features that already exist. Usually, maintenance takes up about 40% to 80% of the project cost therefore, focusing on maintenance keeps the costs down.\n",
            "\n",
            "\n",
            "== Education ==\n",
            "Knowledge of computer programming is a prerequisite for becoming a software engineer. In 2004 the IEEE Computer Society produced the SWEBOK, which has been published as ISO/IEC Technical Report 1979:2005, describing the body of knowledge that they recommend to be mastered by a graduate software engineer with four years of experience.\n",
            "Many software engineers enter the profession by obtaining a university degree or training at a vocational school. One standard international curriculum for undergraduate software engineering degrees was defined by the Joint Task Force on Computing Curricula of the IEEE Computer Society and the Association for Computing Machinery, and updated in 2014. A number of universities have Software Engineering degree programs; as of 2010, there were 244 Campus Bachelor of Software Engineering programs, 70 Online programs, 230 Masters-level programs, 41 Doctorate-level programs, and 69 Certificate-level programs in the United States.\n",
            "In addition to university education, many companies sponsor internships for students wishing to pursue careers in information technology. These internships can introduce the student to interesting real-world tasks that typical software engineers encounter every day. Similar experience can be gained through military service in software engineering.\n",
            "\n",
            "\n",
            "=== Software engineering degree programs ===\n",
            "Half of all practitioners today have degrees in computer science, information systems, or information technology. A small, but growing, number of practitioners have software engineering degrees. In 1987, the Department of Computing at Imperial College London introduced the first three-year software engineering Bachelor's degree in the UK and the world; in the following year, the University of Sheffield established a similar program.  In 1996, the Rochester Institute of Technology established the first software engineering bachelor's degree program in the United States, however, it did not obtain ABET accreditation until 2003, the same time as Rice University, Clarkson University, Milwaukee School of Engineering and Mississippi State University obtained theirs. In 1997, PSG College of Technology in Coimbatore, India was the first to start a five-year integrated Master of Science degree in Software Engineering.Since then, software engineering undergraduate degrees have been established at many universities. A standard international curriculum for undergraduate software engineering degrees, SE2004, was defined by a steering committee between 2001 and 2004 with funding from the Association for Computing Machinery and the IEEE Computer Society. As of 2004, in the U.S., about 50 universities offer software engineering degrees, which teach both computer science and engineering principles and practices. The first software engineering Master's degree was established at Seattle University in 1979. Since then graduate software engineering degrees have been made available from many more universities.  Likewise in Canada, the Canadian Engineering Accreditation Board (CEAB) of the Canadian Council of Professional Engineers has recognized several software engineering programs.\n",
            "In 1998, the US Naval Postgraduate School (NPS) established the first doctorate program in Software Engineering in the world. Additionally, many online advanced degrees in Software Engineering have appeared such as the Master of Science in Software Engineering (MSE) degree offered through the Computer Science and Engineering Department at California State University, Fullerton. Steve McConnell opines that because most universities teach computer science rather than software engineering, there is a shortage of true software engineers. ETS (École de technologie supérieure) University and UQAM (Université du Québec à Montréal) were mandated by IEEE to develop the Software Engineering Body of Knowledge (SWEBOK), which has become an ISO standard describing the body of knowledge covered by a software engineer.\n",
            "\n",
            "\n",
            "== Profession ==\n",
            "\n",
            "Legal requirements for the licensing or certification of professional software engineers vary around the world. In the UK, there is no licensing or legal requirement to assume or use the job title Software Engineer.  In some areas of Canada, such as Alberta, British Columbia, Ontario, and Quebec, software engineers can hold the Professional Engineer (P.Eng) designation and/or the Information Systems Professional (I.S.P.) designation. In Europe, Software Engineers can obtain the European Engineer (EUR ING) professional title. Software Engineers can also become professionally qualified as a Chartered Engineer through the British Computer Society.\n",
            "In the United States, the NCEES began offering a Professional Engineer exam for Software Engineering in 2013, thereby allowing Software Engineers to be licensed and recognized. NCEES ended the exam after April 2019 due to lack of participation. Mandatory licensing is currently still largely debated, and perceived as controversial.The IEEE Computer Society and the ACM, the two main US-based professional organizations of software engineering, publish guides to the profession of software engineering. The IEEE's Guide to the Software Engineering Body of Knowledge – 2004 Version, or SWEBOK, defines the field and describes the knowledge the IEEE expects a practicing software engineer to have. The most current SWEBOK v3 is an updated version and was released in 2014. The IEEE also promulgates a \"Software Engineering Code of Ethics\".\n",
            "\n",
            "\n",
            "=== Employment ===\n",
            "\n",
            "There are an estimated 26.9 million professional software engineers in the world as of 2022, up from 21 million in 2016.Many software engineers work as employees or contractors. Software engineers work with businesses, government agencies (civilian or military), and non-profit organizations. Some software engineers work for themselves as freelancers. Some organizations have specialists to perform each of the tasks in the software development process. Other organizations require software engineers to do many or all of them. In large projects, people may specialize in only one role. In small projects, people may fill several or all roles at the same time. Many companies hire interns, often university or college students during a summer break, or externships. Specializations include analysts, architects, developers, testers, technical support, middleware analysts, project managers, software product managers, educators, and researchers.\n",
            "Most software engineers and programmers work 40 hours a week, but about 15 percent of software engineers and 11 percent of programmers worked more than 50 hours a week in 2008. Potential injuries in these occupations are possible because like other workers who spend long periods sitting in front of a computer terminal typing at a keyboard, engineers and programmers are susceptible to eyestrain, back discomfort, and hand and wrist problems such as carpal tunnel syndrome.\n",
            "\n",
            "\n",
            "==== United States ====\n",
            "The U. S. Bureau of Labor Statistics (BLS) counted 1,365,500 software developers holding jobs in the U.S. in 2018. Due to its relative newness as a field of study, formal education in software engineering is often taught as part of a computer science curriculum, and many software engineers hold computer science degrees. The BLS estimates from 2014 to 2024 that computer software engineering would increase by 17% . This is down from the 2012 to 2022 BLS estimate of 22% for software engineering. And, is further down from their 30% 2010 to 2020 BLS estimate. Due to this trend, job growth may not be as fast as during the last decade, as jobs that would have gone to computer software engineers in the United States would instead be outsourced to computer software engineers in countries such as India and other foreign countries. In addition, the BLS Job Outlook for Computer Programmers, the U.S. Bureau of Labor Statistics (BLS) Occupational Outlook predicts a decline of -7 percent from 2016 to 2026, a further decline of -9 percent from 2019 to 2029, a decline of -10 percent from 2021 to 2031. and then a decline of -11 percent from 2022 to 2032. Since computer programming can be done from anywhere in the world, companies sometimes hire programmers in countries where wages are lower. Furthermore, women in many software fields has also been declining over the years as compared to other engineering fields. Then there is the additional concern that recent advances in Artificial Intelligence might impact the demand for future generations of Software Engineers. However, this trend may change or slow in the future as many current software engineers in the U.S. market flee the profession or age out of the market in the next few decades.\n",
            "\n",
            "\n",
            "=== Certification ===\n",
            "The Software Engineering Institute offers certifications on specific topics like security, process improvement and software architecture. IBM, Microsoft and other companies also sponsor their own certification examinations. Many IT certification programs are oriented toward specific technologies, and managed by the vendors of these technologies. These certification programs are tailored to the institutions that would employ people who use these technologies.\n",
            "Broader certification of general software engineering skills is available through various professional societies. As of 2006, the IEEE had certified over 575 software professionals as a Certified Software Development Professional (CSDP). In 2008 they added an entry-level certification known as the Certified Software Development Associate (CSDA). The ACM had a professional certification program in the early 1980s, which was discontinued due to lack of interest. The ACM examined the possibility of professional certification of software engineers in the late 1990s, but eventually decided that such certification was inappropriate for the professional industrial practice of software engineering.In the U.K. the British Computer Society has developed a legally recognized professional certification called Chartered IT Professional (CITP), available to fully qualified members (MBCS). Software engineers may be eligible for membership of the British Computer Society or Institution of Engineering and Technology and so qualify to be considered for Chartered Engineer status through either of those institutions. In Canada the Canadian Information Processing Society has developed a legally recognized professional certification called Information Systems Professional (ISP). In Ontario, Canada, Software Engineers who graduate from a Canadian Engineering Accreditation Board (CEAB) accredited program, successfully complete PEO's (Professional Engineers Ontario) Professional Practice Examination (PPE) and have at least 48 months of acceptable engineering experience are eligible to be licensed through the Professional Engineers Ontario and can become Professional Engineers P.Eng. The PEO does not recognize any online or distance education however; and does not consider Computer Science programs to be equivalent to software engineering programs despite the tremendous overlap between the two. This has sparked controversy and a certification war. It has also held the number of P.Eng holders for the profession exceptionally low. The vast majority of working professionals in the field hold a degree in CS, not SE. Given the difficult certification path for holders of non-SE degrees, most never bother to pursue the license.\n",
            "\n",
            "\n",
            "=== Impact of globalization ===\n",
            "The initial impact of outsourcing, and the relatively lower cost of international human resources in developing third world countries led to a massive migration of software development activities from corporations in North America and Europe to India and later: China, Russia, and other developing countries. This approach had some flaws, mainly the distance / time zone difference that prevented human interaction between clients and developers and the massive job transfer. This had a negative impact on many aspects of the software engineering profession. For example, some students in the developed world avoid education related to software engineering because of the fear of offshore outsourcing (importing software products or services from other countries) and of being displaced by foreign visa workers. Although statistics do not currently show a threat to software engineering itself; a related career, computer programming does appear to have been affected. Nevertheless, the ability to smartly leverage offshore and near-shore resources via the follow-the-sun workflow has improved the overall operational capability of many organizations. When North Americans are leaving work, Asians are just arriving to work. When Asians are leaving work, Europeans are arriving to work. This provides a continuous ability to have human oversight on business-critical processes 24 hours per day, without paying overtime compensation or disrupting a key human resource, sleep patterns.\n",
            "While global outsourcing has several advantages, global – and generally distributed – development can run into serious difficulties resulting from the distance between developers. This is due to the key elements of this type of distance that have been identified as geographical, temporal, cultural and communication (that includes the use of different languages and dialects of English in different locations). Research has been carried out in the area of global software development over the last 15 years and an extensive body of relevant work published that highlights the benefits and problems associated with the complex activity. As with other aspects of software engineering research is ongoing in this and related areas.\n",
            "\n",
            "\n",
            "=== Prizes ===\n",
            "There are several prizes in the field of software engineering:\n",
            "The Codie awards is a yearly award issued by the Software and Information Industry Association for excellence in software development within the software industry.\n",
            "Jolt Awards are awards in the software industry.\n",
            "Stevens Award is a software engineering award given in memory of Wayne Stevens.\n",
            "Harlan Mills Award for \"contributions to the theory and practice of the information sciences, focused on software engineering\".\n",
            "\n",
            "\n",
            "== Criticism ==\n",
            "Software engineering sees its practitioners as individuals who follow well-defined engineering approaches to problem-solving. These approaches are specified in various software engineering books and research papers, always with the connotations of predictability, precision, mitigated risk and professionalism. This perspective has led to calls for licensing, certification and codified bodies of knowledge as mechanisms for spreading the engineering knowledge and maturing the field.\n",
            "Software engineering extends engineering and draws on the engineering model, i.e. engineering process, engineering project management, engineering requirements, engineering design, engineering construction, and engineering validation. The concept is so new that it is rarely understood, and it is widely misinterpreted, including in software engineering textbooks, papers, and among the communities of programmers and crafters.\n",
            "One of the core issues in software engineering is that its approaches are not empirical enough because a real-world validation of approaches is usually absent, or very limited and hence software engineering is often misinterpreted as feasible only in a \"theoretical environment.\"\n",
            "Edsger Dijkstra, the founder of many of the concepts used within software development today, rejected the idea of \"software engineering\" up until his death in 2002, arguing that those terms were poor analogies for what\n",
            "he called the \"radical novelty\" of computer science:\n",
            "\n",
            "A number of these phenomena have been bundled under the name \"Software Engineering\". As economics is known as \"The Miserable Science\", software engineering should be known as \"The Doomed Discipline\", doomed because it cannot even approach its goal since its goal is self-contradictory. Software engineering, of course, presents itself as another worthy cause, but that is eyewash: if you carefully read its literature and analyse what its devotees actually do, you will discover that software engineering has accepted as its charter \"How to program if you cannot.\"\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "=== Study and practice ===\n",
            "Computer science\n",
            "Data engineering\n",
            "Software craftsmanship\n",
            "Software development\n",
            "Release engineering\n",
            "\n",
            "\n",
            "=== Roles ===\n",
            "Programmer\n",
            "Systems analyst\n",
            "Systems architect\n",
            "\n",
            "\n",
            "=== Professional aspects ===\n",
            "Bachelor of Science in Information Technology\n",
            "Bachelor of Software Engineering\n",
            "List of software engineering conferences\n",
            "List of computer science journals (including software engineering journals)\n",
            "Software Engineering Institute\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "=== Citations ===\n",
            "\n",
            "\n",
            "=== Sources ===\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "Guide to the Software Engineering Body of Knowledge (SWEBOK Guide): Version 3.0. Pierre Bourque, Richard E. Fairley (eds.). IEEE Computer Society. 2014. ISBN 978-0-7695-5166-1.{{cite book}}:  CS1 maint: others (link)\n",
            "Pressman, Roger S (2009). Software Engineering: A Practitioner's Approach (7th ed.). Boston, Mass: McGraw-Hill. ISBN 978-0-07-337597-7.\n",
            "Sommerville, Ian (2010) [2010]. Software Engineering (9th ed.). Harlow, England: Pearson Education. ISBN 978-0-13-703515-1.\n",
            "Jalote, Pankaj (2005) [1991]. An Integrated Approach to Software Engineering (3rd ed.). Springer. ISBN 978-0-387-20881-7.\n",
            "Bruegge, Bernd; Dutoit, Allen (2009). Object-oriented software engineering : using UML, patterns, and Java (3rd ed.). Prentice Hall. ISBN 978-0-13-606125-0.\n",
            "Oshana, Robert (2019-06-21). Software engineering for embedded systems : methods, practical techniques, and applications (Second ed.). Kidlington, Oxford, United Kingdom. ISBN 978-0-12-809433-4.\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "Guide to the Software Engineering Body of Knowledge\n",
            "The Open Systems Engineering and Software Development Life Cycle Framework Archived 2010-07-18 at the Wayback Machine OpenSDLC.org the integrated Creative Commons SDLC\n",
            "Software Engineering Institute Carnegie Mellon...\n",
            "\n",
            "\n",
            "Page Title: Internet of Things\n",
            "Text: The Internet of things (IoT) describes devices with sensors, processing ability, software and other technologies that connect and exchange data with other devices and systems over the Internet or other communications networks. The Internet of things encompasses electronics, communication and computer science engineering. Internet of things has been considered a misnomer because devices do not need to be connected to the public internet, they only need to be connected to a network, and be individually addressable.The field has evolved due to the convergence of multiple technologies, including ubiquitous computing, commodity sensors, and increasingly powerful embedded systems, as well as machine learning. Older fields of embedded systems, wireless sensor networks, control systems, automation (including home and building automation), independently and collectively enable the Internet of things.  In the consumer market, IoT technology is most synonymous with \"smart home\" products, including devices and appliances (lighting fixtures, thermostats, home security systems, cameras, and other home appliances) that support one or more common ecosystems, and can be controlled via devices associated with that ecosystem, such as smartphones and smart speakers. IoT is also used in healthcare systems.There are a number of concerns about the risks in the growth of IoT technologies and products, especially in the areas of privacy and security, and consequently there have been industry and government moves to address these concerns, including the development of international and local standards, guidelines, and regulatory frameworks.\n",
            "\n",
            "\n",
            "== History ==\n",
            "The main concept of a network of smart devices was discussed as early as 1982, with a modified Coca-Cola vending machine at Carnegie Mellon University becoming the first ARPANET-connected appliance, able to report its inventory and whether newly loaded drinks were cold or not. Mark Weiser's 1991 paper on ubiquitous computing, \"The Computer of the 21st Century\", as well as academic venues such as UbiComp and PerCom produced the contemporary vision of the IOT. In 1994, Reza Raji described the concept in IEEE Spectrum as \"[moving] small packets of data to a large set of nodes, so as to integrate and automate everything from home appliances to entire factories\". Between 1993 and 1997, several companies proposed solutions like Microsoft's at Work or Novell's NEST. The field gained momentum when Bill Joy envisioned device-to-device communication as a part of his \"Six Webs\" framework, presented at the World Economic Forum at Davos in 1999.The concept of the \"Internet of things\" and the term itself, first appeared in a speech by Peter T. Lewis, to the Congressional Black Caucus Foundation 15th Annual Legislative Weekend in Washington, D.C., published in September 1985. According to Lewis, \"The Internet of Things, or IoT, is the integration of people, processes and technology with connectable devices and sensors to enable remote monitoring, status, manipulation and evaluation of trends of such devices.\"The term \"Internet of things\" was coined independently by Kevin Ashton of Procter & Gamble, later of MIT's Auto-ID Center, in 1999, though he prefers the phrase \"Internet for things\". At that point, he viewed radio-frequency identification (RFID) as essential to the Internet of things, which would allow computers to manage all individual things. The main theme of the Internet of things is to embed short-range mobile transceivers in various gadgets and daily necessities to enable new forms of communication between people and things, and between things themselves.In 2004 Cornelius \"Pete\" Peterson, CEO of NetSilicon, predicted that, \"The next era of information technology will be dominated by [IoT] devices, and networked devices will ultimately gain in popularity and significance to the extent that they will far exceed the number of networked computers and workstations.\" Peterson believed that medical devices and industrial controls would become dominant applications of the technology.Defining the Internet of things as \"simply the point in time when more 'things or objects' were connected to the Internet than people\", Cisco Systems estimated that the IoT was \"born\" between 2008 and 2009, with the things/people ratio growing from 0.08 in 2003 to 1.84 in 2010.\n",
            "\n",
            "\n",
            "== Applications ==\n",
            "The extensive set of applications for IoT devices is often divided into consumer, commercial, industrial, and infrastructure spaces.\n",
            "\n",
            "\n",
            "=== Consumers ===\n",
            "A growing portion of IoT devices is created for consumer use, including connected vehicles, home automation, wearable technology, connected health, and appliances with remote monitoring capabilities.\n",
            "\n",
            "\n",
            "==== Home automation ====\n",
            "IoT devices are a part of the larger concept of home automation, which can include lighting, heating and air conditioning, media and security systems and camera systems. Long-term benefits could include energy savings by automatically ensuring lights and electronics are turned off or by making the residents in the home aware of usage.A smart home or automated home could be based on a platform or hubs that control smart devices and appliances. For instance, using Apple's HomeKit, manufacturers can have their home products and accessories controlled by an application in iOS devices such as the iPhone and the Apple Watch. This could be a dedicated app or iOS native applications such as Siri. This can be demonstrated in the case of Lenovo's Smart Home Essentials, which is a line of smart home devices that are controlled through Apple's Home app or Siri without the need for a Wi-Fi bridge. There are also dedicated smart home hubs that are offered as standalone platforms to connect different smart home products. These include the Amazon Echo, Google Home, Apple's HomePod, and Samsung's SmartThings Hub. In addition to the commercial systems, there are many non-proprietary, open source ecosystems, including Home Assistant, OpenHAB and Domoticz.\n",
            "\n",
            "\n",
            "==== Elder care ====\n",
            "One key application of a smart home is to assist the elderly and disabled. These home systems use assistive technology to accommodate an owner's specific disabilities. Voice control can assist users with sight and mobility limitations while alert systems can be connected directly to cochlear implants worn by hearing-impaired users. They can also be equipped with additional safety features, including sensors that monitor for medical emergencies such as falls or seizures. Smart home technology applied in this way can provide users with more freedom and a higher quality of life.\n",
            "\n",
            "\n",
            "=== Organizations ===\n",
            "The term \"Enterprise IoT\" refers to devices used in business and corporate settings. By 2019, it is estimated that the EIoT will account for 9.1 billion devices.\n",
            "\n",
            "\n",
            "==== Medical and healthcare ====\n",
            "The Internet of Medical Things (IoMT) is an application of the IoT for medical and health-related purposes, data collection and analysis for research, and monitoring. The IoMT has been referenced as \"Smart Healthcare\", as the technology for creating a digitized healthcare system, connecting available medical resources and healthcare services.IoT devices can be used to enable remote health monitoring and emergency notification systems. These health monitoring devices can range from blood pressure and heart rate monitors to advanced devices capable of monitoring specialized implants, such as pacemakers, Fitbit electronic wristbands, or advanced hearing aids. Some hospitals have begun implementing \"smart beds\" that can detect when they are occupied and when a patient is attempting to get up. It can also adjust itself to ensure appropriate pressure and support are applied to the patient without the manual interaction of nurses. A 2015 Goldman Sachs report indicated that healthcare IoT devices \"can save the United States more than $300 billion in annual healthcare expenditures by increasing revenue and decreasing cost.\" Moreover, the use of mobile devices to support medical follow-up led to the creation of 'm-health', used analyzed health statistics.\"Specialized sensors can also be equipped within living spaces to monitor the health and general well-being of senior citizens, while also ensuring that proper treatment is being administered and assisting people to regain lost mobility via therapy as well. These sensors create a network of intelligent sensors that are able to collect, process, transfer, and analyze valuable information in different environments, such as connecting in-home monitoring devices to hospital-based systems. Other consumer devices to encourage healthy living, such as connected scales or wearable heart monitors, are also a possibility with the IoT. End-to-end health monitoring IoT platforms are also available for antenatal and chronic patients, helping one manage health vitals and recurring medication requirements.Advances in plastic and fabric electronics fabrication methods have enabled ultra-low cost, use-and-throw IoMT sensors. These sensors, along with the required RFID electronics, can be fabricated on paper or e-textiles for wireless powered disposable sensing devices. Applications have been established for point-of-care medical diagnostics, where portability and low system-complexity is essential.As of 2018 IoMT was not only being applied in the clinical laboratory industry, but also in the healthcare and health insurance industries. IoMT in the healthcare industry is now permitting doctors, patients, and others, such as guardians of patients, nurses, families, and similar, to be part of a system, where patient records are saved in a database, allowing doctors and the rest of the medical staff to have access to patient information. IoMT in the insurance industry provides access to better and new types of dynamic information. This includes sensor-based solutions such as biosensors, wearables, connected health devices, and mobile apps to track customer behavior. This can lead to more accurate underwriting and new pricing models.The application of the IoT in healthcare plays a fundamental role in managing chronic diseases and in disease prevention and control. Remote monitoring is made possible through the connection of powerful wireless solutions. The connectivity enables health practitioners to capture patient's data and apply complex algorithms in health data analysis.\n",
            "\n",
            "\n",
            "==== Transportation ====\n",
            "The IoT can assist in the integration of communications, control, and information processing across various transportation systems. Application of the IoT extends to all aspects of transportation systems (i.e., the vehicle, the infrastructure, and the driver or user). Dynamic interaction between these components of a transport system enables inter- and intra-vehicular communication, smart traffic control, smart parking, electronic toll collection systems, logistics and fleet management, vehicle control, safety, and road assistance.\n",
            "\n",
            "\n",
            "==== V2X communications ====\n",
            "\n",
            "In vehicular communication systems, vehicle-to-everything communication (V2X), consists of three main components: vehicle-to-vehicle communication (V2V), vehicle-to-infrastructure communication (V2I) and vehicle to pedestrian communications (V2P). V2X is the first step to autonomous driving and connected road infrastructure.\n",
            "\n",
            "\n",
            "==== Home automation ====\n",
            "IoT devices can be used to monitor and control the mechanical, electrical and electronic systems used in various types of buildings (e.g., public and private, industrial, institutions, or residential) in home automation and building automation systems. In this context, three main areas are being covered in literature:\n",
            "The integration of the Internet with building energy management systems to create energy-efficient and IOT-driven \"smart buildings\".\n",
            "The possible means of real-time monitoring for reducing energy consumption and monitoring occupant behaviors.\n",
            "The integration of smart devices in the built environment and how they might be used in future applications.\n",
            "\n",
            "\n",
            "=== Industrial ===\n",
            "\n",
            "Also known as IIoT, industrial IoT devices acquire and analyze data from connected equipment, operational technology (OT), locations, and people. Combined with operational technology (OT) monitoring devices, IIoT helps regulate and monitor industrial systems. Also, the same implementation can be carried out for automated record updates of asset placement in industrial storage units as the size of the assets can vary from a small screw to the whole motor spare part, and misplacement of such assets can cause a loss of manpower time and money.\n",
            "\n",
            "\n",
            "==== Manufacturing ====\n",
            "The IoT can connect various manufacturing devices equipped with sensing, identification, processing, communication, actuation, and networking capabilities. Network control and management of manufacturing equipment, asset and situation management, or manufacturing process control allow IoT to be used for industrial applications and smart manufacturing. IoT intelligent systems enable rapid manufacturing and optimization of new products and rapid response to product demands.Digital control systems to automate process controls, operator tools and service information systems to optimize plant safety and security are within the purview of the IIoT. IoT can also be applied to asset management via predictive maintenance, statistical evaluation, and measurements to maximize reliability. Industrial management systems can be integrated with smart grids, enabling energy optimization. Measurements, automated controls, plant optimization, health and safety management, and other functions are provided by networked sensors.In addition to general manufacturing, IoT is also used for processes in the industrialization of construction.\n",
            "\n",
            "\n",
            "==== Agriculture ====\n",
            "There are numerous IoT applications in farming such as collecting data on temperature, rainfall, humidity, wind speed, pest infestation, and soil content. This data can be used to automate farming techniques, take informed decisions to improve quality and quantity, minimize risk and waste, and reduce the effort required to manage crops. For example, farmers can now monitor soil temperature and moisture from afar and even apply IoT-acquired data to precision fertilization programs. The overall goal is that data from sensors, coupled with the farmer's knowledge and intuition about his or her farm, can help increase farm productivity, and also help reduce costs.\n",
            "In August 2018, Toyota Tsusho began a partnership with Microsoft to create fish farming tools using the Microsoft Azure application suite for IoT technologies related to water management. Developed in part by researchers from Kindai University, the water pump mechanisms use artificial intelligence to count the number of fish on a conveyor belt, analyze the number of fish, and deduce the effectiveness of water flow from the data the fish provide. The FarmBeats project from Microsoft Research that uses TV white space to connect farms is also a part of the Azure Marketplace now.\n",
            "\n",
            "\n",
            "==== Maritime ====\n",
            "IoT devices are in use to monitor the environments and systems of boats and yachts. Many pleasure boats are left unattended for days in summer, and months in winter so such devices provide valuable early alerts of boat flooding, fire, and deep discharge of batteries. The use of global internet data networks such as Sigfox, combined with long-life batteries, and microelectronics allows the engine rooms, bilge, and batteries to be constantly monitored and reported to connected Android & Apple applications for example.\n",
            "\n",
            "\n",
            "=== Infrastructure ===\n",
            "Monitoring and controlling operations of sustainable urban and rural infrastructures like bridges, railway tracks and on- and offshore wind farms is a key application of the IoT. The IoT infrastructure can be used for monitoring any events or changes in structural conditions that can compromise safety and increase risk. The IoT can benefit the construction industry by cost-saving, time reduction, better quality workday, paperless workflow and increase in productivity. It can help in taking faster decisions and saving money in Real-Time Data Analytics. It can also be used for scheduling repair and maintenance activities efficiently, by coordinating tasks between different service providers and users of these facilities. IoT devices can also be used to control critical infrastructure like bridges to provide access to ships. The usage of IoT devices for monitoring and operating infrastructure is likely to improve incident management and emergency response coordination, and quality of service, up-times and reduce costs of operation in all infrastructure-related areas. Even areas such as waste management can benefit from automation and optimization that could be brought in by the IoT.\n",
            "\n",
            "\n",
            "==== Metropolitan scale deployments ====\n",
            "There are several planned or ongoing large-scale deployments of the IoT, to enable better management of cities and systems. For example, Songdo, South Korea, the first of its kind fully equipped and wired smart city, is gradually being built, with approximately 70 percent of the business district completed as of June 2018. Much of the city is planned to be wired and automated, with little or no human intervention.Another application is currently undergoing a project in Santander, Spain. For this deployment, two approaches have been adopted. This city of 180,000 inhabitants has already seen 18,000 downloads of its city smartphone app. The app is connected to 10,000 sensors that enable services like parking search, environmental monitoring, digital city agenda, and more. City context information is used in this deployment so as to benefit merchants through a spark deals mechanism based on city behavior that aims at maximizing the impact of each notification.Other examples of large-scale deployments underway include the Sino-Singapore Guangzhou Knowledge City; work on improving air and water quality, reducing noise pollution, and increasing transportation efficiency in San Jose, California; and smart traffic management in western Singapore. Using its RPMA (Random Phase Multiple Access) technology, San Diego-based Ingenu has built a nationwide public network for low-bandwidth data transmissions using the same unlicensed 2.4 gigahertz spectrum as Wi-Fi. Ingenu's \"Machine Network\" covers more than a third of the US population across 35 major cities including San Diego and Dallas. French company, Sigfox, commenced building an Ultra Narrowband wireless data network in the San Francisco Bay Area in 2014, the first business to achieve such a deployment in the U.S. It subsequently announced it would set up a total of 4000 base stations to cover a total of 30 cities in the U.S. by the end of 2016, making it the largest IoT network coverage provider in the country thus far. Cisco also participates in smart cities projects. Cisco has started deploying technologies for Smart Wi-Fi, Smart Safety & Security, Smart Lighting, Smart Parking, Smart Transports, Smart Bus Stops, Smart Kiosks, Remote Expert for Government Services (REGS) and Smart Education in the five km area in the city of Vijaywada, India.Another example of a large deployment is the one completed by New York Waterways in New York City to connect all the city's vessels and be able to monitor them live 24/7. The network was designed and engineered by Fluidmesh Networks, a Chicago-based company developing wireless networks for critical applications. The NYWW network is currently providing coverage on the Hudson River, East River, and Upper New York Bay. With the wireless network in place, NY Waterway is able to take control of its fleet and passengers in a way that was not previously possible. New applications can include security, energy and fleet management, digital signage, public Wi-Fi, paperless ticketing and others.\n",
            "\n",
            "\n",
            "==== Energy management ====\n",
            "Significant numbers of energy-consuming devices (e.g. lamps, household appliances, motors, pumps, etc.) already integrate Internet connectivity, which can allow them to communicate with utilities not only to balance power generation but also helps optimize the energy consumption as a whole. These devices allow for remote control by users, or central management via a cloud-based interface, and enable functions like scheduling (e.g., remotely powering on or off heating systems, controlling ovens, changing lighting conditions etc.). The smart grid is a utility-side IoT application; systems gather and act on energy and power-related information to improve the efficiency of the production and distribution of electricity. Using advanced metering infrastructure (AMI) Internet-connected devices, electric utilities not only collect data from end-users, but also manage distribution automation devices like transformers.\n",
            "\n",
            "\n",
            "==== Environmental monitoring ====\n",
            "Environmental monitoring applications of the IoT typically use sensors to assist in environmental protection by monitoring air or water quality, atmospheric or soil conditions, and can even include areas like monitoring the movements of wildlife and their habitats. Development of resource-constrained devices connected to the Internet also means that other applications like earthquake or tsunami early-warning systems can also be used by emergency services to provide more effective aid. IoT devices in this application typically span a large geographic area and can also be mobile. It has been argued that the standardization that IoT brings to wireless sensing will revolutionize this area.Living Lab\n",
            "Another example of integrating the IoT is Living Lab which integrates and combines research and innovation processes, establishing within a public-private-people-partnership. There are currently 320 Living Labs that use the IoT to collaborate and share knowledge between stakeholders to co-create innovative and technological products. For companies to implement and develop IoT services for smart cities, they need to have incentives. The governments play key roles in smart city projects as changes in policies will help cities to implement the IoT which provides effectiveness, efficiency, and accuracy of the resources that are being used. For instance, the government provides tax incentives and cheap rent, improves public transports, and offers an environment where start-up companies, creative industries, and multinationals may co-create, share a common infrastructure and labor markets, and take advantage of locally embedded technologies, production process, and transaction costs. The relationship between the technology developers and governments who manage the city's assets, is key to provide open access to resources to users in an efficient way.\n",
            "\n",
            "\n",
            "=== Military ===\n",
            "\n",
            "The Internet of Military Things (IoMT) is the application of IoT technologies in the military domain for the purposes of reconnaissance, surveillance, and other combat-related objectives. It is heavily influenced by the future prospects of warfare in an urban environment and involves the use of sensors, munitions, vehicles, robots, human-wearable biometrics, and other smart technology that is relevant on the battlefield.One of the examples of IOT devices used in the military is Xaver 1000 system. The Xaver 1000 was developed by Israel's Camero Tech, which is the latest in the company's line of \"through wall imaging systems\". The Xaver line uses millimeter wave (MMW) radar, or radar in the range of 30-300 gigahertz. It is equipped with an AI-based life target tracking system as well as its own 3D 'sense-through-the-wall' technology.\n",
            "\n",
            "\n",
            "==== Internet of Battlefield Things ====\n",
            "The Internet of Battlefield Things (IoBT) is a project initiated and executed by the U.S. Army Research Laboratory (ARL) that focuses on the basic science related to the IoT that enhance the capabilities of Army soldiers. In 2017, ARL launched the Internet of Battlefield Things Collaborative Research Alliance (IoBT-CRA), establishing a working collaboration between industry, university, and Army researchers to advance the theoretical foundations of IoT technologies and their applications to Army operations.\n",
            "\n",
            "\n",
            "==== Ocean of Things ====\n",
            "The Ocean of Things project is a DARPA-led program designed to establish an Internet of things across large ocean areas for the purposes of collecting, monitoring, and analyzing environmental and vessel activity data. The project entails the deployment of about 50,000 floats that house a passive sensor suite that autonomously detect and track military and commercial vessels as part of a cloud-based network.\n",
            "\n",
            "\n",
            "=== Product digitalization ===\n",
            "There are several applications of smart or active packaging in which a QR code or NFC tag is affixed on a product or its packaging. The tag itself is passive, however, it contains a unique identifier (typically a URL) which enables a user to access digital content about the product via a smartphone. Strictly speaking, such passive items are not part of the Internet of things, but they can be seen as enablers of digital interactions. The term \"Internet of Packaging\" has been coined to describe applications in which unique identifiers are used, to automate supply chains, and are scanned on large scale by consumers to access digital content. Authentication of the unique identifiers, and thereby of the product itself, is possible via a copy-sensitive digital watermark or copy detection pattern for scanning when scanning a QR code, while NFC tags can encrypt communication.\n",
            "\n",
            "\n",
            "== Trends and characteristics ==\n",
            "The IoT's major significant trend in recent years is the explosive growth of devices connected and controlled via the Internet. The wide range of applications for IoT technology mean that the specifics can be very different from one device to the next but there are basic characteristics shared by most.\n",
            "The IoT creates opportunities for more direct integration of the physical world into computer-based systems, resulting in efficiency improvements, economic benefits, and reduced human exertions.The number of IoT devices increased 31% year-over-year to 8.4 billion in the year 2017 and it is estimated that there will be 30 billion devices by 2020.\n",
            "\n",
            "\n",
            "=== Intelligence ===\n",
            "Ambient intelligence and autonomous control are not part of the original concept of the Internet of things. Ambient intelligence and autonomous control do not necessarily require Internet structures, either. However, there is a shift in research (by companies such as Intel) to integrate the concepts of the IoT and autonomous control, with initial outcomes towards this direction considering objects as the driving force for autonomous IoT. An approach in this context is deep reinforcement learning where most of IoT systems provide a dynamic and interactive environment. Training an agent (i.e., IoT device) to behave smartly in such an environment cannot be addressed by conventional machine learning algorithms such as supervised learning. By reinforcement learning approach, a learning agent can sense the environment's state (e.g., sensing home temperature), perform actions (e.g., turn HVAC on or off) and learn through the maximizing accumulated rewards it receives in long term.\n",
            "IoT intelligence can be offered at three levels: IoT devices, Edge/Fog nodes, and cloud computing. The need for intelligent control and decision at each level depends on the time sensitiveness of the IoT application. For example, an autonomous vehicle's camera needs to make real-time obstacle detection to avoid an accident. This fast decision making would not be possible through transferring data from the vehicle to cloud instances and return the predictions back to the vehicle. Instead, all the operation should be performed locally in the vehicle. Integrating advanced machine learning algorithms including deep learning into IoT devices is an active research area to make smart objects closer to reality. Moreover, it is possible to get the most value out of IoT deployments through analyzing IoT data, extracting hidden information, and predicting control decisions. A wide variety of machine learning techniques have been used in IoT domain ranging from traditional methods such as regression, support vector machine, and random forest to advanced ones such as convolutional neural networks, LSTM, and variational autoencoder.In the future, the Internet of things may be a non-deterministic and open network in which auto-organized or intelligent entities (web services, SOA components) and virtual objects (avatars) will be interoperable and able to act independently (pursuing their own objectives or shared ones) depending on the context, circumstances or environments. Autonomous behavior through the collection and reasoning of context information as well as the object's ability to detect changes in the environment (faults affecting sensors) and introduce suitable mitigation measures constitutes a major research trend, clearly needed to provide credibility to the IoT technology. Modern IoT products and solutions in the marketplace use a variety of different technologies to support such context-aware automation, but more sophisticated forms of intelligence are requested to permit sensor units and intelligent cyber-physical systems to be deployed in real environments.\n",
            "\n",
            "\n",
            "=== Architecture ===\n",
            "IoT system architecture, in its simplistic view, consists of three tiers: Tier 1: Devices, Tier 2: the Edge Gateway, and Tier 3: the Cloud. Devices include networked things, such as the sensors and actuators found in IoT equipment, particularly those that use protocols such as Modbus, Bluetooth, Zigbee, or proprietary protocols, to connect to an Edge Gateway. The Edge Gateway layer consists of sensor data aggregation systems called Edge Gateways that provide functionality, such as pre-processing of the data, securing connectivity to cloud, using systems such as WebSockets, the event hub, and, even in some cases, edge analytics or fog computing. Edge Gateway layer is also required to give a common view of the devices to the upper layers to facilitate in easier management. The final tier includes the cloud application built for IoT using the microservices architecture, which are usually polyglot and inherently secure in nature using HTTPS/OAuth. It includes various database systems that store sensor data, such as time series databases or asset stores using backend data storage systems (e.g. Cassandra, PostgreSQL). The cloud tier in most cloud-based IoT system features event queuing and messaging system that handles communication that transpires in all tiers. Some experts classified the three-tiers in the IoT system as edge, platform, and enterprise and these are connected by proximity network, access network, and service network, respectively.Building on the Internet of things, the web of things is an architecture for the application layer of the Internet of things looking at the convergence of data from IoT devices into Web applications to create innovative use-cases. In order to program and control the flow of information in the Internet of things, a predicted architectural direction is being called BPM Everywhere which is a blending of traditional process management with process mining and special capabilities to automate the control of large numbers of coordinated devices.\n",
            "\n",
            "\n",
            "==== Network architecture ====\n",
            "The Internet of things requires huge scalability in the network space to handle the surge of devices. IETF 6LoWPAN can be used to connect devices to IP networks. With billions of devices being added to the Internet space, IPv6 will play a major role in handling the network layer scalability. IETF's Constrained Application Protocol, ZeroMQ, and MQTT can provide lightweight data transport. In practice many groups of IoT devices are hidden behind gateway nodes and may not have unique addresses. Also the vision of everything-interconnected is not needed for most applications as it is mainly the data which need interconnecting at a higher layer.\n",
            "Fog computing is a viable alternative to prevent such a large burst of data flow through the Internet. The edge devices' computation power to analyze and process data is extremely limited. Limited processing power is a key attribute of IoT devices as their purpose is to supply data about physical objects while remaining autonomous. Heavy processing requirements use more battery power harming IoT's ability to operate. Scalability is easy because IoT devices simply supply data through the internet to a server with sufficient processing power.\n",
            "\n",
            "\n",
            "===== Decentralized IoT =====\n",
            "Decentralized Internet of things, or decentralized IoT, is a modified IoT which utilizes fog computing to handle and balance requests of connected IoT devices in order to reduce loading on the cloud servers and improve responsiveness for latency-sensitive IoT applications like vital signs monitoring of patients, vehicle-to-vehicle communication of autonomous driving, and critical failure detection of industrial devices. Performance is improved, especially for huge IoT systems with millions of nodes.Conventional IoT is connected via a mesh network and led by a major head node (centralized controller). The head node decides how a data is created, stored, and transmitted. In contrast, decentralized IoT attempts to divide IoT systems into smaller divisions. The head node authorizes partial decision-making power to lower level sub-nodes under mutual agreed policy.Some approached to decentralized IoT attempts to address the limited bandwidth and hashing capacity of battery powered or wireless IoT devices via blockchain.\n",
            "\n",
            "\n",
            "=== Complexity ===\n",
            "In semi-open or closed loops (i.e., value chains, whenever a global finality can be settled) the IoT will often be considered and studied as a complex system due to the huge number of different links, interactions between autonomous actors, and its capacity to integrate new actors. At the overall stage (full open loop) it will likely be seen as a chaotic environment (since systems always have finality). \n",
            "As a practical approach, not all elements on the Internet of things run in a global, public space. Subsystems are often implemented to mitigate the risks of privacy, control and reliability. For example, domestic robotics (domotics) running inside a smart home might only share data within and be available via a local network. Managing and controlling a high dynamic ad hoc IoT things/devices network is a tough task with the traditional networks architecture, Software Defined Networking (SDN) provides the agile dynamic solution that can cope with the special requirements of the diversity of innovative IoT applications.\n",
            "\n",
            "\n",
            "=== Size considerations ===\n",
            "The exact scale of the Internet of things is unknown, with quotes of billions or trillions often quoted at the beginning of IoT articles. In 2015 there were 83 million smart devices in people's homes. This number is expected to grow to 193 million devices by 2020.The figure of online capable devices grew 31% from 2016 to 2017 to reach 8.4 billion.\n",
            "\n",
            "\n",
            "=== Space considerations ===\n",
            "In the Internet of things, the precise geographic location of a thing—and also the precise geographic dimensions of a thing—can be critical. Therefore, facts about a thing, such as its location in time and space, have been less critical to track because the person processing the information can decide whether or not that information was important to the action being taken, and if so, add the missing information (or decide to not take the action). (Note that some things on the Internet of things will be sensors, and sensor location is usually important.) The GeoWeb and Digital Earth are applications that become possible when things can become organized and connected by location. However, the challenges that remain include the constraints of variable spatial scales, the need to handle massive amounts of data, and an indexing for fast search and neighbour operations. On the Internet of things, if things are able to take actions on their own initiative, this human-centric mediation role is eliminated. Thus, the time-space context that we as humans take for granted must be given a central role in this information ecosystem. Just as standards play a key role on the Internet and the Web, geo-spatial standards will play a key role on the Internet of things.\n",
            "\n",
            "\n",
            "=== A solution to \"basket of remotes\" ===\n",
            "Many IoT devices have the potential to take a piece of this market. Jean-Louis Gassée (Apple initial alumni team, and BeOS co-founder) has addressed this topic in an article on Monday Note, where he predicts that the most likely problem will be what he calls the \"basket of remotes\" problem, where we'll have hundreds of applications to interface with hundreds of devices that don't share protocols for speaking with one another. For improved user interaction, some technology leaders are joining forces to create standards for communication between devices to solve this problem. Others are turning to the concept of predictive interaction of devices, \"where collected data is used to predict and trigger actions on the specific devices\" while making them work together.\n",
            "\n",
            "\n",
            "=== Social Internet of things ===\n",
            "Social Internet of things (SIoT) is a new kind of IoT that focuses the importance of social interaction and relationship between IoT devices. SIoT is a pattern of how cross-domain IoT devices enabling application to application communication and collaboration without human intervention in order to serve their owners with autonomous services, and this only can be realized when gained low-level architecture support from both IoT software and hardware engineering.\n",
            "\n",
            "\n",
            "==== Social Network for IoT Devices (Not Human) ====\n",
            "IoT defines a device with an identity like a citizen in a community and connect them to the internet to provide services to its users. SIoT defines a social network for IoT devices only to interact with each other for different goals that to serve human.\n",
            "\n",
            "\n",
            "==== How is SIoT different from IoT? ====\n",
            "SIoT is different from the original IoT in terms of the collaboration characteristics. IoT is passive, it was set to serve for dedicated purposes with existing IoT devices in predetermined system. SIoT is active, it was programmed and managed by AI to serve for unplanned purposes with mix and match of potential IoT devices from different systems that benefit its users.\n",
            "\n",
            "\n",
            "==== How does SIoT Work? ====\n",
            "IoT devices built-in with sociability will broadcast their abilities or functionalities, and at the same time discovers, navigates and groups with other IoT devices in the same or nearby network for useful service compositions in order to help its users proactively in every day's life especially during emergency.\n",
            "\n",
            "\n",
            "==== Social IoT Examples ====\n",
            "IoT-based smart home technology monitors health data of patients or aging adults by analyzing their physiological parameters and prompt the nearby health facilities when emergency medical services needed. In case emergency, automatically, ambulance of a nearest available hospital will be called with pickup location provided, ward assigned, patient's health data will be transmitted to the emergency department, and display on the doctor's computer immediately for further action.\n",
            "IoT sensors on the vehicles, road and traffic lights monitor the conditions of the vehicles and drivers and alert when attention needed and also coordinate themselves automatically to ensure autonomous driving is working normally. Unfortunately if an accident happens, IoT camera will inform the nearest hospital and police station for help.\n",
            "\n",
            "\n",
            "==== Social IoT Challenges ====\n",
            "Internet of things is multifaceted and complicated. One of the main factors that hindering people from adopting and use Internet of things (IoT) based products and services is its complexity. Installation and setup is a challenge to people, therefore, there is a need for IoT devices to mix match and configure themselves automatically to provide different services at different situation.\n",
            "System security always a concern for any technology, and it is more crucial for SIoT as not only security of oneself need to be considered but also the mutual trust mechanism between collaborative IoT devices from time to time, from place to place.\n",
            "Another critical challenge for SIoT is the accuracy and reliability of the sensors. At most of the circumstances, IoT sensors would need to respond in nanoseconds to avoid accidents, injury, and loss of life.\n",
            "\n",
            "\n",
            "== Enabling technologies ==\n",
            "There are many technologies that enable the IoT. Crucial to the field is the network used to communicate between devices of an IoT installation, a role that several wireless or wired technologies may fulfill:\n",
            "\n",
            "\n",
            "=== Addressability ===\n",
            "The original idea of the Auto-ID Center is based on RFID-tags and distinct identification through the Electronic Product Code. This has evolved into objects having an IP address or URI. An alternative view, from the world of the Semantic Web focuses instead on making all things (not just those electronic, smart, or RFID-enabled) addressable by the existing naming protocols, such as URI. The objects themselves do not converse, but they may now be referred to by other agents, such as powerful centralised servers acting for their human owners. Integration with the Internet implies that devices will use an IP address as a distinct identifier. Due to the limited address space of IPv4 (which allows for 4.3 billion different addresses), objects in the IoT will have to use the next generation of the Internet protocol (IPv6) to scale to the extremely large address space required.\n",
            "Internet-of-things devices additionally will benefit from the stateless address auto-configuration present in IPv6, as it reduces the configuration overhead on the hosts, and the IETF 6LoWPAN header compression. To a large extent, the future of the Internet of things will not be possible without the support of IPv6; and consequently, the global adoption of IPv6 in the coming years will be critical for the successful development of the IoT in the future.\n",
            "\n",
            "\n",
            "=== Application Layer ===\n",
            "ADRC defines an application layer protocol and supporting framework for implementing IoT applications.\n",
            "\n",
            "\n",
            "=== Short-range wireless ===\n",
            "Bluetooth mesh networking – Specification providing a mesh networking variant to Bluetooth low energy (BLE) with an increased number of nodes and standardized application layer (Models).\n",
            "Light-Fidelity (Li-Fi) – Wireless communication technology similar to the Wi-Fi standard, but using visible light communication for increased bandwidth.\n",
            "Near-field communication (NFC) – Communication protocols enabling two electronic devices to communicate within a 4 cm range.\n",
            "Radio-frequency identification (RFID) – Technology using electromagnetic fields to read data stored in tags embedded in other items.\n",
            "Wi-Fi – Technology for local area networking based on the IEEE 802.11 standard, where devices may communicate through a shared access point or directly between individual devices.\n",
            "Zigbee – Communication protocols for personal area networking based on the IEEE 802.15.4 standard, providing low power consumption, low data rate, low cost, and high throughput.\n",
            "Z-Wave – Wireless communications protocol used primarily for home automation and security applications\n",
            "\n",
            "\n",
            "=== Medium-range wireless ===\n",
            "LTE-Advanced – High-speed communication specification for mobile networks. Provides enhancements to the LTE standard with extended coverage, higher throughput, and lower latency.\n",
            "5G - 5G wireless networks can be used to achieve the high communication requirements of the IoT and connect a large number of IoT devices, even when they are on the move. There are three features of 5G that are each considered to be useful for supporting particular elements of IoT: enhanced mobile broadband (eMBB), massive machine type communications (mMTC) and ultra-reliable low latency communications (URLLC).\n",
            "\n",
            "\n",
            "=== Long-range wireless ===\n",
            "Low-power wide-area networking (LPWAN) – Wireless networks designed to allow long-range communication at a low data rate, reducing power and cost for transmission. Available LPWAN technologies and protocols: LoRaWan, Sigfox, NB-IoT, Weightless, RPMA, MIoTy.\n",
            "Very small aperture terminal (VSAT) – Satellite communication technology using small dish antennas for narrowband and broadband data.\n",
            "\n",
            "\n",
            "=== Wired ===\n",
            "Ethernet – General purpose networking standard using twisted pair and fiber optic links in conjunction with hubs or switches.\n",
            "Power-line communication (PLC) – Communication technology using electrical wiring to carry power and data. Specifications such as HomePlug or G.hn utilize PLC for networking IoT devices.\n",
            "\n",
            "\n",
            "=== Comparison of technologies by layer ===\n",
            "\n",
            "Different technologies have different roles in a protocol stack. Below is a simplified presentation of the roles of several popular communication technologies in IoT applications:\n",
            "\n",
            "\n",
            "=== Standards and standards organizations ===\n",
            "This is a list of technical standards for the IoT, most of which are open standards, and the standards organizations that aspire to successfully setting them.\n",
            "\n",
            "\n",
            "== Politics and civic engagement ==\n",
            "Some scholars and activists argue that the IoT can be used to create new models of civic engagement if device networks can be open to user control and inter-operable platforms. Philip N. Howard, a professor and author, writes that political life in both democracies and authoritarian regimes will be shaped by the way the IoT will be used for civic engagement. For that to happen, he argues that any connected device should be able to divulge a list of the \"ultimate beneficiaries\" of its sensor data and that individual citizens should be able to add new organisations to the beneficiary list. In addition, he argues that civil society groups need to start developing their IoT strategy for making use of data and engaging with the public.\n",
            "\n",
            "\n",
            "== Government regulation ==\n",
            "One of the key drivers of the IoT is data. The success of the idea of connecting devices to make them more efficient is dependent upon access to and storage & processing of data. For this purpose, companies working on the IoT collect data from multiple sources and store it in their cloud network for further processing. This leaves the door wide open for privacy and security dangers and single point vulnerability of multiple systems. The other issues pertain to consumer choice and ownership of data and how it is used. Though still in their infancy, regulations and governance regarding these issues of privacy, security, and data ownership continue to develop. IoT regulation depends on the country. Some examples of legislation that is relevant to privacy and data collection are: the US Privacy Act of 1974, OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data of 1980, and the EU Directive 95/46/EC of 1995.Current regulatory environment:\n",
            "A report published by the Federal Trade Commission (FTC) in January 2015 made the following three recommendations:\n",
            "Data security – At the time of designing IoT companies should ensure that data collection, storage and processing would be secure at all times. Companies should adopt a \"defense in depth\" approach and encrypt data at each stage.\n",
            "Data consent – users should have a choice as to what data they share with IoT companies and the users must be informed if their data gets exposed.\n",
            "Data minimisation – IoT companies should collect only the data they need and retain the collected information only for a limited time.However, the FTC stopped at just making recommendations for now. According to an FTC analysis, the existing framework, consisting of the FTC Act, the Fair Credit Reporting Act, and the Children's Online Privacy Protection Act, along with developing consumer education and business guidance, participation in multi-stakeholder efforts and advocacy to other agencies at the federal, state and local level, is sufficient to protect consumer rights.A resolution passed by the Senate in March 2015, is already being considered by the Congress. This resolution recognized the need for formulating a National Policy on IoT and the matter of privacy, security and spectrum. Furthermore, to provide an impetus to the IoT ecosystem, in March 2016, a bipartisan group of four Senators proposed a bill, The Developing Innovation and Growing the Internet of Things (DIGIT) Act, to direct the Federal Communications Commission to assess the need for more spectrum to connect IoT devices.\n",
            "Approved on 28 September 2018, California Senate Bill No. 327 goes into effect on 1 January 2020. The bill requires \"a manufacturer of a connected device, as those terms are defined, to equip the device with a reasonable security feature or features that are appropriate to the nature and function of the device, appropriate to the information it may collect, contain, or transmit, and designed to protect the device and any information contained therein from unauthorized access, destruction, use, modification, or disclosure,\"\n",
            "Several standards for the IoT industry are actually being established relating to automobiles because most concerns arising from use of connected cars apply to healthcare devices as well. In fact, the National Highway Traffic Safety Administration (NHTSA) is preparing cybersecurity guidelines and a database of best practices to make automotive computer systems more secure.A recent report from the World Bank examines the challenges and opportunities in government adoption of IoT. These include –\n",
            "\n",
            "Still early days for the IoT in government \n",
            "Underdeveloped policy and regulatory frameworks \n",
            "Unclear business models, despite strong value proposition \n",
            "Clear institutional and capacity gap in government AND the private sector \n",
            "Inconsistent data valuation and management \n",
            "Infrastructure a major barrier \n",
            "Government as an enabler \n",
            "Most successful pilots share common characteristics (public-private partnership, local, leadership)In early December 2021, the U.K. government introduced the Product Security and Telecommunications Infrastructure bill (PST), an effort to legislate IoT distributors, manufacturers, and importers to meet certain cybersecurity standards. The bill also seeks to improve the security credentials of consumer IoT devices.\n",
            "\n",
            "\n",
            "== Criticism, problems and controversies ==\n",
            "\n",
            "\n",
            "=== Platform fragmentation ===\n",
            "The IoT suffers from platform fragmentation, lack of interoperability and common technical standards a situation where the variety of IoT devices, in terms of both hardware variations and differences in the software running on them, makes the task of developing applications that work consistently between different inconsistent technology ecosystems hard. For example, wireless connectivity for IoT devices can be done using Bluetooth, Wi-Fi, Wi-Fi HaLow, Zigbee, Z-Wave, LoRa, NB-IoT, Cat M1 as well as completely custom proprietary radios – each with its own advantages and disadvantages; and unique support ecosystem.The IoT's amorphous computing nature is also a problem for security, since patches to bugs found in the core operating system often do not reach users of older and lower-price devices. One set of researchers say that the failure of vendors to support older devices with patches and updates leaves more than 87% of active Android devices vulnerable.\n",
            "\n",
            "\n",
            "=== Privacy, autonomy, and control ===\n",
            "Philip N. Howard, a professor and author, writes that the Internet of things offers immense potential for empowering citizens, making government transparent, and broadening information access. Howard cautions, however, that privacy threats are enormous, as is the potential for social control and political manipulation.Concerns about privacy have led many to consider the possibility that big data infrastructures such as the Internet of things and data mining are inherently incompatible with privacy. Key challenges of increased digitalization in the water, transport or energy sector are related to privacy and cybersecurity which necessitate an adequate response from research and policymakers alike.Writer Adam Greenfield claims that IoT technologies are not only an invasion of public space but are also being used to perpetuate normative behavior, citing an instance of billboards with hidden cameras that tracked the demographics of passersby who stopped to read the advertisement.\n",
            "The Internet of Things Council compared the increased prevalence of digital surveillance due to the Internet of things to the conceptual panopticon described by Jeremy Bentham in the 18th century. The assertion was defended by the works of French philosophers Michel Foucault and Gilles Deleuze. In Discipline and Punish: The Birth of the Prison, Foucault asserts that the panopticon was a central element of the discipline society developed during the Industrial Era. Foucault also argued that the discipline systems established in factories and school reflected Bentham's vision of panopticism. In his 1992 paper \"Postscripts on the Societies of Control\", Deleuze wrote that the discipline society had transitioned into a control society, with the computer replacing the panopticon as an instrument of discipline and control while still maintaining the qualities similar to that of panopticism.Peter-Paul Verbeek, a professor of philosophy of technology at the University of Twente, Netherlands, writes that technology already influences our moral decision making, which in turn affects human agency, privacy and autonomy. He cautions against viewing technology merely as a human tool and advocates instead to consider it as an active agent.Justin Brookman, of the Center for Democracy and Technology, expressed concern regarding the impact of the IoT on consumer privacy, saying that \"There are some people in the commercial space who say, 'Oh, big data – well, let's collect everything, keep it around forever, we'll pay for somebody to think about security later.' The question is whether we want to have some sort of policy framework in place to limit that.\"Tim O'Reilly believes that the way companies sell the IoT devices on consumers are misplaced, disputing the notion that the IoT is about gaining efficiency from putting all kinds of devices online and postulating that the \"IoT is really about human augmentation. The applications are profoundly different when you have sensors and data driving the decision-making.\"Editorials at WIRED have also expressed concern, one stating \"What you're about to lose is your privacy. Actually, it's worse than that. You aren't just going to lose your privacy, you're going to have to watch the very concept of privacy be rewritten under your nose.\"The American Civil Liberties Union (ACLU) expressed concern regarding the ability of IoT to erode people's control over their own lives. The ACLU wrote that \"There's simply no way to forecast how these immense powers – disproportionately accumulating in the hands of corporations seeking financial advantage and governments craving ever more control – will be used. Chances are big data and the Internet of Things will make it harder for us to control our own lives, as we grow increasingly transparent to powerful corporations and government institutions that are becoming more opaque to us.\"In response to rising concerns about privacy and smart technology, in 2007 the British Government stated it would follow formal Privacy by Design principles when implementing their smart metering program. The program would lead to replacement of traditional power meters with smart power meters, which could track and manage energy usage more accurately. However the British Computer Society is doubtful these principles were ever actually implemented. In 2009 the Dutch Parliament rejected a similar smart metering program, basing their decision on privacy concerns. The Dutch program later revised and passed in 2011.\n",
            "\n",
            "\n",
            "=== Data storage ===\n",
            "A challenge for producers of IoT applications is to clean, process and interpret the vast amount of data which is gathered by the sensors. There is a solution proposed for the analytics of the information referred to as Wireless Sensor Networks. These networks share data among sensor nodes that are sent to a distributed system for the analytics of the sensory data.Another challenge is the storage of this bulk data. Depending on the application, there could be high data acquisition requirements, which in turn lead to high storage requirements. Currently the Internet is already responsible for 5% of the total energy generated, and a \"daunting challenge to power\" IoT devices to collect and even store data still remains.Data silos, although a common challenge of legacy systems, still commonly occur with the implementation of IoT devices, particularly within manufacturing. As there are a lot of benefits to be gained from IoT and IIoT devices, the means in which the data is stored can present serious challenges without the principles of autonomy, transparency, and interoperability being considered. The challenges do not occur by the device itself, but the means in which databases are warehouses are set-up. These challenges were commonly identified in manufactures and enterprises which have begun upon digital transformation, and are part of the digital foundation, indicating that in order to receive the optimal benefits from IoT devices and for decision making, enterprises will have to first re-align their data storing methods. These challenges were identified by Keller (2021) when investigating the IT and application landscape of I4.0 implementation within German M&E manufactures.\n",
            "\n",
            "\n",
            "=== Security ===\n",
            "Security is the biggest concern in adopting Internet of things technology, with concerns that rapid development is happening without appropriate consideration of the profound security challenges involved and the regulatory changes that might be necessary. The rapid development of the Internet of Things (IoT) has allowed billions of devices to connect to the network. Due to too many connected devices and the limitation of communication security technology, various security issues gradually appear in the IoT.Most of the technical security concerns are similar to those of conventional servers, workstations and smartphones. These concerns include using weak authentication, forgetting to change default credentials, unencrypted messages sent between devices, SQL injections, Man-in-the-middle attacks, and poor handling of security updates. However, many IoT devices have severe operational limitations on the computational power available to them. These constraints often make them unable to directly use basic security measures such as implementing firewalls or using strong cryptosystems to encrypt their communications with other devices - and the low price and consumer focus of many devices makes a robust security patching system uncommon.Rather than conventional security vulnerabilities, fault injection attacks are on the rise and targeting IoT devices. A fault injection attack is a physical attack on a device to purposefully introduce faults in the system to change the intended behavior. Faults might happen unintentionally by environmental noises and electromagnetic fields. There are ideas stemmed from control-flow integrity (CFI) to prevent fault injection attacks and system recovery to a healthy state before the fault.Internet of things devices also have access to new areas of data, and can often control physical devices, so that even by 2014 it was possible to say that many Internet-connected appliances could already \"spy on people in their own homes\" including televisions, kitchen appliances, cameras, and thermostats. Computer-controlled devices in automobiles such as brakes, engine, locks, hood and trunk releases, horn, heat, and dashboard have been shown to be vulnerable to attackers who have access to the on-board network. In some cases, vehicle computer systems are Internet-connected, allowing them to be exploited remotely. By 2008 security researchers had shown the ability to remotely control pacemakers without authority. Later hackers demonstrated remote control of insulin pumps and implantable cardioverter defibrillators.Poorly secured Internet-accessible IoT devices can also be subverted to attack others. In 2016, a distributed denial of service attack powered by Internet of things devices running the Mirai malware took down a DNS provider and major web sites. The Mirai Botnet had infected roughly 65,000 IoT devices within the first 20 hours. Eventually the infections increased to around 200,000 to 300,000 infections. Brazil, Colombia and Vietnam made up of 41.5% of the infections. The Mirai Botnet had singled out specific IoT devices that consisted of DVRs, IP cameras, routers and printers. Top vendors that contained the most infected devices were identified as Dahua, Huawei, ZTE, Cisco, ZyXEL and MikroTik. In May 2017, Junade Ali, a Computer Scientist at Cloudflare noted that native DDoS vulnerabilities exist in IoT devices due to a poor implementation of the Publish–subscribe pattern. These sorts of attacks have caused security experts to view IoT as a real threat to Internet services.The U.S. National Intelligence Council in an unclassified report maintains that it would be hard to deny \"access to networks of sensors and remotely-controlled objects by enemies of the United States, criminals, and mischief makers... An open market for aggregated sensor data could serve the interests of commerce and security no less than it helps criminals and spies identify vulnerable targets. Thus, massively parallel sensor fusion may undermine social cohesion, if it proves to be fundamentally incompatible with Fourth-Amendment guarantees against unreasonable search.\" In general, the intelligence community views the Internet of things as a rich source of data.On 31 January 2019, the Washington Post wrote an article regarding the security and ethical challenges that can occur with IoT doorbells and cameras: \"Last month, Ring got caught allowing its team in Ukraine to view and annotate certain user videos; the company says it only looks at publicly shared videos and those from Ring owners who provide consent. Just last week, a California family's Nest camera let a hacker take over and broadcast fake audio warnings about a missile attack, not to mention peer in on them, when they used a weak password.\"There have been a range of responses to concerns over security. The Internet of Things Security Foundation (IoTSF) was launched on 23 September 2015 with a mission to secure the Internet of things by promoting knowledge and best practice. Its founding board is made from technology providers and telecommunications companies. In addition, large IT companies are continually developing innovative solutions to ensure the security of IoT devices. In 2017, Mozilla launched Project Things, which allows to route IoT devices through a safe Web of Things gateway. As per the estimates from KBV Research, the overall IoT security market would grow at 27.9% rate during 2016–2022 as a result of growing infrastructural concerns and diversified usage of Internet of things.Governmental regulation is argued by some to be necessary to secure IoT devices and the wider Internet – as market incentives to secure IoT devices is insufficient. It was found that due to the nature of most of the IoT development boards, they generate predictable and weak keys which make it easy to be utilized by Man-in-the-middle attack. However, various hardening approaches were proposed by many researchers to resolve the issue of SSH weak implementation and weak keys.IoT security within the field of manufacturing presents different challenges, and varying perspectives. Within the EU and Germany, data protection is constantly referenced throughout manufacturing and digital policy particularly that of I4.0. However, the attitude towards data security differs from the enterprise perspective whereas there is an emphasis on less data protection in the form of GDPR as the data being collected from IoT devices in the manufacturing sector does not display personal details. Yet, research has indicated that manufacturing experts are concerned about \"data security for protecting machine technology from international competitors with the ever-greater push for interconnectivity\".\n",
            "\n",
            "\n",
            "=== Safety ===\n",
            "IoT systems are typically controlled by event-driven smart apps that take as input either sensed data, user inputs, or other external triggers (from the Internet) and command one or more actuators towards providing different forms of automation. Examples of sensors include smoke detectors, motion sensors, and contact sensors. Examples of actuators include smart locks, smart power outlets, and door controls. Popular control platforms on which third-party developers can build smart apps that interact wirelessly with these sensors and actuators include Samsung's SmartThings, Apple's HomeKit, and Amazon's Alexa, among others.\n",
            "A problem specific to IoT systems is that buggy apps, unforeseen bad app interactions, or device/communication failures, can cause unsafe and dangerous physical states, e.g., \"unlock the entrance door when no one is at home\" or \"turn off the heater when the temperature is below 0 degrees Celsius and people are sleeping at night\". Detecting flaws that lead to such states, requires a holistic view of installed apps, component devices, their configurations, and more importantly, how they interact. Recently, researchers from the University of California Riverside have proposed IotSan, a novel practical system that uses model checking as a building block to reveal \"interaction-level\" flaws by identifying events that can lead the system to unsafe states. They have evaluated IotSan on the Samsung SmartThings platform. From 76 manually configured systems, IotSan detects 147 vulnerabilities (i.e., violations of safe physical states/properties).\n",
            "\n",
            "\n",
            "=== Design ===\n",
            "Given widespread recognition of the evolving nature of the design and management of the Internet of things, sustainable and secure deployment of IoT solutions must design for \"anarchic scalability\". Application of the concept of anarchic scalability can be extended to physical systems (i.e. controlled real-world objects), by virtue of those systems being designed to account for uncertain management futures. This hard anarchic scalability thus provides a pathway forward to fully realize the potential of Internet-of-things solutions by selectively constraining physical systems to allow for all management regimes without risking physical failure.Brown University computer scientist Michael Littman has argued that successful execution of the Internet of things requires consideration of the interface's usability as well as the technology itself. These interfaces need to be not only more user-friendly but also better integrated: \"If users need to learn different interfaces for their vacuums, their locks, their sprinklers, their lights, and their coffeemakers, it's tough to say that their lives have been made any easier.\"\n",
            "\n",
            "\n",
            "=== Environmental sustainability impact ===\n",
            "A concern regarding Internet-of-things technologies pertains to the environmental impacts of the manufacture, use, and eventual disposal of all these semiconductor-rich devices. Modern electronics are replete with a wide variety of heavy metals and rare-earth metals, as well as highly toxic synthetic chemicals. This makes them extremely difficult to properly recycle. Electronic components are often incinerated or placed in regular landfills. Furthermore, the human and environmental cost of mining the rare-earth metals that are integral to modern electronic components continues to grow. This leads to societal questions concerning the environmental impacts of IoT devices over their lifetime.\n",
            "\n",
            "\n",
            "=== Intentional obsolescence of devices ===\n",
            "The Electronic Frontier Foundation has raised concerns that companies can use the technologies necessary to support connected devices to intentionally disable or \"brick\" their customers' devices via a remote software update or by disabling a service necessary to the operation of the device. In one example, home automation devices sold with the promise of a \"Lifetime Subscription\" were rendered useless after Nest Labs acquired Revolv and made the decision to shut down the central servers the Revolv devices had used to operate. As Nest is a company owned by Alphabet (Google's parent company), the EFF argues this sets a \"terrible precedent for a company with ambitions to sell self-driving cars, medical devices, and other high-end gadgets that may be essential to a person's livelihood or physical safety.\"Owners should be free to point their devices to a different server or collaborate on improved software. But such action violates the United States DMCA section 1201, which only has an exemption for \"local use\". This forces tinkerers who want to keep using their own equipment into a legal grey area. EFF thinks buyers should refuse electronics and software that prioritize the manufacturer's wishes above their own.Examples of post-sale manipulations include Google Nest Revolv, disabled privacy settings on Android, Sony disabling Linux on PlayStation 3, enforced EULA on Wii U.\n",
            "\n",
            "\n",
            "=== Confusing terminology ===\n",
            "Kevin Lonergan at Information Age, a business technology magazine, has referred to the terms surrounding the IoT as a \"terminology zoo\". The lack of clear terminology is not \"useful from a practical point of view\" and a \"source of confusion for the end user\". A company operating in the IoT space could be working in anything related to sensor technology, networking, embedded systems, or analytics. According to Lonergan, the term IoT was coined before smart phones, tablets, and devices as we know them today existed, and there is a long list of terms with varying degrees of overlap and technological convergence: Internet of things, Internet of everything (IoE), Internet of goods (supply chain), industrial Internet, pervasive computing, pervasive sensing, ubiquitous computing, cyber-physical systems (CPS), wireless sensor networks (WSN), smart objects, digital twin, cyberobjects or avatars, cooperating objects, machine to machine (M2M), ambient intelligence (AmI), Operational technology (OT), and information technology (IT). Regarding IIoT, an industrial sub-field of IoT, the Industrial Internet Consortium's Vocabulary Task Group has created a \"common and reusable vocabulary of terms\" to ensure \"consistent terminology\" across publications issued by the Industrial Internet Consortium. IoT One has created an IoT Terms Database including a New Term Alert to be notified when a new term is published. As of March 2020, this database aggregates 807 IoT-related terms, while keeping material \"transparent and comprehensive\".\n",
            "\n",
            "\n",
            "== Adoption barriers ==\n",
            "\n",
            "\n",
            "=== Lack of interoperability and unclear value propositions ===\n",
            "Despite a shared belief in the potential of the IoT, industry leaders and consumers are facing barriers to adopt IoT technology more widely. Mike Farley argued in Forbes that while IoT solutions appeal to early adopters, they either lack interoperability or a clear use case for end-users. A study by Ericsson regarding the adoption of IoT among Danish companies suggests that many struggle \"to pinpoint exactly where the value of IoT lies for them\".\n",
            "\n",
            "\n",
            "=== Privacy and security concerns ===\n",
            "As for IoT, especially in regards to consumer IoT, information about a user's daily routine is collected so that the \"things\" around the user can cooperate to provide better services that fulfill personal preference. When the collected information which describes a user in detail travels through multiple hops in a network, due to a diverse integration of services, devices and network, the information stored on a device is vulnerable to privacy violation by compromising nodes existing in an IoT network.For example, on 21 October 2016, a multiple distributed denial of service (DDoS) attacks systems operated by domain name system provider Dyn, which caused the inaccessibility of several websites, such as GitHub, Twitter, and others. This attack is executed through a botnet consisting of a large number of IoT devices including IP cameras, gateways, and even baby monitors.Fundamentally there are 4 security objectives that the IoT system requires: (1) data confidentiality: unauthorised parties cannot have access to the transmitted and stored data; (2) data integrity: intentional and unintentional corruption of transmitted and stored data must be detected; (3) non-repudiation: the sender cannot deny having sent a given message; (4) data availability: the transmitted and stored data should be available to authorised parties even with the denial-of-service (DOS) attacks.Information privacy regulations also require organisations to practice \"reasonable security\". California's SB-327 Information privacy: connected devices \"would require a manufacturer of a connected device, as those terms are defined, to equip the device with a reasonable security feature or features that are appropriate to the nature and function of the device, appropriate to the information it may collect, contain, or transmit, and designed to protect the device and any information contained therein from unauthorised access, destruction, use, modification, or disclosure, as specified\". As each organisation's environment is unique, it can prove challenging to demonstrate what \"reasonable security\" is and what potential risks could be involved for the business. Oregon's HB 2395 Archived 30 September 2020 at the Wayback Machine also \"requires [a] person that manufactures, sells or offers to sell connected device] manufacturer to equip connected device with reasonable security features that protect connected device and information that connected device collects, contains, stores or transmits] stores from access, destruction, modification, use or disclosure that consumer does not authorise.\"According to antivirus provider Kaspersky, there were 639 million data breaches of IoT devices in 2020 and 1.5 billion breaches in the first six months of 2021.\n",
            "\n",
            "\n",
            "=== Traditional governance structure ===\n",
            "A study issued by Ericsson regarding the adoption of Internet of things among Danish companies identified a \"clash between IoT and companies' traditional governance structures, as IoT still presents both uncertainties and a lack of historical precedence.\" Among the respondents interviewed, 60 percent stated that they \"do not believe they have the organizational capabilities, and three of four do not believe they have the processes needed, to capture the IoT opportunity.\" This has led to a need to understand organizational culture in order to facilitate organizational design processes and to test new innovation management practices. A lack of digital leadership in the age of digital transformation has also stifled innovation and IoT adoption to a degree that many companies, in the face of uncertainty, \"were waiting for the market dynamics to play out\", or further action in regards to IoT \"was pending competitor moves, customer pull, or regulatory requirements\". Some of these companies risk being \"kodaked\" – \"Kodak was a market leader until digital disruption eclipsed film photography with digital photos\" – failing to \"see the disruptive forces affecting their industry\" and \"to truly embrace the new business models the disruptive change opens up\". Scott Anthony has written in Harvard Business Review that Kodak \"created a digital camera, invested in the technology, and even understood that photos would be shared online\" but ultimately failed to realize that \"online photo sharing was the new business, not just a way to expand the printing business.\"\n",
            "\n",
            "\n",
            "=== Business planning and project management ===\n",
            "According to 2018 study, 70–75% of IoT deployments were stuck in the pilot or prototype stage, unable to reach scale due in part to a lack of business planning.Even though scientists, engineers, and managers across the world are continuously working to create and exploit the benefits of IoT products, there are some flaws in the governance, management and implementation of such projects. Despite tremendous forward momentum in the field of information and other underlying technologies, IoT still remains a complex area and the problem of how IoT projects are managed still needs to be addressed. IoT projects must be run differently than simple and traditional IT, manufacturing or construction projects. Because IoT projects have longer project timelines, a lack of skilled resources and several security/legal issues, there is a need for new and specifically designed project processes. The following management techniques should improve the success rate of IoT projects:\n",
            "A separate research and development phase \n",
            "A Proof-of-Concept/Prototype before the actual project begins \n",
            "Project managers with interdisciplinary technical knowledge \n",
            "Universally defined business and technical jargon\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== Notes ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Bibliography ==\n",
            "\n",
            "Acharjya, D.P.; Geetha, M.K., eds. (2017). Internet of Things: Novel Advances and Envisioned Applications. Springer. p. 311. ISBN 9783319534725.\n",
            "Li, S.; Xu, L.D., eds. (2017). Securing the Internet of Things. Syngress. p. 154. ISBN 9780128045053.\n",
            "Rowland, C.; Goodman, E.; Charlier, M.; et al., eds. (2015). Designing Connected Products: UX for the Consumer Internet of Things. O'Reilly Media. p. 726. ISBN 9781449372569.\n",
            "Thomas, Jayant; Traukina, Alena (2018). Industrial Internet Application Development: Simplify IIoT development using the elasticity of Public Cloud and Native Cloud Services. Packt Publishing. p. 25. ISBN 978-1788298599.\n",
            "Stephenson, W. David (2018). The Future Is Smart: how your company can capitalize on the Internet of Things--and win in a connected economy. HarperCollins Leadership. p. 250. ISBN 9780814439777....\n",
            "\n",
            "\n",
            "Page Title: Computer Networks\n",
            "Text: A computer network is a set of computers sharing resources located on or provided by network nodes. Computers use common communication protocols over digital interconnections to communicate with each other. These interconnections are made up of telecommunication network technologies based on physically wired, optical, and wireless radio-frequency methods that may be arranged in a variety of network topologies.\n",
            "The nodes of a computer network can include personal computers, servers, networking hardware, or other specialized or general-purpose hosts. They are identified by network addresses and may have hostnames. Hostnames serve as memorable labels for the nodes and are rarely changed after initial assignment. Network addresses serve for locating and identifying the nodes by communication protocols such as the Internet Protocol.\n",
            "Computer networks may be classified by many criteria, including the transmission medium used to carry signals, bandwidth, communications protocols to organize network traffic, the network size, the topology, traffic control mechanisms, and organizational intent.Computer networks support many applications and services, such as access to the World Wide Web, digital video and audio, shared use of application and storage servers, printers and fax machines, and use of email and instant messaging applications.\n",
            "\n",
            "\n",
            "== History ==\n",
            "Computer networking may be considered a branch of computer science, computer engineering, and telecommunications, since it relies on the theoretical and practical application of the related disciplines. Computer networking was influenced by a wide array of technology developments and historical milestones.\n",
            "\n",
            "In the late 1950s, a network of computers was built for the U.S. military Semi-Automatic Ground Environment (SAGE) radar system using the Bell 101 modem. It was the first commercial modem for computers, released by AT&T Corporation in 1958. The modem allowed digital data to be transmitted over regular unconditioned telephone lines at a speed of 110 bits per second (bit/s).\n",
            "In 1959, Christopher Strachey filed a patent application for time-sharing and John McCarthy initiated the first project to implement time-sharing of user programs at MIT. Stratchey passed the concept on to J. C. R. Licklider at the inaugural UNESCO Information Processing Conference in Paris that year. McCarthy was instrumental in the creation of three of the earliest time-sharing systems (the Compatible Time-Sharing System in 1961, the BBN Time-Sharing System in 1962, and the Dartmouth Time Sharing System in 1963).\n",
            "In 1959, Anatoly Kitov proposed to the Central Committee of the Communist Party of the Soviet Union a detailed plan for the re-organisation of the control of the Soviet armed forces and of the Soviet economy on the basis of a network of computing centres. Kitov's proposal was rejected, as later was the 1962 OGAS economy management network project.\n",
            "In 1960, the commercial airline reservation system semi-automatic business research environment (SABRE) went online with two connected mainframes.\n",
            "In 1963, J. C. R. Licklider sent a memorandum to office colleagues discussing the concept of the \"Intergalactic Computer Network\", a computer network intended to allow general communications among computer users.\n",
            "Throughout the 1960s, Paul Baran and Donald Davies independently developed the concept of packet switching to transfer information between computers over a network. Davies pioneered the implementation of the concept. The NPL network, a local area network at the National Physical Laboratory (United Kingdom) used a line speed of 768 kbit/s and later high-speed T1 links (1.544 Mbit/s line rate).\n",
            "In 1965, Western Electric introduced the first widely used telephone switch that implemented computer control in the switching fabric.\n",
            "In 1969, the first four nodes of the ARPANET were connected using 50 kbit/s circuits between the University of California at Los Angeles, the Stanford Research Institute, the University of California at Santa Barbara, and the University of Utah. In the early 1970s, Leonard Kleinrock carried out mathematical work to model the performance of packet-switched networks, which underpinned the development of the ARPANET. His theoretical work on hierarchical routing in the late 1970s with student Farouk Kamoun remains critical to the operation of the Internet today.\n",
            "In 1972, commercial services were first deployed on public data networks in Europe, which began using X.25 in the late 1970s and spread across the globe. The underlying infrastructure was used for expanding TCP/IP networks in the 1980s.\n",
            "In 1973, the French CYCLADES network, directed by Louis Pouzin was the first to make the hosts responsible for the reliable delivery of data, rather than this being a centralized service of the network itself.\n",
            "In 1973, Peter Kirstein put internetworking into practice at University College London (UCL), connecting the ARPANET to British academic networks, the first international heterogeneous computer network.\n",
            "In 1973, Robert Metcalfe wrote a formal memo at Xerox PARC describing Ethernet, a networking system that was based on the Aloha network, developed in the 1960s by Norman Abramson and colleagues at the University of Hawaii. In July 1976, Robert Metcalfe and David Boggs published their paper \"Ethernet: Distributed Packet Switching for Local Computer Networks\" and collaborated on several patents received in 1977 and 1978.\n",
            "In 1974, Vint Cerf, Yogen Dalal, and Carl Sunshine published the Transmission Control Protocol (TCP) specification, RFC 675, coining the term Internet as a shorthand for internetworking.\n",
            "In 1976, John Murphy of Datapoint Corporation created ARCNET, a token-passing network first used to share storage devices.\n",
            "In 1977, the first long-distance fiber network was deployed by GTE in Long Beach, California.\n",
            "In 1977, Xerox Network Systems (XNS) was developed by Robert Metcalfe and Yogen Dalal at Xerox.\n",
            "In 1979, Robert Metcalfe pursued making Ethernet an open standard.\n",
            "In 1980, Ethernet was upgraded from the original 2.94 Mbit/s protocol to the 10 Mbit/s protocol, which was developed by Ron Crane, Bob Garner, Roy Ogus, and Yogen Dalal.\n",
            "In 1995, the transmission speed capacity for Ethernet increased from 10 Mbit/s to 100 Mbit/s. By 1998, Ethernet supported transmission speeds of 1 Gbit/s. Subsequently, higher speeds of up to 400 Gbit/s were added (as of 2018). The scaling of Ethernet has been a contributing factor to its continued use.\n",
            "\n",
            "\n",
            "== Use ==\n",
            "Computer networks extend interpersonal communications by electronic means with various technologies, such as email, instant messaging, online chat, voice and video telephone calls, and video conferencing. A network allows sharing of network and computing resources. Users may access and use resources provided by devices on the network, such as printing a document on a shared network printer or use of a shared storage device. A network allows sharing of files, data, and other types of information giving authorized users the ability to access information stored on other computers on the network. Distributed computing uses computing resources across a network to accomplish tasks.\n",
            "\n",
            "\n",
            "== Network packet ==\n",
            "Most modern computer networks use protocols based on packet-mode transmission. A network packet is a formatted unit of data carried by a packet-switched network.\n",
            "Packets consist of two types of data: control information and user data (payload). The control information provides data the network needs to deliver the user data, for example, source and destination network addresses, error detection codes, and sequencing information. Typically, control information is found in packet headers and trailers, with payload data in between.\n",
            "With packets, the bandwidth of the transmission medium can be better shared among users than if the network were circuit switched. When one user is not sending packets, the link can be filled with packets from other users, and so the cost can be shared, with relatively little interference, provided the link is not overused. Often the route a packet needs to take through a network is not immediately available. In that case, the packet is queued and waits until a link is free.\n",
            "The physical link technologies of packet networks typically limit the size of packets to a certain maximum transmission unit (MTU). A longer message may be fragmented before it is transferred and once the packets arrive, they are reassembled to construct the original message.\n",
            "\n",
            "\n",
            "== Network topology ==\n",
            "\n",
            "The physical or geographic locations of network nodes and links generally have relatively little effect on a network, but the topology of interconnections of a network can significantly affect its throughput and reliability. With many technologies, such as bus or star networks, a single failure can cause the network to fail entirely. In general, the more interconnections there are, the more robust the network is; but the more expensive it is to install. Therefore, most network diagrams are arranged by their network topology which is the map of logical interconnections of network hosts.\n",
            "Common topologies are:\n",
            "\n",
            "Bus network: all nodes are connected to a common medium along this medium. This was the layout used in the original Ethernet, called 10BASE5 and 10BASE2. This is still a common topology on the data link layer, although modern physical layer variants use point-to-point links instead, forming a star or a tree.\n",
            "Star network: all nodes are connected to a special central node. This is the typical layout found in a small switched Ethernet LAN, where each client connects to a central network switch, and logically in a wireless LAN, where each wireless client associates with the central wireless access point.\n",
            "Ring network: each node is connected to its left and right neighbor node, such that all nodes are connected and that each node can reach each other node by traversing nodes left- or rightwards. Token ring networks, and the Fiber Distributed Data Interface (FDDI), made use of such a topology.\n",
            "Mesh network: each node is connected to an arbitrary number of neighbors in such a way that there is at least one traversal from any node to any other.\n",
            "Fully connected network: each node is connected to every other node in the network.\n",
            "Tree network: nodes are arranged hierarchically. This is the natural topology for a larger Ethernet network with multiple switches and without redundant meshing.The physical layout of the nodes in a network may not necessarily reflect the network topology. As an example, with FDDI, the network topology is a ring, but the physical topology is often a star, because all neighboring connections can be routed via a central physical location. Physical layout is not completely irrelevant, however, as common ducting and equipment locations can represent single points of failure due to issues like fires, power failures and flooding.\n",
            "\n",
            "\n",
            "=== Overlay network ===\n",
            "An overlay network is a virtual network that is built on top of another network. Nodes in the overlay network are connected by virtual or logical links.  Each link corresponds to a path, perhaps through many physical links, in the underlying network. The topology of the overlay network may (and often does) differ from that of the underlying one. For example, many peer-to-peer networks are overlay networks.  They are organized as nodes of a virtual system of links that run on top of the Internet.Overlay networks have been around since the invention of networking when computer systems were connected over telephone lines using modems before any data network existed.\n",
            "The most striking example of an overlay network is the Internet itself. The Internet itself was initially built as an overlay on the telephone network. Even today, each Internet node can communicate with virtually any other through an underlying mesh of sub-networks of wildly different topologies and technologies. Address resolution and routing are the means that allow mapping of a fully connected IP overlay network to its underlying network.\n",
            "Another example of an overlay network is a distributed hash table, which maps keys to nodes in the network. In this case, the underlying network is an IP network, and the overlay network is a table (actually a map) indexed by keys.\n",
            "Overlay networks have also been proposed as a way to improve Internet routing, such as through quality of service guarantees achieve higher-quality streaming media. Previous proposals such as IntServ, DiffServ, and IP multicast have not seen wide acceptance largely because they require modification of all routers in the network.  On the other hand, an overlay network can be incrementally deployed on end-hosts running the overlay protocol software, without cooperation from Internet service providers.  The overlay network has no control over how packets are routed in the underlying network between two overlay nodes, but it can control, for example, the sequence of overlay nodes that a message traverses before it reaches its destination.\n",
            "For example, Akamai Technologies manages an overlay network that provides reliable, efficient content delivery (a kind of multicast).  Academic research includes end system multicast, resilient routing and quality of service studies, among others.\n",
            "\n",
            "\n",
            "== Network links ==\n",
            "\n",
            "The transmission media (often referred to in the literature as the physical medium) used to link devices to form a computer network include electrical cable, optical fiber, and free space. In the OSI model, the software to handle the media is defined at layers 1 and 2 — the physical layer and the data link layer.\n",
            "A widely adopted family that uses copper and fiber media in local area network (LAN) technology are collectively known as Ethernet. The media and protocol standards that enable communication between networked devices over Ethernet are defined by IEEE 802.3.  Wireless LAN standards use radio waves, others use infrared signals as a transmission medium. Power line communication uses a building's power cabling to transmit data.\n",
            "\n",
            "\n",
            "=== Wired ===\n",
            "The following classes of wired technologies are used in computer networking.\n",
            "\n",
            "Coaxial cable is widely used for cable television systems, office buildings, and other work-sites for local area networks. Transmission speed ranges from 200 million bits per second to more than 500 million bits per second.\n",
            "ITU-T G.hn technology uses existing home wiring (coaxial cable, phone lines and power lines) to create a high-speed local area network.\n",
            "Twisted pair cabling is used for wired Ethernet and other standards. It typically consists of 4 pairs of copper cabling that can be utilized for both voice and data transmission. The use of two wires twisted together helps to reduce crosstalk and electromagnetic induction. The transmission speed ranges from 2 Mbit/s to 10 Gbit/s. Twisted pair cabling comes in two forms: unshielded twisted pair (UTP) and shielded twisted-pair (STP). Each form comes in several category ratings, designed for use in various scenarios.An optical fiber is a glass fiber. It carries pulses of light that represent data via lasers and optical amplifiers. Some advantages of optical fibers over metal wires are very low transmission loss and immunity to electrical interference. Using dense wave division multiplexing, optical fibers can simultaneously carry multiple streams of data on different wavelengths of light, which greatly increases the rate that data can be sent to up to trillions of bits per second. Optic fibers can be used for long runs of cable carrying very high data rates, and are used for undersea communications cables to interconnect continents. There are two basic types of fiber optics, single-mode optical fiber (SMF) and multi-mode optical fiber (MMF).  Single-mode fiber has the advantage of being able to sustain a coherent signal for dozens or even a hundred kilometers. Multimode fiber is cheaper to terminate but is limited to a few hundred or even only a few dozens of meters, depending on the data rate and cable grade.\n",
            "\n",
            "\n",
            "=== Wireless ===\n",
            "\n",
            "Network connections can be established wirelessly using radio or other electromagnetic means of communication.\n",
            "\n",
            " Terrestrial microwave – Terrestrial microwave communication uses Earth-based transmitters and receivers resembling satellite dishes. Terrestrial microwaves are in the low gigahertz range, which limits all communications to line-of-sight. Relay stations are spaced approximately 40 miles (64 km) apart.\n",
            "Communications satellites – Satellites also communicate via microwave. The satellites are stationed in space, typically in geosynchronous orbit 35,400 km (22,000 mi) above the equator. These Earth-orbiting systems are capable of receiving and relaying voice, data, and TV signals.\n",
            "Cellular networks use several radio communications technologies. The systems divide the region covered into multiple geographic areas. Each area is served by a low-power transceiver.\n",
            "Radio and spread spectrum technologies – Wireless LANs use a high-frequency radio technology similar to digital cellular. Wireless LANs use spread spectrum technology to enable communication between multiple devices in a limited area. IEEE 802.11 defines a common flavor of open-standards wireless radio-wave technology known as Wi-Fi.\n",
            "Free-space optical communication uses visible or invisible light for communications. In most cases, line-of-sight propagation is used, which limits the physical positioning of communicating devices.\n",
            "Extending the Internet to interplanetary dimensions via radio waves and optical means, the Interplanetary Internet.\n",
            "IP over Avian Carriers was a humorous April fool's Request for Comments, issued as RFC 1149. It was implemented in real life in 2001.The last two cases have a large round-trip delay time, which gives slow two-way communication but does not prevent sending large amounts of information (they can have high throughput).\n",
            "\n",
            "\n",
            "== Network nodes ==\n",
            "\n",
            "Apart from any physical transmission media, networks are built from additional basic system building blocks, such as network interface controllers, repeaters, hubs, bridges, switches, routers, modems, and firewalls. Any particular piece of equipment will frequently contain multiple building blocks and so may perform multiple functions.\n",
            "\n",
            "\n",
            "=== Network interfaces ===\n",
            "\n",
            "A network interface controller (NIC) is computer hardware that connects the computer to the network media and has the ability to process low-level network information. For example, the NIC may have a connector for accepting a cable, or an aerial for wireless transmission and reception, and the associated circuitry.\n",
            "In Ethernet networks, each NIC has a unique Media Access Control (MAC) address—usually stored in the controller's permanent memory. To avoid address conflicts between network devices, the Institute of Electrical and Electronics Engineers (IEEE) maintains and administers MAC address uniqueness. The size of an Ethernet MAC address is six octets. The three most significant octets are reserved to identify NIC manufacturers. These manufacturers, using only their assigned prefixes, uniquely assign the three least-significant octets of every Ethernet interface they produce.\n",
            "\n",
            "\n",
            "=== Repeaters and hubs ===\n",
            "\n",
            "A repeater is an electronic device that receives a network signal, cleans it of unnecessary noise and regenerates it. The signal is retransmitted at a higher power level, or to the other side of obstruction so that the signal can cover longer distances without degradation. In most twisted-pair Ethernet configurations, repeaters are required for cable that runs longer than 100 meters. With fiber optics, repeaters can be tens or even hundreds of kilometers apart.\n",
            "Repeaters work on the physical layer of the OSI model but still require a small amount of time to regenerate the signal. This can cause a propagation delay that affects network performance and may affect proper function. As a result, many network architectures limit the number of repeaters used in a network, e.g., the Ethernet 5-4-3 rule.\n",
            "An Ethernet repeater with multiple ports is known as an Ethernet hub. In addition to reconditioning and distributing network signals, a repeater hub assists with collision detection and fault isolation for the network. Hubs and repeaters in LANs have been largely obsoleted by modern network switches.\n",
            "\n",
            "\n",
            "=== Bridges and switches ===\n",
            "\n",
            "Network bridges and network switches are distinct from a hub in that they only forward frames to the ports involved in the communication whereas a hub forwards to all ports. Bridges only have two ports but a switch can be thought of as a multi-port bridge. Switches normally have numerous ports, facilitating a star topology for devices, and for cascading additional switches.\n",
            "Bridges and switches operate at the data link layer (layer 2) of the OSI model and bridge traffic between two or more network segments to form a single local network. Both are devices that forward frames of data between ports based on the destination MAC address in each frame.\n",
            "They learn the association of physical ports to MAC addresses by examining the source addresses of received frames and only forward the frame when necessary. If an unknown destination MAC is targeted, the device broadcasts the request to all ports except the source, and discovers the location from the reply.\n",
            "Bridges and switches divide the network's collision domain but maintain a single broadcast domain. Network segmentation through bridging and switching helps break down a large, congested network into an aggregation of smaller, more efficient networks.\n",
            "\n",
            "\n",
            "=== Routers ===\n",
            "\n",
            "A router is an internetworking device that forwards packets between networks by processing the addressing or routing information included in the packet.  The routing information is often processed in conjunction with the routing table.  A router uses its routing table to determine where to forward packets and does not require broadcasting packets which is inefficient for very big networks.\n",
            "\n",
            "\n",
            "=== Modems ===\n",
            "\n",
            "Modems (modulator-demodulator) are used to connect network nodes via wire not originally designed for digital network traffic, or for wireless. To do this one or more carrier signals are modulated by the digital signal to produce an analog signal that can be tailored to give the required properties for transmission. Early modems modulated audio signals sent over a standard voice telephone line. Modems are still commonly used for telephone lines, using a digital subscriber line technology and cable television systems using DOCSIS technology.\n",
            "\n",
            "\n",
            "=== Firewalls ===\n",
            "\n",
            "A firewall is a network device or software for controlling network security and access rules. Firewalls are inserted in connections between secure internal networks and potentially insecure external networks such as the Internet. Firewalls are typically configured to reject access requests from unrecognized sources while allowing actions from recognized ones. The vital role firewalls play in network security grows in parallel with the constant increase in cyber attacks.\n",
            "\n",
            "\n",
            "== Communication protocols ==\n",
            "A communication protocol is a set of rules for exchanging information over a network. Communication protocols have various characteristics.  They may be connection-oriented or connectionless, they may use circuit mode or packet switching, and they may use hierarchical addressing or flat addressing.\n",
            "In a protocol stack, often constructed per the OSI model, communications functions are divided up into protocol layers, where each layer leverages the services of the layer below it until the lowest layer controls the hardware that sends information across the media. The use of protocol layering is ubiquitous across the field of computer networking. An important example of a protocol stack is HTTP (the World Wide Web protocol) running over TCP over IP (the Internet protocols) over IEEE 802.11 (the Wi-Fi protocol). This stack is used between the wireless router and the home user's personal computer when the user is surfing the web.\n",
            "There are many communication protocols, a few of which are described below.\n",
            "\n",
            "\n",
            "=== Common protocols ===\n",
            "\n",
            "\n",
            "==== Internet protocol suite ====\n",
            "The Internet protocol suite, also called TCP/IP, is the foundation of all modern networking. It offers connection-less and connection-oriented services over an inherently unreliable network traversed by datagram transmission using Internet protocol (IP). At its core, the protocol suite defines the addressing, identification, and routing specifications for Internet Protocol Version 4 (IPv4) and for IPv6, the next generation of the protocol with a much enlarged addressing capability. The Internet protocol suite is the defining set of protocols for the Internet.\n",
            "\n",
            "\n",
            "==== IEEE 802 ====\n",
            "IEEE 802 is a family of IEEE standards dealing with local area networks and metropolitan area networks. The complete IEEE 802 protocol suite provides a diverse set of networking capabilities. The protocols have a flat addressing scheme. They operate mostly at layers 1 and 2 of the OSI model.\n",
            "For example, MAC bridging (IEEE 802.1D) deals with the routing of Ethernet packets using a Spanning Tree Protocol. IEEE 802.1Q describes VLANs, and IEEE 802.1X defines a port-based Network Access Control protocol, which forms the basis for the authentication mechanisms used in VLANs (but it is also found in WLANs) – it is what the home user sees when the user has to enter a \"wireless access key\".\n",
            "\n",
            "\n",
            "===== Ethernet =====\n",
            "Ethernet is a family of technologies used in wired LANs. It is described by a set of standards together called IEEE 802.3 published by the Institute of Electrical and Electronics Engineers.\n",
            "\n",
            "\n",
            "===== Wireless LAN =====\n",
            "Wireless LAN based on the IEEE 802.11 standards, also widely known as WLAN or WiFi, is probably the most well-known member of the IEEE 802 protocol family for home users today. IEEE 802.11 shares many properties with wired Ethernet.\n",
            "\n",
            "\n",
            "==== SONET/SDH ====\n",
            "Synchronous optical networking (SONET) and Synchronous Digital Hierarchy (SDH) are standardized multiplexing protocols that transfer multiple digital bit streams over optical fiber using lasers. They were originally designed to transport circuit mode communications from a variety of different sources, primarily to support circuit-switched digital telephony. However, due to its protocol neutrality and transport-oriented features, SONET/SDH also was the obvious choice for transporting Asynchronous Transfer Mode (ATM) frames.\n",
            "\n",
            "\n",
            "==== Asynchronous Transfer Mode ====\n",
            "Asynchronous Transfer Mode (ATM) is a switching technique for telecommunication networks.  It uses asynchronous time-division multiplexing and encodes data into small, fixed-sized cells. This differs from other protocols such as the Internet protocol suite or Ethernet that use variable-sized packets or frames. ATM has similarities with both circuit and packet switched networking.  This makes it a good choice for a network that must handle both traditional high-throughput data traffic, and real-time, low-latency content such as voice and video. ATM uses a connection-oriented model in which a virtual circuit must be established between two endpoints before the actual data exchange begins.\n",
            "ATM still plays a role in the last mile, which is the connection between an Internet service provider and the home user.\n",
            "\n",
            "\n",
            "==== Cellular standards ====\n",
            "There are a number of different digital cellular standards, including: Global System for Mobile Communications (GSM), General Packet Radio Service (GPRS), cdmaOne, CDMA2000, Evolution-Data Optimized (EV-DO), Enhanced Data Rates for GSM Evolution (EDGE), Universal Mobile Telecommunications System (UMTS), Digital Enhanced Cordless Telecommunications (DECT), Digital AMPS (IS-136/TDMA), and Integrated Digital Enhanced Network (iDEN).\n",
            "\n",
            "\n",
            "=== Routing ===\n",
            "Routing is the process of selecting network paths to carry network traffic. Routing is performed for many kinds of networks, including circuit switching networks and packet switched networks.\n",
            "In packet-switched networks, routing protocols direct packet forwarding through intermediate nodes. Intermediate nodes are typically network hardware devices such as routers, bridges, gateways, firewalls, or switches. General-purpose computers can also forward packets and perform routing, though because they lack specialized hardware, may offer limited performance. The routing process directs forwarding on the basis of routing tables, which maintain a record of the routes to various network destinations. Most routing algorithms use only one network path at a time. Multipath routing techniques enable the use of multiple alternative paths.\n",
            "Routing can be contrasted with bridging in its assumption that network addresses are structured and that similar addresses imply proximity within the network. Structured addresses allow a single routing table entry to represent the route to a group of devices.  In large networks, the structured addressing used by routers outperforms unstructured addressing used by bridging. Structured IP addresses are used on the Internet. Unstructured MAC addresses are used for bridging on Ethernet and similar local area networks.\n",
            "\n",
            "\n",
            "== Geographic scale ==\n",
            "Networks may be characterized by many properties or features, such as physical capacity, organizational purpose, user authorization, access rights, and others. Another distinct classification method is that of the physical extent or geographic scale.\n",
            "\n",
            "\n",
            "=== Nanoscale network ===\n",
            "A nanoscale network has key components implemented at the nanoscale, including message carriers, and leverages physical principles that differ from macroscale communication mechanisms. Nanoscale communication extends communication to very small sensors and actuators such as those found in biological systems and also tends to operate in environments that would be too harsh for other communication techniques.\n",
            "\n",
            "\n",
            "=== Personal area network ===\n",
            "A personal area network (PAN) is a computer network used for communication among computers and different information technological devices close to one person. Some examples of devices that are used in a PAN are personal computers, printers, fax machines, telephones, PDAs, scanners, and video game consoles. A PAN may include wired and wireless devices. The reach of a PAN typically extends to 10 meters. A wired PAN is usually constructed with USB and FireWire connections while technologies such as Bluetooth and infrared communication typically form a wireless PAN.\n",
            "\n",
            "\n",
            "=== Local area network ===\n",
            "A local area network (LAN) is a network that connects computers and devices in a limited geographical area such as a home, school, office building, or closely positioned group of buildings. Wired LANs are most commonly based on Ethernet technology.  Other networking technologies such as ITU-T G.hn also provide a way to create a wired LAN using existing wiring, such as coaxial cables, telephone lines, and power lines.A LAN can be connected to a wide area network (WAN) using a router. The defining characteristics of a LAN, in contrast to a WAN, include higher data transfer rates, limited geographic range, and lack of reliance on leased lines to provide connectivity. Current Ethernet or other IEEE 802.3 LAN technologies operate at data transfer rates up to and in excess of 100 Gbit/s, standardized by IEEE in 2010.\n",
            "\n",
            "\n",
            "=== Home area network ===\n",
            "A home area network (HAN) is a residential LAN used for communication between digital devices typically deployed in the home, usually a small number of personal computers and accessories, such as printers and mobile computing devices. An important function is the sharing of Internet access, often a broadband service through a cable Internet access or digital subscriber line (DSL) provider.\n",
            "\n",
            "\n",
            "=== Storage area network ===\n",
            "A storage area network (SAN) is a dedicated network that provides access to consolidated, block-level data storage. SANs are primarily used to make storage devices, such as disk arrays, tape libraries, and optical jukeboxes, accessible to servers so that the storage appears as locally attached devices to the operating system. A SAN typically has its own network of storage devices that are generally not accessible through the local area network by other devices. The cost and complexity of SANs dropped in the early 2000s to levels allowing wider adoption across both enterprise and small to medium-sized business environments.\n",
            "\n",
            "\n",
            "=== Campus area network ===\n",
            "A campus area network (CAN) is made up of an interconnection of LANs within a limited geographical area. The networking equipment (switches, routers) and transmission media (optical fiber, Cat5 cabling, etc.) are almost entirely owned by the campus tenant or owner (an enterprise, university, government, etc.).\n",
            "For example, a university campus network is likely to link a variety of campus buildings to connect academic colleges or departments, the library, and student residence halls.\n",
            "\n",
            "\n",
            "=== Backbone network ===\n",
            "A backbone network is part of a computer network infrastructure that provides a path for the exchange of information between different LANs or subnetworks.  A backbone can tie together diverse networks within the same building, across different buildings, or over a wide area. When designing a network backbone, network performance and network congestion are critical factors to take into account.  Normally, the backbone network's capacity is greater than that of the individual networks connected to it.\n",
            "For example, a large company might implement a backbone network to connect departments that are located around the world. The equipment that ties together the departmental networks constitutes the network backbone. Another example of a backbone network is the Internet backbone, which is a massive, global system of fiber-optic cable and optical networking that carry the bulk of data between wide area networks (WANs), metro, regional, national and transoceanic networks.\n",
            "\n",
            "\n",
            "=== Metropolitan area network ===\n",
            "A metropolitan area network (MAN) is a large computer network that interconnects users with computer resources in a geographic region of the size of a metropolitan area.\n",
            "\n",
            "\n",
            "=== Wide area network ===\n",
            "A wide area network (WAN) is a computer network that covers a large geographic area such as a city, country, or spans even intercontinental distances.  A WAN uses a communications channel that combines many types of media such as telephone lines, cables, and airwaves. A WAN often makes use of transmission facilities provided by common carriers, such as telephone companies. WAN technologies generally function at the lower three layers of the OSI model: the physical layer, the data link layer, and the network layer.\n",
            "\n",
            "\n",
            "=== Enterprise private network ===\n",
            "An enterprise private network is a network that a single organization builds to interconnect its office locations (e.g., production sites, head offices, remote offices, shops) so they can share computer resources.\n",
            "\n",
            "\n",
            "=== Virtual private network ===\n",
            "A virtual private network (VPN) is an overlay network in which some of the links between nodes are carried by open connections or virtual circuits in some larger network (e.g., the Internet) instead of by physical wires. The data link layer protocols of the virtual network are said to be tunneled through the larger network. One common application is secure communications through the public Internet, but a VPN need not have explicit security features, such as authentication or content encryption. VPNs, for example, can be used to separate the traffic of different user communities over an underlying network with strong security features.\n",
            "VPN may have best-effort performance or may have a defined service level agreement (SLA) between the VPN customer and the VPN service provider.\n",
            "\n",
            "\n",
            "=== Global area network ===\n",
            "A global area network (GAN) is a network used for supporting mobile users across an arbitrary number of wireless LANs, satellite coverage areas, etc. The key challenge in mobile communications is handing off communications from one local coverage area to the next. In IEEE Project 802, this involves a succession of terrestrial wireless LANs.\n",
            "\n",
            "\n",
            "== Organizational scope ==\n",
            "Networks are typically managed by the organizations that own them. Private enterprise networks may use a combination of intranets and extranets. They may also provide network access to the Internet, which has no single owner and permits virtually unlimited global connectivity.\n",
            "\n",
            "\n",
            "=== Intranet ===\n",
            "An intranet is a set of networks that are under the control of a single administrative entity.  An intranet typically uses the Internet Protocol and IP-based tools such as web browsers and file transfer applications. The administrative entity limits the use of the intranet to its authorized users. Most commonly, an intranet is the internal LAN of an organization. A large intranet typically has at least one web server to provide users with organizational information.\n",
            "\n",
            "\n",
            "=== Extranet ===\n",
            "An extranet is a network that is under the administrative control of a single organization but supports a limited connection to a specific external network.  For example, an organization may provide access to some aspects of its intranet to share data with its business partners or customers.  These other entities are not necessarily trusted from a security standpoint.  The network connection to an extranet is often, but not always, implemented via WAN technology.\n",
            "\n",
            "\n",
            "=== Internet ===\n",
            "An internetwork is the connection of multiple different types of computer networks to form a single computer network using higher-layer network protocols and connecting them together using routers.\n",
            "The Internet is the largest example of internetwork. It is a global system of interconnected governmental, academic, corporate, public, and private computer networks. It is based on the networking technologies of the Internet protocol suite. It is the successor of the Advanced Research Projects Agency Network (ARPANET) developed by DARPA of the United States Department of Defense. The Internet utilizes copper communications and an optical networking backbone to enable the World Wide Web (WWW), the Internet of things, video transfer, and a broad range of information services.\n",
            "Participants on the Internet use a diverse array of methods of several hundred documented, and often standardized, protocols compatible with the Internet protocol suite and the IP addressing system administered by the Internet Assigned Numbers Authority and address registries. Service providers and large enterprises exchange information about the reachability of their address spaces through the Border Gateway Protocol (BGP), forming a redundant worldwide mesh of transmission paths.\n",
            "\n",
            "\n",
            "=== Darknet ===\n",
            "A darknet is an overlay network, typically running on the Internet, that is only accessible through specialized software. It is an anonymizing network where connections are made only between trusted peers — sometimes called friends (F2F) — using non-standard protocols and ports.\n",
            "Darknets are distinct from other distributed peer-to-peer networks as sharing is anonymous (that is, IP addresses are not publicly shared), and therefore users can communicate with little fear of governmental or corporate interference.\n",
            "\n",
            "\n",
            "== Network service ==\n",
            "Network services are applications hosted by servers on a computer network, to provide some functionality for members or users of the network, or to help the network itself to operate.\n",
            "The World Wide Web, E-mail, printing and network file sharing are examples of well-known network services. Network services such as Domain Name System (DNS) give names for IP and MAC addresses (people remember names like nm.lan better than numbers like 210.121.67.18), and Dynamic Host Configuration Protocol (DHCP) to ensure that the equipment on the network has a valid IP address.Services are usually based on a service protocol that defines the format and sequencing of messages between clients and servers of that network service.\n",
            "\n",
            "\n",
            "== Network performance ==\n",
            "\n",
            "\n",
            "=== Bandwidth ===\n",
            "Bandwidth in bit/s may refer to consumed bandwidth, corresponding to achieved throughput or goodput, i.e., the average rate of successful data transfer through a communication path. The throughput is affected by processes such as bandwidth shaping, bandwidth management, bandwidth throttling, bandwidth cap and bandwidth allocation (using, for example, bandwidth allocation protocol and dynamic bandwidth allocation).\n",
            "\n",
            "\n",
            "=== Network delay ===\n",
            "\n",
            "Network delay is a design and performance characteristic of a telecommunications network. It specifies the latency for a bit of data to travel across the network from one communication endpoint to another. Delay may differ slightly, depending on the location of the specific pair of communicating endpoints. Engineers usually report both the maximum and average delay, and they divide the delay into several components, the sum of which is the total delay:\n",
            "\n",
            "Processing delay –  time it takes a router to process the packet header\n",
            "Queuing delay –  time the packet spends in routing queues\n",
            "Transmission delay –  time it takes to push the packet's bits onto the link\n",
            "Propagation delay –  time for a signal to propagate through the mediaA certain minimum level of delay is experienced by signals due to the time it takes to transmit a packet serially through a link. This delay is extended by more variable levels of delay due to network congestion. IP network delays can range from less than a microsecond to several hundred milliseconds.\n",
            "\n",
            "\n",
            "=== Performance metrics ===\n",
            "The parameters that affect performance typically can include throughput, jitter, bit error rate and latency.\n",
            "In circuit-switched networks, network performance is synonymous with the grade of service. The number of rejected calls is a measure of how well the network is performing under heavy traffic loads. Other types of performance measures can include the level of noise and echo.\n",
            "In an Asynchronous Transfer Mode (ATM) network, performance can be measured by line rate, quality of service (QoS), data throughput, connect time, stability, technology, modulation technique, and modem enhancements.There are many ways to measure the performance of a network, as each network is different in nature and design. Performance can also be modeled instead of measured. For example, state transition diagrams are often used to model queuing performance in a circuit-switched network. The network planner uses these diagrams to analyze how the network performs in each state, ensuring that the network is optimally designed.\n",
            "\n",
            "\n",
            "=== Network congestion ===\n",
            "Network congestion occurs when a link or node is subjected to a greater data load than it is rated for, resulting in a deterioration of its quality of service. When networks are congested and queues become too full, packets have to be discarded, and so networks rely on re-transmission. Typical effects of congestion include queueing delay, packet loss or the blocking of new connections.  A consequence of these latter two is that incremental increases in offered load lead either to only a small increase in the network throughput or to a reduction in network throughput.\n",
            "Network protocols that use aggressive retransmissions to compensate for packet loss tend to keep systems in a state of network congestion—even after the initial load is reduced to a level that would not normally induce network congestion. Thus, networks using these protocols can exhibit two stable states under the same level of load. The stable state with low throughput is known as congestive collapse.\n",
            "Modern networks use congestion control, congestion avoidance and traffic control techniques to try to avoid congestion collapse (i.e. endpoints typically slow down or sometimes even stop transmission entirely when the network is congested). These techniques include: exponential backoff in protocols such as 802.11's CSMA/CA and the original Ethernet, window reduction in TCP, and fair queueing in devices such as routers. Another method to avoid the negative effects of network congestion is implementing priority schemes so that some packets are transmitted with higher priority than others. Priority schemes do not solve network congestion by themselves, but they help to alleviate the effects of congestion for some services. An example of this is 802.1p. A third method to avoid network congestion is the explicit allocation of network resources to specific flows. One example of this is the use of Contention-Free Transmission Opportunities (CFTXOPs) in the ITU-T G.hn standard, which provides high-speed (up to 1 Gbit/s) Local area networking over existing home wires (power lines, phone lines and coaxial cables).\n",
            "For the Internet, RFC 2914 addresses the subject of congestion control in detail.\n",
            "\n",
            "\n",
            "=== Network resilience ===\n",
            "Network resilience is \"the ability to provide and maintain an acceptable level of service in the face of faults and challenges to normal operation.\"\n",
            "\n",
            "\n",
            "== Security ==\n",
            "\n",
            "Computer networks are also used by security hackers to deploy computer viruses or computer worms on devices connected to the network, or to prevent these devices from accessing the network via a denial-of-service attack.\n",
            "\n",
            "\n",
            "=== Network security ===\n",
            "Network Security consists of provisions and policies adopted by the network administrator to prevent and monitor unauthorized access, misuse, modification, or denial of the computer network and its network-accessible resources. Network security is the authorization of access to data in a network, which is controlled by the network administrator. Users are assigned an ID and password that allows them access to information and programs within their authority.  Network security is used on a variety of computer networks, both public and private, to secure daily transactions and communications among businesses, government agencies, and individuals.\n",
            "\n",
            "\n",
            "=== Network surveillance ===\n",
            "Network surveillance is the monitoring of data being transferred over computer networks such as the Internet. The monitoring is often done surreptitiously and may be done by or at the behest of governments, by corporations, criminal organizations, or individuals. It may or may not be legal and may or may not require authorization from a court or other independent agency.\n",
            "Computer and network surveillance programs are widespread today, and almost all Internet traffic is or could potentially be monitored for clues to illegal activity.\n",
            "Surveillance is very useful to governments and law enforcement to maintain social control, recognize and monitor threats, and prevent/investigate criminal activity. With the advent of programs such as the Total Information Awareness program, technologies such as high-speed surveillance computers and biometrics software, and laws such as the Communications Assistance For Law Enforcement Act, governments now possess an unprecedented ability to monitor the activities of citizens.However, many civil rights and privacy groups—such as Reporters Without Borders, the Electronic Frontier Foundation, and the American Civil Liberties Union—have expressed concern that increasing surveillance of citizens may lead to a mass surveillance society, with limited political and personal freedoms. Fears such as this have led to numerous lawsuits such as Hepting v. AT&T. The hacktivist group Anonymous has hacked into government websites in protest of what it considers \"draconian surveillance\".\n",
            "\n",
            "\n",
            "=== End to end encryption ===\n",
            "End-to-end encryption (E2EE) is a digital communications paradigm of uninterrupted protection of data traveling between two communicating parties. It involves the originating party encrypting data so only the intended recipient can decrypt it, with no dependency on third parties. End-to-end encryption prevents intermediaries, such as Internet service providers or application service providers, from discovering or tampering with communications. End-to-end encryption generally protects both confidentiality and integrity.\n",
            "Examples of end-to-end encryption include HTTPS for web traffic, PGP for email, OTR for instant messaging, ZRTP for telephony, and TETRA for radio.\n",
            "Typical server-based communications systems do not include end-to-end encryption. These systems can only guarantee the protection of communications between clients and servers, not between the communicating parties themselves. Examples of non-E2EE systems are Google Talk, Yahoo Messenger, Facebook, and Dropbox. Some such systems, for example, LavaBit and SecretInk, have even described themselves as offering \"end-to-end\" encryption when they do not. Some systems that normally offer end-to-end encryption have turned out to contain a back door that subverts negotiation of the encryption key between the communicating parties, for example Skype or Hushmail.\n",
            "The end-to-end encryption paradigm does not directly address risks at the endpoints of the communication themselves, such as the technical exploitation of clients, poor quality random number generators, or key escrow. E2EE also does not address traffic analysis, which relates to things such as the identities of the endpoints and the times and quantities of messages that are sent.\n",
            "\n",
            "\n",
            "=== SSL/TLS ===\n",
            "\n",
            "The introduction and rapid growth of e-commerce on the World Wide Web in the mid-1990s made it obvious that some form of authentication and encryption was needed. Netscape took the first shot at a new standard. At the time, the dominant web browser was Netscape Navigator. Netscape created a standard called secure socket layer (SSL). SSL requires a server with a certificate. When a client requests access to an SSL-secured server, the server sends a copy of the certificate to the client. The SSL client checks this certificate (all web browsers come with an exhaustive list of CA root certificates preloaded), and if the certificate checks out, the server is authenticated and the client negotiates a symmetric-key cipher for use in the session. The session is now in a very secure encrypted tunnel between the SSL server and the SSL client.\n",
            "\n",
            "\n",
            "== Views of networks ==\n",
            "Users and network administrators typically have different views of their networks. Users can share printers and some servers from a workgroup, which usually means they are in the same geographic location and are on the same LAN, whereas a Network Administrator is responsible to keep that network up and running.  A community of interest has less of a connection of being in a local area and should be thought of as a set of arbitrarily located users who share a set of servers, and possibly also communicate via peer-to-peer technologies.\n",
            "Network administrators can see networks from both physical and logical perspectives. The physical perspective involves geographic locations, physical cabling, and the network elements (e.g., routers, bridges and application layer gateways) that interconnect via the transmission media. Logical networks, called, in the TCP/IP architecture, subnets, map onto one or more transmission media. For example, a common practice in a campus of buildings is to make a set of LAN cables in each building appear to be a common subnet, using VLAN technology.\n",
            "Both users and administrators are aware, to varying extents, of the trust and scope characteristics of a network. Again using TCP/IP architectural terminology, an intranet is a community of interest under private administration usually by an enterprise, and is only accessible by authorized users (e.g. employees).  Intranets do not have to be connected to the Internet, but generally have a limited connection.  An extranet is an extension of an intranet that allows secure communications to users outside of the intranet (e.g. business partners, customers).Unofficially, the Internet is the set of users, enterprises, and content providers that are interconnected by Internet Service Providers (ISP). From an engineering viewpoint, the Internet is the set of subnets, and aggregates of subnets, that share the registered IP address space and exchange information about the reachability of those IP addresses using the Border Gateway Protocol. Typically, the human-readable names of servers are translated to IP addresses, transparently to users, via the directory function of the Domain Name System (DNS).\n",
            "Over the Internet, there can be  business-to-business (B2B),  business-to-consumer (B2C) and consumer-to-consumer (C2C) communications. When money or sensitive information is exchanged, the communications are apt to be protected by some form of communications security mechanism.  Intranets and extranets can be securely superimposed onto the Internet, without any access by general Internet users and administrators, using secure Virtual Private Network (VPN) technology.\n",
            "\n",
            "\n",
            "== Journals and newsletters ==\n",
            "Open Computer Science (open access journal)\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            " This article incorporates public domain material from Federal Standard 1037C. General Services Administration. Archived from the original on 2022-01-22.\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "Shelly, Gary, et al. \"Discovering Computers\" 2003 Edition.\n",
            "Wendell Odom, Rus Healy, Denise Donohue. (2010) CCIE Routing and Switching. Indianapolis, IN: Cisco Press\n",
            "Kurose James F and Keith W. Ross: Computer Networking: A Top-Down Approach Featuring the Internet, Pearson Education 2005.\n",
            "William Stallings, Computer Networking with Internet Protocols and Technology, Pearson Education 2004.\n",
            "Important publications in computer networks\n",
            "Network Communication Architecture and Protocols: OSI Network Architecture 7 Layers Model\n",
            "Dimitri Bertsekas, and Robert Gallager, \"Data Networks,\" Prentice Hall, 1992.\n",
            "\n",
            "\n",
            "== External links ==\n",
            "Networking at Curlie\n",
            "IEEE Ethernet manufacturer information\n",
            "A computer networking acronym guide...\n",
            "\n",
            "\n",
            "Page Title: Databases\n",
            "Text: In computing, a database is an organized collection of data or a type of data store based on the use of a database management system (DBMS), the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a database system. Often the term \"database\" is also used loosely to refer to any of the DBMS, the database system or an application associated with the database.\n",
            "Small databases can be stored on a file system, while large databases are hosted on computer clusters or cloud storage. The design of databases spans formal techniques and practical considerations, including data modeling, efficient data representation and storage, query languages, security and privacy of sensitive data, and distributed computing issues, including supporting concurrent access and fault tolerance.\n",
            "Computer scientists may classify database management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, collectively referred to as NoSQL, because they use different query languages.\n",
            "\n",
            "\n",
            "== Terminology and overview ==\n",
            "Formally, a \"database\" refers to a set of related data accessed through the use of a \"database management system\" (DBMS), which is an integrated set of computer software that allows users to interact with one or more databases and provides access to all of the data contained in the database (although restrictions may exist that limit access to particular data). The DBMS provides various functions that allow entry, storage and retrieval of large quantities of information and provides ways to manage how that information is organized.\n",
            "Because of the close relationship between them, the term \"database\" is often used casually to refer to both a database and the DBMS used to manipulate it.\n",
            "Outside the world of professional information technology, the term database is often used to refer to any collection of related data (such as a spreadsheet or a card index) as size and usage requirements typically necessitate use of a database management system.Existing DBMSs provide various functions that allow management of a database and its data which can be classified into four main functional groups:\n",
            "\n",
            "Data definition – Creation, modification and removal of definitions that define the organization of the data.\n",
            "Update – Insertion, modification, and deletion of the actual data.\n",
            "Retrieval – Providing information in a form directly usable or for further processing by other applications. The retrieved data may be made available in a form basically the same as it is stored in the database or in a new form obtained by altering or combining existing data from the database.\n",
            "Administration – Registering and monitoring users, enforcing data security, monitoring performance, maintaining data integrity, dealing with concurrency control, and recovering information that has been corrupted by some event such as an unexpected system failure.Both a database and its DBMS conform to the principles of a particular database model. \"Database system\" refers collectively to the database model, database management system, and database.Physically, database servers are dedicated computers that hold the actual databases and run only the DBMS and related software. Database servers are usually multiprocessor computers, with generous memory and RAID disk arrays used for stable storage. Hardware database accelerators, connected to one or more servers via a high-speed channel, are also used in large-volume transaction processing environments. DBMSs are found at the heart of most database applications. DBMSs may be built around a custom multitasking kernel with built-in networking support, but modern DBMSs typically rely on a standard operating system to provide these functions.Since DBMSs comprise a significant market, computer and storage vendors often take into account DBMS requirements in their own development plans.Databases and DBMSs can be categorized according to the database model(s) that they support (such as relational or XML), the type(s) of computer they run on (from a server cluster to a mobile phone), the query language(s) used to access the database (such as SQL or XQuery), and their internal engineering, which affects performance, scalability, resilience, and security.\n",
            "\n",
            "\n",
            "== History ==\n",
            "The sizes, capabilities, and performance of databases and their respective DBMSs have grown in orders of magnitude. These performance increases were enabled by the technology progress in the areas of processors, computer memory, computer storage, and computer networks. The concept of a database was made possible by the emergence of direct access storage media such as magnetic disks, which became widely available in the mid-1960s; earlier systems relied on sequential storage of data on magnetic tape. The subsequent development of database technology can be divided into three eras based on data model or structure: navigational, SQL/relational, and post-relational.\n",
            "The two main early navigational data models were the hierarchical model and the CODASYL model (network model). These were characterized by the use of pointers (often physical disk addresses) to follow relationships from one record to another.\n",
            "The relational model, first proposed in 1970 by Edgar F. Codd, departed from this tradition by insisting that applications should search for data by content, rather than by following links. The relational model employs sets of ledger-style tables, each used for a different type of entity. Only in the mid-1980s did computing hardware become powerful enough to allow the wide deployment of relational systems (DBMSs plus applications). By the early 1990s, however, relational systems dominated in all large-scale data processing applications, and as of 2018 they remain dominant: IBM Db2, Oracle, MySQL, and Microsoft SQL Server are the most searched DBMS. The dominant database language, standardized SQL for the relational model, has influenced database languages for other data models.Object databases were developed in the 1980s to overcome the inconvenience of object–relational impedance mismatch, which led to the coining of the term \"post-relational\" and also the development of hybrid object–relational databases.\n",
            "The next generation of post-relational databases in the late 2000s became known as NoSQL databases, introducing fast key–value stores and document-oriented databases. A competing \"next generation\" known as NewSQL databases attempted new implementations that retained the relational/SQL model while aiming to match the high performance of NoSQL compared to commercially available relational DBMSs.\n",
            "\n",
            "\n",
            "=== 1960s, navigational DBMS ===\n",
            "\n",
            "The introduction of the term database coincided with the availability of direct-access storage (disks and drums) from the mid-1960s onwards. The term represented a contrast with the tape-based systems of the past, allowing shared interactive use rather than daily batch processing. The Oxford English Dictionary cites a 1962 report by the System Development Corporation of California as the first to use the term \"data-base\" in a specific technical sense.As computers grew in speed and capability, a number of general-purpose database systems emerged; by the mid-1960s a number of such systems had come into commercial use. Interest in a standard began to grow, and Charles Bachman, author of one such product, the Integrated Data Store (IDS), founded the Database Task Group within CODASYL, the group responsible for the creation and standardization of COBOL. In 1971, the Database Task Group delivered their standard, which generally became known as the CODASYL approach, and soon a number of commercial products based on this approach entered the market.\n",
            "The CODASYL approach offered applications the ability to navigate around a linked data set which was formed into a large network. Applications could find records by one of three methods:\n",
            "\n",
            "Use of a primary key (known as a CALC key, typically implemented by hashing)\n",
            "Navigating relationships (called sets) from one record to another\n",
            "Scanning all the records in a sequential orderLater systems added B-trees to provide alternate access paths. Many CODASYL databases also added a declarative query language for end users (as distinct from the navigational API). However, CODASYL databases were complex and required significant training and effort to produce useful applications.\n",
            "IBM also had its own DBMS in 1966, known as Information Management System (IMS). IMS was a development of software written for the Apollo program on the System/360. IMS was generally similar in concept to CODASYL, but used a strict hierarchy for its model of data navigation instead of CODASYL's network model. Both concepts later became known as navigational databases due to the way data was accessed: the term was popularized by Bachman's 1973 Turing Award presentation The Programmer as Navigator. IMS is classified by IBM as a hierarchical database. IDMS and Cincom Systems' TOTAL databases are classified as network databases. IMS remains in use as of 2014.\n",
            "\n",
            "\n",
            "=== 1970s, relational DBMS ===\n",
            "Edgar F. Codd worked at IBM in San Jose, California, in one of their offshoot offices that were primarily involved in the development of hard disk systems. He was unhappy with the navigational model of the CODASYL approach, notably the lack of a \"search\" facility. In 1970, he wrote a number of papers that outlined a new approach to database construction that eventually culminated in the groundbreaking A Relational Model of Data for Large Shared Data Banks.In this paper, he described a new system for storing and working with large databases. Instead of records being stored in some sort of linked list of free-form records as in CODASYL, Codd's idea was to organize the data as a number of \"tables\", each table being used for a different type of entity. Each table would contain a fixed number of columns containing the attributes of the entity. One or more columns of each table were designated as a  primary key by which the rows of the table could be uniquely identified; cross-references between tables always used these primary keys, rather than disk addresses, and queries would join tables based on these key relationships, using a set of operations based on the mathematical system of relational calculus (from which the model takes its name). Splitting the data into a set of normalized tables (or relations) aimed to ensure that each \"fact\" was only stored once, thus simplifying update operations. Virtual tables called views could present the data in different ways for different users, but views could not be directly updated.\n",
            "Codd used mathematical terms to define the model: relations, tuples, and domains rather than tables, rows, and columns. The terminology that is now familiar came from early implementations. Codd would later criticize the tendency for practical implementations to depart from the mathematical foundations on which the model was based.\n",
            "\n",
            "The use of primary keys (user-oriented identifiers) to represent cross-table relationships, rather than disk addresses, had two primary motivations. From an engineering perspective, it enabled tables to be relocated and resized without expensive database reorganization. But Codd was more interested in the difference in semantics: the use of explicit identifiers made it easier to define update operations with clean mathematical definitions, and it also enabled query operations to be defined in terms of the established discipline of first-order predicate calculus; because these operations have clean mathematical properties, it becomes possible to rewrite queries in provably correct ways, which is the basis of query optimization. There is no loss of expressiveness compared with the hierarchic or network models, though the connections between tables are no longer so explicit.\n",
            "In the hierarchic and network models, records were allowed to have a complex internal structure. For example, the salary history of an employee might be represented as a \"repeating group\" within the employee record. In the relational model, the process of normalization led to such internal structures being replaced by data held in multiple tables, connected only by logical keys.\n",
            "For instance, a common use of a database system is to track information about users, their name, login information, various addresses and phone numbers. In the navigational approach, all of this data would be placed in a single variable-length record. In the relational approach, the data would be normalized into a user table, an address table and a phone number table (for instance). Records would be created in these optional tables only if the address or phone numbers were actually provided.\n",
            "As well as identifying rows/records using logical identifiers rather than disk addresses, Codd changed the way in which applications assembled data from multiple records. Rather than requiring applications to gather data one record at a time by navigating the links, they would use a declarative query language that expressed what data was required, rather than the access path by which it should be found. Finding an efficient access path to the data became the responsibility of the database management system, rather than the application programmer. This process, called query optimization, depended on the fact that queries were expressed in terms of mathematical logic.\n",
            "Codd's paper was picked up by two people at Berkeley, Eugene Wong and Michael Stonebraker. They started a project known as INGRES using funding that had already been allocated for a geographical database project and student programmers to produce code. Beginning in 1973, INGRES delivered its first test products which were generally ready for widespread use in 1979. INGRES was similar to System R in a number of ways, including the use of a \"language\" for data access, known as QUEL. Over time, INGRES moved to the emerging SQL standard.\n",
            "IBM itself did one test implementation of the relational model, PRTV, and a production one, Business System 12, both now discontinued. Honeywell wrote MRDS for Multics, and now there are two new implementations: Alphora Dataphor and Rel. Most other DBMS implementations usually called relational are actually SQL DBMSs.\n",
            "In 1970, the University of Michigan began development of the MICRO Information Management System based on D.L. Childs' Set-Theoretic Data model. MICRO was used to manage very large data sets by the US Department of Labor, the U.S. Environmental Protection Agency, and researchers from the University of Alberta, the University of Michigan, and Wayne State University. It ran on IBM mainframe computers using the Michigan Terminal System. The system remained in production until 1998.\n",
            "\n",
            "\n",
            "=== Integrated approach ===\n",
            "\n",
            "In the 1970s and 1980s, attempts were made to build database systems with integrated hardware and software. The underlying philosophy was that such integration would provide higher performance at a lower cost. Examples were IBM System/38, the early offering of Teradata, and the Britton Lee, Inc. database machine.\n",
            "Another approach to hardware support for database management was ICL's CAFS accelerator, a hardware disk controller with programmable search capabilities. In the long term, these efforts were generally unsuccessful because specialized database machines could not keep pace with the rapid development and progress of general-purpose computers. Thus most database systems nowadays are software systems running on general-purpose hardware, using general-purpose computer data storage. However, this idea is still pursued in certain applications by some companies like Netezza and Oracle (Exadata).\n",
            "\n",
            "\n",
            "=== Late 1970s, SQL DBMS ===\n",
            "IBM started working on a prototype system loosely based on Codd's concepts as System R in the early 1970s. The first version was ready in 1974/5, and work then started on multi-table systems in which the data could be split so that all of the data for a record (some of which is optional) did not have to be stored in a single large \"chunk\". Subsequent multi-user versions were tested by customers in 1978 and 1979, by which time a standardized query language – SQL – had been added. Codd's ideas were establishing themselves as both workable and superior to CODASYL, pushing IBM to develop a true production version of System R, known as SQL/DS, and, later, Database 2 (IBM Db2).\n",
            "Larry Ellison's Oracle Database (or more simply, Oracle) started from a different chain, based on IBM's papers on System R. Though Oracle V1 implementations were completed in 1978, it was not until Oracle Version 2 when Ellison beat IBM to market in 1979.Stonebraker went on to apply the lessons from INGRES to develop a new database, Postgres, which is now known as PostgreSQL. PostgreSQL is often used for global mission-critical applications (the .org and .info domain name registries use it as their primary data store, as do many large companies and financial institutions).\n",
            "In Sweden, Codd's paper was also read and Mimer SQL was developed in the mid-1970s at Uppsala University. In 1984, this project was consolidated into an independent enterprise.\n",
            "Another data model, the entity–relationship model, emerged in 1976 and gained popularity for database design as it emphasized a more familiar description than the earlier relational model. Later on, entity–relationship constructs were retrofitted as a data modeling construct for the relational model, and the difference between the two has become irrelevant.\n",
            "\n",
            "\n",
            "=== 1980s, on the desktop ===\n",
            "The 1980s ushered in the age of desktop computing. The new computers empowered their users with spreadsheets like Lotus 1-2-3 and database software like dBASE. The dBASE product was lightweight and easy for any computer user to understand out of the box. C. Wayne Ratliff, the creator of dBASE, stated: \"dBASE was different from programs like BASIC, C, FORTRAN, and COBOL in that a lot of the dirty work had already been done. The data manipulation is done by dBASE instead of by the user, so the user can concentrate on what he is doing, rather than having to mess with the dirty details of opening, reading, and closing files, and managing space allocation.\" dBASE was one of the top selling software titles in the 1980s and early 1990s.\n",
            "\n",
            "\n",
            "=== 1990s, object-oriented ===\n",
            "The 1990s, along with a rise in object-oriented programming, saw a growth in how data in various databases were handled. Programmers and designers began to treat the data in their databases as objects. That is to say that if a person's data were in a database, that person's attributes, such as their address, phone number, and age, were now considered to belong to that person instead of being extraneous data. This allows for relations between data to be related to objects and their attributes and not to individual fields. The term \"object–relational impedance mismatch\" described the inconvenience of translating between programmed objects and database tables. Object databases and object–relational databases attempt to solve this problem by providing an object-oriented language (sometimes as extensions to SQL) that programmers can use as alternative to purely relational SQL. On the programming side, libraries known as object–relational mappings (ORMs) attempt to solve the same problem.\n",
            "\n",
            "\n",
            "=== 2000s, NoSQL and NewSQL ===\n",
            "\n",
            "XML databases are a type of structured document-oriented database that allows querying based on XML document attributes. XML databases are mostly used in applications where the data is conveniently viewed as a collection of documents, with a structure that can vary from the very flexible to the highly rigid: examples include scientific articles, patents, tax filings, and personnel records.\n",
            "NoSQL databases are often very fast, do not require fixed table schemas, avoid join operations by storing denormalized data, and are designed to scale horizontally.\n",
            "In recent years, there has been a strong demand for massively distributed databases with high partition tolerance, but according to the CAP theorem, it is impossible for a distributed system to simultaneously provide consistency, availability, and partition tolerance guarantees. A distributed system can satisfy any two of these guarantees at the same time, but not all three. For that reason, many NoSQL databases are using what is called eventual consistency to provide both availability and partition tolerance guarantees with a reduced level of data consistency.\n",
            "NewSQL is a class of modern relational databases that aims to provide the same scalable performance of NoSQL systems for online transaction processing (read-write) workloads while still using SQL and maintaining the ACID guarantees of a traditional database system.\n",
            "\n",
            "\n",
            "== Use cases ==\n",
            "Databases are used to support internal operations of organizations and to underpin online interactions with customers and suppliers (see Enterprise software).\n",
            "Databases are used to hold administrative information and more specialized data, such as engineering data or economic models. Examples include computerized library systems, flight reservation systems, computerized parts inventory systems, and many content management systems that store websites as collections of webpages in a database.\n",
            "\n",
            "\n",
            "== Classification ==\n",
            "One way to classify databases involves the type of their contents, for example: bibliographic, document-text, statistical, or multimedia objects. Another way is by their application area, for example: accounting, music compositions, movies, banking, manufacturing, or insurance. A third way is by some technical aspect, such as the database structure or interface type. This section lists a few of the adjectives used to characterize different kinds of databases.\n",
            "\n",
            "An in-memory database is a database that primarily resides in main memory, but is typically backed-up by non-volatile computer data storage. Main memory databases are faster than disk databases, and so are often used where response time is critical, such as in telecommunications network equipment.\n",
            "An active database includes an event-driven architecture which can respond to conditions both inside and outside the database. Possible uses include security monitoring, alerting, statistics gathering and authorization. Many databases provide active database features in the form of database triggers.\n",
            "A cloud database relies on cloud technology. Both the database and most of its DBMS reside remotely, \"in the cloud\", while its applications are both developed by programmers and later maintained and used by end-users through a web browser and Open APIs.\n",
            "Data warehouses archive data from operational databases and often from external sources such as market research firms. The warehouse becomes the central source of data for use by managers and other end-users who may not have access to operational data. For example, sales data might be aggregated to weekly totals and converted from internal product codes to use UPCs so that they can be compared with ACNielsen data. Some basic and essential components of data warehousing include extracting, analyzing, and mining data, transforming, loading, and managing data so as to make them available for further use.\n",
            "A deductive database combines logic programming with a relational database.\n",
            "A distributed database is one in which both the data and the DBMS span multiple computers.\n",
            "A document-oriented database is designed for storing, retrieving, and managing document-oriented, or semi structured, information. Document-oriented databases are one of the main categories of NoSQL databases.\n",
            "An embedded database system is a DBMS which is tightly integrated with an application software that requires access to stored data in such a way that the DBMS is hidden from the application's end-users and requires little or no ongoing maintenance.\n",
            "End-user databases consist of data developed by individual end-users. Examples of these are collections of documents, spreadsheets, presentations, multimedia, and other files. Several products exist to support such databases.\n",
            "A federated database system comprises several distinct databases, each with its own DBMS. It is handled as a single database by a federated database management system (FDBMS), which transparently integrates multiple autonomous DBMSs, possibly of different types (in which case it would also be a heterogeneous database system), and provides them with an integrated conceptual view.\n",
            "Sometimes the term multi-database is used as a synonym for federated database, though it may refer to a less integrated (e.g., without an FDBMS and a managed integrated schema) group of databases that cooperate in a single application. In this case, typically middleware is used for distribution, which typically includes an atomic commit protocol (ACP), e.g., the two-phase commit protocol, to allow distributed (global) transactions across the participating databases.\n",
            "A graph database is a kind of NoSQL database that uses graph structures with nodes, edges, and properties to represent and store information. General graph databases that can store any graph are distinct from specialized graph databases such as triplestores and network databases.\n",
            "An array DBMS is a kind of NoSQL DBMS that allows modeling, storage, and retrieval of (usually large) multi-dimensional arrays such as satellite images and climate simulation output.\n",
            "In a hypertext or hypermedia database, any word or a piece of text representing an object, e.g., another piece of text, an article, a picture, or a film, can be hyperlinked to that object. Hypertext databases are particularly useful for organizing large amounts of disparate information. For example, they are useful for organizing online encyclopedias, where users can conveniently jump around the text. The World Wide Web is thus a large distributed hypertext database.\n",
            "A knowledge base (abbreviated KB, kb or Δ) is a special kind of database for knowledge management, providing the means for the computerized collection, organization, and retrieval of knowledge. Also a collection of data representing problems with their solutions and related experiences.A mobile database can be carried on or synchronized from a mobile computing device.\n",
            "Operational databases store detailed data about the operations of an organization. They typically process relatively high volumes of updates using transactions. Examples include customer databases that record contact, credit, and demographic information about a business's customers, personnel databases that hold information such as salary, benefits, skills data about employees, enterprise resource planning systems that record details about product components, parts inventory, and financial databases that keep track of the organization's money, accounting and financial dealings.\n",
            "A parallel database seeks to improve performance through parallelization for tasks such as loading data, building indexes and evaluating queries.The major parallel DBMS architectures which are induced by the underlying hardware architecture are:\n",
            "Shared memory architecture, where multiple processors share the main memory space, as well as other data storage.\n",
            "Shared disk architecture, where each processing unit (typically consisting of multiple processors) has its own main memory, but all units share the other storage.\n",
            "Shared-nothing architecture, where each processing unit has its own main memory and other storage.Probabilistic databases employ fuzzy logic to draw inferences from imprecise data.\n",
            "Real-time databases process transactions fast enough for the result to come back and be acted on right away.\n",
            "A spatial database can store the data with multidimensional features. The queries on such data include location-based queries, like \"Where is the closest hotel in my area?\".\n",
            "A temporal database has built-in time aspects, for example a temporal data model and a temporal version of SQL. More specifically the temporal aspects usually include valid-time and transaction-time.\n",
            "A terminology-oriented database builds upon an object-oriented database, often customized for a specific field.\n",
            "An unstructured data database is intended to store in a manageable and protected way diverse objects that do not fit naturally and conveniently in common databases. It may include email messages, documents, journals, multimedia objects, etc. The name may be misleading since some objects can be highly structured. However, the entire possible object collection does not fit into a predefined structured framework. Most established DBMSs now support unstructured data in various ways, and new dedicated DBMSs are emerging.\n",
            "\n",
            "\n",
            "== Database management system ==\n",
            "Connolly and Begg define database management system (DBMS) as a \"software system that enables users to define, create, maintain and control access to the database\". Examples of DBMS's include MySQL, MariaDB, PostgreSQL, Microsoft SQL Server, Oracle Database, and Microsoft Access.\n",
            "The DBMS acronym is sometimes extended to indicate the underlying database model, with RDBMS for the relational, OODBMS for the object (oriented) and ORDBMS for the object–relational model. Other extensions can indicate some other characteristics, such as DDBMS for a distributed database management systems.\n",
            "The functionality provided by a DBMS can vary enormously. The core functionality is the storage, retrieval and update of data. Codd proposed the following functions and services a fully-fledged general purpose DBMS should provide:\n",
            "Data storage, retrieval and update\n",
            "User accessible catalog or data dictionary describing the metadata\n",
            "Support for transactions and concurrency\n",
            "Facilities for recovering the database should it become damaged\n",
            "Support for authorization of access and update of data\n",
            "Access support from remote locations\n",
            "Enforcing constraints to ensure data in the database abides by certain rulesIt is also generally to be expected the DBMS will provide a set of utilities for such purposes as may be necessary to administer the database effectively, including import, export, monitoring, defragmentation and analysis utilities. The core part of the DBMS interacting between the database and the application interface sometimes referred to as the database engine.\n",
            "Often DBMSs will have configuration parameters that can be statically and dynamically tuned, for example the maximum amount of main memory on a server the database can use. The trend is to minimize the amount of manual configuration, and for cases such as embedded databases the need to target zero-administration is paramount.\n",
            "The large major enterprise DBMSs have tended to increase in size and functionality and have involved up to thousands of human years of development effort throughout their lifetime.Early multi-user DBMS typically only allowed for the application to reside on the same computer with access via terminals or terminal emulation software. The client–server architecture was a development where the application resided on a client desktop and the database on a server allowing the processing to be distributed. This evolved into a multitier architecture incorporating application servers and web servers with the end user interface via a web browser with the database only directly connected to the adjacent tier.A general-purpose DBMS will provide public application programming interfaces (API) and optionally a processor for database languages such as SQL to allow applications to be written to interact with and manipulate the database. A special purpose DBMS may use a private API and be specifically customized and linked to a single application. For example, an email system performs many of the functions of a general-purpose DBMS such as message insertion, message deletion, attachment handling, blocklist lookup, associating messages an email address and so forth however these functions are limited to what is required to handle email.\n",
            "\n",
            "\n",
            "== Application ==\n",
            "\n",
            "External interaction with the database will be via an application program that interfaces with the DBMS. This can range from a database tool that allows users to execute SQL queries textually or graphically, to a website that happens to use a database to store and search information.\n",
            "\n",
            "\n",
            "=== Application program interface ===\n",
            "A programmer will code interactions to the database (sometimes referred to as a datasource) via an application program interface (API) or via a database language. The particular API or language chosen will need to be supported by DBMS, possibly indirectly via a preprocessor or a bridging API. Some API's aim to be database independent, ODBC being a commonly known example. Other common API's include JDBC and ADO.NET.\n",
            "\n",
            "\n",
            "== Database languages ==\n",
            "Database languages are special-purpose languages, which allow one or more of the following tasks, sometimes distinguished as sublanguages:\n",
            "\n",
            "Data control language (DCL) – controls access to data;\n",
            "Data definition language (DDL) – defines data types such as creating, altering, or dropping tables and the relationships among them;\n",
            "Data manipulation language (DML) – performs tasks such as inserting, updating, or deleting data occurrences;\n",
            "Data query language (DQL) – allows searching for information and computing derived information.Database languages are specific to a particular data model. Notable examples include:\n",
            "\n",
            "SQL combines the roles of data definition, data manipulation, and query in a single language. It was one of the first commercial languages for the relational model, although it departs in some respects from the relational model as described by Codd (for example, the rows and columns of a table can be ordered). SQL became a standard of the American National Standards Institute (ANSI) in 1986, and of the International Organization for Standardization (ISO) in 1987. The standards have been regularly enhanced since and are supported (with varying degrees of conformance) by all mainstream commercial relational DBMSs.\n",
            "OQL is an object model language standard (from the Object Data Management Group). It has influenced the design of some of the newer query languages like JDOQL and EJB QL.\n",
            "XQuery is a standard XML query language implemented by XML database systems such as MarkLogic and eXist, by relational databases with XML capability such as Oracle and Db2, and also by in-memory XML processors such as Saxon.\n",
            "SQL/XML combines XQuery with SQL.A database language may also incorporate features like:\n",
            "\n",
            "DBMS-specific configuration and storage engine management\n",
            "Computations to modify query results, like counting, summing, averaging, sorting, grouping, and cross-referencing\n",
            "Constraint enforcement (e.g. in an automotive database, only allowing one engine type per car)\n",
            "Application programming interface version of the query language, for programmer convenience\n",
            "\n",
            "\n",
            "== Storage ==\n",
            "\n",
            "Database storage is the container of the physical materialization of a database. It comprises the internal (physical) level in the database architecture. It also contains all the information needed (e.g., metadata, \"data about the data\", and internal data structures) to reconstruct the conceptual level and external level from the internal level when needed. Databases as digital objects contain three layers of information which must be stored: the data, the structure, and the semantics. Proper storage of all three layers is needed for future preservation and longevity of the database. Putting data into permanent storage is generally the responsibility of the database engine a.k.a. \"storage engine\". Though typically accessed by a DBMS through the underlying operating system (and often using the operating systems' file systems as intermediates for storage layout), storage properties and configuration settings are extremely important for the efficient operation of the DBMS, and thus are closely maintained by database administrators. A DBMS, while in operation, always has its database residing in several types of storage (e.g., memory and external storage). The database data and the additional needed information, possibly in very large amounts, are coded into bits. Data typically reside in the storage in structures that look completely different from the way the data look at the conceptual and external levels, but in ways that attempt to optimize (the best possible) these levels' reconstruction when needed by users and programs, as well as for computing additional types of needed information from the data (e.g., when querying the database).\n",
            "Some DBMSs support specifying which character encoding was used to store data, so multiple encodings can be used in the same database.\n",
            "Various low-level database storage structures are used by the storage engine to serialize the data model so it can be written to the medium of choice. Techniques such as indexing may be used to improve performance. Conventional storage is row-oriented, but there are also column-oriented and correlation databases.\n",
            "\n",
            "\n",
            "=== Materialized views ===\n",
            "\n",
            "Often storage redundancy is employed to increase performance. A common example is storing materialized views, which consist of frequently needed external views or query results. Storing such views saves the expensive computing them each time they are needed. The downsides of materialized views are the overhead incurred when updating them to keep them synchronized with their original updated database data, and the cost of storage redundancy.\n",
            "\n",
            "\n",
            "=== Replication ===\n",
            "\n",
            "Occasionally a database employs storage redundancy by database objects replication (with one or more copies) to increase data availability (both to improve performance of simultaneous multiple end-user accesses to the same database object, and to provide resiliency in a case of partial failure of a distributed database). Updates of a replicated object need to be synchronized across the object copies. In many cases, the entire database is replicated.\n",
            "\n",
            "\n",
            "=== Virtualization ===\n",
            "With data virtualization, the data used remains in its original locations and real-time access is established to allow analytics across multiple sources. This can aid in resolving some technical difficulties such as compatibility problems when combining data from various platforms, lowering the risk of error caused by faulty data, and guaranteeing that the newest data is used. Furthermore, avoiding the creation of a new database containing personal information can make it easier to comply with privacy regulations. However, with data virtualization, the connection to all necessary data sources must be operational as there is no local copy of the data, which is one of the main drawbacks of the approach.\n",
            "\n",
            "\n",
            "== Security ==\n",
            "\n",
            "Database security deals with all various aspects of protecting the database content, its owners, and its users. It ranges from protection from intentional unauthorized database uses to unintentional database accesses by unauthorized entities (e.g., a person or a computer program).\n",
            "Database access control deals with controlling who (a person or a certain computer program) are allowed to access what information in the database. The information may comprise specific database objects (e.g., record types, specific records, data structures), certain computations over certain objects (e.g., query types, or specific queries), or using specific access paths to the former (e.g., using specific indexes or other data structures to access information). Database access controls are set by special authorized (by the database owner) personnel that uses dedicated protected security DBMS interfaces.\n",
            "This may be managed directly on an individual basis, or by the assignment of individuals and privileges to groups, or (in the most elaborate models) through the assignment of individuals and groups to roles which are then granted entitlements. Data security prevents unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or subsets of it called \"subschemas\". For example, an employee database can contain all the data about an individual employee, but one group of users may be authorized to view only payroll data, while others are allowed access to only work history and medical data. If the DBMS provides a way to interactively enter and update the database, as well as interrogate it, this capability allows for managing personal databases.\n",
            "Data security in general deals with protecting specific chunks of data, both physically (i.e., from corruption, or destruction, or removal; e.g., see physical security), or the interpretation of them, or parts of them to meaningful information (e.g., by looking at the strings of bits that they comprise, concluding specific valid credit-card numbers; e.g., see data encryption).\n",
            "Change and access logging records who accessed which attributes, what was changed, and when it was changed. Logging services allow for a forensic database audit later by keeping a record of access occurrences and changes. Sometimes application-level code is used to record changes rather than leaving this in the database. Monitoring can be set up to attempt to detect security breaches. Therefore, organizations must take database security seriously because of the many benefits it provides. Organizations will be safeguarded from security breaches and hacking activities like firewall intrusion, virus spread, and ransom ware. This helps in protecting the company's essential information, which cannot be shared with outsiders at any cause.\n",
            "\n",
            "\n",
            "== Transactions and concurrency ==\n",
            "\n",
            "Database transactions can be used to introduce some level of fault tolerance and data integrity after recovery from a crash. A database transaction is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring or releasing a lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction's programmer via special transaction commands).\n",
            "The acronym ACID describes some ideal properties of a database transaction: atomicity, consistency, isolation, and durability.\n",
            "\n",
            "\n",
            "== Migration ==\n",
            "\n",
            "A database built with one DBMS is not portable to another DBMS (i.e., the other DBMS cannot run it). However, in some situations, it is desirable to migrate a database from one DBMS to another. The reasons are primarily economical (different DBMSs may have different total costs of ownership or TCOs), functional, and operational (different DBMSs may have different capabilities). The migration involves the database's transformation from one DBMS type to another. The transformation should maintain (if possible) the database related application (i.e., all related application programs) intact. Thus, the database's conceptual and external architectural levels should be maintained in the transformation. It may be desired that also some aspects of the architecture internal level are maintained. A complex or large database migration may be a complicated and costly (one-time) project by itself, which should be factored into the decision to migrate. This is in spite of the fact that tools may exist to help migration between specific DBMSs. Typically, a DBMS vendor provides tools to help import databases from other popular DBMSs.\n",
            "\n",
            "\n",
            "== Building, maintaining, and tuning ==\n",
            "\n",
            "After designing a database for an application, the next stage is building the database. Typically, an appropriate general-purpose DBMS can be selected to be used for this purpose. A DBMS provides the needed user interfaces to be used by database administrators to define the needed application's data structures within the DBMS's respective data model. Other user interfaces are used to select needed DBMS parameters (like security related, storage allocation parameters, etc.).\n",
            "When the database is ready (all its data structures and other needed components are defined), it is typically populated with initial application's data (database initialization, which is typically a distinct project; in many cases using specialized DBMS interfaces that support bulk insertion) before making it operational. In some cases, the database becomes operational while empty of application data, and data are accumulated during its operation.\n",
            "After the database is created, initialized and populated it needs to be maintained. Various database parameters may need changing and the database may need to be tuned (tuning) for better performance; application's data structures may be changed or added, new related application programs may be written to add to the application's functionality, etc.\n",
            "\n",
            "\n",
            "== Backup and restore ==\n",
            "\n",
            "Sometimes it is desired to bring a database back to a previous state (for many reasons, e.g., cases when the database is found corrupted due to a software error, or if it has been updated with erroneous data). To achieve this, a backup operation is done occasionally or continuously, where each desired database state (i.e., the values of its data and their embedding in database's data structures) is kept within dedicated backup files (many techniques exist to do this effectively). When it is decided by a database administrator to bring the database back to this state (e.g., by specifying this state by a desired point in time when the database was in this state), these files are used to restore that state.\n",
            "\n",
            "\n",
            "== Static analysis ==\n",
            "Static analysis techniques for software verification can be applied also in the scenario of query languages. In particular, the *Abstract interpretation framework has been extended to the field of query languages for relational databases as a way to support sound approximation techniques. The semantics of query languages can be tuned according to suitable abstractions of the concrete domain of data. The abstraction of relational database systems has many interesting applications, in particular, for security purposes, such as fine-grained access control, watermarking, etc.\n",
            "\n",
            "\n",
            "== Miscellaneous features ==\n",
            "Other DBMS features might include:\n",
            "\n",
            "Database logs – This helps in keeping a history of the executed functions.\n",
            "Graphics component for producing graphs and charts, especially in a data warehouse system.\n",
            "Query optimizer – Performs query optimization on every query to choose an efficient query plan (a partial order (tree) of operations) to be executed to compute the query result. May be specific to a particular storage engine.\n",
            "Tools or hooks for database design, application programming, application program maintenance, database performance analysis and monitoring, database configuration monitoring, DBMS hardware configuration (a DBMS and related database may span computers, networks, and storage units) and related database mapping (especially for a distributed DBMS), storage allocation and database layout monitoring, storage migration, etc.Increasingly, there are calls for a single system that incorporates all of these core functionalities into the same build, test, and deployment framework for database management and source control. Borrowing from other developments in the software industry, some market such offerings as \"DevOps for database\".\n",
            "\n",
            "\n",
            "== Design and modeling ==\n",
            "\n",
            "The first task of a database designer is to produce a conceptual data model that reflects the structure of the information to be held in the database. A common approach to this is to develop an entity–relationship model, often with the aid of drawing tools. Another popular approach is the Unified Modeling Language. A successful data model will accurately reflect the possible state of the external world being modeled: for example, if people can have more than one phone number, it will allow this information to be captured. Designing a good conceptual data model requires a good understanding of the application domain; it typically involves asking deep questions about the things of interest to an organization, like \"can a customer also be a supplier?\", or \"if a product is sold with two different forms of packaging, are those the same product or different products?\", or \"if a plane flies from New York to Dubai via Frankfurt, is that one flight or two (or maybe even three)?\". The answers to these questions establish definitions of the terminology used for entities (customers, products, flights, flight segments) and their relationships and attributes.\n",
            "Producing the conceptual data model sometimes involves input from business processes, or the analysis of workflow in the organization. This can help to establish what information is needed in the database, and what can be left out. For example, it can help when deciding whether the database needs to hold historic data as well as current data.\n",
            "Having produced a conceptual data model that users are happy with, the next stage is to translate this into a schema that implements the relevant data structures within the database. This process is often called logical database design, and the output is a logical data model expressed in the form of a schema. Whereas the conceptual data model is (in theory at least) independent of the choice of database technology, the logical data model will be expressed in terms of a particular database model supported by the chosen DBMS. (The terms data model and database model are often used interchangeably, but in this article we use data model for the design of a specific database, and database model for the modeling notation used to express that design).\n",
            "The most popular database model for general-purpose databases is the relational model, or more precisely, the relational model as represented by the SQL language. The process of creating a logical database design using this model uses a methodical approach known as normalization. The goal of normalization is to ensure that each elementary \"fact\" is only recorded in one place, so that insertions, updates, and deletions automatically maintain consistency.\n",
            "The final stage of database design is to make the decisions that affect performance, scalability, recovery, security, and the like, which depend on the particular DBMS. This is often called physical database design, and the output is the physical data model. A key goal during this stage is data independence, meaning that the decisions made for performance optimization purposes should be invisible to end-users and applications. There are two types of data independence: Physical data independence and logical data independence. Physical design is driven mainly by performance requirements, and requires a good knowledge of the expected workload and access patterns, and a deep understanding of the features offered by the chosen DBMS.\n",
            "Another aspect of physical database design is security. It involves both defining access control to database objects as well as defining security levels and methods for the data itself.\n",
            "\n",
            "\n",
            "=== Models ===\n",
            "\n",
            "A database model is a type of data model that determines the logical structure of a database and fundamentally determines in which manner data can be stored, organized, and manipulated. The most popular example of a database model is the relational model (or the SQL approximation of relational), which uses a table-based format.\n",
            "Common logical data models for databases include:\n",
            "\n",
            "Navigational databases\n",
            "Hierarchical database model\n",
            "Network model\n",
            "Graph database\n",
            "Relational model\n",
            "Entity–relationship model\n",
            "Enhanced entity–relationship model\n",
            "Object model\n",
            "Document model\n",
            "Entity–attribute–value model\n",
            "Star schemaAn object–relational database combines the two related structures.\n",
            "Physical data models include:\n",
            "\n",
            "Inverted index\n",
            "Flat fileOther models include:\n",
            "\n",
            "Multidimensional model\n",
            "Array model\n",
            "Multivalue modelSpecialized models are optimized for particular types of data:\n",
            "\n",
            "XML database\n",
            "Semantic model\n",
            "Content store\n",
            "Event store\n",
            "Time series model\n",
            "\n",
            "\n",
            "=== External, conceptual, and internal views ===\n",
            "A database management system provides three views of the database data:\n",
            "\n",
            "The external level defines how each group of end-users sees the organization of data in the database. A single database can have any number of views at the external level.\n",
            "The conceptual level (or logical level) unifies the various external views into a compatible global view. It provides the synthesis of all the external views. It is out of the scope of the various database end-users, and is rather of interest to database application developers and database administrators.\n",
            "The internal level (or physical level) is the internal organization of data inside a DBMS. It is concerned with cost, performance, scalability and other operational matters. It deals with storage layout of the data, using storage structures such as indexes to enhance performance. Occasionally it stores data of individual views (materialized views), computed from generic data, if performance justification exists for such redundancy. It balances all the external views' performance requirements, possibly conflicting, in an attempt to optimize overall performance across all activities.While there is typically only one conceptual and internal view of the data, there can be any number of different external views. This allows users to see database information in a more business-related way rather than from a technical, processing viewpoint. For example, a financial department of a company needs the payment details of all employees as part of the company's expenses, but does not need details about employees that are in the interest of the human resources department. Thus different departments need different views of the company's database.\n",
            "The three-level database architecture relates to the concept of data independence which was one of the major initial driving forces of the relational model. The idea is that changes made at a certain level do not affect the view at a higher level. For example, changes in the internal level do not affect application programs written using conceptual level interfaces, which reduces the impact of making physical changes to improve performance.\n",
            "The conceptual view provides a level of indirection between internal and external. On the one hand it provides a common view of the database, independent of different external view structures, and on the other hand it abstracts away details of how the data are stored or managed (internal level). In principle every level, and even every external view, can be presented by a different data model. In practice usually a given DBMS uses the same data model for both the external and the conceptual levels (e.g., relational model). The internal level, which is hidden inside the DBMS and depends on its implementation, requires a different level of detail and uses its own types of data structure types.\n",
            "\n",
            "\n",
            "== Research ==\n",
            "Database technology has been an active research topic since the 1960s, both in academia and in the research and development groups of companies (for example IBM Research). Research activity includes theory and development of prototypes. Notable research topics have included models, the atomic transaction concept, related concurrency control techniques, query languages and query optimization methods, RAID, and more.\n",
            "The database research area has several dedicated academic journals (for example, ACM Transactions on Database Systems-TODS, Data and Knowledge Engineering-DKE) and annual conferences (e.g., ACM SIGMOD, ACM PODS, VLDB, IEEE ICDE).\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== Notes ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Sources ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "Ling Liu and Tamer M. Özsu (Eds.) (2009).  \"Encyclopedia of Database Systems, 4100 p. 60 illus. ISBN 978-0-387-49616-0.\n",
            "Gray, J. and Reuter, A. Transaction Processing: Concepts and Techniques, 1st edition,  Morgan Kaufmann Publishers, 1992.\n",
            "Kroenke, David M. and David J. Auer. Database Concepts. 3rd ed. New York: Prentice, 2007.\n",
            "Raghu Ramakrishnan and Johannes Gehrke, Database Management Systems.\n",
            "Abraham Silberschatz, Henry F. Korth, S. Sudarshan, Database System Concepts.\n",
            "Lightstone, S.; Teorey, T.; Nadeau, T. (2007). Physical Database Design: the database professional's guide to exploiting indexes, views, storage, and more. Morgan Kaufmann Press. ISBN 978-0-12-369389-1.\n",
            "Teorey, T.; Lightstone, S. and Nadeau, T. Database Modeling & Design: Logical Design, 4th edition, Morgan Kaufmann Press, 2005. ISBN 0-12-685352-5.\n",
            "CMU Database courses playlist\n",
            "MIT OCW 6.830 | Fall 2010 | Database Systems\n",
            "Berkeley CS W186\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "DB File extension – information about files with the DB extension...\n",
            "\n",
            "\n",
            "Page Title: Cybersecurity\n",
            "Text: Computer security, cyber security, digital security or information technology security (IT security) is the protection of computer systems and networks from attacks by malicious actors that may result in unauthorized information disclosure, theft of, or damage to hardware, software, or data, as well as from the disruption or misdirection of the services they provide.The field is significant due to the expanded reliance on computer systems, the Internet, and wireless network standards such as Bluetooth and Wi-Fi. Also, due to the growth of smart devices, including smartphones, televisions, and the various devices that constitute the Internet of things (IoT). Cybersecurity is one of the most significant challenges of the contemporary world, due to both the complexity of information systems and the societies they support. Security is of especially high importance for systems that govern large-scale systems with far-reaching physical effects, such as power distribution, elections, and finance.\n",
            "\n",
            "\n",
            "== Vulnerabilities and attacks ==\n",
            "\n",
            "A vulnerability is a weakness in design, implementation, operation, or internal control of a computer or system. Most of the vulnerabilities that have been discovered are documented in the Common Vulnerabilities and Exposures (CVE) database. An exploitable vulnerability is one for which at least one working attack or exploit exists. Vulnerabilities can be researched, reverse-engineered, hunted, or exploited using automated tools or customized scripts.Various people or parties are vulnerable to cyber attacks, however different groups are likely to experience different types of attacks more than others.In April 2023 the United Kingdom Department for Science, Innovation & Technology realised a report on cyber attacks over the last 12 months. They surveyed 2,263 UK businesses, 1,174 UK registered charities and 554 education institutions. The research found that \"32% of businesses and 24% of charities overall recall any breaches or attacks from the last 12 months.\" This figures were much higher for \"medium businesses (59%), large businesses (69%) and high-income charities with £500,000 or more in annual income (56%).\" Yet, although medium or large businesses are more often the victims, since larger companies have generally improved their security over the last decade, small and midsize businesses (SMBs) have also become increasing vulnerable as they often \"do not have advanced tools to defend the business.\" SMBs are most likely to be affected by malware, ransomware, phishing, man-in-the-middle attacks, and Denial-of Service (DoS) Attacks.Normal people working for a business or simply using the internet are most likely to be affected by \"un-targeted\" cyber attacks. These are where attackers indiscriminately target as many devices, services or users as possible. They do this using techniques that take advantage of the \"openness\" of the Internet. These strategies mostly include phishing, ransomware, water holing and scanning.To secure a computer system, it is important to understand the attacks that can be made against it, and these threats can typically be classified into one of the following categories:\n",
            "\n",
            "\n",
            "=== Backdoor ===\n",
            "A backdoor in a computer system, a cryptosystem, or an algorithm, is any secret method of bypassing normal authentication or security controls. These weaknesses may exist for many reasons, including original design or poor configuration. Due to the nature of backdoors, they are of greater concern to companies and databases as opposed to individuals.\n",
            "Backdoors may be added by an authorized party to allow some legitimate access, or by an attacker for malicious reasons. However, criminals often use malware to install backdoors, giving them remote administrative access to a system. Once they have access, cybercriminals can \"modify files, steal personal information, install unwanted software, and even take control of the entire computer.\"Backdoors can be very hard to detect, and are usually discovered by someone who has access to the application source code or intimate knowledge of the operating system of the computer.  \n",
            "\n",
            "\n",
            "=== Denial-of-service attack ===\n",
            "Denial of service attacks (DoS) are designed to make a machine or network resource unavailable to its intended users. Attackers can deny service to individual victims, such as by deliberately entering a wrong password enough consecutive times to cause the victim's account to be locked, or they may overload the capabilities of a machine or network and block all users at once. While a network attack from a single IP address can be blocked by adding a new firewall rule, many forms of Distributed denial of service (DDoS) attacks are possible, where the attack comes from a large number of points – and defending is much more difficult. Such attacks can originate from the zombie computers of a botnet or from a range of other possible techniques, including distributed reflective denial of service (DRDoS), where innocent systems are fooled into sending traffic to the victim. With such attacks, the amplification factor makes the attack easier for the attacker because they have to use little bandwidth themselves.\n",
            "To understand why attackers may carry out these attacks, see the 'attacker motivation' section. \n",
            "\n",
            "\n",
            "=== Direct-access attacks ===\n",
            "A direct-access attack is when an unauthorized user (an attacker) gains physical access to a computer, most likely to directly copy data from it or to steal information. Attackers may also compromise security by making operating system modifications, installing software worms, keyloggers, covert listening devices or using wireless microphones. Even when the system is protected by standard security measures, these may be bypassed by booting another operating system or tool from a CD-ROM or other bootable media. Disk encryption and Trusted Platform Module are designed to prevent these attacks.\n",
            "Direct service attackers are related in concept to direct memory attacks that allows an attacker to gain direct access to a computer’s memory. The attacks \"take advantage of a feature of modern computers that allow certain devices, such as external hard drives, graphics cards or network cards, to access the computer’s memory directly.\"To help prevent these attacks, computer users must ensure that they have a strong passwords, that their computer is locked at all times when they are not using it, and that they keep their computer with them at all times when traveling.\n",
            "\n",
            "\n",
            "=== Eavesdropping ===\n",
            "Eavesdropping is the act of surreptitiously listening to a private computer conversation (communication), usually between hosts on a network. It typically occurs when a user connects to a network where traffic is not secured or encrypted and sends sensitive business data to a colleague, which when listened to by an attacker could be exploited. Data transmitted across an \"open network\" gives an attacker the opportunity to exploit a vulnerability and intercept it via various methods.\n",
            "Unlike malware, direct-access attacks, or other forms of cyber attacks, eavesdropping attacks are unlikely to negatively affect the performance of networks or devices, making them difficult to notice. In fact, \"the attacker does not need to have any ongoing connection to the software at all. He or she can insert the software onto a compromised device, perhaps by direct insertion or perhaps by a virus or other malware, and then come back some time later to retrieve any data that is found or trigger the software to send the data at some determined time.\"Using a virtual private network (VPN), which encrypts data between two points, is one of the most common forms of protection against eavesdropping. Using the best form of encryption possible for wireless networks is best practice, as well as using HTTPS instead of the unencrypted HTTP.Programs such as Carnivore and NarusInSight have been used by the Federal Bureau of Investigation (FBI) and NSA to eavesdrop on the systems of internet service providers. Even machines that operate as a closed system (i.e., with no contact with the outside world) can be eavesdropped upon by monitoring the faint electromagnetic transmissions generated by the hardware. TEMPEST is a specification by the NSA referring to these attacks.\n",
            "\n",
            "\n",
            "=== Malware ===\n",
            "Malicious software (malware) is any software code or computer program \"intentionally written to harm a computer system or its users.\" Once present on a computer, it can leak sensitive details such as personal information, business information and passwords, can give control of the system to the attacker, and can corrupt or delete data permanently. Another type of malware is ransomware, which is when \"malware installs itself onto a victim’s machine, encrypts their files, and then turns around and demands a ransom (usually in Bitcoin) to return that data to the user.\"Types of malware include some of the following:\n",
            "\n",
            "Viruses are a specific type of malware, and are normally a malicious code that hijacks software with the intension to \"do damage and spread copies of itself.\" Copies are made with the aim to spread to other programs on a computer.\n",
            "Worms are similar to viruses, however viruses can only function when a user runs (opens) a comprised program. Worms therefore are self-replicating malware that spread between programs, apps and devices without the need for human interaction.\n",
            "Trojan horses are programs that pretend to be helpful or hide themselves within desired or legitimate software to \"trick users into installing them.\" Once installed, a RAT (remote access trojan) can create a secret backdoor on the affected device.\n",
            "Spyware is a type of malware that secretly gathers information on an infected computers and transmits the sensitive information back to the attacker. One of the most common forms of spyware are known as keyloggers, which is a kind of malware which recorders all of a users keyboard inputs/keystrokes, used to \"allow hackers to harvest usernames, passwords, bank account and credit card numbers.\"\n",
            "Scareware, as the name suggests, is a form of malware which uses social engineering (manipulation) to scare, shock, trigger anxiety, or suggest the perception of a threat in order to manipulate users into buying or installing unwanted software. These attacks often begin with a \"sudden pop-up with an urgent message, usually warning the user that they've broken the law or their device has a virus.\"\n",
            "\n",
            "\n",
            "=== Multi-vector, polymorphic attacks ===\n",
            "Surfacing in 2017, a new class of multi-vector, polymorphic cyber threats combined several types of attacks and changed form to avoid cybersecurity controls as they spread.\n",
            "Multi-vector polymorphic attacks, as the name describes, are both multi-vectored and polymorphic. Firstly, they are a singular offensive that involves multiple methods of attack. In this sense, they are “multi-vectored (i.e. the attack can use multiple means of propagation such as via the Web, email and applications.\" However,  they are also multi-staged, meaning that “they can infiltrate networks and move laterally inside the network.” The attacks can be polymorphic, meaning that the cyberattacks used such as viruses, worms or trojans “constantly change (“morph”) making it nearly impossible to detect them using signature-based defences.”\n",
            "\n",
            "\n",
            "=== Phishing ===\n",
            "Phishing is the attempt of acquiring sensitive information such as usernames, passwords, and credit card details directly from users by deceiving the users. Phishing is typically carried out by email spoofing, instant messaging, text message, or on a phone call, and it often directs users to enter details at a fake website whose look and feel are almost identical to the legitimate one. The fake website often asks for personal information, such as login details and passwords. This information can then be used to gain access to the individual's real account on the real website. \n",
            "Preying on a victim's trust, phishing can be classified as a form of social engineering. Attackers are using creative ways to gain access to real accounts. A common scam is for attackers to send fake electronic invoices to individuals showing that they recently purchased music, apps, or others, and instructing them to click on a link if the purchases were not authorized. A more strategic type of phishing is spear-phishing which leverages personal or organization-specific details to make the attacker appear like a trusted source. Spear-phishing attacks target specific individuals, rather than the broad net cast by phishing attempts.\n",
            "\n",
            "\n",
            "=== Privilege escalation ===\n",
            "Privilege escalation describes a situation where an attacker with some level of restricted access is able to, without authorization, elevate their privileges or access level. For example, a standard computer user may be able to exploit a vulnerability in the system to gain access to restricted data; or even become root and have full unrestricted access to a system. The severity of attacks can range from attacks simply sending an unsolicited email to a ransomware attack on large amounts of data. Privilege escalation usually starts with social engineering techniques, often phishing.Privilege escalation can be separated into to strategies, horizontal and vertical privilege escalation:\n",
            "\n",
            "Horizontal escalation (or account takeover) is where an attacker gains access to a normal user account that has relatively low-level privileges. This may be through stealing the user’s username and password. Once they have access, they have gained a “foothold,” and using this foothold the attacker then may move around the network of users at this same lower level, gaining access to information of this similar privilege.\n",
            "Vertical escalation however targets people higher up in a company and often with more administrative power, such as an employee in IT with a higher privilege. Using this privileged account will then enable to attacker to invade other accounts.\n",
            "\n",
            "\n",
            "=== Side-channel attack ===\n",
            "\n",
            "Any computational system affects its environment in some form. This effect it has on its environment includes a wide range of criteria, which can range from electromagnetic radiation to residual effect on RAM cells which as a consequence make a Cold boot attack possible, to hardware implementation faults that allow for access and or guessing of other values that normally should be inaccessible. In Side-channel attack scenarios, the attacker would gather such information about a system or network to guess its internal state and as a result access the information which is assumed by the victim to be secure.\n",
            "\n",
            "\n",
            "=== Social engineering ===\n",
            "Social engineering, in the context of computer security, aims to convince a user to disclose secrets such as passwords, card numbers, etc. or grant physical access by, for example, impersonating a senior executive, bank, a contractor, or a customer. This generally involves exploiting people's trust, and relying on their cognitive biases. A common scam involves emails sent to accounting and finance department personnel, impersonating their CEO and urgently requesting some action. One of the main techniques of social engineering are phishing attacks. \n",
            "In early 2016, the FBI reported that such business email compromise (BEC) scams had cost US businesses more than $2 billion in about two years.In May 2016, the Milwaukee Bucks NBA team was the victim of this type of cyber scam with a perpetrator impersonating the team's president Peter Feigin, resulting in the handover of all the team's employees' 2015 W-2 tax forms.\n",
            "\n",
            "\n",
            "=== Spoofing ===\n",
            "\n",
            "Spoofing is an act of pretending to be a valid entity through the falsification of data (such as an IP address or username), in order to gain access to information or resources that one is otherwise unauthorized to obtain. Spoofing is closely related to phishing. There are several types of spoofing, including:\n",
            "\n",
            "Email spoofing, is where an attacker forges the sending (From, or source) address of an email.\n",
            "IP address spoofing, where an attacker alters the source IP address in a network packet to hide their identity or impersonate another computing system.\n",
            "MAC spoofing, where an attacker modifies the Media Access Control (MAC) address of their network interface controller to obscure their identity, or to pose as another.\n",
            "Biometric spoofing, where an attacker produces a fake biometric sample to pose as another user.\n",
            "Address Resolution Protocol (ARP) spoofing, where an attacker sends spoofed address resolution protocol onto a local area network to associate their Media Access Control address with a different host's IP address. This causes data to be sent to the attacker rather than the intended host.In 2018, the cybersecurity firm Trellix published research on the life-threatening risk of spoofing in the healthcare industry.\n",
            "\n",
            "\n",
            "=== Tampering ===\n",
            "Tampering describes a malicious modification or alteration of data. An intentional but unauthorized act resulting in the modification of a system, components of systems, its intended behavior, or data. So-called Evil Maid attacks and security services planting of surveillance capability into routers are examples.\n",
            "\n",
            "\n",
            "=== HTML smuggling ===\n",
            "HTML files can carry payloads concealed as benign, inert data in order to defeat content filters. These payloads can be reconstructed on the other side of the filter.HTML smuggling allows an attacker to \"smuggle\" a malicious code inside a particular HTML or web page.\n",
            "\n",
            "\n",
            "== Information security culture ==\n",
            "Employee behavior can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness toward information security within an organization. Information security culture is the \"...totality of patterns of behavior in an organization that contributes to the protection of information of all kinds.\"Andersson and Reimers (2014) found that employees often do not see themselves as part of their organization's information security effort and often take actions that impede organizational changes. Indeed, the Verizon Data Breach Investigations Report 2020, which examined 3,950 security breaches, discovered 30% of cybersecurity incidents involved internal actors within a company. Research shows information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change\", authors commented, \"It's a never-ending process, a cycle of evaluation and change or maintenance.\" To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\n",
            "Pre-evaluation: To identify the awareness of information security within employees and to analyze the current security policies.\n",
            "Strategic planning: To come up with a better awareness program, clear targets need to be set. Assembling a team of skilled professionals is helpful to achieve it.\n",
            "Operative planning: A good security culture can be established based on internal communication, management buy-in, security awareness and a training program.\n",
            "Implementation: Four stages should be used to implement the information security culture. They are:Commitment of the management\n",
            "Communication with organizational members\n",
            "Courses for all organizational members\n",
            "Commitment of the employeesPost-evaluation: To assess the success of the planning and implementation, and to identify unresolved areas of concern.\n",
            "\n",
            "\n",
            "== Computer protection (countermeasures) ==\n",
            "In computer security, a countermeasure is an action, device, procedure or technique that reduces a threat, a vulnerability, or an attack by eliminating or preventing it, by minimizing the harm it can cause, or by discovering and reporting it so that corrective action can be taken.Some common countermeasures are listed in the following sections:\n",
            "\n",
            "\n",
            "=== Security by design ===\n",
            "\n",
            "Security by design, or alternately secure by design, means that the software has been designed from the ground up to be secure. In this case, security is considered a main feature.\n",
            "Some of the techniques in this approach include:\n",
            "\n",
            "The principle of least privilege, where each part of the system has only the privileges that are needed for its function. That way, even if an attacker gains access to that part, they only have limited access to the whole system.\n",
            "Automated theorem proving to prove the correctness of crucial software subsystems.\n",
            "Code reviews and unit testing, approaches to make modules more secure where formal correctness proofs are not possible.\n",
            "Defense in depth, where the design is such that more than one subsystem needs to be violated to compromise the integrity of the system and the information it holds.\n",
            "Default secure settings, and design to fail secure rather than fail insecure (see fail-safe for the equivalent in safety engineering). Ideally, a secure system should require a deliberate, conscious, knowledgeable and free decision on the part of legitimate authorities in order to make it insecure.\n",
            "Audit trails track system activity so that when a security breach occurs, the mechanism and extent of the breach can be determined. Storing audit trails remotely, where they can only be appended to, can keep intruders from covering their tracks.\n",
            "Full disclosure of all vulnerabilities, to ensure that the window of vulnerability is kept as short as possible when bugs are discovered.\n",
            "\n",
            "\n",
            "=== Security architecture ===\n",
            "The Open Security Architecture organization defines IT security architecture as \"the design artifacts that describe how the security controls (security countermeasures) are positioned, and how they relate to the overall information technology architecture. These controls serve the purpose to maintain the system's quality attributes: confidentiality, integrity, availability, accountability and assurance services\".Techopedia defines security architecture as \"a unified security design that addresses the necessities and potential risks involved in a certain scenario or environment. It also specifies when and where to apply security controls. The design process is generally reproducible.\" The key attributes of security architecture are:\n",
            "the relationship of different components and how they depend on each other.\n",
            "determination of controls based on risk assessment, good practices, finances, and legal matters.\n",
            "the standardization of controls.Practicing security architecture provides the right foundation to systematically address business, IT and security concerns in an organization.\n",
            "\n",
            "\n",
            "=== Security measures ===\n",
            "A state of computer security is the conceptual ideal, attained by the use of the three processes: threat prevention, detection, and response. These processes are based on various policies and system components, which include the following:\n",
            "\n",
            "User account access controls and cryptography can protect systems files and data, respectively.\n",
            "Firewalls are by far the most common prevention systems from a network security perspective as they can (if properly configured) shield access to internal network services, and block certain kinds of attacks through packet filtering. Firewalls can be both hardware and software-based.\n",
            "Intrusion Detection System (IDS) products are designed to detect network attacks in-progress and assist in post-attack forensics, while audit trails and logs serve a similar function for individual systems.\n",
            "Response is necessarily defined by the assessed security requirements of an individual system and may cover the range from simple upgrade of protections to notification of legal authorities, counter-attacks, and the like. In some special cases, the complete destruction of the compromised system is favored, as it may happen that not all the compromised resources are detected.\n",
            "Cyber security awareness training to cope with cyber threats and attacks.\n",
            "Forward web proxy solutions can prevent the client to visit malicious web pages and inspect the content before downloading to the client machines.Today, computer security consists mainly of preventive measures, like firewalls or an exit procedure. A firewall can be defined as a way of filtering network data between a host or a network and another network, such as the Internet, and can be implemented as software running on the machine, hooking into the network stack (or, in the case of most UNIX-based operating systems such as Linux, built into the operating system kernel) to provide real-time filtering and blocking. Another implementation is a so-called physical firewall, which consists of a separate machine filtering network traffic. Firewalls are common amongst machines that are permanently connected to the Internet.\n",
            "Some organizations are turning to big data platforms, such as Apache Hadoop, to extend data accessibility and machine learning to detect advanced persistent threats.However, relatively few organizations maintain computer systems with effective detection systems, and fewer still have organized response mechanisms in place. As a result, as Reuters pointed out in 2010: \"Companies for the first time report they are losing more through electronic theft of data than physical stealing of assets\".In order to ensure adequate security, the confidentiality, integrity and availability of a network, better known as the CIA triad, must be protected and is considered the foundation to information security. To achieve those objectives, administrative, physical and technical security measures should be employed. The amount of security afforded to an asset can only be determined when its value is known.\n",
            "\n",
            "\n",
            "=== Vulnerability management ===\n",
            "\n",
            "Vulnerability management is the cycle of identifying, remediating or mitigating vulnerabilities, especially in software and firmware. Vulnerability management is integral to computer security and network security.\n",
            "Vulnerabilities can be discovered with a vulnerability scanner, which analyzes a computer system in search of known vulnerabilities, such as open ports, insecure software configuration, and susceptibility to malware.  In order for these tools to be effective, they must be kept up to date with every new update the vendor release.  Typically, these updates will scan for the new vulnerabilities that were introduced recently.\n",
            "Beyond vulnerability scanning, many organizations contract outside security auditors to run regular penetration tests against their systems to identify vulnerabilities. In some sectors, this is a contractual requirement.\n",
            "\n",
            "\n",
            "=== Reducing vulnerabilities ===\n",
            "Information technology security assessment aims to assess systems for risk and to predict and test for their vulnerabilities.\n",
            "While formal verification of the correctness of computer systems is possible, it is not yet common. Operating systems formally verified include seL4, and SYSGO's PikeOS – but these make up a very small percentage of the market.\n",
            "Two factor authentication is a method for mitigating unauthorized access to a system or sensitive information. It requires something you know; a password or PIN, and something you have; a card, dongle, cellphone, or another piece of hardware. This increases security as an unauthorized person needs both of these to gain access.\n",
            "Social engineering and direct computer access (physical) attacks can only be prevented by non-computer means, which can be difficult to enforce, relative to the sensitivity of the information. Training is often involved to help mitigate this risk, but even in highly disciplined environments (e.g. military organizations), social engineering attacks can still be difficult to foresee and prevent.\n",
            "Inoculation, derived from inoculation theory, seeks to prevent social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.It is possible to reduce an attacker's chances by keeping systems up to date with security patches and updates, using a security scanner and/or hiring people with expertise in security, though none of these guarantee the prevention of an attack. The effects of data loss/damage can be reduced by careful backing up and insurance.\n",
            "\n",
            "\n",
            "=== Hardware protection mechanisms ===\n",
            "\n",
            "While hardware may be a source of insecurity, such as with microchip vulnerabilities maliciously introduced during the manufacturing process, hardware-based or assisted computer security also offers an alternative to software-only computer security. Using devices and methods such as dongles, trusted platform modules, intrusion-aware cases, drive locks, disabling USB ports, and mobile-enabled access may be considered more secure due to the physical access (or sophisticated backdoor access) required in order to be compromised. Each of these is covered in more detail below.\n",
            "\n",
            "USB dongles are typically used in software licensing schemes to unlock software capabilities, but they can also be seen as a way to prevent unauthorized access to a computer or other device's software. The dongle, or key, essentially creates a secure encrypted tunnel between the software application and the key. The principle is that an encryption scheme on the dongle, such as Advanced Encryption Standard (AES) provides a stronger measure of security since it is harder to hack and replicate the dongle than to simply copy the native software to another machine and use it. Another security application for dongles is to use them for accessing web-based content such as cloud software or Virtual Private Networks (VPNs). In addition, a USB dongle can be configured to lock or unlock a computer.\n",
            "Trusted platform modules (TPMs) secure devices by integrating cryptographic capabilities onto access devices, through the use of microprocessors, or so-called computers-on-a-chip. TPMs used in conjunction with server-side software offer a way to detect and authenticate hardware devices, preventing unauthorized network and data access.\n",
            "Computer case intrusion detection refers to a device, typically a push-button switch, which detects when a computer case is opened. The firmware or BIOS is programmed to show an alert to the operator when the computer is booted up the next time.\n",
            "Drive locks are essentially software tools to encrypt hard drives, making them inaccessible to thieves. Tools exist specifically for encrypting external drives as well.\n",
            "Disabling USB ports is a security option for preventing unauthorized and malicious access to an otherwise secure computer. Infected USB dongles connected to a network from a computer inside the firewall are considered by the magazine Network World as the most common hardware threat facing computer networks.\n",
            "Disconnecting or disabling peripheral devices ( like camera, GPS, removable storage etc.), that are not in use.\n",
            "Mobile-enabled access devices are growing in popularity due to the ubiquitous nature of cell phones. Built-in capabilities such as Bluetooth, the newer Bluetooth low energy (LE), near-field communication (NFC) on non-iOS devices and biometric validation such as thumbprint readers, as well as QR code reader software designed for mobile devices, offer new, secure ways for mobile phones to connect to access control systems. These control systems provide computer security and can also be used for controlling access to secure buildings.\n",
            "IOMMUs allow for hardware-based sandboxing of components in mobile and desktop computers by utilizing direct memory access protections.\n",
            "Physical Unclonable Functions (PUFs) can be used as a digital fingerprint or a unique identifier to integrated circuits and hardware, providing users the ability to secure the hardware supply chains going into their systems.\n",
            "\n",
            "\n",
            "=== Secure operating systems ===\n",
            "\n",
            "One use of the term computer security refers to technology that is used to implement secure operating systems. In the 1980s, the United States Department of Defense (DoD) used the \"Orange Book\" standards, but the current international standard ISO/IEC 15408, Common Criteria defines a number of progressively more stringent Evaluation Assurance Levels. Many common operating systems meet the EAL4 standard of being \"Methodically Designed, Tested and Reviewed\", but the formal verification required for the highest levels means that they are uncommon. An example of an EAL6 (\"Semiformally Verified Design and Tested\") system is INTEGRITY-178B, which is used in the Airbus A380\n",
            "and several military jets.\n",
            "\n",
            "\n",
            "=== Secure coding ===\n",
            "\n",
            "In software engineering, secure coding aims to guard against the accidental introduction of security vulnerabilities. It is also possible to create software designed from the ground up to be secure. Such systems are secure by design. Beyond this, formal verification aims to prove the correctness of the algorithms underlying a system;\n",
            "important for cryptographic protocols for example.\n",
            "\n",
            "\n",
            "=== Capabilities and access control lists ===\n",
            "\n",
            "Within computer systems, two of the main security models capable of enforcing privilege separation are access control lists (ACLs) and role-based access control (RBAC).\n",
            "An access-control list (ACL), with respect to a computer file system, is a list of permissions associated with an object. An ACL specifies which users or system processes are granted access to objects, as well as what operations are allowed on given objects.\n",
            "Role-based access control is an approach to restricting system access to authorized users,  used by the majority of enterprises with more than 500 employees, and can implement mandatory access control (MAC) or discretionary access control (DAC).\n",
            "A further approach, capability-based security has been mostly restricted to research operating systems. Capabilities can, however, also be implemented at the language level, leading to a style of programming that is essentially a refinement of standard object-oriented design. An open-source project in the area is the E language.\n",
            "\n",
            "\n",
            "=== End user security training ===\n",
            "The end-user is widely recognized as the weakest link in the security chain and it is estimated that more than 90% of security incidents and breaches involve some kind of human error. Among the most commonly recorded forms of errors and misjudgment are poor password management, sending emails containing sensitive data and attachments to the wrong recipient, the inability to recognize misleading URLs and to identify fake websites and dangerous email attachments.  A common mistake that users make is saving their user id/password in their browsers to make it easier to log in to banking sites.  This is a gift to attackers who have obtained access to a machine by some means.  The risk may be mitigated by the use of two-factor authentication.As the human component of cyber risk is particularly relevant in determining the global cyber risk an organization is facing, security awareness training, at all levels, not only provides formal compliance with regulatory and industry mandates but is considered essential in reducing cyber risk and protecting individuals and companies from the great majority of cyber threats.\n",
            "The focus on the end-user represents a profound cultural change for many security practitioners, who have traditionally approached cybersecurity exclusively from a technical perspective, and moves along the lines suggested by major security centers to develop a culture of cyber awareness within the organization, recognizing that a security-aware user provides an important line of defense against cyber attacks.\n",
            "\n",
            "\n",
            "=== Digital hygiene ===\n",
            "Related to end-user training, digital hygiene or cyber hygiene is a fundamental principle relating to information security and, as the analogy with personal hygiene shows, is the equivalent of establishing simple routine measures to minimize the risks from cyber threats. The assumption is that good cyber hygiene practices can give networked users another layer of protection, reducing the risk that one vulnerable node will be used to either mount attacks or compromise another node or network, especially from common cyberattacks. Cyber hygiene should also not be mistaken for proactive cyber defence, a military term.As opposed to a purely technology-based defense against threats, cyber hygiene mostly regards routine measures that are technically simple to implement and mostly dependent on discipline or education. It can be thought of as an abstract list of tips or measures that have been demonstrated as having a positive effect on personal and/or collective digital security. As such, these measures can be performed by laypeople, not just security experts.\n",
            "Cyber hygiene relates to personal hygiene as computer viruses relate to biological viruses (or pathogens). However, while the term computer virus was coined almost simultaneously with the creation of the first working computer viruses, the term cyber hygiene is a much later invention, perhaps as late as 2000 by Internet pioneer Vint Cerf. It has since been adopted by the Congress and Senate of the United States, the FBI, EU institutions and heads of state.\n",
            "\n",
            "\n",
            "=== Difficulty of responding to breaches ===\n",
            "Responding to attempted security breaches is often very difficult for a variety of reasons, including:\n",
            "\n",
            "Identifying attackers is difficult, as they may operate through proxies, temporary anonymous dial-up accounts, wireless connections, and other anonymizing procedures which make back-tracing difficult -  and are often located in another jurisdiction. If they successfully breach security, they have also often gained enough administrative access to enable them to delete logs to cover their tracks.\n",
            "The sheer number of attempted attacks, often by automated vulnerability scanners and computer worms, is so large that organizations cannot spend time pursuing each.\n",
            "Law enforcement officers often lack the skills, interest or budget to pursue attackers. In addition, the identification of attackers across a network may require logs from various points in the network and in many countries, which may be difficult or time-consuming to obtain.Where an attack succeeds and a breach occurs, many jurisdictions now have in place mandatory security breach notification laws.\n",
            "\n",
            "\n",
            "=== Types of security and privacy ===\n",
            "\n",
            "\n",
            "== Systems at risk ==\n",
            "The growth in the number of computer systems and the increasing reliance upon them by individuals, businesses, industries, and governments means that there are an increasing number of systems at risk.\n",
            "\n",
            "\n",
            "=== Financial systems ===\n",
            "The computer systems of financial regulators and financial institutions like the U.S. Securities and Exchange Commission, SWIFT, investment banks, and commercial banks are prominent hacking targets for cybercriminals interested in manipulating markets and making illicit gains. Websites and apps that accept or store credit card numbers, brokerage accounts, and bank account information are also prominent hacking targets, because of the potential for immediate financial gain from transferring money, making purchases, or selling the information on the black market. In-store payment systems and ATMs have also been tampered with in order to gather customer account data and PINs.\n",
            "The UCLA Internet Report: Surveying the Digital Future (2000) found that the privacy of personal data created barriers to online sales and that more than nine out of 10 internet users were somewhat or very concerned about credit card security.The most common web technologies for improving security between browsers and websites are named SSL (Secure Sockets Layer), and its successor TLS (Transport Layer Security), identity management and authentication services, and domain name services allow companies and consumers to engage in secure communications and commerce. Several versions of SSL and TLS are commonly used today in applications such as web browsing, e-mail, internet faxing, instant messaging, and VoIP (voice-over-IP). There are various interoperable implementations of these technologies, including at least one implementation that is  open source. Open source allows anyone to view the application's source code, and look for and report vulnerabilities.\n",
            "The credit card companies Visa and MasterCard cooperated to develop the secure EMV chip which is embedded in credit cards. Further developments include the Chip Authentication Program where banks give customers hand-held card readers to perform online secure transactions. Other developments in this arena include the development of technology such as Instant Issuance which has enabled shopping mall kiosks acting on behalf of banks to issue on-the-spot credit cards to interested customers.\n",
            "\n",
            "\n",
            "=== Utilities and industrial equipment ===\n",
            "Computers control functions at many utilities, including coordination of telecommunications, the power grid, nuclear power plants, and valve opening and closing in water and gas networks. The Internet is a potential attack vector for such machines if connected, but the Stuxnet worm demonstrated that even equipment controlled by computers not connected to the Internet can be vulnerable. In 2014, the Computer Emergency Readiness Team, a division of the Department of Homeland Security, investigated 79 hacking incidents at energy companies.\n",
            "\n",
            "\n",
            "=== Aviation ===\n",
            "The aviation industry is very reliant on a series of complex systems which could be attacked. A simple power outage at one airport can cause repercussions worldwide, much of the system relies on radio transmissions which could be disrupted, and controlling aircraft over oceans is especially dangerous because radar surveillance only extends 175 to 225 miles offshore. There is also potential for attack from within an aircraft.In Europe, with the (Pan-European Network Service) and NewPENS, and in the US with the NextGen program, air navigation service providers are moving to create their own dedicated networks.\n",
            "Many modern passports are now biometric passports, containing an embedded microchip that stores a digitized photograph and personal information such as name, gender, and date of birth. In addition, more countries are introducing facial recognition technology to reduce identity-related fraud. The introduction of the ePassport has assisted border officials in verifying the identity of the passport holder, thus allowing for quick passenger processing. Plans are under way in the US, the UK, and Australia to introduce SmartGate kiosks with both retina and fingerprint recognition technology. The airline industry is moving from the use of traditional paper tickets towards the use of electronic tickets (e-tickets). These have been made possible by advances in online credit card transactions in partnership with the airlines. Long-distance bus companies are also switching over to e-ticketing transactions today.\n",
            "The consequences of a successful attack range from loss of confidentiality to loss of system integrity, air traffic control outages, loss of aircraft, and even loss of life.\n",
            "\n",
            "\n",
            "=== Consumer devices ===\n",
            "Desktop computers and laptops are commonly targeted to gather passwords or financial account information or to construct a botnet to attack another target. Smartphones, tablet computers, smart watches, and other mobile devices such as quantified self devices like activity trackers have sensors such as cameras, microphones, GPS receivers, compasses, and accelerometers which could be exploited, and may collect personal information, including sensitive health information. WiFi, Bluetooth, and cell phone networks on any of these devices could be used as attack vectors, and sensors might be remotely activated after a successful breach.The increasing number of home automation devices such as the Nest thermostat are also potential targets.\n",
            "\n",
            "\n",
            "=== Healthcare ===\n",
            "Today many health-care providers and health insurance companies use the internet to provide enhanced products and services, for example through use of tele-health to potentially offer better quality and access to healthcare, or fitness trackers to lower insurance premiums.\n",
            "The health care company Humana partners with WebMD, Oracle Corporation, EDS and Microsoft to enable its members to access their health care records, as well as to provide an overview of health care plans. Patient records are increasingly being placed on secure in-house networks, alleviating the need for extra storage space.\n",
            "\n",
            "\n",
            "=== Large corporations ===\n",
            "Large corporations are common targets. In many cases attacks are aimed at financial gain through identity theft and involve data breaches. Examples include the loss of millions of clients' credit card and financial details by Home Depot, Staples, Target Corporation, and Equifax.Medical records have been targeted in general identify theft, health insurance fraud, and impersonating patients to obtain prescription drugs for recreational purposes or resale. Although cyber threats continue to increase, 62% of all organizations did not increase security training for their business in 2015.Not all attacks are financially motivated, however: security firm HBGary Federal had a serious series of attacks in 2011 from hacktivist group Anonymous in retaliation for the firm's CEO claiming to have infiltrated their group, and Sony Pictures was hacked in 2014 with the apparent dual motive of embarrassing the company through data leaks and crippling the company by wiping workstations and servers.\n",
            "\n",
            "\n",
            "=== Automobiles ===\n",
            "\n",
            "Vehicles are increasingly computerized, with engine timing, cruise control, anti-lock brakes, seat belt tensioners, door locks, airbags and advanced driver-assistance systems on many models. Additionally, connected cars may use WiFi and Bluetooth to communicate with onboard consumer devices and the cell phone network. Self-driving cars are expected to be even more complex. All of these systems carry some security risks, and such issues have gained wide attention.Simple examples of risk include a malicious compact disc being used as an attack vector, and the car's onboard microphones being used for eavesdropping. However, if access is gained to a car's internal controller area network, the danger is much greater – and in a widely publicized 2015 test, hackers remotely carjacked a vehicle from 10 miles away and drove it into a ditch.Manufacturers are reacting in numerous ways, with Tesla in 2016 pushing out some security fixes over the air into its cars' computer systems. In the area of autonomous vehicles, in September 2016 the United States Department of Transportation announced some initial safety standards, and called for states to come up with uniform policies.Additionally, e-Drivers’ licenses are being developed using the same technology. For example, Mexico’s licensing authority (ICV) has used a smart card platform to issue the first e-Drivers’ licenses to the city of Monterrey, in the state of Nuevo León.\n",
            "\n",
            "\n",
            "=== Shipping ===\n",
            "Shipping companies have adopted RFID (Radio Frequency Identification) technology as an efficient, digitally secure, tracking device. Unlike a barcode, RFID can be read up to 20 feet away. RFID is used by FedEx and UPS.\n",
            "\n",
            "\n",
            "=== Government ===\n",
            "Government and military computer systems are commonly attacked by activists and foreign powers. Local and regional government infrastructure such as traffic light controls, police and intelligence agency communications, personnel records, as well as student records.The FBI, CIA, and Pentagon, all utilize secure controlled access technology for any of their buildings. However, the use of this form of technology is spreading into the entrepreneurial world. More and more companies are taking advantage of the development of digitally secure controlled access technology. GE's ACUVision, for example, offers a single panel platform for access control, alarm monitoring and digital recording.\n",
            "\n",
            "\n",
            "=== Internet of things and physical vulnerabilities ===\n",
            "The Internet of things (IoT) is the network of physical objects such as devices, vehicles, and buildings that are embedded with electronics, software, sensors, and network connectivity that enables them to collect and exchange data. Concerns have been raised that this is being developed without appropriate consideration of the security challenges involved.While the IoT creates opportunities for more direct integration of the physical world into computer-based systems,\n",
            "it also provides opportunities for misuse. In particular, as the Internet of Things spreads widely, cyberattacks are likely to become an increasingly physical (rather than simply virtual) threat. If a front door's lock is connected to the Internet, and can be locked/unlocked from a phone, then a criminal could enter the home at the press of a button from a stolen or hacked phone. People could stand to lose much more than their credit card numbers in a world controlled by IoT-enabled devices. Thieves have also used electronic means to circumvent non-Internet-connected hotel door locks.An attack that targets physical infrastructure and/or human lives is sometimes referred to as a cyber-kinetic attack. As IoT devices and appliances gain currency, cyber-kinetic attacks can become pervasive and significantly damaging.\n",
            "\n",
            "\n",
            "=== Medical systems ===\n",
            "\n",
            "Medical devices have either been successfully attacked or had potentially deadly vulnerabilities demonstrated, including both in-hospital diagnostic equipment and implanted devices including pacemakers and insulin pumps. There are many reports of hospitals and hospital organizations getting hacked, including ransomware attacks, Windows XP exploits, viruses, and data breaches of sensitive data stored on hospital servers. On 28 December 2016 the US Food and Drug Administration released its recommendations for how medical device manufacturers should maintain the security of Internet-connected devices – but no structure for enforcement.\n",
            "\n",
            "\n",
            "=== Energy sector ===\n",
            "In distributed generation systems, the risk of a cyber attack is real, according to Daily Energy Insider. An attack could cause a loss of power in a large area for a long period of time, and such an attack could have just as severe consequences as a natural disaster. The District of Columbia is considering creating a Distributed Energy Resources (DER) Authority within the city, with the goal being for customers to have more insight into their own energy use and giving the local electric utility, Pepco, the chance to better estimate energy demand. The D.C. proposal, however, would \"allow third-party vendors to create numerous points of energy distribution, which could potentially create more opportunities for cyber attackers to threaten the electric grid.\"\n",
            "\n",
            "\n",
            "=== Telecommunications ===\n",
            "Perhaps the most widely known digitally secure telecommunication device is the SIM (Subscriber Identity Module) card, a device that is embedded in most of the world’s cellular devices before any service can be obtained. The SIM card is just the beginning of this digitally secure environment.\n",
            "The Smart Card Web Servers draft standard (SCWS) defines the interfaces to an HTTP server in a smart card. Tests are being conducted to secure OTA (\"over-the-air\") payment and credit card information from and to a mobile phone. \n",
            "Combination SIM/DVD devices are being developed through Smart Video Card technology which embeds a DVD-compliant optical disc into the card body of a regular SIM card.\n",
            "Other telecommunication developments involving digital security include mobile signatures, which use the embedded SIM card to generate a legally binding electronic signature.\n",
            "\n",
            "\n",
            "== Cost and impact of security breaches ==\n",
            "Serious financial damage has been caused by security breaches, but because there is no standard model for estimating the cost of an incident, the only data available is that which is made public by the organizations involved. \"Several computer security consulting firms produce estimates of total worldwide losses attributable to virus and worm attacks and to hostile digital acts in general. The 2003 loss estimates by these firms range from $13 billion (worms and viruses only) to $226 billion (for all forms of covert attacks). The reliability of these estimates is often challenged; the underlying methodology is basically anecdotal.\"However, reasonable estimates of the financial cost of security breaches can actually help organizations make rational investment decisions. According to the classic Gordon-Loeb Model analyzing the optimal investment level in information security, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber/information security breach).\n",
            "\n",
            "\n",
            "== Attacker motivation ==\n",
            "As with physical security, the motivations for breaches of computer security vary between attackers. Some are thrill-seekers or vandals, some are activists, others are criminals looking for financial gain. State-sponsored attackers are now common and well resourced but started with amateurs such as Markus Hess who hacked for the KGB, as recounted by Clifford Stoll in The Cuckoo's Egg.\n",
            "Attackers motivations can vary for all types of attacks from pleasure to for political goals. For example, \"hacktivists\" may target a company a company or organisation that carries out activities they do not agree with. This would be to create bad publicity for the company by having its website crash. \n",
            "High capability hackers, often with larger backing or state sponsorship, may attack based on the demands of their financial backers. These attacks are more likely to attempt more serious attack. An example of a more serious attack was the 2015 Ukraine power grid hack, which reportedly utilised the spear-phising, destruction of files, and denial-of-service attacks to carry out the full attack.Additionally, recent attacker motivations can be traced back to extremist organizations seeking to gain political advantage or disrupt social agendas. The growth of the internet, mobile technologies, and inexpensive computing devices have led to a rise in capabilities but also to the risk to environments that are deemed as vital to operations. All critical targeted environments are susceptible to compromise and this has led to a series of proactive studies on how to migrate the risk by taking into consideration motivations by these types of actors. Several stark differences exist between the hacker motivation and that of nation state actors seeking to attack based on an ideological preference.A standard part of threat modeling for any particular system is to identify what might motivate an attack on that system, and who might be motivated to breach it. The level and detail of precautions will vary depending on the system to be secured. A home personal computer, bank, and classified military network face very different threats, even when the underlying technologies in use are similar.\n",
            "\n",
            "\n",
            "== Computer security incident management ==\n",
            "Computer security incident management is an organized approach to addressing and managing the aftermath of a computer security incident or compromise with the goal of preventing a breach or thwarting a cyberattack. An incident that is not identified and managed at the time of intrusion typically escalates to a more damaging event such as a data breach or system failure. The intended outcome of a computer security incident response plan is to contain the incident, limit damage and assist recovery to business as usual. Responding to compromises quickly can mitigate exploited vulnerabilities, restore services and processes and minimize losses.\n",
            "Incident response planning allows an organization to establish a series of best practices to stop an intrusion before it causes damage. Typical incident response plans contain a set of written instructions that outline the organization's response to a cyberattack. Without a documented plan in place, an organization may not successfully detect an intrusion or compromise and stakeholders may not understand their roles, processes and procedures during an escalation, slowing the organization's response and resolution.\n",
            "There are four key components of a computer security incident response plan:\n",
            "\n",
            "Preparation: Preparing stakeholders on the procedures for handling computer security incidents or compromises\n",
            "Detection and analysis: Identifying and investigating suspicious activity to confirm a security incident, prioritizing the response based on impact and coordinating notification of the incident\n",
            "Containment, eradication and recovery: Isolating affected systems to prevent escalation and limit impact, pinpointing the genesis of the incident, removing malware, affected systems and bad actors from the environment and restoring systems and data when a threat no longer remains\n",
            "Post incident activity: Post mortem analysis of the incident, its root cause and the organization's response with the intent of improving the incident response plan and future response efforts.\n",
            "\n",
            "\n",
            "== Notable attacks and breaches ==\n",
            "\n",
            "Some illustrative examples of different types of computer security breaches are given below.\n",
            "\n",
            "\n",
            "=== Robert Morris and the first computer worm ===\n",
            "\n",
            "In 1988, 60,000 computers were connected to the Internet, and most were mainframes, minicomputers and professional workstations. On 2 November 1988, many started to slow down, because they were running a malicious code that demanded processor time and that spread itself to other computers – the first internet computer worm. The software was traced back to 23-year-old Cornell University graduate student Robert Tappan Morris who said \"he wanted to count how many machines were connected to the Internet\".\n",
            "\n",
            "\n",
            "=== Rome Laboratory ===\n",
            "In 1994, over a hundred intrusions were made by unidentified crackers into the Rome Laboratory, the US Air Force's main command and research facility. Using trojan horses, hackers were able to obtain unrestricted access to Rome's networking systems and remove traces of their activities. The intruders were able to obtain classified files, such as air tasking order systems data and furthermore able to penetrate connected networks of National Aeronautics and Space Administration's Goddard Space Flight Center, Wright-Patterson Air Force Base, some Defense contractors, and other private sector organizations, by posing as a trusted Rome center user.\n",
            "\n",
            "\n",
            "=== TJX customer credit card details ===\n",
            "In early 2007, American apparel and home goods company TJX announced that it was the victim of an unauthorized computer systems intrusion and that the hackers had accessed a system that stored data on credit card, debit card, check, and merchandise return transactions.\n",
            "\n",
            "\n",
            "=== Stuxnet attack ===\n",
            "In 2010, the computer worm known as Stuxnet reportedly ruined almost one-fifth of Iran's nuclear centrifuges. It did so by disrupting industrial programmable logic controllers (PLCs) in a targeted attack. This is generally believed to have been launched by Israel and the United States to disrupt Iran's nuclear program – although neither has publicly admitted this.\n",
            "\n",
            "\n",
            "=== Global surveillance disclosures ===\n",
            "\n",
            "In early 2013, documents provided by Edward Snowden were published by The Washington Post and The Guardian exposing the massive scale of NSA global surveillance. There were also indications that the NSA may have inserted a backdoor in a NIST standard for encryption. This standard was later withdrawn due to widespread criticism. The NSA additionally were revealed to have tapped the links between Google's data centers.\n",
            "\n",
            "\n",
            "=== Target and Home Depot breaches ===\n",
            "A Ukrainian hacker known as Rescator broke into Target Corporation computers in 2013, stealing roughly 40 million credit cards, and then Home Depot computers in 2014, stealing between 53 and 56 million credit card numbers. Warnings were delivered at both corporations, but ignored; physical security breaches using self checkout machines are believed to have played a large role. \"The malware utilized is absolutely unsophisticated and uninteresting,\" says Jim Walter, director of threat intelligence operations at security technology company McAfee – meaning that the heists could have easily been stopped by existing antivirus software had administrators responded to the warnings. The size of the thefts has resulted in major attention from state and Federal United States authorities and the investigation is ongoing.\n",
            "\n",
            "\n",
            "=== Office of Personnel Management data breach ===\n",
            "In April 2015, the Office of Personnel Management discovered it had been hacked more than a year earlier in a data breach, resulting in the theft of approximately 21.5 million personnel records handled by the office. The Office of Personnel Management hack has been described by federal officials as among the largest breaches of government data in the history of the United States. Data targeted in the breach included personally identifiable information such as Social Security numbers, names, dates and places of birth, addresses, and fingerprints of current and former government employees as well as anyone who had undergone a government background check. It is believed the hack was perpetrated by Chinese hackers.\n",
            "\n",
            "\n",
            "=== Ashley Madison breach ===\n",
            "\n",
            "In July 2015, a hacker group is known as The Impact Team successfully breached the extramarital relationship website Ashley Madison, created by Avid Life Media. The group claimed that they had taken not only company data but user data as well. After the breach, The Impact Team dumped emails from the company's CEO, to prove their point, and threatened to dump customer data unless the website was taken down permanently. When Avid Life Media did not take the site offline the group released two more compressed files, one 9.7GB and the second 20GB. After the second data dump, Avid Life Media CEO Noel Biderman resigned; but the website remained to function.\n",
            "\n",
            "\n",
            "=== Colonial Pipeline ransomware attack ===\n",
            "\n",
            "In June 2021, the cyber attack took down the largest fuel pipeline in the U.S. and led to shortages across the East Coast.\n",
            "\n",
            "\n",
            "== Legal issues and global regulation ==\n",
            "International legal issues of cyber attacks are complicated in nature. There is no global base of common rules to judge, and eventually punish, cybercrimes and cybercriminals - and where security firms or agencies do locate the cybercriminal behind the creation of a particular piece of malware or form of cyber attack, often the local authorities cannot take action due to lack of laws under which to prosecute. Proving attribution for cybercrimes and cyberattacks is also a major problem for all law enforcement agencies. \"Computer viruses switch from one country to another, from one jurisdiction to another – moving around the world, using the fact that we don't have the capability to globally police operations like this. So the Internet is as if someone [had] given free plane tickets to all the online criminals of the world.\" The use of techniques such as dynamic DNS, fast flux and bullet proof servers add to the difficulty of investigation and enforcement.\n",
            "\n",
            "\n",
            "== Role of government ==\n",
            "The role of the government is to make regulations to force companies and organizations to protect their systems, infrastructure and information from any cyberattacks, but also to protect its own national infrastructure such as the national power-grid.The government's regulatory role in cyberspace is complicated. For some, cyberspace was seen as a virtual space that was to remain free of government intervention, as can be seen in many of today's libertarian blockchain and bitcoin discussions.Many government officials and experts think that the government should do more and that there is a crucial need for improved regulation, mainly due to the failure of the private sector to solve efficiently the cybersecurity problem. R. Clarke said during a panel discussion at the RSA Security Conference in San Francisco, he believes that the \"industry only responds when you threaten regulation. If the industry doesn't respond (to the threat), you have to follow through.\" On the other hand, executives from the private sector agree that improvements are necessary, but think that government intervention would affect their ability to innovate efficiently. Daniel R. McCarthy analyzed this public-private partnership in cybersecurity and reflected on the role of cybersecurity in the broader constitution of political order.On 22 May 2020, the UN Security Council held its second ever informal meeting on cybersecurity to focus on cyber challenges to international peace. According to UN Secretary-General António Guterres, new technologies are too often used to violate rights.\n",
            "\n",
            "\n",
            "== International actions ==\n",
            "Many different teams and organizations exist, including:\n",
            "\n",
            "The Forum of Incident Response and Security Teams (FIRST) is the global association of CSIRTs. The US-CERT, AT&T, Apple, Cisco, McAfee, Microsoft are all members of this international team.\n",
            "The Council of Europe helps protect societies worldwide from the threat of cybercrime through the Convention on Cybercrime.\n",
            "The purpose of the Messaging Anti-Abuse Working Group (MAAWG) is to bring the messaging industry together to work collaboratively and to successfully address the various forms of messaging abuse, such as spam, viruses, denial-of-service attacks and other messaging exploitations. France Telecom, Facebook, AT&T, Apple, Cisco, Sprint are some of the members of the MAAWG.\n",
            "ENISA : The European Network and Information Security Agency (ENISA) is an agency of the European Union with the objective to improve network and information security in the European Union.\n",
            "\n",
            "\n",
            "=== Europe ===\n",
            "On 14 April 2016, the European Parliament and the Council of the European Union adopted the General Data Protection Regulation (GDPR). The GDPR, which came into force on 25 May 2018, grants individuals within the European Union (EU) and the European Economic Area (EEA) the right to the protection of personal data. The regulation requires that any entity that processes personal data incorporate data protection by design and by default. It also requires that certain organizations appoint a Data Protection Officer (DPO).\n",
            "\n",
            "\n",
            "== National actions ==\n",
            "\n",
            "\n",
            "=== Computer emergency response teams ===\n",
            "\n",
            "Most countries have their own computer emergency response team to protect network security.\n",
            "\n",
            "\n",
            "==== Canada ====\n",
            "Since 2010, Canada has had a cybersecurity strategy. This functions as a counterpart document to the National Strategy and Action Plan for Critical Infrastructure. The strategy has three main pillars: securing government systems, securing vital private cyber systems, and helping Canadians to be secure online. There is also a Cyber Incident Management Framework to provide a coordinated response in the event of a cyber incident.The Canadian Cyber Incident Response Centre (CCIRC) is responsible for mitigating and responding to threats to Canada's critical infrastructure and cyber systems. It provides support to mitigate cyber threats, technical support to respond & recover from targeted cyber attacks, and provides online tools for members of Canada's critical infrastructure sectors. It posts regular cybersecurity bulletins & operates an online reporting tool where individuals and organizations can report a cyber incident.To inform the general public on how to protect themselves online, Public Safety Canada has partnered with STOP.THINK.CONNECT, a coalition of non-profit, private sector, and government organizations, and launched the Cyber Security Cooperation Program. They also run the GetCyberSafe portal for Canadian citizens, and Cyber Security Awareness Month during October.Public Safety Canada aims to begin an evaluation of Canada's cybersecurity strategy in early 2015.\n",
            "\n",
            "\n",
            "==== China ====\n",
            "China's Central Leading Group for Internet Security and Informatization (Chinese: 中央网络安全和信息化领导小组) was established on 27 February 2014. This Leading Small Group (LSG) of the Chinese Communist Party is headed by General Secretary Xi Jinping himself and is staffed with relevant Party and state decision-makers. The LSG was created to overcome the incoherent policies and overlapping responsibilities that characterized China's former cyberspace decision-making mechanisms. The LSG oversees policy-making in the economic, political, cultural, social and military fields as they relate to network security and IT strategy. This LSG also coordinates major policy initiatives in the international arena that promote norms and standards favored by the Chinese government and that emphasizes the principle of national sovereignty in cyberspace.\n",
            "\n",
            "\n",
            "==== Germany ====\n",
            "Berlin starts National Cyber Defense Initiative: On 16 June 2011, the German Minister for Home Affairs, officially opened the new German NCAZ (National Center for Cyber Defense) Nationales Cyber-Abwehrzentrum located in Bonn. The NCAZ closely cooperates with BSI (Federal Office for Information Security) Bundesamt für Sicherheit in der Informationstechnik, BKA (Federal Police Organisation) Bundeskriminalamt (Deutschland), BND (Federal Intelligence Service) Bundesnachrichtendienst, MAD (Military Intelligence Service) Amt für den Militärischen Abschirmdienst and other national organizations in Germany taking care of national security aspects. According to the Minister, the primary task of the new organization founded on 23 February 2011, is to detect and prevent attacks against the national infrastructure and mentioned incidents like Stuxnet. Germany has also established the largest research institution for IT security in Europe, the Center for Research in Security and Privacy (CRISP) in Darmstadt.\n",
            "\n",
            "\n",
            "==== India ====\n",
            "Some provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000.The National Cyber Security Policy 2013 is a policy framework by the Ministry of Electronics and Information Technology (MeitY) which aims to protect the public and private infrastructure from cyberattacks, and safeguard \"information, such as personal information (of web users), financial and banking information and sovereign data\". CERT- In is the nodal agency which monitors the cyber threats in the country. The post of National Cyber Security Coordinator has also been created in the Prime Minister's Office (PMO).\n",
            "The Indian Companies Act 2013 has also introduced cyber law and cybersecurity obligations on the part of Indian directors. Some provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000 Update in 2013.\n",
            "\n",
            "\n",
            "==== South Korea ====\n",
            "Following cyberattacks in the first half of 2013, when the government, news media, television stations, and bank websites were compromised, the national government committed to the training of 5,000 new cybersecurity experts by 2017. The South Korean government blamed its northern counterpart for these attacks, as well as incidents that occurred in 2009, 2011, and 2012, but Pyongyang denies the accusations.\n",
            "\n",
            "\n",
            "==== United States ====\n",
            "\n",
            "\n",
            "===== Legislation =====\n",
            "The 1986 18 U.S.C. § 1030, the Computer Fraud and Abuse Act is the key legislation. It prohibits unauthorized access or damage of protected computers as defined in 18 U.S.C. § 1030(e)(2). Although various other measures have been proposed – none has succeeded.\n",
            "In 2013, executive order 13636 Improving Critical Infrastructure Cybersecurity was signed, which prompted the creation of the NIST Cybersecurity Framework.\n",
            "In response to the Colonial Pipeline ransomware attack President Joe Biden signed Executive Order 14028 on May 12, 2021, to increase software security standards for sales to the government, tighten detection and security on existing systems, improve information sharing and training, establish a Cyber Safety Review Board, and improve incident response.\n",
            "\n",
            "\n",
            "===== Standardized government testing services =====\n",
            "The General Services Administration (GSA) has standardized the penetration test service as a pre-vetted support service, to rapidly address potential vulnerabilities, and stop adversaries before they impact US federal, state and local governments. These services are commonly referred to as Highly Adaptive Cybersecurity Services (HACS).\n",
            "\n",
            "\n",
            "===== Agencies =====\n",
            "The Department of Homeland Security has a dedicated division responsible for the response system, risk management program and requirements for cybersecurity in the United States called the National Cyber Security Division. The division is home to US-CERT operations and the National Cyber Alert System. The National Cybersecurity and Communications Integration Center brings together government organizations responsible for protecting computer networks and networked infrastructure.The third priority of the FBI is to: \"Protect the United States against cyber-based attacks and high-technology crimes\", and they, along with the National White Collar Crime Center (NW3C), and the Bureau of Justice Assistance (BJA) are part of the multi-agency task force, The Internet Crime Complaint Center, also known as IC3.In addition to its own specific duties, the FBI participates alongside non-profit organizations such as InfraGard.The Computer Crime and Intellectual Property Section (CCIPS) operates in the United States Department of Justice Criminal Division. The CCIPS is in charge of investigating computer crime and intellectual property crime and is specialized in the search and seizure of digital evidence in computers and networks. In 2017, CCIPS published A Framework for a Vulnerability Disclosure Program for Online Systems to help organizations \"clearly describe authorized vulnerability disclosure and discovery conduct, thereby substantially reducing the likelihood that such described activities will result in a civil or criminal violation of law under the Computer Fraud and Abuse Act (18 U.S.C. § 1030).\"The United States Cyber Command, also known as USCYBERCOM, \"has the mission to direct, synchronize, and coordinate cyberspace planning and operations to defend and advance national interests in collaboration with domestic and international partners.\" It has no role in the protection of civilian networks.The U.S. Federal Communications Commission's role in cybersecurity is to strengthen the protection of critical communications infrastructure, to assist in maintaining the reliability of networks during disasters, to aid in swift recovery after, and to ensure that first responders have access to effective communications services.The Food and Drug Administration has issued guidance for medical devices, and the National Highway Traffic Safety Administration is concerned with automotive cybersecurity. After being criticized by the Government Accountability Office, and following successful attacks on airports and claimed attacks on airplanes, the Federal Aviation Administration has devoted funding to securing systems on board the planes of private manufacturers, and the Aircraft Communications Addressing and Reporting System. Concerns have also been raised about the future Next Generation Air Transportation System.The US Department of Defense (DoD) issued DoD Directive 8570 in 2004, supplemented by DoD Directive 8140, requiring all DoD employees and all DoD contract personnel involved in information assurance roles and activities to earn and maintain various industry Information Technology (IT) certifications in an effort to ensure that all DoD personnel involved in network infrastructure defense have minimum levels of IT industry recognized knowledge, skills and abilities (KSA). Andersson and Reimers (2019) report these certifications range from CompTIA's A+ and Security+ through the ICS2.org's CISSP, etc.\n",
            "\n",
            "\n",
            "===== Computer emergency readiness team =====\n",
            "Computer emergency response team is a name given to expert groups that handle computer security incidents. In the US, two distinct organizations exist, although they do work closely together.\n",
            "\n",
            "US-CERT: part of the National Cyber Security Division of the United States Department of Homeland Security.\n",
            "CERT/CC: created by the Defense Advanced Research Projects Agency (DARPA) and run by the Software Engineering Institute (SEI).\n",
            "\n",
            "\n",
            "== Modern warfare ==\n",
            "\n",
            "There is growing concern that cyberspace will become the next theater of warfare. As Mark Clayton from The Christian Science Monitor wrote in a 2015 article titled \"The New Cyber Arms Race\":\n",
            "\n",
            "In the future, wars will not just be fought by soldiers with guns or with planes that drop bombs. They will also be fought with the click of a mouse a half a world away that unleashes carefully weaponized computer programs that disrupt or destroy critical industries like utilities, transportation, communications, and energy. Such attacks could also disable military networks that control the movement of troops, the path of jet fighters, the command and control of warships.\n",
            "This has led to new terms such as cyberwarfare and cyberterrorism. The United States Cyber Command was created in 2009 and many other countries have similar forces.\n",
            "There are a few critical voices that question whether cybersecurity is as significant a threat as it is made out to be.\n",
            "\n",
            "\n",
            "== Careers ==\n",
            "Cybersecurity is a fast-growing field of IT concerned with reducing organizations' risk of hack or data breaches. According to research from the Enterprise Strategy Group, 46% of organizations say that they have a \"problematic shortage\" of cybersecurity skills in 2016, up from 28% in 2015. Commercial, government and non-governmental organizations all employ cybersecurity professionals. The fastest increases in demand for cybersecurity workers are in industries managing increasing volumes of consumer data such as finance, health care, and retail. However, the use of the term cybersecurity is more prevalent in government job descriptions.Typical cybersecurity job titles and descriptions include:\n",
            "\n",
            "\n",
            "=== Security analyst ===\n",
            "Analyzes and assesses vulnerabilities in the infrastructure (software, hardware, networks), investigates using available tools and countermeasures to remedy the detected vulnerabilities and recommends solutions and best practices. Analyzes and assesses damage to the data/infrastructure as a result of security incidents, examines available recovery tools and processes, and recommends solutions. Tests for compliance with security policies and procedures. May assist in the creation, implementation, or management of security solutions.\n",
            "\n",
            "\n",
            "=== Security engineer ===\n",
            "Performs security monitoring, security and data/logs analysis, and forensic analysis, to detect security incidents, and mount the incident response. Investigates and utilizes new technologies and processes to enhance security capabilities and implement improvements. May also review code or perform other security engineering methodologies.\n",
            "\n",
            "\n",
            "=== Security architect ===\n",
            "Designs a security system or major components of a security system, and may head a security design team building a new security system.\n",
            "\n",
            "\n",
            "=== Chief Information Security Officer (CISO) ===\n",
            "A high-level management position responsible for the entire information security division/staff. The position may include hands-on technical work.\n",
            "\n",
            "\n",
            "=== Chief Security Officer (CSO) ===\n",
            "A high-level management position responsible for the entire security division/staff. A newer position is now deemed needed as security risks grow.\n",
            "\n",
            "\n",
            "=== Data Protection Officer (DPO) ===\n",
            "A DPO is tasked with monitoring compliance with the UK GDPR and other data protection laws, our data protection policies, awareness-raising, training, and audits.\n",
            "\n",
            "\n",
            "=== Security Consultant/Specialist/Intelligence ===\n",
            "Broad titles that encompass any one or all of the other roles or titles tasked with protecting computers, networks, software, data or information systems against viruses, worms, spyware, malware, intrusion detection, unauthorized access, denial-of-service attacks, and an ever-increasing list of attacks by hackers acting as individuals or as part of organized crime or foreign governments.Student programs are also available for people interested in beginning a career in cybersecurity. Meanwhile, a flexible and effective option for information security professionals of all experience levels to keep studying is online security training, including webcasts. A wide range of certified courses are also available.In the United Kingdom, a nationwide set of cybersecurity forums, known as the U.K Cyber Security Forum, were established supported by the Government's cybersecurity strategy in order to encourage start-ups and innovation and to address the skills gap identified by the U.K Government.\n",
            "In Singapore, the Cyber Security Agency has issued a Singapore Operational Technology (OT) Cybersecurity Competency Framework (OTCCF). The framework defines emerging cybersecurity roles in Operational Technology. The OTCCF was endorsed by the Infocomm Media Development Authority (IMDA). It outlines the different OT cybersecurity job positions as well as the technical skills and core competencies necessary. It also depicts the many career paths available, including vertical and lateral advancement opportunities.\n",
            "\n",
            "\n",
            "== Terminology ==\n",
            "The following terms used with regards to computer security are explained below:\n",
            "\n",
            "Access authorization restricts access to a computer to a group of users through the use of authentication systems. These systems can protect either the whole computer, such as through an interactive login screen, or individual services, such as a FTP server. There are many methods for identifying and authenticating users, such as passwords, identification cards, smart cards, and biometric systems.\n",
            "Anti-virus software consists of computer programs that attempt to identify, thwart, and eliminate computer viruses and other malicious software (malware).\n",
            "Applications are executable code, so general corporate practice is to restrict or block users the power to install them; to install them only when there is a demonstrated need (e.g. software needed to perform assignments); to install only those which are known to be reputable (preferably with access to the computer code used to create the application,- and to reduce the attack surface by installing as few as possible. They are typically run with least privilege, with a robust process in place to identify, test and install any released security patches or updates for them.\n",
            "For example, programs can be installed into an individual user's account, which limits the program's potential access, as well as being a means control which users have specific exceptions to policy.  In Linux], FreeBSD, OpenBSD, and other Unix-like operating systems there is an option to further restrict an application using chroot or other means of restricting the application to its own 'sandbox'.  For example. Linux provides namespaces, and Cgroups to further restrict the access of an application to system resources.\n",
            "Generalized security frameworks such as SELinux or AppArmor help administrators control access.\n",
            "Java and other languages which compile to Java byte code and run in the Java virtual machine can have their access to other applications controlled at the virtual machine level.\n",
            "Some software can be run in software containers which can even provide their own set of system libraries, limiting the software's, or anyone controlling it, access to the server's versions of the libraries.\n",
            "Authentication techniques can be used to ensure that communication end-points are who they say they are.\n",
            "Automated theorem proving and other verification tools can be used to enable critical algorithms and code used in secure systems to be mathematically proven to meet their specifications.\n",
            "Backups are one or more copies kept of important computer files. Typically, multiple copies will be kept at different locations so that if a copy is stolen or damaged, other copies will still exist.\n",
            "Capability and access control list techniques can be used to ensure privilege separation and mandatory access control. Capabilities vs. ACLs discusses their use.\n",
            "Chain of trust techniques can be used to attempt to ensure that all software loaded has been certified as authentic by the system's designers.\n",
            "Confidentiality is the nondisclosure of information except to another authorized person.\n",
            "Cryptographic techniques can be used to defend data in transit between systems, reducing the probability that the data exchange between systems can be intercepted or modified.\n",
            "Cyberwarfare is an Internet-based conflict that involves politically motivated attacks on information and information systems. Such attacks can, for example, disable official websites and networks, disrupt or disable essential services, steal or alter classified data, and cripple financial systems.\n",
            "Data integrity is the accuracy and consistency of stored data, indicated by an absence of any alteration in data between two updates of a data record.Encryption is used to protect the confidentiality of a message. Cryptographically secure ciphers are designed to make any practical attempt of breaking them infeasible. Symmetric-key ciphers are suitable for bulk encryption using shared keys, and public-key encryption using digital certificates can provide a practical solution for the problem of securely communicating when no key is shared in advance.\n",
            "Endpoint security software aids networks in preventing malware infection and data theft at network entry points made vulnerable by the prevalence of potentially infected devices such as laptops, mobile devices, and USB drives.\n",
            "Firewalls serve as a gatekeeper system between networks, allowing only traffic that matches defined rules. They often include detailed logging, and may include intrusion detection and intrusion prevention features. They are near-universal between company local area networks and the Internet, but can also be used internally to impose traffic rules between networks if network segmentation is configured.\n",
            "A hacker is someone who seeks to breach defenses and exploit weaknesses in a computer system or network.\n",
            "Honey pots are computers that are intentionally left vulnerable to attack by crackers. They can be used to catch crackers and to identify their techniques.\n",
            "Intrusion-detection systems are devices or software applications that monitor networks or systems for malicious activity or policy violations.\n",
            "A microkernel is an approach to operating system design which has only the near-minimum amount of code running at the most privileged level – and runs other elements of the operating system such as device drivers, protocol stacks and file systems, in the safer, less privileged user space.\n",
            "Pinging. The standard ping application can be used to test if an IP address is in use. If it is, attackers may then try a port scan to detect which services are exposed.\n",
            "A port scan is used to probe an IP address for open ports to identify accessible network services and applications.\n",
            "A key logger is spyware that silently captures and stores each keystroke that a user types on the computer's keyboard.\n",
            "Social engineering is the use of deception to manipulate individuals to breach security.\n",
            "Logic bombs is a type of malware added to a legitimate program that lies dormant until it is triggered by a specific event.\n",
            "Zero trust security means that no one is trusted by default from inside or outside the network, and verification is required from everyone trying to gain access to resources on the network.\n",
            "\n",
            "\n",
            "== History ==\n",
            "Since the Internet's arrival and with the digital transformation initiated in recent years, the notion of cybersecurity has become a familiar subject in both our professional and personal lives. Cybersecurity and cyber threats have been consistently present for the last 60 years of technological change. In the 1970s and 1980s, computer security was mainly limited to academia until the conception of the Internet, where, with increased connectivity, computer viruses and network intrusions began to take off. After the spread of viruses in the 1990s, the 2000s marked the institutionalization of organized attacks such as distributed denial of service. This led to the formalization of cybersecurity as a professional discipline.The April 1967 session organized by Willis Ware at the Spring Joint Computer Conference, and the later publication of the Ware Report, were foundational moments in the history of the field of computer security. Ware's work straddled the intersection of material, cultural, political, and social concerns.A 1977 NIST publication introduced the CIA triad of confidentiality, integrity, and availability as a clear and simple way to describe key security goals. While still relevant, many more elaborate frameworks have since been proposed.However, in the 1970s and 1980s, there were no grave computer threats because computers and the internet were still developing, and security threats were easily identifiable. More often, threats came from malicious insiders who gained unauthorized access to sensitive documents and files. Although malware and network breaches existed during the early years, they did not use them for financial gain. By the second half of the 1970s, established computer firms like IBM started offering commercial access control systems and computer security software products.One of the earliest examples of an attack on a computer network was the computer worm Creeper written by Bob Thomas at BBN, which propagated through the ARPANET in 1971. The program was purely experimental in nature and carried no malicious payload. A later program, Reaper, was created by Ray Tomlinson in 1972 and used to destroy Creeper.Between September 1986 and June 1987, a group of German hackers performed the first documented case of cyber espionage. The group hacked into American defense contractors, universities, and military base networks and sold gathered information to the Soviet KGB. The group was led by Markus Hess, who was arrested on 29 June 1987. He was convicted of espionage (along with two co-conspirators) on 15 Feb 1990.\n",
            "In 1988, one of the first computer worms, called the Morris worm, was distributed via the Internet. It gained significant mainstream media attention.In 1993, Netscape started developing the protocol SSL, shortly after the National Center for Supercomputing Applications (NCSA) launched Mosaic 1.0, the first web browser, in 1993. Netscape had SSL version 1.0 ready in 1994, but it was never released to the public due to many serious security vulnerabilities. These weaknesses included replay attacks and a vulnerability that allowed hackers to alter unencrypted communications sent by users. However, in February 1995, Netscape launched Version 2.0. The National Security Agency (NSA) is responsible for the protection of U.S. information systems and also for collecting foreign intelligence. The agency analyzes commonly used software and system configurations to find security flaws, which it can use for offensive purposes against competitors of the United States.NSA contractors created and sold click-and-shoot attack tools to US agencies and close allies, but eventually, the tools made their way to foreign adversaries. In 2016, NSAs own hacking tools were hacked, and they have been used by Russia and North Korea. NSA's employees and contractors have been recruited at high salaries by adversaries, anxious to compete in cyberwarfare. In 2007, the United States and Israel began exploiting security flaws in the Microsoft Windows operating system to attack and damage equipment used in Iran to refine nuclear materials. Iran responded by heavily investing in their own cyberwarfare capability, which it began using against the United States.\n",
            "\n",
            "\n",
            "== Notable scholars ==\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "Branch, Jordan (24 September 2020). \"What's in a Name? Metaphors and Cybersecurity\". International Organization. Cambridge University Press (CUP). 75 (1): 39–70. doi:10.1017/s002081832000051x. ISSN 0020-8183. S2CID 224886794.\n",
            "Costigan, Sean; Hennessy, Michael (2016). Cybersecurity: A Generic Reference Curriculum (PDF). NATO. ISBN 978-9284501960. Archived (PDF) from the original on 10 March 2017.\n",
            "Fuller, Christopher J (11 June 2018). \"The Roots of the United States' Cyber (In)Security\" (DOC). Diplomatic History. Oxford University Press (OUP). 43 (1): 157–185. doi:10.1093/dh/dhy038. ISSN 0145-2096.\n",
            "Bob, Yonah Jeremy (21 August 2021). \"Ex-IDF cyber intel. official reveals secrets behind cyber offense\". The Jerusalem Post.\n",
            "Kim, Peter (2014). The Hacker Playbook: Practical Guide To Penetration Testing. Seattle: CreateSpace Independent Publishing Platform. ISBN 978-1494932633.\n",
            "Lee, Newton (2015). Counterterrorism and Cybersecurity: Total Information Awareness (2nd ed.). Springer. ISBN 978-3319172439.\n",
            "Montagnani, Maria Lillà; Cavallo, Mirta Antonella (2018). \"Cybersecurity and Liability in a Big Data World\". Market and Competition Law Review. Elsevier BV. 2 (2): 71–98. doi:10.2139/ssrn.3220475. ISSN 1556-5068. S2CID 216704215. SSRN 3220475.\n",
            "Shariati, Marzieh; Bahmani, Faezeh; Shams, Fereidoon (2011). \"Enterprise information security, a review of architectures and frameworks from interoperability perspective\". Procedia Computer Science. Elsevier BV. 3: 537–543. doi:10.1016/j.procs.2010.12.089. ISSN 1877-0509.\n",
            "Singer, P. W.; Friedman, Allan (2014). Cybersecurity and Cyberwar: What Everyone Needs to Know. Oxford University Press. ISBN 978-0199918119.\n",
            "Wu, Chwan-Hwa (John); Irwin, J. David (2013). Introduction to Computer Networks and Cybersecurity. Boca Raton: CRC Press. ISBN 978-1466572133.\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "Computer security at Curlie...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading 5 Random wikipedia pages"
      ],
      "metadata": {
        "id": "p4-e7EAjuYt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_page = ['Cricket' , 'Rose' , 'Plant' , 'Planet' , 'Name']"
      ],
      "metadata": {
        "id": "Pek-_jlcMbSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download text for each page title\n",
        "for title in random_page:\n",
        "    text = download_wikipedia_page(title)\n",
        "    Sentences.append(text)\n",
        "    print(f\"Page Title: {title}\\nText: {text}...\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCfFJXYQuYAy",
        "outputId": "697b2b21-a601-49b1-9343-f2cbec7612a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page Title: Cricket\n",
            "Text: Cricket is a bat-and-ball game played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps. The batting side scores runs by striking the ball bowled at one of the wickets with the bat and then running between the wickets, while the bowling and fielding side tries to prevent this (by preventing the ball from leaving the field, and getting the ball to either wicket) and dismiss each batter (so they are \"out\"). Means of dismissal include being bowled, when the ball hits the stumps and dislodges the bails, and by the fielding side either catching the ball after it is hit by the bat, but before it hits the ground, or hitting a wicket with the ball before a batter can cross the crease in front of the wicket. When ten batters have been dismissed, the innings ends and the teams swap roles. The game is adjudicated by two umpires, aided by a third umpire and match referee in international matches. They communicate with two off-field scorers who record the match's statistical information.\n",
            "Forms of cricket range from Twenty20 (also known as T20), with each team batting for a single innings of 20 overs (each \"over\" being a set of 6 fair opportunities for the batting team to score) and the game generally lasting three to four hours, to Test matches played over five days. Traditionally cricketers play in all-white kit, but in limited overs cricket they wear club or team colours. In addition to the basic kit, some players wear protective gear to prevent injury caused by the ball, which is a hard, solid spheroid made of compressed leather with a slightly raised sewn seam enclosing a cork core layered with tightly wound string.\n",
            "The earliest known definite reference to cricket is to it being played in South East England in the mid-16th century. It spread globally with the expansion of the British Empire, with the first international matches in the second half of the 19th century. The game's governing body is the International Cricket Council (ICC), which has over 100 members, twelve of which are full members who play Test matches. The game's rules, the Laws of Cricket, are maintained by Marylebone Cricket Club (MCC) in London. The sport is followed primarily in South Asia, Australia, New Zealand, the United Kingdom, Southern Africa and the West Indies.Women's cricket, which is organised and played separately, has also achieved international standard. \n",
            "The most successful side playing international cricket is Australia, which has won eight One Day International trophies, including six World Cups, more than any other country and has been the top-rated Test side more than any other country.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "\n",
            "=== Origins ===\n",
            "\n",
            "Cricket is one of many games in the \"club ball\" sphere that basically involve hitting a ball with a hand-held implement; others include baseball (which shares many similarities with cricket, both belonging in the more specific bat-and-ball games category), golf, hockey, tennis, squash, badminton and table tennis. In cricket's case, a key difference is the existence of a solid target structure, the wicket (originally, it is thought, a \"wicket gate\" through which sheep were herded), that the batter must defend. The cricket historian Harry Altham identified three \"groups\" of \"club ball\" games: the \"hockey group\", in which the ball is driven to and from between two targets (the goals); the \"golf group\", in which the ball is driven towards an undefended target (the hole); and the \"cricket group\", in which \"the ball is aimed at a mark (the wicket) and driven away from it\".It is generally believed that cricket originated as a children's game in the south-eastern counties of England, sometime during the medieval period. Although there are claims for prior dates, the earliest definite reference to cricket being played comes from evidence given at a court case in Guildford in January 1597 (Old Style, equating to January 1598 in the modern calendar). The case concerned ownership of a certain plot of land and the court heard the testimony of a 59-year-old coroner, John Derrick, who gave witness that:\n",
            "Being a scholler in the ffree schoole of Guldeford hee and diverse of his fellows did runne and play there at creckett and other plaies.\n",
            "Given Derrick's age, it was about half a century earlier when he was at school and so it is certain that cricket was being played c. 1550 by boys in Surrey. The view that it was originally a children's game is reinforced by Randle Cotgrave's 1611 English-French dictionary in which he defined the noun \"crosse\" as \"the crooked staff wherewith boys play at cricket\" and the verb form \"crosser\" as \"to play at cricket\".One possible source for the sport's name is the Old English word \"cryce\" (or \"cricc\") meaning a crutch or staff. In Samuel Johnson's Dictionary, he derived cricket from \"cryce, Saxon, a stick\". In Old French, the word \"criquet\" seems to have meant a kind of club or stick. Given the strong medieval trade connections between south-east England and the County of Flanders when the latter belonged to the Duchy of Burgundy, the name may have been derived from the Middle Dutch (in use in Flanders at the time) \"krick\"(-e), meaning a stick (crook). Another possible source is the Middle Dutch word \"krickstoel\", meaning a long low stool used for kneeling in church and which resembled the long low wicket with two stumps used in early cricket. According to Heiner Gillmeister, a European language expert of Bonn University, \"cricket\" derives from the Middle Dutch phrase for hockey, met de (krik ket)sen (i.e., \"with the stick chase\"). Gillmeister has suggested that not only the name but also the sport itself may be of Flemish origin.\n",
            "\n",
            "\n",
            "=== Growth of amateur and professional cricket in England ===\n",
            "Although the main object of the game has always been to score the most runs, the early form of cricket differed from the modern game in certain key technical aspects; the North American variant of cricket known as wicket retained many of these aspects. The ball was bowled underarm by the bowler and along the ground towards a batter armed with a bat that in shape resembled a hockey stick; the batter defended a low, two-stump wicket; and runs were called notches because the scorers recorded them by notching tally sticks.In 1611, the year Cotgrave's dictionary was published, ecclesiastical court records at Sidlesham in Sussex state that two parishioners, Bartholomew Wyatt and Richard Latter, failed to attend church on Easter Sunday because they were playing cricket. They were fined 12d each and ordered to do penance. This is the earliest mention of adult participation in cricket and it was around the same time that the earliest known organised inter-parish or village match was played – at Chevening, Kent. In 1624, a player called Jasper Vinall died after he was accidentally struck on the head during a match between two parish teams in Sussex.Cricket remained a low-key local pursuit for much of the 17th century. It is known, through numerous references found in the records of ecclesiastical court cases, to have been proscribed at times by the Puritans before and during the Commonwealth. The problem was nearly always the issue of Sunday play as the Puritans considered cricket to be \"profane\" if played on the Sabbath, especially if large crowds or gambling were involved.According to the social historian Derek Birley, there was a \"great upsurge of sport after the Restoration\" in 1660. Several members of the court of King Charles II took a strong interest in cricket during that era. Gambling on sport became a problem significant enough for Parliament to pass the 1664 Gambling Act, limiting stakes to £100 which was, in any case, a colossal sum exceeding the annual income of 99% of the population. Along with horse racing, as well as prizefighting and other types of blood sport, cricket was perceived to be a gambling sport. Rich patrons made matches for high stakes, forming teams in which they engaged the first professional players. By the end of the century, cricket had developed into a major sport that was spreading throughout England and was already being taken abroad by English mariners and colonisers – the earliest reference to cricket overseas is dated 1676. A 1697 newspaper report survives of \"a great cricket match\" played in Sussex \"for fifty guineas apiece\" – this is the earliest known contest that is generally considered a First Class match.The patrons, and other players from the social class known as the \"gentry\", began to classify themselves as \"amateurs\" to establish a clear distinction from the professionals, who were invariably members of the working class, even to the point of having separate changing and dining facilities. The gentry, including such high-ranking nobles as the Dukes of Richmond, exerted their honour code of noblesse oblige to claim rights of leadership in any sporting contests they took part in, especially as it was necessary for them to play alongside their \"social inferiors\" if they were to win their bets. In time, a perception took hold that the typical amateur who played in first-class cricket, until 1962 when amateurism was abolished, was someone with a public school education who had then gone to one of Cambridge or Oxford University – society insisted that such people were \"officers and gentlemen\" whose destiny was to provide leadership. In a purely financial sense, the cricketing amateur would theoretically claim expenses for playing while his professional counterpart played under contract and was paid a wage or match fee; in practice, many amateurs claimed more than actual expenditure and the derisive term \"shamateur\" was coined to describe the practice.\n",
            "\n",
            "\n",
            "=== English cricket in the 18th and 19th centuries ===\n",
            "The game underwent major development in the 18th century to become England's national sport. Its success was underwritten by the twin necessities of patronage and betting. Cricket was prominent in London as early as 1707 and, in the middle years of the century, large crowds flocked to matches on the Artillery Ground in Finsbury. The single wicket form of the sport attracted huge crowds and wagers to match, its popularity peaking in the 1748 season. Bowling underwent an evolution around 1760 when bowlers began to pitch the ball instead of rolling or skimming it towards the batter. This caused a revolution in bat design because, to deal with the bouncing ball, it was necessary to introduce the modern straight bat in place of the old \"hockey stick\" shape.The Hambledon Club was founded in the 1760s and, for the next twenty years until the formation of Marylebone Cricket Club (MCC) and the opening of Lord's Old Ground in 1787, Hambledon was both the game's greatest club and its focal point. MCC quickly became the sport's premier club and the custodian of the Laws of Cricket. New Laws introduced in the latter part of the 18th century included the three stump wicket and leg before wicket (lbw).The 19th century saw underarm bowling superseded by first roundarm and then overarm bowling. Both developments were controversial. Organisation of the game at county level led to the creation of the county clubs, starting with Sussex in 1839. In December 1889, the eight leading county clubs formed the official County Championship, which began in 1890.\n",
            "The most famous player of the 19th century was W. G. Grace, who started his long and influential career in 1865. It was especially during the career of Grace that the distinction between amateurs and professionals became blurred by the existence of players like him who were nominally amateur but, in terms of their financial gain, de facto professional. Grace himself was said to have been paid more money for playing cricket than any professional.The last two decades before the First World War have been called the \"Golden Age of cricket\". It is a nostalgic name prompted by the collective sense of loss resulting from the war, but the period did produce some great players and memorable matches, especially as organised competition at county and Test level developed.\n",
            "\n",
            "\n",
            "=== Cricket becomes an international sport ===\n",
            "In 1844, the first-ever international match took place between what were essentially club teams, from the United States and Canada, in Toronto; Canada won. In 1859, a team of English players went to North America on the first overseas tour. Meanwhile, the British Empire had been instrumental in spreading the game overseas and by the middle of the 19th century it had become well established in Australia, the Caribbean, British India (which includes present-day Pakistan and Bangladesh), New Zealand, North America and South Africa.In 1862, an English team made the first tour of Australia. The first Australian team to travel overseas consisted of Aboriginal stockmen which toured England in 1868.In 1876–77, an England team took part in what was retrospectively recognized as the first-ever Test match at the Melbourne Cricket Ground against Australia. The rivalry between England and Australia gave birth to The Ashes in 1882, and this has remained Test cricket's most famous contest. Test cricket began to expand in 1888–89 when South Africa played England.\n",
            "\n",
            "\n",
            "=== World cricket in the 20th century ===\n",
            "The inter-war years were dominated by Australia's Don Bradman, statistically the greatest Test batter of all time. Test cricket continued to expand during the 20th century with the addition of the West Indies (1928), New Zealand (1930) and India (1932) before the Second World War and then Pakistan (1952), Sri Lanka (1982), Zimbabwe (1992), Bangladesh (2000), Ireland and Afghanistan (both 2018) in the post-war period. South Africa was banned from international cricket from 1970 to 1992 as part of the apartheid boycott.\n",
            "\n",
            "\n",
            "=== The rise of limited overs cricket ===\n",
            "Cricket entered a new era in 1963 when English counties introduced the limited overs variant. As it was sure to produce a result, limited overs cricket was lucrative and the number of matches increased. The first Limited Overs International was played in 1971 and the governing International Cricket Council (ICC), seeing its potential, staged the first limited overs Cricket World Cup in 1975. In the 21st century, a new limited overs form, Twenty20, made an immediate impact. On 22 June 2017, Afghanistan and Ireland became the 11th and 12th ICC full members, enabling them to play Test cricket.\n",
            "\n",
            "\n",
            "== Laws and gameplay ==\n",
            "\n",
            "In cricket, the rules of the game are specified in a code called The Laws of Cricket (hereinafter called \"the Laws\") which has a global remit. There are 42 Laws (always written with a capital \"L\"). The earliest known version of the code was drafted in 1744 and, since 1788, it has been owned and maintained by its custodian, the Marylebone Cricket Club (MCC) in London.\n",
            "\n",
            "\n",
            "=== Playing area ===\n",
            "\n",
            "Cricket is a bat-and-ball game played on a cricket field (see image of cricket pitch and creases) between two teams of eleven players each. The field is usually circular or oval in shape and the edge of the playing area is marked by a boundary, which may be a fence, part of the stands, a rope, a painted line or a combination of these; the boundary must if possible be marked along its entire length.In the approximate centre of the field is a rectangular pitch (see image, below) on which a wooden target called a wicket is sited at each end; the wickets are placed 22 yards (20 m) apart. The pitch is a flat surface 10 feet (3.0 m) wide, with very short grass that tends to be worn away as the game progresses (cricket can also be played on artificial surfaces, notably matting). Each wicket is made of three wooden stumps topped by two bails.\n",
            "As illustrated, the pitch is marked at each end with four white painted lines: a bowling crease, a popping crease and two return creases. The three stumps are aligned centrally on the bowling crease, which is eight feet eight inches long. The popping crease is drawn four feet in front of the bowling crease and parallel to it; although it is drawn as a twelve-foot line (six feet either side of the wicket), it is, in fact, unlimited in length. The return creases are drawn at right angles to the popping crease so that they intersect the ends of the bowling crease; each return crease is drawn as an eight-foot line, so that it extends four feet behind the bowling crease, but is also, in fact, unlimited in length.\n",
            "\n",
            "\n",
            "=== Match structure and closure ===\n",
            "\n",
            "Before a match begins, the team captains (who are also players) toss a coin to decide which team will bat first and so take the first innings. Innings is the term used for each phase of play in the match. In each innings, one team bats, attempting to score runs, while the other team bowls and fields the ball, attempting to restrict the scoring and dismiss the batters. When the first innings ends, the teams change roles; there can be two to four innings depending upon the type of match. A match with four scheduled innings is played over three to five days; a match with two scheduled innings is usually completed in a single day. During an innings, all eleven members of the fielding team take the field, but usually only two members of the batting team are on the field at any given time. The exception to this is if a batter has any type of illness or injury restricting his or her ability to run, in this case the batter is allowed a runner who can run between the wickets when the batter hits a scoring run or runs, though this does not apply in international cricket. The order of batters is usually announced just before the match, but it can be varied.The main objective of each team is to score more runs than their opponents but, in some forms of cricket, it is also necessary to dismiss all of the opposition batters in their final innings in order to win the match, which would otherwise be drawn. If the team batting last is all out having scored fewer runs than their opponents, they are said to have \"lost by n runs\" (where n is the difference between the aggregate number of runs scored by the teams). If the team that bats last scores enough runs to win, it is said to have \"won by n wickets\", where n is the number of wickets left to fall. For example, a team that passes its opponents' total having lost six wickets (i.e., six of their batters have been dismissed) have won the match \"by four wickets\".In a two-innings-a-side match, one team's combined first and second innings total may be less than the other side's first innings total. The team with the greater score is then said to have \"won by an innings and n runs\", and does not need to bat again: n is the difference between the two teams' aggregate scores. If the team batting last is all out, and both sides have scored the same number of runs, then the match is a tie; this result is quite rare in matches of two innings a side with only 62 happening in first-class matches from the earliest known instance in 1741 until January 2017. In the traditional form of the game, if the time allotted for the match expires before either side can win, then the game is declared a draw.If the match has only a single innings per side, then usually a maximum number of overs applies to each innings. Such a match is called a \"limited overs\" or \"one-day\" match, and the side scoring more runs wins regardless of the number of wickets lost, so that a draw cannot occur. In some cases, ties are broken by having each team bat for a one-over innings known as a Super Over; subsequent Super Overs may be played if the first Super Over ends in a tie. If this kind of match is temporarily interrupted by bad weather, then a complex mathematical formula, known as the Duckworth–Lewis–Stern method after its developers, is often used to recalculate a new target score. A one-day match can also be declared a \"no-result\" if fewer than a previously agreed number of overs have been bowled by either team, in circumstances that make normal resumption of play impossible; for example, wet weather.In all forms of cricket, the umpires can abandon the match if bad light or rain makes it impossible to continue. There have been instances of entire matches, even Test matches scheduled to be played over five days, being lost to bad weather without a ball being bowled: for example, the third Test of the 1970/71 series in Australia.\n",
            "\n",
            "\n",
            "==== Innings ====\n",
            "\n",
            "The innings (ending with 's' in both singular and plural form) is the term used for each phase of play during a match. Depending on the type of match being played, each team has either one or two innings. Sometimes all eleven members of the batting side take a turn to bat but, for various reasons, an innings can end before they have all done so. The innings terminates if the batting team is \"all out\", a term defined by the Laws: \"at the fall of a wicket or the retirement of a batter, further balls remain to be bowled but no further batter is available to come in\". In this situation, one of the batters has not been dismissed and is termed not out; this is because he has no partners left and there must always be two active batters while the innings is in progress.\n",
            "An innings may end early while there are still two not out batters:\n",
            "the batting team's captain may declare the innings closed even though some of his players have not had a turn to bat: this is a tactical decision by the captain, usually because he believes his team have scored sufficient runs and need time to dismiss the opposition in their innings\n",
            "the set number of overs (i.e., in a limited overs match) have been bowled\n",
            "the match has ended prematurely due to bad weather or running out of time\n",
            "in the final innings of the match, the batting side has reached its target and won the game.\n",
            "\n",
            "\n",
            "===== Overs =====\n",
            "\n",
            "The Laws state that, throughout an innings, \"the ball shall be bowled from each end alternately in overs of 6 balls\". The name \"over\" came about because the umpire calls \"Over!\" when six balls have been bowled. At this point, another bowler is deployed at the other end, and the fielding side changes ends while the batters do not. A bowler cannot bowl two successive overs, although a bowler can (and usually does) bowl alternate overs, from the same end, for several overs which are termed a \"spell\". The batters do not change ends at the end of the over, and so the one who was non-striker is now the striker and vice versa. The umpires also change positions so that the one who was at \"square leg\" now stands behind the wicket at the non-striker's end and vice versa.\n",
            "\n",
            "\n",
            "=== Clothing and equipment ===\n",
            "\n",
            "The wicket-keeper (a specialised fielder behind the batter) and the batters wear protective gear because of the hardness of the ball, which can be delivered at speeds of more than 145 kilometres per hour (90 mph) and presents a major health and safety concern. Protective clothing includes pads (designed to protect the knees and shins), batting gloves or wicket-keeper's gloves for the hands, a safety helmet for the head and a box for male players inside the trousers (to protect the crotch area). Some batters wear additional padding inside their shirts and trousers such as thigh pads, arm pads, rib protectors and shoulder pads. The only fielders allowed to wear protective gear are those in positions very close to the batter (i.e., if they are alongside or in front of him), but they cannot wear gloves or external leg guards.Subject to certain variations, on-field clothing generally includes a collared shirt with short or long sleeves; long trousers; woolen pullover (if needed); cricket cap (for fielding) or a safety helmet; and spiked shoes or boots to increase traction. The kit is traditionally all white and this remains the case in Test and first-class cricket but, in limited overs cricket, team colours are worn instead.\n",
            "\n",
            "\n",
            "==== Bat and ball ====\n",
            "\n",
            "The essence of the sport is that a bowler delivers (i.e., bowls) the ball from his or her end of the pitch towards the batter who, armed with a bat, is \"on strike\" at the other end (see next sub-section: Basic gameplay).\n",
            "The bat is made of wood, usually Salix alba (white willow), and has the shape of a blade topped by a cylindrical handle. The blade must not be more than 4.25 inches (10.8 cm) wide and the total length of the bat not more than 38 inches (97 cm). There is no standard for the weight, which is usually between 2 lb 7 oz and 3 lb (1.1 and 1.4 kg).The ball is a hard leather-seamed spheroid, with a circumference of 9 inches (23 cm). The ball has a \"seam\": six rows of stitches attaching the leather shell of the ball to the string and cork interior. The seam on a new ball is prominent and helps the bowler propel it in a less predictable manner. During matches, the quality of the ball deteriorates to a point where it is no longer usable;  during the course of this deterioration, its behaviour in flight will change and can influence the outcome of the match. Players will, therefore, attempt to modify the ball's behaviour by modifying its physical properties. Polishing the ball and wetting it with sweat or saliva is legal, even when the polishing is deliberately done on one side only to increase the ball's swing through the air, but the acts of rubbing other substances into the ball, scratching the surface or picking at the seam are illegal ball tampering.\n",
            "\n",
            "\n",
            "=== Player roles ===\n",
            "\n",
            "\n",
            "==== Basic gameplay: bowler to batter ====\n",
            "During normal play, thirteen players and two umpires are on the field. Two of the players are batters and the rest are all eleven members of the fielding team. The other nine players in the batting team are off the field in the pavilion. The image with overlay below shows what is happening when a ball is being bowled and which of the personnel are on or close to the pitch.\n",
            "In the photo, the two batters (3 & 8; wearing yellow) have taken position at each end of the pitch (6). Three members of the fielding team (4, 10 & 11; wearing dark blue) are in shot. One of the two umpires (1; wearing white hat) is stationed behind the wicket (2) at the bowler's (4) end of the pitch. The bowler (4) is bowling the ball (5) from his end of the pitch to the batter (8) at the other end who is called the \"striker\". The other batter (3) at the bowling end is called the \"non-striker\". The wicket-keeper (10), who is a specialist, is positioned behind the striker's wicket (9) and behind him stands one of the fielders in a position called \"first slip\" (11). While the bowler and the first slip are wearing conventional kit only, the two batters and the wicket-keeper are wearing protective gear including safety helmets, padded gloves and leg guards (pads).\n",
            "While the umpire (1) in shot stands at the bowler's end of the pitch, his colleague stands in the outfield, usually in or near the fielding position called \"square leg\", so that he is in line with the popping crease (7) at the striker's end of the pitch. The bowling crease (not numbered) is the one on which the wicket is located between the return creases (12). The bowler (4) intends to hit the wicket (9) with the ball (5) or, at least, to prevent the striker (8) from scoring runs. The striker (8) intends, by using his bat, to defend his wicket and, if possible, to hit the ball away from the pitch in order to score runs.\n",
            "Some players are skilled in both batting and bowling, or as either of these as well as wicket-keeping, so are termed all-rounders.  Bowlers are classified according to their style, generally as fast bowlers, seam bowlers or spinners. Batters are classified according to whether they are right-handed or left-handed.\n",
            "\n",
            "\n",
            "==== Fielding ====\n",
            "\n",
            "Of the eleven fielders, three are in shot in the image above. The other eight are elsewhere on the field, their positions determined on a tactical basis by the captain or the bowler. Fielders often change position between deliveries, again as directed by the captain or bowler.If a fielder is injured or becomes ill during a match, a substitute is allowed to field instead of him, but the substitute cannot bowl or act as a captain, except in the case of concussion substitutes in international cricket. The substitute leaves the field when the injured player is fit to return. The Laws of Cricket were updated in 2017 to allow substitutes to act as wicket-keepers.\n",
            "\n",
            "\n",
            "==== Bowling and dismissal ====\n",
            "\n",
            "Most bowlers are considered specialists in that they are selected for the team because of their skill as a bowler, although some are all-rounders and even specialist batters bowl occasionally. The specialists bowl several times during an innings but may not bowl two overs consecutively. If the captain wants a bowler to \"change ends\", another bowler must temporarily fill in so that the change is not immediate.A bowler reaches his delivery stride by means of a \"run-up\" and an over is deemed to have begun when the bowler starts his run-up for the first delivery of that over, the ball then being \"in play\". Fast bowlers, needing momentum, take a lengthy run up while bowlers with a slow delivery take no more than a couple of steps before bowling. The fastest bowlers can deliver the ball at a speed of over 145 kilometres per hour (90 mph) and they sometimes rely on sheer speed to try to defeat the batter, who is forced to react very quickly. Other fast bowlers rely on a mixture of speed and guile by making the ball seam or swing (i.e. curve) in flight. This type of delivery can deceive a batter into miscuing his shot, for example, so that the ball just touches the edge of the bat and can then be \"caught behind\" by the wicket-keeper or a slip fielder. At the other end of the bowling scale is the spin bowler who bowls at a relatively slow pace and relies entirely on guile to deceive the batter. A spinner will often \"buy his wicket\" by \"tossing one up\" (in a slower, steeper parabolic path) to lure the batter into making a poor shot. The batter has to be very wary of such deliveries as they are often \"flighted\" or spun so that the ball will not behave quite as he expects and he could be \"trapped\" into getting himself out. In between the pacemen and the spinners are the medium paced seamers who rely on persistent accuracy to try to contain the rate of scoring and wear down the batter's concentration.There are nine ways in which a batter can be dismissed: five relatively common and four extremely rare. The common forms of dismissal are bowled, caught, leg before wicket (lbw), run out and stumped. Rare methods are hit wicket, hit the ball twice, obstructing the field and timed out. The Laws state that the fielding team, usually the bowler in practice, must appeal for a dismissal before the umpire can give his decision. If the batter is out, the umpire raises a forefinger and says \"Out!\"; otherwise, he will shake his head and say \"Not out\". There is, effectively, a tenth method of dismissal, retired out, which is not an on-field dismissal as such but rather a retrospective one for which no fielder is credited.\n",
            "\n",
            "\n",
            "==== Batting, runs and extras ====\n",
            "\n",
            "Batters take turns to bat via a batting order which is decided beforehand by the team captain and presented to the umpires, though the order remains flexible when the captain officially nominates the team. Substitute batters are generally not allowed, except in the case of concussion substitutes in international cricket.In order to begin batting the batter first adopts a batting stance. Standardly, this involves adopting a slight crouch with the feet pointing across the front of the wicket, looking in the direction of the bowler, and holding the bat so it passes over the feet and so its tip can rest on the ground near to the toes of the back foot.A skilled batter can use a wide array of \"shots\" or \"strokes\" in both defensive and attacking mode. The idea is to hit the ball to the best effect with the flat surface of the bat's blade. If the ball touches the side of the bat it is called an \"edge\". The batter does not have to play a shot and can allow the ball to go through to the wicketkeeper. Equally, he does not have to attempt a run when he hits the ball with his bat. Batters do not always seek to hit the ball as hard as possible, and a good player can score runs just by making a deft stroke with a turn of the wrists or by simply \"blocking\" the ball but directing it away from fielders so that he has time to take a run. A wide variety of shots are played, the batter's repertoire including strokes named according to the style of swing and the direction aimed: e.g., \"cut\", \"drive\", \"hook\", \"pull\".The batter on strike (i.e. the \"striker\") must prevent the ball hitting the wicket, and try to score runs by hitting the ball with his bat so that he and his partner have time to run from one end of the pitch to the other before the fielding side can return the ball. To register a run, both runners must touch the ground behind the popping crease with either their bats or their bodies (the batters carry their bats as they run). Each completed run increments the score of both the team and the striker.\n",
            "The decision to attempt a run is ideally made by the batter who has the better view of the ball's progress, and this is communicated by calling: usually \"yes\", \"no\" or \"wait\". More than one run can be scored from a single hit: hits worth one to three runs are common, but the size of the field is such that it is usually difficult to run four or more. To compensate for this, hits that reach the boundary of the field are automatically awarded four runs if the ball touches the ground en route to the boundary or six runs if the ball clears the boundary without touching the ground within the boundary. In these cases the batters do not need to run. Hits for five are unusual and generally rely on the help of \"overthrows\" by a fielder returning the ball. \n",
            "If an odd number of runs is scored by the striker, the two batters have changed ends, and the one who was non-striker is now the striker. Only the striker can score individual runs, but all runs are added to the team's total.Additional runs can be gained by the batting team as extras (called \"sundries\" in Australia) due to errors made by the fielding side. This is achieved in four ways: no-ball, a penalty of one extra conceded by the bowler if he breaks the rules; wide, a penalty of one extra conceded by the bowler if he bowls so that the ball is out of the batter's reach; bye, an extra awarded if the batter misses the ball and it goes past the wicket-keeper and gives the batters time to run in the conventional way; leg bye, as for a bye except that the ball has hit the batter's body, though not his bat. If the bowler has conceded a no-ball or a wide, his team incurs an additional penalty because that ball (i.e., delivery) has to be bowled again and hence the batting side has the opportunity to score more runs from this extra ball.\n",
            "\n",
            "\n",
            "==== Specialist roles ====\n",
            "\n",
            "The captain is often the most experienced player in the team, certainly the most tactically astute, and can possess any of the main skillsets as a batter, a bowler or a wicket-keeper. Within the Laws, the captain has certain responsibilities in terms of nominating his players to the umpires before the match and ensuring that his players conduct themselves \"within the spirit and traditions of the game as well as within the Laws\".The wicket-keeper (sometimes called simply the \"keeper\") is a specialist fielder subject to various rules within the Laws about his equipment and demeanour. He is the only member of the fielding side who can effect a stumping and is the only one permitted to wear gloves and external leg guards.Depending on their primary skills, the other ten players in the team tend to be classified as specialist batters or specialist bowlers. Generally, a team will include five or six specialist batters and four or five specialist bowlers, plus the wicket-keeper.\n",
            "\n",
            "\n",
            "=== Umpires and scorers ===\n",
            "\n",
            "The game on the field is regulated by the two umpires, one of whom stands behind the wicket at the bowler's end, the other in a position called \"square leg\" which is about 15–20 metres away from the batter on strike and in line with the popping crease on which he is taking guard. The umpires have several responsibilities including adjudication on whether a ball has been correctly bowled (i.e., not a no-ball or a wide); when a run is scored; whether a batter is out (the fielding side must first appeal to the umpire, usually with the phrase \"How's that?\" or \"Owzat?\"); when intervals start and end; and the suitability of the pitch, field and weather for playing the game. The umpires are authorised to interrupt or even abandon a match due to circumstances likely to endanger the players, such as a damp pitch or deterioration of the light.Off the field in televised matches, there is usually a third umpire who can make decisions on certain incidents with the aid of video evidence. The third umpire is mandatory under the playing conditions for Test and Limited Overs International matches played between two ICC full member countries. These matches also have a match referee whose job is to ensure that play is within the Laws and the spirit of the game.The match details, including runs and dismissals, are recorded by two official scorers, one representing each team. The scorers are directed by the hand signals of an umpire (see image, right). For example, the umpire raises a forefinger to signal that the batter is out (has been dismissed); he raises both arms above his head if the batter has hit the ball for six runs. The scorers are required by the Laws to record all runs scored, wickets taken and overs bowled; in practice, they also note significant amounts of additional data relating to the game.A match's statistics are summarised on a scorecard. Prior to the popularisation of scorecards, most scoring was done by men sitting on vantage points cuttings notches on tally sticks and runs were originally called notches. According to Rowland Bowen, the earliest known scorecard templates were introduced in 1776 by T. Pratt of Sevenoaks and soon came into general use. It is believed that scorecards were printed and sold at Lord's for the first time in 1846.\n",
            "\n",
            "\n",
            "=== Spirit of the Game ===\n",
            "\n",
            "Besides observing the Laws, cricketers must respect the \"Spirit of Cricket\", a concept encompassing sportsmanship, fair play and mutual respect. This spirit has long been considered an integral part of the sport but is only nebulously defined. Amidst concern that the spirit was weakening, in 2000 a Preamble was added to the Laws instructing all participants to play within the spirit of the game. The Preamble was last updated in 2017, now opening with the line:\n",
            "\"Cricket owes much of its appeal and enjoyment to the fact that it should be played not only\n",
            "according to the Laws, but also within the Spirit of Cricket\".\n",
            "The Preamble is a short statement intended to emphasise the \"positive behaviours that make cricket an exciting game that encourages leadership, friendship, and teamwork.\" Its second line states that \"the major responsibility for ensuring fair play rests with the captains, but extends to all players, match officials and, especially in junior cricket, teachers, coaches and parents.\"The umpires are the sole judges of fair and unfair play. They are required under the Laws to intervene in case of dangerous or unfair play or in cases of unacceptable conduct by a player.\n",
            "Previous versions of the Spirit identified actions that were deemed contrary (for example, appealing knowing that the batter is not out) but all specifics are now covered in the Laws of Cricket, the relevant governing playing regulations and disciplinary codes, or left to the judgement of the umpires, captains, their clubs and governing bodies. The terse expression of the Spirit of Cricket now avoids the diversity of cultural conventions that exist in the detail of sportsmanship – or its absence.\n",
            "\n",
            "\n",
            "== Women's cricket ==\n",
            "\n",
            "Women's cricket was first recorded in Surrey in 1745. International development began at the start of the 20th century and the first Test match was played between Australia and England in December 1934. The following year, New Zealand joined them, and in 2007 Netherland became the tenth women's Test nation when they made their debut against South Africa. In 1958, the International Women's Cricket Council was founded (it merged with the ICC in 2005). In 1973, the first Cricket World Cup of any kind took place when a Women's World Cup was held in England.  In 2005, the International Women's Cricket Council was merged with the International Cricket Council (ICC) to form one unified body to help manage and develop cricket. The ICC Women's Rankings were launched on 1 October 2015 covering all three formats of women's cricket. In October 2018 following the ICC's decision to award T20 International status to all members, the Women's rankings were split into separate ODI (for Full Members) and T20I lists.\n",
            "\n",
            "\n",
            "== Governance ==\n",
            "\n",
            "The International Cricket Council (ICC), which has its headquarters in Dubai, is the global governing body of cricket. It was founded as the Imperial Cricket Conference in 1909 by representatives from England, Australia and South Africa, renamed the International Cricket Conference in 1965 and took up its current name in 1989. The ICC in 2017 has 105 member nations, twelve of which hold full membership and can play Test cricket. The ICC is responsible for the organisation and governance of cricket's major international tournaments, notably the men's and women's versions of the Cricket World Cup. It also appoints the umpires and referees that officiate at all sanctioned Test matches, Limited Overs Internationals and Twenty20 Internationals.\n",
            "Each member nation has a national cricket board which regulates cricket matches played in its country, selects the national squad, and organises home and away tours for the national team. In the West Indies, which for cricket purposes is a federation of nations, these matters are addressed by Cricket West Indies.The table below lists the ICC full members and their national cricket boards:\n",
            "\n",
            "\n",
            "== Forms of cricket ==\n",
            "\n",
            "Cricket is a multi-faceted sport with multiple formats that can effectively be divided into first-class cricket, limited overs cricket and, historically, single wicket cricket. \n",
            "The highest standard is Test cricket (always written with a capital \"T\") which is in effect the international version of first-class cricket and is restricted to teams representing the twelve countries that are full members of the ICC (see above). Although the term \"Test match\" was not coined until much later, Test cricket is deemed to have begun with two matches between Australia and England in the 1876–77 Australian season; since 1882, most Test series between England and Australia have been played for a trophy known as The Ashes. The term \"first-class\", in general usage, is applied to top-level domestic cricket. Test matches are played over five days and first-class over three to four days; in all of these matches, the teams are allotted two innings each and the draw is a valid result.Limited overs cricket is always scheduled for completion in a single day, and the teams are allotted one innings each. There are two main types: List A which normally allows fifty overs per team; and Twenty20 in which the teams have twenty overs each. Both of the limited overs forms are played internationally as Limited Overs Internationals (LOI) and Twenty20 Internationals (T20I). List A was introduced in England in the 1963 season as a knockout cup contested by the first-class county clubs. In 1969, a national league competition was established. The concept was gradually introduced to the other leading cricket countries and the first limited overs international was played in 1971. In 1975, the first Cricket World Cup took place in England. Twenty20 is a new variant of limited overs itself with the purpose being to complete the match within about three to four hours, usually in an evening session. The first Twenty20 World Championship was held in 2007. In addition, a few full-member cricket boards have decided to start leagues that are played in the T10 format, in which games are intended to last approximately 90 minutes. Limited overs matches cannot be drawn, although a tie is possible and an unfinished match is a \"no result\".Single wicket was popular in the 18th and 19th centuries and its matches were generally considered top-class. In this form, although each team may have from one to six players, there is only one batter in at a time and he must face every delivery bowled while his innings lasts. Single wicket has rarely been played since limited overs cricket began. Matches tended to have two innings per team like a full first-class one and they could end in a draw.\n",
            "\n",
            "\n",
            "== Competitions ==\n",
            "Cricket is played at both the international and domestic level. There is one major international championship per format, and top-level domestic competitions mirror the three main international formats. There are now a number of T20 leagues, which have spawned a \"T20 freelancer\" phenomenon.\n",
            "\n",
            "\n",
            "=== International competitions ===\n",
            "\n",
            "Most international matches are played as parts of 'tours', when one nation travels to another for a number of weeks or months, and plays a number of matches of various sorts against the host nation. Sometimes a perpetual trophy is awarded to the winner of the Test series, the most famous of which is The Ashes.\n",
            "The ICC also organises competitions that are for several countries at once, including the Cricket World Cup, ICC T20 World Cup and ICC Champions Trophy. A league competition for Test matches played as part of normal tours, the ICC World Test Championship, had been proposed several times, and its first instance began in 2019. A league competition for ODIs, the ICC Cricket World Cup Super League, began in August 2020 and lasted only for one edition. The ICC maintains Test rankings, ODI rankings and T20 rankings systems for the countries which play these forms of cricket.\n",
            "Competitions for member nations of the ICC with Associate status include the ICC Intercontinental Cup, for first-class cricket matches, and the World Cricket League for one-day matches, the final matches of which now also serve as the ICC World Cup Qualifier.\n",
            "The game's only appearance in an Olympic Games was the 1900 Olympics. However, it is scheduled to make a return, with the T20 format of the game, in the 2028 Summer Olympics in Los Angeles.\n",
            "\n",
            "\n",
            "=== National competitions ===\n",
            "\n",
            "\n",
            "==== First-class ====\n",
            "\n",
            "First-class cricket in England is played for the most part by the 18 county clubs which contest the County Championship. The concept of a champion county has existed since the 18th century but the official competition was not established until 1890. The most successful club has been Yorkshire, who had won 32 official titles (plus one shared) as of 2019.Australia established its national first-class championship in 1892–93 when the Sheffield Shield was introduced. In Australia, the first-class teams represent the various states. New South Wales has the highest number of titles.\n",
            "The other ICC full members have national championship trophies called the Ahmad Shah Abdali 4-day Tournament (Afghanistan); the National Cricket League (Bangladesh); the Ranji Trophy (India); the Inter-Provincial Championship (Ireland); the Plunket Shield (New Zealand); the Quaid-e-Azam Trophy (Pakistan); the Currie Cup (South Africa); the Premier Trophy (Sri Lanka); the Shell Shield (West Indies); and the Logan Cup (Zimbabwe).\n",
            "\n",
            "\n",
            "==== Limited overs ====\n",
            "\n",
            "\n",
            "==== Other ====\n",
            "\n",
            "\n",
            "=== Club and school cricket ===\n",
            "\n",
            "The world's earliest known cricket match was a village cricket meeting in Kent which has been deduced from a 1640 court case recording a \"cricketing\" of \"the Weald and the Upland\" versus \"the Chalk Hill\" at Chevening \"about thirty years since\" (i.e., c. 1611). Inter-parish contests became popular in the first half of the 17th century and continued to develop through the 18th with the first local leagues being founded in the second half of the 19th.At the grassroots level, local club cricket is essentially an amateur pastime for those involved but still usually involves teams playing in competitions at weekends or in the evening. Schools cricket, first known in southern England in the 17th century, has a similar scenario and both are widely played in the countries where cricket is popular. Although there can be variations in game format, compared with professional cricket, the Laws are always observed and club/school matches are therefore formal and competitive events. The sport has numerous informal variants such as French cricket. On the North American side, in 2023, Monroe Township High School, in Monroe Township, Middlesex County, New Jersey, launched the first U.S. high school cricket club.\n",
            "\n",
            "\n",
            "== Culture ==\n",
            "\n",
            "\n",
            "=== Influence on everyday life ===\n",
            "Cricket has had a broad impact on popular culture, both in the Commonwealth of Nations and elsewhere. It has, for example, influenced the lexicon of these nations, especially the English language, with various phrases such as \"that's not cricket\" (that's unfair), \"had a good innings\" (lived a long life) and \"sticky wicket\". \"On a sticky wicket\" (aka \"sticky dog\" or \"glue pot\") is a metaphor used to describe a difficult circumstance. It originated as a term for difficult batting conditions in cricket, caused by a damp and soft pitch.\n",
            "\n",
            "\n",
            "=== In the arts and popular culture ===\n",
            "\n",
            "Cricket is the subject of works by noted English poets, including William Blake and Lord Byron. Beyond a Boundary (1963), written by Trinidadian C. L. R. James, is often named the best book on any sport ever written.\n",
            "In the visual arts, notable cricket paintings include Albert Chevallier Tayler's Kent vs Lancashire at Canterbury (1907) and Russell Drysdale's The Cricketers (1948), which has been called \"possibly the most famous Australian painting of the 20th century.\" French impressionist Camille Pissarro painted cricket on a visit to England in the 1890s. Francis Bacon, an avid cricket fan, captured a batter in motion. Caribbean artist Wendy Nanan's cricket images are featured in a limited edition first day cover for Royal Mail's \"World of Invention\" stamp issue, which celebrated the London Cricket Conference 1–3 March 2007, first international workshop of its kind and part of the celebrations leading up to the 2007 Cricket World Cup.In music, many calypsos make reference to the Sport of Cricket.\n",
            "\n",
            "\n",
            "=== Influence on other sports ===\n",
            "Cricket has close historical ties with Australian rules football and many players have competed at top levels in both sports. In 1858, prominent Australian cricketer Tom Wills called for the formation of a \"foot-ball club\" with \"a code of laws\" to keep cricketers fit during the off-season. The Melbourne Football Club was founded the following year, and Wills and three other members codified the first laws of the game. It is typically played on modified cricket fields.In England, a number of association football clubs owe their origins to cricketers who sought to play football as a means of keeping fit during the winter months. Derby County was founded as a branch of the Derbyshire County Cricket Club in 1884; Aston Villa (1874) and Everton (1876) were both founded by members of church cricket teams. Sheffield United's Bramall Lane ground was, from 1854, the home of the Sheffield Cricket Club, and then of Yorkshire; it was not used for football until 1862 and was shared by Yorkshire and Sheffield United from 1889 to 1973.In the late 19th century, a former cricketer, English-born Henry Chadwick of Brooklyn, New York, was credited with devising the baseball box score (which he adapted from the cricket scorecard) for reporting game events. The first box score appeared in an 1859 issue of the Clipper. The statistical record is so central to the game's \"historical essence\" that Chadwick is sometimes referred to as \"the Father of Baseball\" because he facilitated the popularity of the sport in its early days.\n",
            "\n",
            "\n",
            "== See also ==\n",
            "Glossary of cricket terms\n",
            "Willow and StumpyRelated sports\n",
            "\n",
            "Street cricket\n",
            "Bete-ombro – Brazilian version\n",
            "Plaquita – Dominican version\n",
            "Baseball\n",
            "Comparison of baseball and cricket\n",
            "Stoolball\n",
            "\n",
            "\n",
            "== Footnotes ==\n",
            "\n",
            "\n",
            "== Citations ==\n",
            "\n",
            "\n",
            "== Sources ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "Guha, Ramachandra (2002). A Corner of a Foreign Field: The Indian History of a British Sport. London: Picador. ISBN 0-330-49117-2. OCLC 255899689.\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "Cricket at Curlie\n",
            "International Cricket Council (ICC)\n",
            "ESPNcricinfo\n",
            "\"Cricket\". Encyclopædia Britannica Online...\n",
            "\n",
            "\n",
            "Page Title: Rose\n",
            "Text: Love encompasses a range of strong and positive emotional and mental states, from the most sublime virtue or good habit, the deepest interpersonal affection, to the simplest pleasure. An example of this range of meanings is that the love of a mother differs from the love of a spouse, which differs from the love for food. Most commonly, love refers to a feeling of strong attraction and emotional attachment.Love is considered to be both positive and negative, with its virtue representing human kindness, compassion, and affection—\"the unselfish, loyal and benevolent concern for the good of another\"—and its vice representing a human moral flaw akin to vanity, selfishness, amour-propre, and egotism, potentially leading people into a type of mania, obsessiveness, or codependency. It may also describe compassionate and affectionate actions towards other humans, oneself, or animals. In its various forms, love acts as a major facilitator of interpersonal relationships and, owing to its central psychological importance, is one of the most common themes in the creative arts. Love has been postulated to be a function that keeps human beings together against menaces and to facilitate the continuation of the species.Ancient Greek philosophers identified six forms of love: familial love (storge), friendly love or platonic love (philia), romantic love (eros), self-love (philautia), guest love (xenia), and divine or unconditional love (agape). Modern authors have distinguished further varieties of love: unrequited love, empty love, companionate love, consummate love, infatuated love, amour de soi, and courtly love. Numerous cultures have also distinguished Ren, Yuanfen, Mamihlapinatapai, Cafuné, Kama, Bhakti, Mettā, Ishq, Chesed, Amore, Charity, Saudade (and other variants or symbioses of these states), as culturally unique words, definitions, or expressions of love in regard to specified \"moments\" currently lacking in the English language.The color wheel theory of love defines three primary, three secondary, and nine tertiary love styles, describing them in terms of the traditional color wheel. The triangular theory of love suggests intimacy, passion, and commitment are core components of love. Love has additional religious or spiritual meaning. This diversity of uses and meanings, combined with the complexity of the feelings involved, makes love unusually difficult to consistently define, compared to other emotional states.\n",
            "\n",
            "\n",
            "== Definitions ==\n",
            "The word \"love\" can have a variety of related but distinct meanings in different contexts. Many other languages use multiple words to express some of the different concepts that in English are denoted as \"love\"; one example is the plurality of Greek concepts for \"love\" (agape, eros, philia, storge). Cultural differences in conceptualizing love make it difficult to establish a universal definition.Although the nature or essence of love is a subject of frequent debate, different aspects of the word can be clarified by determining what is not love (antonyms of \"love\"). Love, as a general expression of positive sentiment (a stronger form of like), is commonly contrasted with hate (or neutral apathy). As a less sexual and more emotionally intimate form of romantic attachment, love is commonly contrasted with lust. As an interpersonal relationship with romantic overtones, love is sometimes contrasted with friendship, although the word love is often applied to close friendships or platonic love. (Further possible ambiguities come with usages like \"girlfriend\", \"boyfriend\" and \"just good friends\".)\n",
            "\n",
            " Abstractly discussed, love usually refers to a feeling one person experiences for another person. Love often involves caring for, or identifying with, a person or thing (cf. vulnerability and care theory of love), including oneself (cf. narcissism). In addition to cross-cultural differences in understanding love, ideas about love have also changed greatly over time. Some historians date modern conceptions of romantic love to courtly Europe during or after the Middle Ages, although the prior existence of romantic attachments is attested by ancient love poetry.The complex and abstract nature of love often reduces its discourse to a thought-terminating cliché. Several common proverbs regard love, from Virgil's \"Love conquers all\" to The Beatles' \"All You Need Is Love\". St. Thomas Aquinas, following Aristotle, defines love as \"to will the good of another.\" Bertrand Russell describes love as a condition of \"absolute value,\" as opposed to relative value. Philosopher Gottfried Leibniz said that love is \"to be delighted by the happiness of another.\" Meher Baba stated that in love there is a \"feeling of unity\" and an \"active appreciation of the intrinsic worth of the object of love.\" Biologist Jeremy Griffith defines love as \"unconditional selflessness\".\n",
            "\n",
            "\n",
            "== Impersonal ==\n",
            "People can have a profound dedication and immense appreciation for an object, principle, or objective, thereby experiencing a sense of love towards it. For example, compassionate outreach and volunteer workers' \"love\" of their cause may sometimes be born not of interpersonal love but impersonal love, altruism, and strong spiritual or political convictions. People can also \"love\" material objects, animals, or activities if they invest themselves in bonding or otherwise identifying with those things. If sexual passion is also involved, then this feeling is called paraphilia.\n",
            "\n",
            "\n",
            "== Interpersonal ==\n",
            "Interpersonal love refers to love between human beings. It is a much more potent sentiment than liking a person. Unrequited love refers to feelings of love that are not reciprocated. Interpersonal love is most closely associated with interpersonal relationships. Such love might exist between family members, friends, and couples. There are also a number of psychological disorders related to love, such as erotomania.\n",
            "Throughout history, philosophy and religion have speculated about the phenomenon of love. In the 20th century, the science of psychology has studied the subject. The sciences of anthropology, neuroscience, and biology have also added to the understanding of the concept of love.\n",
            "\n",
            "\n",
            "=== Biological basis ===\n",
            "\n",
            "Biological models of sex tend to view love as a mammalian drive, much like hunger or thirst. Helen Fisher, an anthropologist and human behavior researcher, divides the experience of love into three partly overlapping stages: lust, attraction, and attachment. Lust is the feeling of sexual desire; romantic attraction determines what partners mates find attractive and pursue, conserving time and energy by choosing; and attachment involves sharing a home, parental duties, mutual defense, and in humans involves feelings of safety and security. Three distinct neural circuitries, including neurotransmitters, and three behavioral patterns, are associated with these three romantic styles.\n",
            "Lust is the initial passionate sexual desire that promotes mating, and involves the increased release of hormones such as testosterone and estrogen. These effects rarely last more than a few weeks or months. Attraction is the more individualized and romantic desire for a specific candidate for mating, which develops out of lust as commitment to an individual mate forms. Recent studies in neuroscience have indicated that as people fall in love, the brain consistently releases a certain set of chemicals, including the neurotransmitter hormones dopamine, norepinephrine, and serotonin, the same compounds released by amphetamine, stimulating the brain's pleasure center and leading to side effects such as increased heart rate, reduced appetite and sleep, and an intense feeling of excitement. Research indicates that this stage generally lasts from one and a half to three years.Since the lust and attraction stages are both considered temporary, a third stage is needed to account for long-term relationships. Attachment is the bonding that promotes relationships lasting for many years and even decades. Attachment is generally based on commitments such as marriage and children, or mutual friendship based on things like shared interests. It has been linked to higher levels of the chemicals oxytocin and vasopressin, to a greater degree than what is found in short-term relationships. Enzo Emanuele and coworkers reported the protein molecule known as the nerve growth factor (NGF) has high levels when people first fall in love, but these return to previous levels after one year.\n",
            "\n",
            "\n",
            "=== Psychological basis ===\n",
            "\n",
            "Psychology depicts love as a cognitive and social phenomenon. Psychologist Robert Sternberg formulated a triangular theory of love in which love has three components: intimacy, commitment, and passion. Intimacy is when two people share confidences and various details of their personal lives, and is usually shown in friendships and romantic love affairs. Commitment is the expectation that the relationship is permanent. Passionate love is shown in infatuation as well as romantic love. All forms of love are viewed as varying combinations of these three components. Non-love does not include any of these components. Liking only includes intimacy. Infatuated love only includes passion. Empty love only includes commitment. Romantic love includes both intimacy and passion. Companionate love includes intimacy and commitment. Fatuous love includes passion and commitment. Consummate love includes all three components.American psychologist Zick Rubin sought to define love by psychometrics in the 1970s. His work identifies a different set of three factors that constitute love: attachment, caring, and intimacy.Following developments in electrical theories such as Coulomb's law, which showed that positive and negative charges attract, analogs in human life were envisioned, such as \"opposites attract\". Research on human mating has generally found this not to be true when it comes to character and personality—people tend to like people similar to themselves. However, in a few unusual and specific domains, such as immune systems, it seems that humans prefer others who are unlike themselves (e.g., with an orthogonal immune system), perhaps because this will lead to a baby that has the best of both worlds.In recent years, various human bonding theories have been developed, described in terms of attachments, ties, bonds, and affinities.\n",
            "Some Western authorities disaggregate into two main components, the altruistic and the narcissistic. This view is represented in the works of Scott Peck, whose work in the field of applied psychology explored the definitions of love and evil. Peck maintains that love is a combination of the \"concern for the spiritual growth of another\" and simple narcissism. In combination, love is an activity, not simply a feeling.\n",
            "Psychologist Erich Fromm maintained in his book The Art of Loving that love is not merely a feeling but is also actions, and that in fact the \"feeling\" of love is superficial in comparison to one's commitment to love via a series of loving actions over time. Fromm held that love is ultimately not a feeling at all, but rather is a commitment to, and adherence to, loving actions towards another, oneself, or many others, over a sustained duration. Fromm also described love as a conscious choice that in its early stages might originate as an involuntary feeling, but which then later no longer depends on those feelings, but rather depends only on conscious commitment.\n",
            "\n",
            "\n",
            "=== Evolutionary basis ===\n",
            "Evolutionary psychology has attempted to provide various reasons for love as a survival tool. Humans are dependent on parental help for a large portion of their lifespans compared to other mammals. Love has therefore been seen as a mechanism to promote parental support of children for this extended time period. Furthermore, researchers as early as Charles Darwin identified unique features of human love compared to other mammals and credited love as a major factor for creating social support systems that enabled the development and expansion of the human species. Another factor may be that sexually transmitted diseases can cause, among other effects, permanently reduced fertility, injury to the fetus, and increase complications during childbirth. This would favor monogamous relationships over polygamy.\n",
            "\n",
            "\n",
            "=== Adaptive benefit ===\n",
            "Interpersonal love between a man and woman provides an evolutionary adaptive benefit since it facilitates mating and sexual reproduction. However, some organisms can reproduce asexually without mating. Understanding the adaptive benefit of interpersonal love depends on understanding the adaptive benefit of sexual reproduction as opposed to asexual reproduction. Richard Michod reviewed evidence that love, and consequently sexual reproduction, provides two major adaptive advantages. First, sexual reproduction facilitates repair of damages in the DNA that is passed from parent to progeny (during meiosis, a key stage of the sexual process). Second, a gene in either parent may contain a harmful mutation, but in the progeny produced by sexual reproduction, expression of a harmful mutation introduced by one parent is likely to be masked by expression of the unaffected homologous gene from the other parent.\n",
            "\n",
            "\n",
            "=== Comparison of scientific models ===\n",
            "Biological models of love tend to see it as a mammalian drive, similar to hunger or thirst. Psychology sees love as more of a social and cultural phenomenon. Love is influenced by hormones (such as oxytocin), neurotrophins (such as NGF), and pheromones, and how people think and behave in love is influenced by their conceptions of love. The conventional view in biology is that there are two major drives in love: sexual attraction and attachment. Attachment between adults is presumed to work on the same principles that lead an infant to become attached to its mother. The traditional psychological view sees love as being a combination of companionate love and passionate love. Passionate love is intense longing, and is often accompanied by physiological arousal (shortness of breath, rapid heart rate); companionate love is affection and a feeling of intimacy not accompanied by physiological arousal.\n",
            "\n",
            "\n",
            "== Cultural views ==\n",
            "\n",
            "\n",
            "=== Ancient Greek ===\n",
            "\n",
            "Greek distinguishes several different senses in which the word \"love\" is used. Ancient Greeks identified four forms of love: kinship or familiarity (storge), friendship and/or platonic desire (philia), sexual and/or romantic desire (eros), and self-emptying or divine love (agape). Modern authors have distinguished further varieties of romantic love. However, with Greek (as with many other languages), it has been historically difficult to separate the meanings of these words totally. At the same time, the Ancient Greek text of the Bible has examples of the verb agapo having the same meaning as phileo.\n",
            "\n",
            "Agape (ἀγάπη agápē)\n",
            "love in modern-day Greek. The term s'agapo means I love you in Greek. The word agapo is the verb I love. It generally refers to a \"pure,\" ideal type of love, rather than the physical attraction suggested by eros. However, there are some examples of agape used to mean the same as eros. It has also been translated as \"love of the soul.\"Eros (ἔρως érōs)\n",
            "(from the Greek deity Eros) is passionate love, with sensual desire and longing. The Greek word erota means in love. Plato refined his own definition. Although eros is initially felt for a person, with contemplation it becomes an appreciation of the beauty within that person, or even becomes appreciation of beauty itself. Eros helps the soul recall knowledge of beauty and contributes to an understanding of spiritual truth. Lovers and philosophers are all inspired to seek truth by eros. Some translations list it as \"love of the body\".Philia (φιλία philía)\n",
            "dispassionate virtuous love, was a concept addressed and developed by Aristotle in his Nicomachean Ethics Book VIII. It includes loyalty to friends, family, and community, and requires virtue, equality, and familiarity. Philia is motivated by practical reasons; one or both of the parties benefit from the relationship. It can also mean \"love of the mind.\"Storge (στοργή storgē)\n",
            "natural affection, like that felt by parents for offspringXenia (ξενία xenía)\n",
            "hospitality, was an extremely important practice in ancient Greece. It was an almost ritualized friendship formed between a host and his guest, who could previously have been strangers. The host fed and provided quarters for the guest, who was expected to repay only with gratitude. The importance of this can be seen throughout Greek mythology—in particular, Homer's Iliad and Odyssey.\n",
            "\n",
            "\n",
            "=== Ancient Roman (Latin) ===\n",
            "The Latin language has several verbs corresponding to the English word \"love.\" amō is the basic verb meaning I love, with the infinitive amare (\"to love\") as it still is in Italian today. The Romans used it both in an affectionate sense as well as in a romantic or sexual sense. From this verb come amans—a lover, amator, \"professional lover,\" often with the accessory notion of lechery—and amica, \"girlfriend\" in the English sense, often being applied euphemistically to a prostitute. The corresponding noun is amor (the significance of this term for the Romans is well illustrated in the fact, that the name of the city, Rome—in Latin: Roma—can be viewed as an anagram for amor, which was used as the secret name of the City in wide circles in ancient times), which is also used in the plural form to indicate love affairs or sexual adventures. This same root also produces amicus—\"friend\"—and amicitia, \"friendship\" (often based to mutual advantage, and corresponding sometimes more closely to \"indebtedness\" or \"influence\"). Cicero wrote a treatise called On Friendship (de Amicitia), which discusses the notion at some length. Ovid wrote a guide to dating called Ars Amatoria (The Art of Love), which addresses, in depth, everything from extramarital affairs to overprotective parents.\n",
            "Latin sometimes uses amāre where English would simply say to like. This notion, however, is much more generally expressed in Latin by the terms placere or delectāre, which are used more colloquially, the latter used frequently in the love poetry of Catullus. Diligere often implies \"to be affectionate for,\" \"to esteem,\" and rarely if ever is used for romantic love. This word would be appropriate to describe the friendship of two men. The corresponding noun diligentia, however, has the meaning of \"diligence\" or \"carefulness,\" and has little semantic overlap with the verb. Observare is a synonym for diligere; despite the cognate with English, this verb and its corresponding noun, observantia, often denote \"esteem\" or \"affection.\" Caritas is used in Latin translations of the Christian Bible to mean \"charitable love\"; this meaning, however, is not found in Classical pagan Roman literature. As it arises from a conflation with a Greek word, there is no corresponding verb.\n",
            "\n",
            "\n",
            "=== Chinese and other Sinic ===\n",
            "Two philosophical underpinnings of love exist in the Chinese tradition, one from Confucianism which emphasized actions and duty while the other came from Mohism which championed a universal love. A core concept to Confucianism is 仁 (Ren, \"benevolent love\"), which focuses on duty, action, and attitude in a relationship rather than love itself. In Confucianism, one displays benevolent love by performing actions such as filial piety from children, kindness from parents, loyalty to the king and so forth.\n",
            "The concept of 愛 (Mandarin: ài) was developed by the Chinese philosopher Mozi in the 4th century BCE in reaction to Confucianism's benevolent love. Mozi tried to replace what he considered to be the long-entrenched Chinese over-attachment to family and clan structures with the concept of \"universal love\" (兼愛, jiān'ài). In this, he argued directly against Confucians who believed that it was natural and correct for people to care about different people in different degrees. Mozi, by contrast, believed people in principle should care for all people equally. Mohism stressed that rather than adopting different attitudes towards different people, love should be unconditional and offered to everyone without regard to reciprocation; not just to friends, family, and other Confucian relations. Later in Chinese Buddhism, the term Ai (愛) was adopted to refer to a passionate, caring love and was considered a fundamental desire. In Buddhism, Ai was seen as capable of being either selfish or selfless, the latter being a key element towards enlightenment.\n",
            "In Mandarin Chinese, 愛 (ài) is often used as the equivalent of the Western concept of love. 愛 (ài) is used as both a verb (e.g. 我愛你, Wǒ ài nǐ, or \"I love you\") and a noun (such as 愛情 àiqíng, or \"romantic love\"). However, due to the influence of Confucian 仁 (rén), the phrase 我愛你 (Wǒ ài nǐ, I love you) carries with it a very specific sense of responsibility, commitment, and loyalty. Instead of frequently saying \"I love you\" as in some Western societies, the Chinese are more likely to express feelings of affection in a more casual way. Consequently, \"I like you\" (我喜欢你, Wǒ xǐhuan nǐ) is a more common way of expressing affection in Mandarin; it is more playful and less serious. This is also true in Japanese (suki da, 好きだ).\n",
            "\n",
            "\n",
            "=== Japanese ===\n",
            "The Japanese language uses three words to convey the English equivalent of \"love\". Because \"love\" covers a wide range of emotions and behavioral phenomena, there are nuances distinguishing the three terms. The term ai (愛), which is often associated with maternal love or selfless love, originally referred to beauty and was often used in a religious context. Following the Meiji Restoration of 1868, the term became associated with \"love\" in order to translate Western literature.\n",
            "Prior to Western influence, the term koi (恋 or 孤悲) generally represented romantic love, and was often the subject of the popular Man'yōshū Japanese poetry collection. Koi describes a longing for a member of the opposite sex and is typically interpreted as selfish and wanting. The term's origins come from the concept of lonely solitude as a result of separation from a loved one. Though modern usage of koi focuses on sexual love and infatuation, the Manyō used the term to cover a wider range of situations, including tenderness, benevolence, and material desire.The third term, ren'ai (恋愛), is a more modern construction that combines the kanji characters for both ai and koi, though its usage more closely resembles that of koi in the form of romantic love.Amae (甘え), referring to the desire to be loved and cared for by an authority figure, is another important aspect of Japan's cultural perspective on love, and has been analysed in detail in Takeo Doi's The Anatomy of Dependence\n",
            "\n",
            "\n",
            "=== Indian ===\n",
            "In contemporary literature, the Sanskrit words for love is sneha. Other terms include priya which refers to innocent love, prema refers to spiritual love, and kama refers usually to sexual desire. However, the term also refers to any sensory enjoyment, emotional attraction and aesthetic pleasure such as from arts, dance, music, painting, sculpture and nature.The concept of kama is found in some of the earliest known verses in Vedas. For example, Book 10 of Rig Veda describes the creation of the universe from nothing by the great heat. In hymn 129, it states:\n",
            "\n",
            "\n",
            "=== Persian ===\n",
            "\n",
            "Rumi, Hafiz, and Sa'di are icons of the passion and love that the Persian culture and language present. The Persian word for love is Ishq, which is derived from Arabic; however, it is considered by most to be too stalwart a term for interpersonal love and is more commonly substituted with \"doost dashtan\" (\"liking\"). In the Persian culture, everything is encompassed by love and all is for love, starting from loving friends and family, husbands and wives, and eventually reaching the divine love that is the ultimate goal in life.\n",
            "\n",
            "\n",
            "== Religious views ==\n",
            "\n",
            "\n",
            "=== Abrahamic ===\n",
            "\n",
            "\n",
            "==== Judaism ====\n",
            "\n",
            "In Hebrew, אהבה (ahava) is the most commonly used term for both interpersonal love and love between God and God's creations. Chesed, often translated as loving-kindness, is used to describe many forms of love between human beings.\n",
            "The commandment to love other people is given in the Torah, which states, \"Love your neighbor like yourself\" (Leviticus 19:18). The Torah's commandment to love God \"with all your heart, with all your soul and with all your might\" (Deuteronomy 6:5) is taken by the Mishnah (a central text of the Jewish oral law) to refer to good deeds, willingness to sacrifice one's life rather than commit certain serious transgressions, willingness to sacrifice all of one's possessions, and being grateful to the Lord despite adversity (tractate Berachoth 9:5). Rabbinic literature differs as to how this love can be developed, e.g., by contemplating divine deeds or witnessing the marvels of nature.\n",
            "As for love between marital partners, this is deemed an essential ingredient to life: \"See life with the wife you love\" (Ecclesiastes 9:9). Rabbi David Wolpe writes that \"love is not only about the feelings of the lover... It is when one person believes in another person and shows it.\" He further states that \"love... is a feeling that expresses itself in action. What we really feel is reflected in what we do.\" The biblical book Song of Solomon is considered a romantically phrased metaphor of love between God and his people, but in its plain reading it reads like a love song. The 20th-century rabbi Eliyahu Eliezer Dessler is frequently quoted as defining love from the Jewish point of view as \"giving without expecting to take\".\n",
            "\n",
            "\n",
            "==== Christianity ====\n",
            "The Christian understanding is that love comes from God, who is himself love (1 John 4:8). The love of man and woman—eros in Greek—and the unselfish love of others (agape), are often contrasted as \"descending\" and \"ascending\" love, respectively, but are ultimately the same thing.There are several Greek words for \"love\" that are regularly referred to in Christian circles.\n",
            "\n",
            "agape\n",
            "In the New Testament, agapē is charitable, selfless, altruistic, and unconditional. It is parental love, seen as creating goodness in the world; it is the way God is seen to love humanity, and it is seen as the kind of love that Christians aspire to have for one another.\n",
            "phileo\n",
            "Also used in the New Testament, phileo is a human response to something that is found to be delightful. Also known as \"brotherly love.\"Two other words for love in the Greek language, eros (sexual love) and storge (child-to-parent love), were never used in the New Testament.Christians believe that to love God with all your heart, mind, and strength and love your neighbor as yourself are the two most important things in life (the greatest commandment of the Jewish Torah, according to Jesus; cf. Gospel of Mark 12:28–34). Saint Augustine summarized this when he wrote \"Love God, and do as thou wilt.\"The Apostle Paul glorified love as the most important virtue of all. Describing love in the famous poetic interpretation in 1 Corinthians, he wrote, \"Love is patient, love is kind. It does not envy, it does not boast, it is not proud. It is not rude, it is not self-seeking, it is not easily angered, it keeps no record of wrongs. Love does not delight in evil but rejoices with the truth. It always protects, always trusts, always hopes, and always perseveres.\" (1 Corinthians 13:4–7)\n",
            "The Apostle John wrote, \"For God so loved the world that he gave his one and only Son, that whoever believes in him shall not perish but have eternal life. For God did not send his Son into the world to condemn the world, but to save the world through him.\" (John 3:16–17) John also wrote, \"Dear friends, let us love one another for love comes from God. Everyone who loves has been born of God and knows God. Whoever does not love does not know God, because God is love.\" (1 John 4:7–8)\n",
            "Saint Augustine wrote that one must be able to decipher the difference between love and lust. Lust, according to Saint Augustine, is an overindulgence, but to love and be loved is what he has sought for his entire life. He even says, \"I was in love with love.\" Finally, he does fall in love and is loved back, by God. Saint Augustine says the only one who can love you truly and fully is God, because love with a human only allows for flaws such as \"jealousy, suspicion, fear, anger, and contention.\": III.1  According to Saint Augustine, to love God is \"to attain the peace which is yours.\": X.27 Augustine regards the duplex commandment of love in Matthew 22 as the heart of Christian faith and the interpretation of the Bible. After the review of Christian doctrine, Augustine treats the problem of love in terms of use and enjoyment until the end of Book I of De Doctrina Christiana (1.22.21–1.40.44).Christian theologians see God as the source of love, which is mirrored in humans and their own loving relationships. Influential Christian theologian C. S. Lewis wrote a book called The Four Loves. Benedict XVI named his first encyclical God is love. He said that a human being, created in the image of God, who is love, is able to practice love; to give himself to God and others (agape) and by receiving and experiencing God's love in contemplation (eros). This life of love, according to him, is the life of the saints such as Teresa of Calcutta and Mary, the mother of Jesus and is the direction Christians take when they believe that God loves them.\n",
            "Pope Francis asserts that the \"Cross (Jesus crucified) is the greatest meaning of the greatest love,\" and in the crucifixion is found everything, all knowledge and the entirety of God's love. Pope Francis taught that \"True love is both loving and letting oneself be loved... what is important in love is not our loving, but allowing ourselves to be loved by God.\" And so, in the analysis of a Catholic theologian, for Pope Francis, \"the key to love... is not our activity. It is the activity of the greatest, and the source, of all the powers in the universe: God's.\"In Christianity the practical definition of love is summarised by Thomas Aquinas, who defined love as \"to will the good of another,\" or to desire for another to succeed. This is an explanation of the Christian need to love others, including their enemies. Thomas Aquinas explains that Christian love is motivated by the need to see others succeed in life, to be good people.\n",
            "Regarding love for enemies, Jesus is quoted in the Gospel of Matthew:\n",
            "\n",
            "You have heard that it was said, \"Love your neighbor and hate your enemy.\" But I tell you, love your enemies and pray for those who persecute you, that you may be children of your Father in heaven. He causes his sun to rise on the evil and the good, and sends rain on the righteous and the unrighteous. If you love those who love you, what reward will you get? Are not even the tax collectors doing that? And if you greet only your own people, what are you doing more than others? Do not even pagans do that? Be perfect, therefore, as your heavenly Father is perfect.\n",
            "Tertullian wrote regarding love for enemies: \"Our individual, extraordinary, and perfect goodness consists in loving our enemies. To love one's friends is common practice, to love one's enemies only among Christians.\"\n",
            "\n",
            "\n",
            "==== Islam ====\n",
            "Love encompasses the Islamic view of life as universal brotherhood that applies to all who hold faith. Among the 99 names of God (Allah) is the name Al-Wadud, or \"the Loving One,\" which is found in Surah 11:90 and 85:14. God is also referenced at the beginning of every chapter in the Qur'an as Ar-Rahman and Ar-Rahim, or the \"Most Compassionate\" and the \"Most Merciful\", indicating that nobody is more loving, compassionate, and benevolent than God. The Qur'an refers to God as being \"full of loving kindness.\"\n",
            "The Qur'an exhorts Muslim believers to treat all people, those who have not persecuted them, with birr or \"deep kindness\" as stated in Surah 6:8-9. Birr is also used by the Qur'an to describe the love and kindness that children must show to their parents.\n",
            "Ishq, or divine love, is emphasized by Sufism in the Islamic tradition. Practitioners of Sufism believe that love is a projection of the essence of God into the universe. God desires to recognize beauty, and as if one looks at a mirror to see oneself, God \"looks\" at himself within the dynamics of nature. Since everything is a reflection of God, the school of Sufism practices seeing the beauty inside the apparently ugly. Sufism is often referred to as the religion of love. God in Sufism is referred to in three main terms—Lover, Loved, and Beloved—with the last of these terms often seen in Sufi poetry. A common viewpoint of Sufism is that through love, humankind can return to its inherent purity and grace. The saints of Sufism are infamous for being \"drunk\" due to their love of God; hence, the constant reference to wine in Sufi poetry and music.\n",
            "\n",
            "\n",
            "==== Bahá'í Faith ====\n",
            "In his Paris Talks, `Abdu'l-Bahá described four types of love: the love that flows from God to human beings; the love that flows from human beings to God; the love of God towards the Self or Identity of God; and the love of human beings for human beings.\n",
            "\n",
            "\n",
            "=== Dharmic ===\n",
            "\n",
            "\n",
            "==== Buddhism ====\n",
            "In Buddhism, kāma is sensuous, sexual love. It is an obstacle on the path to enlightenment, since it is selfish. Karuṇā is compassion and mercy, which reduces the suffering of others. It is complementary to wisdom and is necessary for enlightenment. Adveṣa and mettā are benevolent love. This love is unconditional and requires considerable self-acceptance. This is quite different from ordinary love, which is usually about attachment and sex and which rarely occurs without self-interest. Instead, in Buddhism love refers to detachment and unselfish interest in others' welfare.\n",
            "The Bodhisattva ideal in Mahayana Buddhism involves the complete renunciation of oneself in order to take on the burden of a suffering world.\n",
            "\n",
            "\n",
            "==== Hinduism ====\n",
            "\n",
            "In Hinduism, kāma is pleasurable, sexual love, personified by the god Kamadeva. For many Hindu schools, it is the third end (Kama) in life. Kamadeva is often pictured holding a bow of sugar cane and an arrow of flowers; he may ride upon a great parrot. He is usually accompanied by his consort Rati and his companion Vasanta, lord of the spring season. Stone images of Kamadeva and Rati can be seen on the door of the Chennakeshava temple at Belur, in Karnataka, India. Maara is another name for kāma.In contrast to kāma, prema—or premefers to elevated love. Karuṇā is compassion and mercy, which impels one to help reduce the suffering of others. Bhakti is a Sanskrit term meaning \"loving devotion to the supreme God.\" A person who practices bhakti is called a bhakta. Hindu writers, theologians, and philosophers have distinguished nine forms of bhakti, which can be found in the Bhagavata Purana and works by Tulsidas. The philosophical work Narada Bhakti Sutra, written by an unknown author (presumed to be Narada), distinguishes eleven forms of love.\n",
            "In certain Vaishnava sects within Hinduism, attaining unadulterated, unconditional, and incessant love for the Godhead is considered the foremost goal of life. Gaudiya Vaishnavas who worship Krishna as the Supreme Personality of Godhead and the cause of all causes consider Love for Godhead (Prema) to act in two ways: sambhoga and vipralambha (union and separation)—two opposites.In the condition of separation, there is an acute yearning for being with the beloved and in the condition of union, there is supreme happiness and nectarean. Gaudiya Vaishnavas consider that Krishna-prema (Love for Godhead) burns away one's material desires, pierces the heart, and washes away everything—one's pride, one's religious rules, and one's shyness. Krishna-prema is considered to make one drown in the ocean of transcendental ecstasy and pleasure. The love of Radha, a cowherd girl, for Krishna is often cited as the supreme example of love for Godhead by Gaudiya Vaishnavas. Radha is considered to be the internal potency of Krishna, and is the supreme lover of Godhead. Her example of love is considered to be beyond the understanding of material realm as it surpasses any form of selfish love or lust that is visible in the material world. The reciprocal love between Radha (the supreme lover) and Krishna (God as the Supremely Loved) is the subject of many poetic compositions in India such as the Gita Govinda of Jayadeva and Hari Bhakti Shuddhodhaya.\n",
            "In the Bhakti tradition within Hinduism, it is believed that execution of devotional service to God leads to the development of Love for God (taiche bhakti-phale krsne prema upajaya), and as love for God increases in the heart, the more one becomes free from material contamination (krishna-prema asvada haile, bhava nasa paya). Being perfectly in love with God or Krishna makes one perfectly free from material contamination, and this is the ultimate way of salvation or liberation. In this tradition, salvation or liberation is considered inferior to love, and just an incidental by-product. Being absorbed in Love for God is considered to be the perfection of life.\n",
            "\n",
            "\n",
            "== Political views ==\n",
            "\n",
            "\n",
            "=== Free love ===\n",
            "\n",
            "The term \"free love\" has been used to describe a social movement that rejects marriage, which is seen as a form of social bondage. The free love movement's initial goal was to separate the state from sexual matters such as marriage, birth control, and adultery. It claimed that such issues were the concern of the people involved, and no one else.Many people in the early 19th century believed that marriage was an important aspect of life to \"fulfill earthly human happiness.\" Middle-class Americans wanted the home to be a place of stability in an uncertain world. This mentality created a vision of strongly defined gender roles, which provoked the advancement of the free love movement as a contrast.Advocates of free love had two strong beliefs: opposition to the idea of forceful sexual activity in a relationship and advocacy for a woman to use her body in any way that she pleases. These are also beliefs of feminism.\n",
            "\n",
            "\n",
            "== Philosophical views ==\n",
            "\n",
            "The philosophy of love is a field of social philosophy and ethics that attempts to explain the nature of love. The philosophical investigation of love includes the tasks of distinguishing between the various kinds of personal love, asking if and how love is or can be justified, asking what the value of love is, and what impact love has on the autonomy of both the lover and the beloved.\n",
            "\n",
            "\n",
            "== Literature depictions ==\n",
            "\n",
            "\n",
            "== See also ==\n",
            "Color wheel theory of love – Idea created by psychologist John Alan LeePages displaying short descriptions of redirect targets\n",
            "Finger heart – Hand gesture\n",
            "Hand heart – Affectionate hand gesture\n",
            "Heart in hand – Symbol of charity\n",
            "Human bonding – Process of development of a close, interpersonal relationship\n",
            "ILY sign – American Sign Language gesture\n",
            "Love at first sight – Falling in long-lasting love with someone on first sight\n",
            "Love-in – Peaceful public gatheringPages displaying wikidata descriptions as a fallback\n",
            "Pair bond – Biological term\n",
            "Polyamory – Intimacy for multiple partners\n",
            "Relationship science – Field dedicated to the scientific study of interpersonal relationship processes\n",
            "Romance (love) – Type of love that focuses on feelings\n",
            "Self-love – Concept in philosophy and psychology\n",
            "Social connection – Term in psychology referring to the experience of feeling close and connected to others\n",
            "Traditional forms, Agape, Philia, Philautia, Storge, Eros: Greek terms for love\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Sources ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "Bayer, A, ed. (2008). Art and love in Renaissance Italy. New York: The Metropolitan Museum of Art.\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "History of Love, Internet Encyclopedia of Philosophy\n",
            "Friendship at Curlie\n",
            "Philanthropy at Curlie\n",
            "Romance at Curlie...\n",
            "\n",
            "\n",
            "Page Title: Plant\n",
            "Text: A plan is typically any diagram or list of steps with details of timing and resources, used to achieve an objective to do something. It is commonly understood as a temporal set of intended actions through which one expects to achieve a goal.\n",
            "For spatial or planar topologic or topographic sets see map.\n",
            "Plans can be formal or informal:\n",
            "\n",
            "Structured and formal plans, used by multiple people, are more likely to occur in projects, diplomacy, careers, economic development, military campaigns, combat, sports, games, or in the conduct of other business. In most cases, the absence of a well-laid plan can have adverse effects: for example, a non-robust project plan can cost the organization time and money.\n",
            "Informal or ad hoc plans are created by individuals in all of their pursuits.The most popular ways to describe plans are by their breadth, time frame, and specificity; however, these planning classifications are not independent of one another. For instance, there is a close relationship between the short- and long-term categories and the strategic and operational categories.\n",
            "It is common for less formal plans to be created as abstract ideas, and remain in that form as they are maintained and put to use. More formal plans as used for business and military purposes, while initially created with and as an abstract thought, are likely to be written down, drawn up or otherwise stored in a form that is accessible to multiple people across time and space. This allows more reliable collaboration in the execution of the plan.\n",
            "\n",
            "\n",
            "== Topics ==\n",
            "\n",
            "\n",
            "=== Planning ===\n",
            "The term planning implies the working out of sub-components in some degree of elaborate detail. Broader-brush enunciations of objectives may qualify as metaphorical roadmaps. Planning literally just means the creation of a plan; it can be as simple as making a list. It has not acquired a technical meaning, however, to cover the area of government legislation and regulations elated to the use of resources.\n",
            "Planning can refer to the planned use of any and all resources, as in the succession of Five-Year Plans through which the government of the Soviet Union sought to develop the country. However, the term is most frequently used in relation to planning for the use of land and related resources, for example in urban planning, transportation planning, etc.\n",
            "In a governmental context, \"planning\" without any qualification is most likely to mean the regulation of land use. See also zoning.\n",
            "\n",
            "\n",
            "=== Planners ===\n",
            "Planners are the professionals that have the requisite training to take or make decisions that will help or balance the society in order to have a functional, aesthetic, and convenient environment.\n",
            "\n",
            "\n",
            "=== Methodology ===\n",
            "Concepts such as top-down planning (as opposed to bottom-up planning) reveal similarities with the systems thinking behind the top-down model.\n",
            "The subject touches such broad fields as psychology, game theory, communications and information theory, which inform the planning methods that people seek to use and refine; as well as logic and science (i.e. methodological naturalism) which serve as a means of testing different parts of a plan for reliability or consistency.\n",
            "The specific methods used to create and refine plans depend on who is to make it, who is to put it to use, and what resources are available for the task. The methods used by an individual in his or her mind or personal organizer, may be very different from the collection of planning techniques found in a corporate board-room, and the planning done by a project manager has different priorities and uses different tools to the planning done by an engineer or industrial designer.\n",
            "\n",
            "\n",
            "== Examples of plans ==\n",
            "Architectural plan\n",
            "Business plan\n",
            "Fragplan\n",
            "Flight plan\n",
            "Health plan\n",
            "Marketing plan\n",
            "Military plan\n",
            "Project plan\n",
            "Site plan\n",
            "The Schlieffen Plan\n",
            "The Five-Year Plan system in the former Soviet Union\n",
            "The Marshall Plan\n",
            "\n",
            "\n",
            "== See also ==\n",
            "Automated planning\n",
            "Critical path method\n",
            "PDCA (plan–do–check–act)\n",
            "Program evaluation and review technique (PERT)\n",
            "Roadmap\n",
            "Strategy\n",
            "\n",
            "\n",
            "== References ==...\n",
            "\n",
            "\n",
            "Page Title: Planet\n",
            "Text: Plants are the eukaryotes that form the kingdom Plantae; they are predominantly photosynthetic. This means that they obtain their energy from sunlight, using chloroplasts derived from endosymbiosis with cyanobacteria to produce sugars from carbon dioxide and water, using the green pigment chlorophyll. Exceptions are parasitic plants that have lost the genes for chlorophyll and photosynthesis, and obtain their energy from other plants or fungi.\n",
            "Historically, as in Aristotle's biology, the plant kingdom encompassed all living things that were not animals, and included algae and fungi. Definitions have narrowed since then; current definitions exclude the fungi and some of the algae. By the definition used in this article, plants form the clade Viridiplantae (green plants), which consists of the green algae and the embryophytes or land plants (hornworts, liverworts, mosses, lycophytes, ferns, conifers and other gymnosperms, and flowering plants). A definition based on genomes includes the Viridiplantae, along with the red algae and the glaucophytes, in the clade Archaeplastida.\n",
            "There are about 380,000 known species of plants, of which the majority, some 260,000, produce seeds. They range in size from single cells to the tallest trees. Green plants provide a substantial proportion of the world's molecular oxygen; the sugars they create supply the energy for most of Earth's ecosystems; other organisms, including animals, either consume plants directly or rely on organisms which do so.\n",
            "Grain, fruit, and vegetables are basic human foods and have been domesticated for millennia. People use plants for many purposes, such as building materials, ornaments, writing materials, and, in great variety, for medicines. The scientific study of plants is known as botany, a branch of biology.\n",
            "\n",
            "\n",
            "== Definition ==\n",
            "\n",
            "\n",
            "=== Taxonomic history ===\n",
            "\n",
            "All living things were traditionally placed into one of two groups, plants and animals. This classification dates from Aristotle (384–322 BC), who distinguished different levels of beings in his biology, based on whether living things had a \"sensitive soul\" or like plants only a \"vegetative soul\". Theophrastus, Aristotle's student, continued his work in plant taxonomy and classification. Much later, Linnaeus (1707–1778) created the basis of the modern system of scientific classification, but retained the animal and plant kingdoms, naming the plant kingdom the Vegetabilia.\n",
            "\n",
            "\n",
            "=== Alternative concepts ===\n",
            "When the name Plantae or plant is applied to a specific group of organisms or taxa, it usually refers to one of four concepts. From least to most inclusive, these four groupings are:\n",
            "\n",
            "\n",
            "== Evolution ==\n",
            "\n",
            "\n",
            "=== Diversity ===\n",
            "There are about 382,000 accepted species of plants, of which the great majority, some 283,000, produce seeds. The table below shows some species count estimates of different green plant (Viridiplantae) divisions. About 85–90% of all plants are flowering plants. Several projects are currently attempting to collect records on all plant species in online databases, e.g. the World Flora Online.Plants range in scale from single-celled organisms such as desmids (from 10 micrometres across) and picozoa (less than 3 micrometres across), to the largest trees (megaflora) such as the conifer Sequoia sempervirens (up to 380 feet (120 m) tall ) and the angiosperm Eucalyptus regnans (up to 325 feet (99 m) tall ).\n",
            "The naming of plants is governed by the International Code of Nomenclature for algae, fungi, and plants and the International Code of Nomenclature for Cultivated Plants.\n",
            "\n",
            "\n",
            "=== Evolutionary history ===\n",
            "\n",
            "The ancestors of land plants evolved in water. An algal scum formed on the land 1,200 million years ago, but it was not until the Ordovician, around 450 million years ago, that the first land plants appeared, with a level of organisation like that of bryophytes. However, evidence from carbon isotope ratios in Precambrian rocks suggests that complex plants developed over 1000 mya.Primitive land plants began to diversify in the late Silurian, around 420 million years ago. Bryophytes, club mosses, and ferns then appear in the fossil record. Early plant anatomy is preserved in cellular detail in an early Devonian fossil assemblage from the Rhynie chert. These early plants were preserved by being petrified in chert formed in silica-rich volcanic hot springs.By the end of the Devonian, most of the basic features of plants today were present, including roots, leaves and secondary wood in trees such as Archaeopteris. The Carboniferous Period saw the development of forests in swampy environments dominated by clubmosses and horsetails, including some as large as trees, and the appearance of early gymnosperms, the first seed plants. The Permo-Triassic extinction event radically changed the structures of communities. This may have set the scene for the evolution of flowering plants in the Triassic (~200 million years ago), with an adaptive radiation in the Cretaceous so rapid that Darwin called it an \"abominable mystery\". Conifers diversified from the Late Triassic onwards, and became a dominant part of floras in the Jurassic.\n",
            "\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\n",
            "\n",
            "=== Phylogeny ===\n",
            "In 2019, a phylogeny based on genomes and transcriptomes from 1,153 plant species was proposed. The placing of algal groups is supported by phylogenies based on genomes from the Mesostigmatophyceae and Chlorokybophyceae that have since been sequenced. Both the \"chlorophyte algae\" and the \"streptophyte algae\" are treated as paraphyletic (vertical bars beside phylogenetic tree diagram) in this analysis, as the land plants arose from within those groups. The classification of Bryophyta is supported both by Puttick et al. 2018, and by phylogenies involving the hornwort genomes that have also since been sequenced.\n",
            "\n",
            "\n",
            "== Physiology ==\n",
            "\n",
            "\n",
            "=== Plant cells ===\n",
            "\n",
            "Plant cells have distinctive features that other eukaryotic cells (such as those of animals) lack. These include the large water-filled central vacuole, chloroplasts, and the strong flexible cell wall, which is outside the cell membrane. Chloroplasts are derived from what was once a symbiosis of a non-photosynthetic cell and photosynthetic cyanobacteria. The cell wall, made mostly of cellulose, allows plant cells to swell up with water without bursting. The vacuole allows the cell to change in size while the amount of cytoplasm stays the same.\n",
            "\n",
            "\n",
            "=== Plant structure ===\n",
            "\n",
            "Most plants are multicellular. Plant cells differentiate into multiple cell types, forming tissues such as the vascular tissue with specialized xylem and phloem of leaf veins and stems, and organs with different physiological functions such as roots to absorb water and minerals, stems for support and to transport water and synthesized molecules, leaves for photosynthesis, and flowers for reproduction.\n",
            "\n",
            "\n",
            "=== Photosynthesis ===\n",
            "\n",
            "Plants photosynthesize, manufacturing food molecules (sugars) using energy obtained from light. Plant cells contain chlorophylls inside their chloroplasts, which are green pigments that are used to capture light energy. The end-to-end chemical equation for photosynthesis is:\n",
            "\n",
            "  \n",
            "    \n",
            "      \n",
            "        \n",
            "          6\n",
            "          \n",
            "          \n",
            "            CO\n",
            "            \n",
            "              2\n",
            "            \n",
            "            \n",
            "              \n",
            "            \n",
            "          \n",
            "          \n",
            "\n",
            "          \n",
            "          +\n",
            "          6\n",
            "          \n",
            "          \n",
            "            H\n",
            "            \n",
            "              2\n",
            "            \n",
            "            \n",
            "              \n",
            "            \n",
            "          \n",
            "          O\n",
            "          \n",
            "\n",
            "          \n",
            "          \n",
            "            \n",
            "              →\n",
            "              \n",
            "                \n",
            "                  light\n",
            "                \n",
            "              \n",
            "            \n",
            "          \n",
            "          \n",
            "            C\n",
            "            \n",
            "              6\n",
            "            \n",
            "            \n",
            "              \n",
            "            \n",
            "          \n",
            "          \n",
            "            H\n",
            "            \n",
            "              12\n",
            "            \n",
            "            \n",
            "              \n",
            "            \n",
            "          \n",
            "          \n",
            "            O\n",
            "            \n",
            "              6\n",
            "            \n",
            "            \n",
            "              \n",
            "            \n",
            "          \n",
            "          \n",
            "\n",
            "          \n",
            "          +\n",
            "          6\n",
            "          \n",
            "          \n",
            "            O\n",
            "            \n",
            "              2\n",
            "            \n",
            "            \n",
            "              \n",
            "            \n",
            "          \n",
            "          \n",
            "\n",
            "          \n",
            "        \n",
            "      \n",
            "    \n",
            "    {\\displaystyle {\\ce {6CO2{}+6H2O{}->[{\\text{light}}]C6H12O6{}+6O2{}}}}\n",
            "  This causes plants to release oxygen into the atmosphere. Green plants provide a substantial proportion of the world's molecular oxygen, alongside the contributions from photosynthetic algae and cyanobacteria.Plants that have secondarily adopted a parasitic lifestyle may lose the genes involved in photosynthesis and the production of chlorophyll.\n",
            "\n",
            "\n",
            "=== Growth and repair ===\n",
            "Growth is determined by the interaction of a plant's genome with its physical and biotic environment. Factors of the physical or abiotic environment include temperature, water, light, carbon dioxide, and nutrients in the soil. Biotic factors that affect plant growth include crowding, grazing, beneficial symbiotic bacteria and fungi, and attacks by insects or plant diseases.Frost and dehydration can damage or kill plants. Some plants have antifreeze proteins, heat-shock proteins and sugars in their cytoplasm that enable them to tolerate these stresses. Plants are continuously exposed to a range of physical and biotic stresses which cause DNA damage, but they can tolerate and repair much of this damage.\n",
            "\n",
            "\n",
            "=== Reproduction ===\n",
            "\n",
            "Plants reproduce to generate offspring, whether sexually, involving gametes, or asexually, involving ordinary growth. Many plants use both mechanisms.\n",
            "\n",
            "\n",
            "==== Sexual ====\n",
            "When reproducing sexually, plants have complex lifecycles involving alternation of generations. One generation, the sporophyte, which is diploid (with 2 sets of chromosomes), gives rise to the next generation, the gametophyte, which is haploid (with one set of chromosomes). Some plants also reproduce asexually via spores. In some non-flowering plants such as mosses, the sexual gametophyte forms most of the visible plant. In seed plants (gymnosperms and flowering plants), the sporophyte forms most of the visible plant, and the gametophyte is very small. Flowering plants reproduce sexually using flowers, which contain male and female parts: these may be within the same (hermaphrodite) flower, on different flowers on the same plant, or on different plants. The pollen produces male gametes that enter the ovule to fertilize the egg cell of the female gametophyte. Fertilization takes place within the carpels or ovaries, which develop into fruits that contain seeds. Fruits may be dispersed whole, or they may split open and the seeds dispersed individually.\n",
            "\n",
            "\n",
            "==== Asexual ====\n",
            "Plants reproduce asexually by growing any of a wide variety of structures capable of growing into new plants. At the simplest, plants such as mosses or liverworts may be broken into pieces, each of which may regrow into whole plants. The propagation of flowering plants by cuttings is a similar process. Structures such as runners enable plants to grow to cover an area, forming a clone. Many plants grow food storage structures such as tubers or bulbs which may each develop into a new plant.Some non-flowering plants, such as many liverworts, mosses and some clubmosses, along with a few flowering plants, grow small clumps of cells called gemmae which can detach and grow.\n",
            "\n",
            "\n",
            "=== Disease resistance ===\n",
            "\n",
            "Plants use pattern-recognition receptors to recognize pathogens such as bacteria that cause plant diseases. This recognition triggers a protective response. The first such plant receptors were identified in rice and in Arabidopsis thaliana.\n",
            "\n",
            "\n",
            "=== Genomics ===\n",
            "\n",
            "Plants have some of the largest genomes among all organisms. The largest plant genome (in terms of gene number) is that of wheat (Triticum aestivum), predicted to encode ≈94,000 genes and thus almost 5 times as many as the human genome. The first plant genome sequenced was that of Arabidopsis thaliana which encodes about 25,500 genes. In terms of sheer DNA sequence, the smallest published genome is that of the carnivorous bladderwort (Utricularia gibba) at 82 Mb (although it still encodes 28,500 genes) while the largest, from the Norway spruce (Picea abies), extends over 19.6 Gb (encoding about 28,300 genes).\n",
            "\n",
            "\n",
            "== Ecology ==\n",
            "\n",
            "\n",
            "=== Distribution ===\n",
            "\n",
            "Plants are distributed almost worldwide. While they inhabit several biomes which can be divided into a multitude of ecoregions, only the hardy plants of the Antarctic flora, consisting of algae, mosses, liverworts, lichens, and just two flowering plants, have adapted to the prevailing conditions on that southern continent.Plants are often the dominant physical and structural component of the habitats where they occur. Many of the Earth's biomes are named for the type of vegetation because plants are the dominant organisms in those biomes, such as grassland, savanna, and tropical rainforest.\n",
            "\n",
            "\n",
            "=== Primary producers ===\n",
            "\n",
            "The photosynthesis conducted by land plants and algae is the ultimate source of energy and organic material in nearly all ecosystems. Photosynthesis, at first by cyanobacteria and later by photosynthetic eukaryotes, radically changed the composition of the early Earth's anoxic atmosphere, which as a result is now 21% oxygen. Animals and most other organisms are aerobic, relying on oxygen; those that do not are confined to relatively rare anaerobic environments. Plants are the primary producers in most terrestrial ecosystems and form the basis of the food web in those ecosystems. Plants form about 80% of the world biomass at about 450 gigatonnes (4.4×1011 long tons; 5.0×1011 short tons) of carbon.\n",
            "\n",
            "\n",
            "=== Ecological relationships ===\n",
            "\n",
            "Numerous animals have coevolved with plants; flowering plants have evolved pollination syndromes, suites of flower traits that favour their reproduction. Many, including insect and bird partners, are pollinators, visiting flowers and accidentally transferring pollen in exchange for food in the form of pollen or nectar.Many animals disperse seeds that are adapted for such dispersal. Various mechanisms of dispersal have evolved. Some fruits offer nutritious outer layers attractive to animals, while the seeds are adapted to survive the passage through the animal's gut; others have hooks that enable them to attach to a mammal's fur.Myrmecophytes are plants that have coevolved with ants. The plant provides a home, and sometimes food, for the ants. In exchange, the ants defend the plant from herbivores and sometimes competing plants. Ant wastes serve as organic fertilizer.The majority of plant species have fungi associated with their root systems in a mutualistic symbiosis known as mycorrhiza. The fungi help the plants gain water and mineral nutrients from the soil, while the plant gives the fungi carbohydrates manufactured in photosynthesis.\n",
            "Some plants serve as homes for endophytic fungi that protect the plant from herbivores by producing toxins. The fungal endophyte Neotyphodium coenophialum in tall fescue grass has pest status in the American cattle industry.Many legumes have Rhizobium nitrogen-fixing bacteria in nodules of their roots, which fix nitrogen from the air for the plant to use; in return, the plants supply sugars to the bacteria. Nitrogen fixed in this way can become available to other plants, and is important in agriculture; for example, farmers may grow a crop rotation of a legume such as beans, followed by a cereal such as wheat, to provide cash crops with a reduced input of nitrogen fertilizer.Some 1% of plants are parasitic. They range from the semi-parasitic mistletoe that merely takes some nutrients from its host, but still has photosynthetic leaves, to the fully-parasitic broomrape and toothwort that acquire all their nutrients through connections to the roots of other plants, and so have no chlorophyll. Full parasites can be extremely harmful to their plant hosts.Plants that grow on other plants, usually trees, without parasitizing them, are called epiphytes. These may support diverse arboreal ecosystems. Some may indirectly harm their host plant, such as by intercepting light. Hemiepiphytes like the strangler fig begin as epiphytes, but eventually set their own roots and overpower and kill their host. Many orchids, bromeliads, ferns, and mosses grow as epiphytes. Among the epiphytes, the bromeliads accumulate water in their leaf axils; these water-filled cavities can support complex aquatic food webs.Some 630 species of plants are carnivorous, such as the Venus flytrap (Dionaea muscipula) and sundew (Drosera species). They trap small animals and digest them to obtain mineral nutrients, especially nitrogen and phosphorus.\n",
            "\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\t\t\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\n",
            "\n",
            "\n",
            "=== Competition ===\n",
            "Competition for shared resources reduces a plant's growth. Shared resources include sunlight, water and nutrients. Light is a critical resource because it is necessary for photosynthesis. Plants use their leaves to shade other plants from sunlight and grow quickly to maximize their own expose. Water too is essential for photosynthesis; roots compete to maximize water uptake from soil. Some plants have deep roots that are able to locate water stored deep underground, and others have shallower roots that are capable of extending longer distances to collect recent rainwater.\n",
            "Minerals are important for plant growth and development. Common nutrients competed for amongst plants include nitrogen, phosphorus, and potassium.\n",
            "\n",
            "\n",
            "== Importance to humans ==\n",
            "\n",
            "\n",
            "=== Food ===\n",
            "\n",
            "Human cultivation of plants is the core of agriculture, which in turn has played a key role in the history of world civilizations. Humans depend on plants for food, either directly or as feed in animal husbandry. Agriculture includes agronomy for arable crops, horticulture for vegetables and fruit, and forestry for timber. About 7,000 species of plant have been used for food, though most of today's food is derived from only 30 species. The major staples include cereals such as rice and wheat, starchy roots and tubers such as cassava and potato, and legumes such as peas and beans. Vegetable oils such as olive oil and palm oil provide lipids, while fruit and vegetables contribute vitamins and minerals to the diet. Coffee, tea, and chocolate are major crops whose caffeine-containing products serve as mild stimulants. The study of plant uses by people is called economic botany or ethnobotany.\n",
            "\n",
            "\n",
            "=== Medicines ===\n",
            "\n",
            "Medicinal plants are a primary source of organic compounds, both for their medicinal and physiological effects, and for the industrial synthesis of a vast array of organic chemicals. Many hundreds of medicines, as well as narcotics, are derived from plants, both traditional medicines used in herbalism and chemical substances purified from plants or first identified in them, sometimes by ethnobotanical search, and then synthesised for use in modern medicine. Modern medicines derived from plants include aspirin, taxol, morphine, quinine, reserpine, colchicine, digitalis and vincristine. Plants used in herbalism include ginkgo, echinacea, feverfew, and Saint John's wort. The pharmacopoeia of Dioscorides, De materia medica, describing some 600 medicinal plants, was written between 50 and 70 CE and remained in use in Europe and the Middle East until around 1600 CE; it was the precursor of all modern pharmacopoeias.\n",
            "\n",
            "\n",
            "=== Nonfood products ===\n",
            "\n",
            "Plants grown as industrial crops are the source of a wide range of products used in manufacturing. Nonfood products include essential oils, natural dyes, pigments, waxes, resins, tannins, alkaloids, amber and cork. Products derived from plants include soaps, shampoos, perfumes, cosmetics, paint, varnish, turpentine, rubber, latex, lubricants, linoleum, plastics, inks, and gums. Renewable fuels from plants include firewood, peat and other biofuels. The fossil fuels coal, petroleum and natural gas are derived from the remains of aquatic organisms including phytoplankton in geological time. Many of the coal fields date to the Carboniferous period of Earth's history. Terrestrial plants also form type III kerogen, a source of natural gas.Structural resources and fibres from plants are used to construct dwellings and to manufacture clothing. Wood is used for buildings, boats, and furniture, and for smaller items such as musical instruments and sports equipment. Wood is pulped to make paper and cardboard. Cloth is often made from cotton, flax, ramie or synthetic fibres such as rayon, derived from plant cellulose. Thread used to sew cloth likewise comes in large part from cotton.\n",
            "\n",
            "\n",
            "=== Ornamental plants ===\n",
            "\n",
            "Thousands of plant species are cultivated for their beauty and to provide shade, modify temperatures, reduce wind, abate noise, provide privacy, and reduce soil erosion. Plants are the basis of a multibillion-dollar per year tourism industry, which includes travel to historic gardens, national parks, rainforests, forests with colourful autumn leaves, and festivals such as Japan's and America's cherry blossom festivals.Plants may be grown indoors as houseplants, or in specialized buildings such as greenhouses. Plants such as Venus flytrap, sensitive plant and resurrection plant are sold as novelties. Art forms specializing in the arrangement of cut or living plant include bonsai, ikebana, and the arrangement of cut or dried flowers. Ornamental plants have sometimes changed the course of history, as in tulipomania.\n",
            "\n",
            "\n",
            "=== In science ===\n",
            "\n",
            "The traditional study of plants is the science of botany. Basic biological research has often used plants as its model organisms. In genetics, the breeding of pea plants allowed Gregor Mendel to derive the basic laws governing inheritance, and examination of chromosomes in maize allowed Barbara McClintock to demonstrate their connection to inherited traits. The plant Arabidopsis thaliana is used in laboratories as a model organism to understand how genes control the growth and development of plant structures. Tree rings provide a method of dating in archeology, and a record of past climates. The study of plant fossils, or Paleobotany, provides information about the evolutions of plants, paleogeographical reconstructions, and past climate change. Plant fossils can also help determine the age of rocks.\n",
            "\n",
            "\n",
            "=== In mythology, religion, and culture ===\n",
            "\n",
            "Plants including trees appear in mythology, religion, and literature. In multiple Indo-European, Siberian, and Native American religions, the world tree motif is depicted as a colossal tree growing on the earth, supporting the heavens, and with its roots reaching into the underworld. It may also appear as a cosmic tree or an eagle and serpent tree. Forms of the world tree include the archetypal tree of life, which is in turn connected to the Eurasian concept of the sacred tree. Another widespread ancient motif, found for example in Iran, has a tree of life flanked by a pair of confronted animals.Flowers are often used as memorials, gifts and to mark special occasions such as births, deaths, weddings and holidays. Flower arrangements may be used to send hidden messages. Plants and especially  flowers form the subjects of many paintings.\n",
            "\n",
            "\n",
            "=== Negative effects ===\n",
            "Weeds are commercially or aesthetically undesirable plants growing in managed environments such as in agriculture and gardens. People have spread many plants beyond their native ranges; some of these plants have become invasive, damaging existing ecosystems by displacing native species, and sometimes becoming serious weeds of cultivation.Some plants that produce windblown pollen, including grasses, invoke allergic reactions in people who suffer from hay fever. Many plants produce toxins to protect themselves from herbivores. Major classes of plant toxins include alkaloids, terpenoids, and phenolics. These can be harmful to humans and livestock by ingestion or, as with poison ivy, by contact. Some plants have negative effects on other plants, preventing seedling growth or the growth of nearby plants by releasing allopathic chemicals.\n",
            "\n",
            "\n",
            "== See also ==\n",
            "Plant identification\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "General:\n",
            "\n",
            "Evans, L.T. (1998). Feeding the Ten Billion – Plants and Population Growth. Cambridge University Press. Paperback, 247 pages. ISBN 0-521-64685-5.\n",
            "Kenrick, Paul & Crane, Peter R. (1997). The Origin and Early Diversification of Land Plants: A Cladistic Study. Washington, D.C.: Smithsonian Institution Press. ISBN 1-56098-730-8.\n",
            "Raven, Peter H.; Evert, Ray F.; & Eichhorn, Susan E. (2005). Biology of Plants (7th ed.). New York: W.H. Freeman and Company. ISBN 0-7167-1007-2.\n",
            "Taylor, Thomas N. & Taylor, Edith L. (1993). The Biology and Evolution of Fossil Plants. Englewood Cliffs, NJ: Prentice Hall. ISBN 0-13-651589-4.Species estimates and counts:\n",
            "\n",
            "International Union for Conservation of Nature and Natural Resources (IUCN) Species Survival Commission (2004). IUCN Red List The IUCN Red List of Threatened Species.\n",
            "Prance, G. T. (2001). \"Discovering the Plant World\". Taxon. 50 (2, Golden Jubilee Part 4): 345–359. doi:10.2307/1223885. JSTOR 1223885.\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "Index Nominum Algarum\n",
            "Interactive Cronquist classification. Archived 10 February 2006.\n",
            "Plant Resources of Tropical Africa. Archived 11 June 2010.\n",
            "Tree of Life. Archived 9 March 2022 at the Wayback Machine.Botanical and vegetation databasesAfrican Plants Initiative database\n",
            "Australia\n",
            "Chilean plants at Chilebosque\n",
            "e-Floras (Flora of China, Flora of North America and others). Archived 19 February 2022 at the Wayback Machine.\n",
            "Flora Europaea\n",
            "Flora of Central Europe (in German)\n",
            "Flora of North America. Archived 19 February 2022 at the Wayback Machine.\n",
            "List of Japanese Wild Plants Online. Archived 16 March 2022 at the Wayback Machine.\n",
            "Meet the Plants-National Tropical Botanical Garden. Archived 16 June 2007.\n",
            "Lady Bird Johnson Wildflower Center – Native Plant Information Network at University of Texas, Austin\n",
            "United States Department of Agriculture not limited to continental US species....\n",
            "\n",
            "\n",
            "Page Title: Name\n",
            "Text: A name is a term used for identification by an external observer. They can identify a class or category of things, or a single thing, either uniquely, or within a given context. The entity identified by a name is called its referent. A personal name identifies, not necessarily uniquely, a specific individual human. The name of a specific entity is sometimes called a proper name (although that term has a philosophical meaning as well) and is, when consisting of only one word, a proper noun. Other nouns are sometimes called \"common names\" or (obsolete) \"general names\". A name can be given to a person, place, or thing; for example, parents can give their child a name or a scientist can give an element a name.\n",
            "\n",
            "\n",
            "== Etymology ==\n",
            "The word name comes from Old English nama; cognate with Old High German (OHG) namo, Sanskrit नामन् (nāman), Latin nomen, Greek ὄνομα (onoma), and Persian نام (nâm), from the Proto-Indo-European (PIE) *h₁nómn̥. Outside Indo-European, it can be connected to Proto-Uralic *nime.\n",
            "\n",
            "\n",
            "== Naming conventions ==\n",
            "A naming convention is a set of agreed, stipulated, or generally accepted standards, norms, social norms, or criteria for naming things.\n",
            "Parents may follow a naming convention when selecting names for their children. Some have chosen alphabetical names by birth order. In some East Asian cultures it is common for one syllable in a two-syllable given name to be a generation name which is the same for immediate siblings. In many cultures it is common for the son to be named after the father or a grandfather. In certain African cultures, such as in Cameroon, the eldest son gets the family name for his given name. In other cultures, the name may include the place of residence, or the place of birth.\n",
            "Major naming conventions include:\n",
            "\n",
            "In astronomy, astronomical naming conventions\n",
            "In biology, binomial nomenclature\n",
            "In chemistry, chemical nomenclature\n",
            "In classics, Roman naming conventions\n",
            "In computer programming, identifier naming conventions\n",
            "In computer networking, computer naming schemes\n",
            "In planetary science, planetary nomenclature\n",
            "In sciences generally, systematic names for a variety of thingsProducts may follow a naming convention. Automobiles typically have a binomial name, a \"make\" (manufacturer) and a \"model\", in addition to a model year, such as a 2007 Chevrolet Corvette. Sometimes there is a name for the car's \"decoration level\" or \"trim line\" as well: e.g., Cadillac Escalade EXT Platinum, after the precious metal. Computers often have increasing numbers in their names to signify the next generation.\n",
            "Courses at schools typically follow a naming convention: an abbreviation for the subject area and then a number ordered by increasing level of difficulty.\n",
            "Many numbers (e.g., bank accounts, government IDs, credit cards, etc.) are not random but have an internal structure and convention. Virtually all organizations that assign names or numbers will follow some convention in generating these identifiers. Airline flight numbers, Space Shuttle flight numbers, even phone numbers all have an internal convention.\n",
            "\n",
            "\n",
            "== Personal name ==\n",
            "\n",
            "A personal name is an identifying word or words by which an individual is intimately known or designated. In many countries, it is traditional for individuals to have a personal name (also called a given name or first name) and a surname (also called a last name or family name because it is shared by members of the same family). Some people have two surnames, one inherited from each parent. In most of Europe and the Americas, the given name typically comes before the surname, whereas in parts of Asia and Hungary the surname comes before the given name. In some cultures it is traditional for a woman to take her husband's surname when she gets married.\n",
            "A common practice in many countries is patronym which means that a component of a personal name is based on the given name of one's father. A less common practice in countries is matronym which means that a component of a personal name is based on the given name of one's mother. In some East Asian cultures, it is traditional for given names to include a generation name, a syllable shared between siblings and cousins of the same generation.\n",
            "Middle names are also used by many people as a third identifier, and can be chosen for personal reasons including signifying relationships, preserving pre-marital/maiden names (a popular practice in the United States), and to perpetuate family names. The practice of using middle names dates back to ancient Rome, where it was common for members of the elite to have a praenomen (a personal name), a nomen (a family name, not exactly used the way middle names are used today), and a cognomen (a name representing an individual attribute or the specific branch of a person's family). Middle names eventually fell out of use, but regained popularity in Europe during the nineteenth century.Besides first, middle, and last names, individuals may also have nicknames, aliases, or titles. Nicknames are informal names used by friends or family to refer to a person (\"Chris\" may be used as a short form of the personal name \"Christopher\"). A person may choose to use an alias, or a fake name, instead of their real name, possibly to protect or obscure their identity. People may also have titles designating their role in an institution or profession (members of royal families may use various terms such as king, Queen, duke, or duchess to signify their positions of authority or their relation to the throne).\n",
            "\n",
            "\n",
            "== Names of names ==\n",
            "In onomastic terminology, personal names of men are called andronyms (from Ancient Greek ἀνήρ / man, and ὄνομα / name), while personal names of women are called gynonyms (from Ancient Greek γυνή / woman, and ὄνομα / name).\n",
            "\n",
            "\n",
            "== Brand names ==\n",
            "\n",
            "Developing a name for a brand or product is heavily influenced by marketing research and strategy to be appealing and marketable. The brand name is often a neologism or pseudoword, such as Kodak or Sony.\n",
            "\n",
            "\n",
            "== Religious names ==\n",
            "\n",
            "In the ancient world, particularly in the ancient near-east (Israel, Mesopotamia, Egypt, Persia) names were thought to be extremely powerful and act, in some ways, as a separate manifestation of a person or deity. This viewpoint is responsible both for the reluctance to use the proper name of God in Hebrew writing or speech, as well as the common understanding in ancient magic that magical rituals had to be carried out \"in [someone's] name\". By invoking a god or spirit by name, one was thought to be able to summon that spirit's power for some kind of miracle or magic (see Luke 9:49, in which the disciples claim to have seen a man driving out demons using the name of Jesus). This understanding passed into later religious tradition, for example the stipulation in Catholic exorcism that the demon cannot be expelled until the exorcist has forced it to give up its name, at which point the name may be used in a stern command which will drive the demon away.\n",
            "\n",
            "\n",
            "=== Biblical names ===\n",
            "\n",
            "In the Old Testament, the names of individuals are meaningful, and a change of name indicates a change of status. For example, the patriarch Abram and his wife Sarai were renamed \"Abraham\" and \"Sarah\" at the institution of the Abrahamic covenant (Genesis 17:4, 17:15). Simon was renamed Peter when he was given the Keys to Heaven. This is recounted in the Gospel of Matthew chapter 16, which according to Roman Catholic teaching was when Jesus promised to Saint Peter the power to take binding actions. Proper names are \"saturated with meaning\".Throughout the Bible, characters are given names at birth that reflect something of significance or describe the course of their lives. For example: Solomon meant peace, and the king with that name was the first whose reign was without war. Likewise, Joseph named his firstborn son Manasseh (Hebrew: \"causing to forget\")(Genesis 41:51); when Joseph also said, \"God has made me forget all my troubles and everyone in my father's family.\" Biblical Jewish people did not have surnames which were passed from generation to generation. However, they were typically known as the child of their father. For example: דוד בן ישי (David ben Yishay) meaning, David, son of Jesse (1 Samuel 17:12,58). Today, this style of name is still used in Jewish religious rites.\n",
            "\n",
            "\n",
            "=== Indian name ===\n",
            "\n",
            "Indian names are based on a variety of systems and naming conventions, which vary from region to region. Names are also influenced by religion and caste and may come from epics. India's population speaks a wide variety of languages and nearly every major religion in the world has a following in India. This variety makes for subtle, often confusing, differences in names and naming styles. Due to historical Indian cultural influences, several names across South and Southeast Asia are influenced by or adapted from Indian names or words.\n",
            "For some Indians, their birth name is different from their official name; the birth name starts with a randomly selected name from the person's horoscope (based on the nakshatra or lunar mansion corresponding to the person's birth).\n",
            "Many children are given three names, sometimes as a part of religious teaching.\n",
            "\n",
            "\n",
            "=== Quranic names (Arabic names) ===\n",
            "\n",
            "We can see many Arabic names in the Quran and in Muslim people, such as Allah, Muhammad, Khwaja, Ismail, Mehboob, Suhelahmed, Shoheb Ameena, Aaisha, Sameena, Rumana, Swaleha, etc. The names Mohammed and Ahmed are the same, for example Suhel Ahmad or Mohammad Suhel are the same. There are many similar names in Islam and Christianity, such as Yosef (Islamic)/Joseph (Christian), Adam/Adam, Dawood/David, Rumana/Romana, Maryam/Mary, Nuh/Noah, etc.\n",
            "\n",
            "\n",
            "== Name use by animals and plants ==\n",
            "\n",
            "The use of personal names is not unique to humans. Dolphins and green-rumped parrotlets also use symbolic names to address contact calls to specific individuals. Individual dolphins have distinctive signature whistles, to which they will respond even when there is no other information to clarify which dolphin is being referred to.\n",
            "\n",
            "\n",
            "== Named entities ==\n",
            "\n",
            "\n",
            "== See also ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== Sources ==\n",
            "\n",
            "\n",
            "== Further reading ==\n",
            "\"Names\" by Sam Cumming, Stanford Encyclopedia of Philosophy (SEP), a philosophical dissertation on the syntax and semantics of names\n",
            "Pilcher, Jane (2017). \"Names, Bodies and Identities\". Sociology. 50 (4): 764–779. doi:10.1177/0038038515582157. S2CID 145136869.\n",
            "Matthews, Elaine; Hornblower, Simon; Fraser, Peter Marshall, Greek Personal Names: Their Value as Evidence, Proceedings of the British Academy (104), Oxford University Press, 2000. ISBN 0-19-726216-3\n",
            "Name and Form – from Sacred Texts Buddhism\n",
            "\n",
            "\n",
            "== External links ==\n",
            "\n",
            "Lexicon of Greek Personal Names, Oxford (over 35,000 published names)\n",
            "Behind The Name, The etymology of first names\n",
            "The Name Tradition In The Christian Culture\n",
            "Kate Monk's Onomastikon Names over the world throughout the history\n",
            "\"Name\" . Encyclopædia Britannica (11th ed.). 1911....\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkAux9hD1uxz",
        "outputId": "8e2a8fb7-f51f-4aeb-fd8f-e03761e4329c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Computer science is the study of computation, information, and automation. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). Though more often considered an academic discipline, computer science is closely related to computer programming.Algorithms and data structures are central to computer science.\\nThe theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.\\nThe fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.\\n\\n\\n== History ==\\n\\nThe earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\". \"A crucial step was the adoption of a punched card system derived from the Jacquard loom\" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1914, the Spanish engineer Leonardo Torres Quevedo published his Essays on Automatics, and designed, inspired by Babbage, a theoretical electromechanical calculating machine which was to be controlled by a read-only program. The paper also introduced the idea of floating-point arithmetic. In 1920, to celebrate the 100th anniversary of the invention of the arithmometer, Torres presented in Paris the  Electromechanical Arithmometer, a prototype that demonstrated the feasibility of an electromechanical analytical engine, on which commands could be typed and the results printed automatically. In 1937, one hundred years after Babbage\\'s impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage\\'s Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as \"Babbage\\'s dream come true\".\\nDuring the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan\\'s West Side was IBM\\'s first laboratory devoted to pure science. The lab is the forerunner of IBM\\'s Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and Columbia University was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world\\'s first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.\\n\\n\\n== Etymology ==\\n\\nAlthough first proposed in 1956, the term \"computer science\" appears in a 1959 article in Communications of the ACM,\\nin which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921. Louis justifies the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.\\nHis efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.\\nIn the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. Three months later in the same journal, comptologist was suggested, followed next year by hypologist. The term computics has also been suggested. In Europe, terms derived from contracted translations of the expression \"automatic information\" (e.g. \"informazione automatica\" in Italian) or \"information and mathematics\" are often used, e.g. informatique (French), Informatik (German), informatica (Italian, Dutch), informática (Spanish, Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki (πληροφορική, which means informatics) in Greek. Similar words have also been adopted in the UK (as in the School of Informatics, University of Edinburgh). \"In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain.\"A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\" The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been exchange of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, Earth science, statistics, philosophy, and logic.\\nComputer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.The relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term \"software engineering\" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.\\n\\n\\n== Philosophy ==\\n\\n\\n=== Epistemology of computer science ===\\nDespite the word \"science\" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. Allen Newell and Herbert A. Simon argued in 1975, Computer science is an empirical discipline. We would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. Nonetheless, they are experiments. Each new machine that is built is an experiment. Actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. It has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. Proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. They also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.Proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.\\n\\n\\n=== Paradigms of computer science ===\\nA number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning\\'s working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the \"rationalist paradigm\" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the \"technocratic paradigm\" (which might be found in engineering approaches, most prominently in software engineering), and the \"scientific paradigm\" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).\\nComputer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.\\n\\n\\n== Fields ==\\n\\nAs a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.\\nComputer science is no more about computers than astronomy is about telescopes.\\n\\n\\n=== Theoretical computer science ===\\n\\nTheoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.\\n\\n\\n==== Theory of computation ====\\n\\nAccording to Peter Denning, the fundamental question underlying computer science is, \"What can be automated?\" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.\\nThe famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.\\n\\n\\n==== Information and coding theory ====\\n\\nInformation theory, closely related to probability and statistics, is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.\\nCoding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.\\n\\n\\n==== Data structures and algorithms ====\\nData structures and algorithms are the studies of commonly used computational methods and their computational efficiency.\\n\\n\\n==== Programming language theory and formal methods ====\\n\\nProgramming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.\\nFormal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.\\n\\n\\n=== Applied computer science ===\\n\\n\\n==== Computer graphics and visualization ====\\n\\nComputer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.\\n\\n\\n==== Image and sound processing ====\\n\\nInformation can take the form of images, sound, video or other multimedia. Bits of information can be streamed via signals. Its processing is the central notion of informatics, the European view on computing, which studies information processing algorithms independently of the type of information carrier – whether it is electrical, mechanical or biological. This field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. What is the lower bound on the complexity of fast Fourier transform algorithms? is one of unsolved problems in theoretical computer science.\\n\\n\\n==== Computational science, finance and engineering ====\\n\\nScientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. A major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE, as well as software for physical realization of new (or modified) designs. The latter includes essential design software for integrated circuits.\\n\\n\\n==== Social computing and human–computer interaction ====\\n\\nSocial computing is an area that is concerned with the intersection of social behavior and computational systems. Human–computer interaction research develops theories, principles, and guidelines for user interface designers.\\n\\n\\n==== Software engineering ====\\n\\nSoftware engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it does not just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For example software testing, systems engineering, technical debt and software development processes.\\n\\n\\n==== Artificial intelligence ====\\n\\nArtificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting point in the late 1940s was Alan Turing\\'s question \"Can computers think?\", and the question remains effectively unanswered, although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.\\n\\n\\n=== Computer systems ===\\n\\n\\n==== Computer architecture and organization ====\\n\\nComputer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. Computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. The term \"architecture\" in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM\\'s main research center in 1959.\\n\\n\\n==== Concurrent, parallel and distributed computing ====\\n\\nConcurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.\\n\\n\\n==== Computer networks ====\\n\\nThis branch of computer science aims to manage networks between computers worldwide.\\n\\n\\n==== Computer security and cryptography ====\\n\\nComputer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.\\nHistorical cryptography is the art of writing and deciphering secret messages. Modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. Technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.\\n\\n\\n==== Databases and data mining ====\\n\\nA database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. Data mining is a process of discovering patterns in large data sets.\\n\\n\\n== Discoveries ==\\nThe philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:\\nGottfried Wilhelm Leibniz\\'s, George Boole\\'s, Alan Turing\\'s, Claude Shannon\\'s, and Samuel Morse\\'s insight: there are only two objects that a computer has to deal with in order to represent \"anything\".All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as \"on/off\", \"magnetized/de-magnetized\", \"high-voltage/low-voltage\", etc.).\\nAlan Turing\\'s insight: there are only five actions that a computer has to perform in order to do \"anything\".Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;\\nmove right one location;\\nread symbol at current location;\\nprint 0 at current location;\\nprint 1 at current location.\\nCorrado Böhm and Giuseppe Jacopini\\'s insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do \"anything\".Only three rules are needed to combine any set of basic instructions into more complex ones:\\nsequence: first do this, then do that;\\n selection: IF such-and-such is the case, THEN do this, ELSE do that;\\nrepetition: WHILE such-and-such is the case, DO this.\\nThe three rules of Boehm\\'s and Jacopini\\'s insight can be further simplified with the use of goto (which means it is more elementary than structured programming).\\n\\n\\n== Programming paradigms ==\\n\\nProgramming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:\\n\\nFunctional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.\\nImperative programming, a programming paradigm that uses statements that change a program\\'s state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.\\nObject-oriented programming, a programming paradigm based on the concept of \"objects\", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object\\'s procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.\\nService-oriented programming, a programming paradigm that uses \"services\" as the unit of computer work, to design and implement integrated business applications and mission critical software programsMany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.\\n\\n\\n== Research ==\\n\\nConferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.\\n\\n\\n== Education ==\\n\\nComputer Science, known by its near synonyms, Computing, Computer Studies, has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science. According to a 2021 report, only 51% of high schools in the US offer computer science.Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.\\n\\n\\n== See also ==\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\n\\n\\n== External links ==\\n\\nDBLP Computer Science Bibliography\\nAssociation for Computing Machinery\\nInstitute of Electrical and Electronics Engineers',\n",
              " 'Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science which develops and studies intelligent machines. Such machines may be called AIs.\\nAI technology is widely used throughout industry, government, and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Google Assistant, Siri, and Alexa), self-driving cars (e.g., Waymo), generative and creative tools (ChatGPT and AI art), and superhuman play and analysis in strategy games (such as chess and Go).Alan Turing was the first person to carry out substantial research in the field that he called Machine Intelligence. Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture.The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to complete any task performable by a human) is among the field\\'s long-term goals.\\nTo solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.\\n\\n\\n== Goals ==\\nThe general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\\n\\n\\n=== Reasoning, problem-solving ===\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.\\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\\nAccurate and efficient reasoning is an unsolved problem.\\n\\n\\n=== Knowledge representation ===\\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as:\\nobjects, properties, categories and relations between objects;\\n\\nsituations, events, states and time;\\ncauses and effects;\\nknowledge about knowledge (what we know about what other people know);default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\\nAmong the most difficult problems in KR are: the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).Knowledge acquisition is the difficult problem of obtaining knowledge for AI applications. Modern AI gathers knowledge by \"scraping\" the internet (including Wikipedia). The knowledge itself was collected by the volunteers and professionals who published the information (who may or may not have agreed to provide their work to AI companies). This \"crowd sourced\" technique does not guarantee that the knowledge is correct or reliable. The knowledge of Large Language Models (such as ChatGPT) is highly unreliable—it generates misinformation and falsehoods (known as \"hallucinations\"). Providing accurate knowledge for these modern AI applications is an unsolved problem.\\n\\n\\n=== Planning and decision making ===\\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.\\nIn automated planning, the agent has a specific goal. In automated decision making, the agent has preferences – there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.In classical planning, the agent knows exactly what the effect of any action will be.\\nIn most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\\nIn some problems, the agent\\'s preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences.Information value theory can be used to weigh the value of exploratory or experimental actions.\\nThe space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g. by iteration), be heuristic, or it can be learned.Game theory describes rational behavior of multiple interacting agents, and is used in AI programs that make decisions that involve other agents.\\n\\n\\n=== Learning ===\\nMachine learning is the study of programs that can improve their performance on a given task automatically.\\nIt has been a part of AI from the beginning.There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.Supervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\\nIn reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\\n\\n\\n=== Natural language processing ===\\nNatural language processing (NLP) allows programs to read, write and communicate in human languages such as English.\\nSpecific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.Early work, based on Noam Chomsky\\'s generative grammar and semantic networks, had difficulty with word-sense disambiguation\\nunless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning, and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023 these models were able to get human-level scores on the bar exam, SAT, GRE, and many other real-world applications.\\n\\n\\n=== Perception ===\\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\\nThe field includes speech recognition,image classification,facial recognition, object recognition,\\nand robotic perception.\\n\\n\\n=== Social intelligence ===\\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood.\\nFor example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\\nHowever, this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.\\n\\n\\n=== General intelligence ===\\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\\n\\n\\n== Tools ==\\nAI research uses a wide variety of tools to accomplish the goals above.\\n\\n\\n=== Search and optimization ===\\nAI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\\n\\n\\n==== State space search ====\\nState space search searches through a tree of possible states to try to find a goal state.\\nFor example, Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.Simple exhaustive searches\\nare rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.\\n\"Heuristics\" or \"rules of thumb\" can help to prioritize choices that are more likely to reach a goal.Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.\\n\\n\\n==== Local search ====\\nLocal search uses mathematical optimization to find a numeric solution to a problem. It begins with some form of a guess and then refines the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. This process is called stochastic gradient descent.Evolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses).Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).Neural networks and statistical classifiers (discussed below), also use a form of local search, where the \"landscape\" to be searched is formed by learning.\\n\\n\\n=== Logic ===\\nFormal Logic is used for reasoning and knowledge representation.\\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")\\nand predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").Logical inference (or deduction) is the process of proving a new statement (conclusion) from other statements that are already known to be true (the premises).\\nA logical knowledge base also handles queries and assertions as a special case of inference.\\nAn inference rule describes what is a valid step in a proof. The most general inference rule is resolution.\\nInference can be reduced to performing a search to find a path that leads from premises to conclusions, where each step is the application of an inference rule.\\nInference performed this way is intractable except for short proofs in restricted domains. No efficient, powerful and general method has been discovered.Fuzzy logic assigns a \"degree of truth\" between 0 and 1 and handles uncertainty and probabilistic situations.Non-monotonic logics are designed to handle default reasoning.\\nOther specialized versions of logic have been developed to describe many complex domains (see knowledge representation above).\\n\\n\\n=== Probabilistic methods for uncertain reasoning ===\\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.Bayesian networks\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks)\\nand perception (using dynamic Bayesian networks).Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,\\nand information value theory.\\nThese tools include models such as Markov decision processes,\\ndynamic decision networks, game theory and mechanism design.\\n\\n\\n=== Classifiers and statistical learning methods ===\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \"if shiny then diamond\"), on one hand, and controllers (e.g. \"if diamond then pick up\"), on the other hand. Classifiers\\nare functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.There are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\\nThe naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.Neural networks are also used as classifiers.\\n\\n\\n=== Artificial neural networks ===\\nArtificial neural networks were inspired by the design of the human brain: a simple \"neuron\" N accepts input from other neurons, each of which, when activated (or \"fired\"), casts a weighted \"vote\" for or against whether neuron N should itself activate. In practice, the input \"neurons\" are a list of numbers, the \"weights\" are a matrix, the next layer is the dot product (i.e., several weighted sums) scaled by an increasing function, such as the logistic function. \"The resemblance to real neural cells and structures is superficial\", according to Russell and Norvig.Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.\\nNeural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.In feedforward neural networks the signal passes in only one direction.Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.Perceptrons\\nuse only a single layer of neurons, deep learning uses multiple layers.\\nConvolutional neural networks strengthen the connection between neurons that are \"close\" to each other – this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.\\n\\n\\n=== Deep learning ===\\nDeep learning\\nuses several layers of neurons between the network\\'s inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classification\\nand others. The reason that deep learning performs so well in so many applications is not known as of 2023.\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.\\n\\n\\n=== Specialized hardware and software ===\\n\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models\\' training.\\nHistorically, specialized languages, such as Lisp, Prolog, Python and others, had been used.\\n\\n\\n== Applications ==\\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple\\'s Face ID or Microsoft\\'s DeepFace and Google\\'s FaceNet) and image labeling (used by Facebook, Apple\\'s iPhoto and TikTok).\\n\\n\\n=== Health and Medicine ===\\n\\nThe application of AI in medicine and medical research has the potential to increase patient care and quality of life.  Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\\nFor medical research, AI is an important tool for processing and integrating Big Data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. \\nIt has been suggested that AI can overcome discrepancies in funding allocated to different fields of research, such as cardiovascular research which typically receives a disproportionately less funding that areas such as cancer research, relative to the morbidity and mortality of these diseases. New AI tools can deepen our understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.\\n\\n\\n=== Games ===\\n\\nGame playing programs have been used since the 1950s to demonstrate and test AI\\'s most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM\\'s question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then it defeated Ke Jie in 2017, who at the time continuously held the world No. 1 ranking for two years. Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus and Cepheus. DeepMind in the 2010s developed a \"generalized artificial intelligence\" that could learn many diverse Atari games on its own.\\n\\n\\n=== Military ===\\n\\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams. AI was incorporated into military operations in Iraq and Syria.\\n\\n\\n=== Generative AI ===\\n\\nIn the early 2020s, generative AI gained widespread prominence. ChatGPT, based on GPT-3, and other large language models, were tried by 14% of Americans adults. The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion sparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat, the fictional arrest of Donald Trump, and a hoax of an attack on the Pentagon, as well as the usage in professional creative arts.\\n\\n\\n=== Industry Specific Tasks ===\\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported they had incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\\nIn agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\\n\\n\\n== Ethics ==\\nAI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified.Anyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning.\\n\\n\\n=== Risks and harm ===\\n\\n\\n==== Privacy and copyright ====\\n\\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\\nTechnology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.\\nFor example, in order to build speech recognition algorithms, Amazon have recorded millions of private conversations and allowed temps to listen to and transcribe some of them.\\nOpinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.AI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.\\nSince 2016, some privacy experts, such as Cynthia Dwork, began to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of \\'what they know\\' to the question of \\'what they\\'re doing with it\\'.\".Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under a rationale of \"fair use\". Experts disagree about how well, and under what circumstances, this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.\\n\\n\\n==== Misinformation ====\\n\\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\\nIn 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing.  It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\\n\\n\\n==== Algorithmic bias and fairness ====\\n\\nMachine learning applications will be biased if they learn from biased data.\\nThe developers may not be aware that the bias exists.\\nBias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.Fairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \"fairness\" in a way that satisfies all stakeholders.On June 28, 2015, Google Photos\\'s new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\\nIn 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".\\nMoritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn\\'t work.\"Criticism of COMPAS highlighted a deeper problem with the misuse of AI. Machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. Unfortunately, if an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022) the Association for Computing Machinery, in Seoul, South Korea, presented and published findings recommending that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.\\n\\n\\n==== Lack of transparency ====\\n\\nMany AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.People who have been harmed by an algorithm\\'s decision have a right to an explanation. Doctors, for example, are required to clearly and completely explain the reasoning behind any decision they make. Early drafts of the European Union\\'s General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.DARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try and solve these problems.There are several potential solutions to the transparency problem. SHAP helps visualise the contribution of each feature to the output. LIME can locally approximate a model with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.\\n\\n\\n==== Bad actors and weaponized AI ====\\n\\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. By 2015, over fifty countries were reported to be researching battlefield robots. These weapons are considered especially dangerous for several reasons: if they kill an innocent person it is not clear who should be held accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations\\' Convention on Certain Conventional Weapons, however the United States and others disagreed.AI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian centralized decision making more competitive with liberal and decentralized systems such as markets.AI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.Terrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons.\\nMachine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.\\n\\n\\n==== Technological unemployment ====\\n\\nFrom the early days of the development of artificial intelligence there have been arguments, for example those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we\\'re in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.In April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.\\n\\n\\n==== Existential risk ====\\n\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\\nFirst, AI does not require human-like \"sentience\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can\\'t fetch the coffee if you\\'re dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity\\'s morality and values so that it is \"fundamentally on our side\".Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk have expressed concern about existential risk from AI.\\nIn the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.\\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI. In 2023, many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".\\n\\n\\n=== Ethical machines and alignment ===\\n\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\\nThe field of machine ethics is also called computational morality,\\nand was founded at an AAAI symposium in 2005.Other approaches include Wendell Wallach\\'s \"artificial moral agents\"\\nand Stuart J. Russell\\'s three principles for developing provably beneficial machines.\\n\\n\\n=== Frameworks ===\\nArtificial Intelligence projects can have their ethical permissibility tested while designing, developing, and implementing an AI system. An AI framework such as the SUM framework developed by the Alan Turing Institute tests projects in four main areas:\\nRESPECT the dignity of individual people\\nCONNECT with other people sincerely, openly and inclusively\\nCARE for the wellbeing of everyone\\nPROTECT social values, justice and the public interestOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE\\'s Ethics of Autonomous Systems initiative, among others; however, these principles do not go without their criticisms, especially regards to the people chosen contributes to these frameworks.Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\\n\\n\\n=== Regulation ===\\n\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.\\nThe regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.\\nBetween 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.\\nMost EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, US and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.\\nThe Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.\\nIn 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics.In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.\\nIn a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".In November 2023, a global AI safety summit was held in Bletchley Park to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.\\n\\n\\n== History ==\\n\\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing\\'s theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis. This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \"electronic brain\".Alan Turing was thinking about machine intelligence at least as early as 1941, when he circulated a paper on machine intelligence which could be the earliest paper in the field of AI - though it is now lost. The first available paper generally recognized as \"AI\" was McCullouch and Pitts design for Turing-complete \"artificial neurons\" in 1943 - the first mathematical model of a neural network. The paper was influenced by Turing\\'s earlier paper \\'On Computable Numbers\\' from 1936 using similar two-state boolean \\'neurons\\', but was the first to apply it to neuronal function.The term \\'Machine Intelligence\\' was used by Alan Turing during his life which was later often referred to as \\'Artificial Intelligence\\' after his death in 1954. In 1950 Turing published the best known of his papers \\'Computing Machinery and Intelligence\\', the paper introduced his concept of what is now known as the Turing test to the general public. Then followed three radio broadcasts on AI by Turing, the lectures: \\'Intelligent Machinery, A Heretical Theory’, ‘Can Digital Computers Think’? and the panel discussion ‘Can Automatic Calculating Machines be Said to Think’. By 1956 computer intelligence had been actively pursued for more than a decade in Britain; the earliest AI programmes were written there in 1951–52.In 1951, using a Ferranti Mark 1 computer of the University of Manchester, checkers and chess programs were wrote where you could play against the computer. The field of American AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial Intelligence laboratories were set up at a number of British and US Universities in the latter 1950s and early 1960s.They had, however, underestimated the difficulty of the problem. Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky\\'s and Papert\\'s book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan\\'s fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.Many researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches. Robotics researchers, such as Rodney Brooks, rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).\\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".Several academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\\nFor many specific tasks, other methods were abandoned.\\nDeep learning\\'s success was based on both hardware improvements (faster computers, graphics processing units, cloud computing)\\nand access to large amounts of data (including curated datasets, such as ImageNet).\\nDeep learning\\'s success led to an enormous increase in interest and funding in AI.\\nThe amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019,\\nand WIPO reported that AI was the most prolific emerging technology in terms of the number of patent applications and granted patents.\\nAccording to \\'AI Impacts\\', about $50 billion annually was invested in \"AI\" around 2022 in the US alone and about 20% of new US Computer Science PhD graduates have specialized in \"AI\";\\nabout 800,000 \"AI\"-related US job openings existed in 2022. The large majority of the advances have occurred within the United States, with its companies, universities, and research labs leading artificial intelligence research.In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\\n\\n\\n== Philosophy ==\\n\\n\\n=== Defining artificial intelligence ===\\n\\nAlan Turing wrote in 1950 \"I propose to consider the question \\'can machines think\\'?\"\\nHe advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".\\nHe devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks\"Russell and Norvig agree with Turing that AI must be defined in terms of \"acting\" and not \"thinking\". However, they are critical that the test compares machines to people. \"Aeronautical engineering texts,\" they wrote, \"do not define the goal of their field as making \\'machines that fly so exactly like pigeons that they can fool other pigeons.\\'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world.\" Another AI founder, Marvin Minsky similarly defines it as \"the ability to solve hard problems\". These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google, a major practitioner in the field of AI.\\nThis definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\n\\n\\n=== Evaluating approaches to AI ===\\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\\n\\n\\n==== Symbolic AI and its limits ====\\nSymbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec\\'s paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.\\nPhilosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.\\nAlthough his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree.The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\n\\n==== Neat vs. scruffy ====\\n\\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 70s and 80s,\\nbut eventually was seen as irrelevant. Modern AI has elements of both.\\n\\n\\n==== Soft vs. hard computing ====\\n\\nFinding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 80s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\n\\n\\n==== Narrow vs. general AI ====\\n\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field\\'s long-term goals.\\nGeneral intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\\n\\n\\n=== Machine consciousness, sentience and mind ===\\n\\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\n\\n\\n==== Consciousness ====\\n\\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett\\'s consciousness illusionism says this is an illusion). Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\\n\\n\\n==== Computationalism and functionalism ====\\n\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.Philosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.\\n\\n\\n==== Robot rights ====\\n\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.\\nThis issue has been considered in fiction for centuries,\\nand is now being considered by, for example, California\\'s Institute for the Future; however, critics argue that the discussion is premature.\\n\\n\\n== Future ==\\n\\n\\n=== Superintelligence and the singularity ===\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".However, technologies can\\'t improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\\n\\n\\n=== Transhumanism ===\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.Edward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler\\'s \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.\\n\\n\\n== In fiction ==\\n\\nThought-capable artificial beings have appeared as storytelling devices since antiquity,\\nand have been a persistent theme in science fiction.A common trope in these works began with Mary Shelley\\'s Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke\\'s and Stanley Kubrick\\'s 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov\\'s laws are often brought up during lay discussions of machine ethics;\\nwhile almost all artificial intelligence researchers are familiar with Asimov\\'s laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek\\'s R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\\n\\n\\n== See also ==\\nAI effect\\nArtificial intelligence detection software – Software to detect AI-generated contentPages displaying short descriptions of redirect targets\\nArtificial intelligence in healthcare – Overview of the use of artificial intelligence in healthcare\\nBehavior selection algorithm – Algorithm that selects actions for intelligent agents\\nBusiness process automation – Technology-enabled automation of complex business processes\\nCase-based reasoning – Process of solving new problems based on the solutions of similar past problems\\nEmergent algorithm – Algorithm exhibiting emergent behavior\\nFemale gendering of AI technologies\\nGlossary of artificial intelligence – List of definitions of terms and concepts commonly used in the study of artificial intelligence\\nRobotic process automation – Form of business process automation technology\\nWeak artificial intelligence – Form of artificial intelligence\\nWetware computer – Computer composed of organic material\\n\\n\\n== Explanatory notes ==\\n\\n\\n== References ==\\n\\n\\n=== AI textbooks ===\\nThe two most widely used textbooks in 2023. (See the Open Syllabus).\\n\\nRussell, Stuart J.; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0134610993. LCCN 20190474.\\nRich, Elaine; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0070087705.These were the four of the most widely used AI textbooks in 2008:\\n\\n\\n=== History of AI ===\\n\\n\\n=== Other sources ===\\n\\n\\n== Further reading ==\\n\\n\\n== External links ==\\n\\n\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.\\nThomason, Richmond. \"Logic and Artificial Intelligence\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\\nArtificial Intelligence. BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander (In Our Time, 8 December 2005).\\nTheranostics and AI—The Next Advance in Cancer Precision Medicine',\n",
              " 'Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.Deep-learning architectures such as deep neural networks, deep belief networks, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog. ANNs are generally seen as low quality models for brain function.\\n\\n\\n== Definition ==\\nDeep learning is a class of machine learning algorithms that:\\u200a199–200\\u200a uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.\\nFrom another angle to view deep learning, deep learning refers to \"computer-simulate\" or \"automate\" human learning processes from a source (e.g., an image of dogs) to a learned object (dogs). Therefore, a notion coined as \"deeper\" learning or \"deepest\" learning makes sense. The deepest learning refers to the fully automatic learning from a source to a final learned object. A deeper learning thus refers to a mixed learning process: a human learning process from a source to a learned semi-object, followed by a computer learning process from the human learned semi-object to a final learned object.\\n\\n\\n== Overview ==\\nMost modern deep learning models are based on multi-layered artificial neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\\nDeep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.\\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.Machine learning models are now adept at identifying complex patterns in financial market data. Due to the benefits of artificial intelligence, investors are increasingly utilizing deep learning techniques to forecast and analyze trends in stock and foreign exchange markets.\\n\\n\\n== Interpretations ==\\nDeep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima\\'s rectified linear unit.The universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\\nThe probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.\\n\\n\\n== History ==\\nThere are two types of neural networks: feedforward neural networks (FNNs) and recurrent neural networks (RNNs). RNNs have cycles in their connectivity structure, FNNs don\\'t. In the 1920s, Wilhelm Lenz and Ernst Ising created and analyzed the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun\\'ichi Amari made this architecture adaptive. His learning RNN was popularised by John Hopfield in 1982. RNNs have become central for speech recognition and language processing.\\nCharles Tappert writes that Frank Rosenblatt developed and explored all of the basic ingredients of the deep learning systems of today, referring to Rosenblatt\\'s 1962 book which introduced a multilayer perceptron (MLP) with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. However, since only the output layer had learning connections, this was not yet deep learning. It was what later was called an extreme learning machine. In addition, term deep learning was proposed in 1986 by Rina Dechter Dechter (1986) although the history of its appearance is apparently more complicated.The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967. A 1971 paper described a deep network with eight layers trained by the group method of data handling.The first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun\\'ichi Amari. In computer experiments conducted by Amari\\'s student Saito, a five layer MLP with two modifiable layers learned  internal representations to classify non-linearily separable pattern classes. In 1987 Matthew Brand reported that wide 12-layer nonlinear perceptrons could be fully end-to-end trained to reproduce logic functions of nontrivial circuit depth via gradient descent on small batches of random input/output samples, but concluded that training time on contemporary hardware (sub-megaflop computers) made the technique impractical, and proposed using fixed random early layers as an input hash for a single modifiable layer.  Instead, subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\\nIn 1970, Seppo Linnainmaa published the reverse mode of automatic differentiation of discrete connected networks of nested differentiable functions. This became known as backpropagation. It is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. \\nThe terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation already in 1960 in the context of control theory. In 1982, Paul Werbos applied backpropagation to MLPs in the way that has become standard. In 1985, David E. Rumelhart et al. published an experimental analysis of the technique.Deep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1980. In 1969, he also introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for CNNs and deep learning in general. CNNs have become an essential tool for computer vision.\\nThe term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.In 1988, Wei Zhang et al. applied the backpropagation algorithm \\nto a convolutional neural network (a simplified Neocognitron with convolutional interconnections between the image feature layers and the last fully connected layer) for alphabet recognition. They also proposed an implementation of the CNN with an optical computing system. \\nIn 1989, Yann LeCun et al. applied backpropagation to a CNN with the purpose of recognizing handwritten ZIP codes on mail. While the algorithm worked, training required 3 days. Subsequently, Wei Zhang, et al. modified their model by removing the last fully connected layer and applied it for medical image object segmentation in 1991 and breast cancer detection in mammograms in 1994. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.\\nIn the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, Jürgen Schmidhuber (1992) proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning. It uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by distilling a higher level chunker network into a lower level automatizer network. In 1993, a chunker solved a deep learning task whose depth exceeded 1000.In 1992, Jürgen Schmidhuber also published an alternative to RNNs which is now called a linear Transformer or a  Transformer with linearized self-attention (save for a normalization operator). It learns internal spotlights of attention: a slow feedforward neural network learns by gradient descent to control the fast weights of another neural network through outer products of self-generated activation patterns FROM and TO (which are now called key and value for self-attention). This fast weight attention mapping is applied to a query pattern.\\nThe modern Transformer was introduced by Ashish Vaswani et. al. in their 2017 paper \"Attention Is All You Need\". \\nIt combines this with a softmax operator and a projection matrix.\\nTransformers have increasingly become the model of choice for natural language processing. Many modern large language models such as ChatGPT, GPT-4, and BERT use it. Transformers are also increasingly being used in computer vision.In 1991, Jürgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network\\'s gain is the other network\\'s loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in a generative adversarial network (GAN) by Ian Goodfellow et al. Here the environmental reaction is 1 or 0 depending on whether the first network\\'s output is in a given set. This can be used to create realistic deepfakes. Excellent image quality is achieved by Nvidia\\'s StyleGAN (2018) based on the Progressive GAN by Tero Karras et. al. Here the GAN generator is grown from small to large scale in a pyramidal fashion.\\nSepp Hochreiter\\'s diploma thesis (1991) was called \"one of the most important documents in the history of machine learning\" by his supervisor Schmidhuber. It not only tested the neural history compressor, but also identified and analyzed the vanishing gradient problem. Hochreiter proposed recurrent residual connections to solve this problem. This led to the deep learning method called long short-term memory (LSTM), published in 1997. LSTM recurrent neural networks can learn \"very deep learning\" tasks with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. The \"vanilla LSTM\" with forget gate was introduced in 1999 by Felix Gers, Schmidhuber and Fred Cummins. LSTM has become the  most cited neural network of the 20th century.\\nIn 2015, Rupesh Kumar Srivastava, Klaus Greff, and Schmidhuber used LSTM principles to create the Highway network, a feedforward neural network with hundreds of layers, much deeper than previous networks. 7 months later, Kaiming He, Xiangyu Zhang;  Shaoqing Ren, and Jian Sun won the ImageNet 2015 competition with an open-gated or gateless Highway network variant called Residual neural network. This has become the most cited neural network of the 21st century.In 1994, André de Carvalho, together with Mike Fairhurst and David Bisset, published experimental results of a multi-layer boolean neural network, also known as a weightless neural network, composed of a 3-layers self-organising feature extraction neural network module (SOFT) followed by a multi-layer classification neural network module (GSN), which were independently trained. Each layer in the feature extraction module extracted features with growing complexity regarding the previous layer.In 1995, Brendan Frey demonstrated that it was possible to train (over two days) a network containing six fully connected layers and several hundred hidden units using the wake-sleep algorithm, co-developed with Peter Dayan and Hinton.Since 1997, Sven Behnke extended the feed-forward hierarchical convolutional approach in the Neural Abstraction Pyramid by lateral and backward connections in order to flexibly incorporate context into decisions and iteratively resolve local ambiguities.\\nSimpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) were a popular choice in the 1990s and 2000s, because of artificial neural network\\'s (ANN) computational cost and a lack of understanding of how the brain wires its biological networks.\\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power. Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government\\'s NSA and DARPA, SRI studied deep neural networks in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 National Institute of Standards and Technology Speaker Recognition evaluation. The SRI deep neural network was then deployed in the Nuance Verifier, representing the first major industrial application of deep learning. The principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.Speech recognition was taken over by LSTM. In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks. In 2006, Alex Graves, Santiago Fernández, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC) in stacks of LSTM RNNs. In 2015, Google\\'s speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through Google Voice Search.The impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.\\nIn 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh showed how a many-layered feedforward neural network could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then fine-tuning it using supervised backpropagation. The papers referred to learning for deep belief nets.\\nThe 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets (DNN) might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.  That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\\nIn 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks (CNNs) were superseded for ASR by CTC for LSTM. but are more successful in computer vision.\\nAdvances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the \"big bang\" of deep learning, \"as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs)\". That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times. In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.\\n\\n\\n=== Deep learning revolution ===\\nIn the late 2000s, deep learning started to outperform other methods in machine learning competitions.\\nIn 2009, a long short-term memory trained by connectionist temporal classification (Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber, 2006) was the first RNN to win pattern recognition contests, winning three competitions in connected handwriting recognition. Google later used CTC-trained LSTM for speech recognition on the smartphone.Significant impacts in image or object recognition were felt from 2011 to 2012. Although CNNs trained by backpropagation had been around for decades, and GPU implementations of NNs for years, including CNNs, faster implementations of CNNs on GPUs were needed to progress on computer vision. In 2011, the DanNet by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. Also in 2011, DanNet won the ICDAR Chinese handwriting contest, and in May 2012, it won the ISBI image segmentation contest. Until 2011, CNNs did not play a major role at computer vision conferences, but in June 2012, a paper by Ciresan et al. at the leading conference CVPR showed how max-pooling CNNs on GPU can dramatically improve many vision benchmark records.  In September 2012, DanNet also won the ICPR contest on analysis of large medical images for cancer detection, and in the following year also the MICCAI Grand Challenge on the same topic. In October 2012, the similar AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. \\nThe VGG-16 network by Karen Simonyan and Andrew Zisserman further reduced the error rate and\\nwon the ImageNet 2014 competition, following a similar trend in large-scale speech recognition.\\nImage classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.In 2012, a team led by George E. Dahl won the \"Merck Molecular Activity Challenge\" using multi-task deep neural networks to predict the biomolecular target of one drug. In 2014, Sepp Hochreiter\\'s group used deep learning to detect off-target and toxic effects of environmental chemicals in nutrients, household products and drugs and won the \"Tox21 Data Challenge\" of NIH, FDA and NCATS.In 2016, Roger Parloff mentioned a \"deep learning revolution\" that has transformed the AI industry.In March 2019, Yoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.\\n\\n\\n== Neural networks ==\\n\\nArtificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.\\nAn ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\\nNeural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\").\\n\\n\\n=== Deep neural networks ===\\nA deep neural network (DNN) is an artificial neural network (ANN) with multiple layers between the input and output layers. There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions. These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.For example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer, and complex DNN have many layers, hence the name \"deep\" networks.\\nDNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives. The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network. For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.Deep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights. That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\\nRecurrent neural networks (RNNs), in which data can flow in any direction, are used for applications such as language modeling. Long short-term memory is particularly effective for this use.Convolutional deep neural networks (CNNs) are used in computer vision. CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).\\n\\n\\n==== Challenges ====\\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time.\\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko\\'s unit pruning or weight decay (\\n  \\n    \\n      \\n        \\n          ℓ\\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\ell _{2}}\\n  -regularization) or sparsity (\\n  \\n    \\n      \\n        \\n          ℓ\\n          \\n            1\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\ell _{1}}\\n  -regularization) can be applied during training to combat overfitting. Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies. Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.DNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples) speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.Alternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn\\'t require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.\\n\\n\\n== Hardware ==\\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.Special electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform. Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).Atomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\\nIn 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).In 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing. The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds. Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.\\n\\n\\n== Applications ==\\n\\n\\n=== Automatic speech recognition ===\\n\\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.The initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\\n\\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003–2007, accelerated progress in eight major areas:\\nScale-up/out and accelerated DNN training and decoding\\nSequence discriminative training\\nFeature processing by deep models with solid understanding of the underlying mechanisms\\nAdaptation of DNNs and related deep models\\nMulti-task and transfer learning by DNNs and related deep models\\nCNNs and how to design them to best exploit domain knowledge of speech\\nRNN and its rich LSTM variants\\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models.All major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.\\n\\n\\n=== Image recognition ===\\n\\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.Deep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.Deep learning-trained vehicles now interpret 360° camera views. Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\\n\\n\\n=== Visual art processing ===\\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\\n\\nidentifying the style period of a given painting\\nNeural Style Transfer –  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video\\ngenerating striking imagery based on random visual input fields.\\n\\n\\n=== Natural language processing ===\\n\\nNeural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.Other key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.Recent developments generalize word embedding to sentence embedding.\\nGoogle Translate (GT) uses a large end-to-end long short-term memory (LSTM) network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\". It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages. The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\". GT uses English as an intermediate between most language pairs.\\n\\n\\n=== Drug discovery and toxicology ===\\n\\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects. Research has explored use of deep learning to predict the biomolecular targets, off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.AtomNet is a deep learning system for structure-based rational drug design. AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus and multiple sclerosis.In 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set. In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.\\n\\n\\n=== Customer relationship management ===\\n\\nDeep reinforcement learning has been used to approximate the value of possible direct marketing actions, defined in terms of RFM variables. The estimated value function was shown to have a natural interpretation as customer lifetime value.\\n\\n\\n=== Recommendation systems ===\\n\\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations. Multi-view deep learning has been applied for learning user preferences from multiple domains. The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\\n\\n\\n=== Bioinformatics ===\\n\\nAn autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.In medical informatics, deep learning was used to predict sleep quality based on data from wearables and predictions of health complications from electronic health record data.\\n\\n\\n=== Deep Neural Network Estimations ===\\nDeep neural networks (DNN) can be used to estimate the entropy of a stochastic process and called Neural Joint Entropy Estimator (NJEE). Such an estimation provides insights on the affects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels\\' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in case of large alphabet sizes.\\n\\n\\n=== Medical image analysis ===\\nDeep learning has been shown to produce competitive results in medical application such as cancer cell classification, lesion detection, organ segmentation and image enhancement. Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.\\n\\n\\n=== Mobile advertising ===\\nFinding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server. Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\\n\\n\\n=== Image restoration ===\\nDeep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization. These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\" which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration.\\n\\n\\n=== Financial fraud detection ===\\nDeep learning is being successfully applied to financial fraud detection, tax evasion detection, and anti-money laundering.\\n\\n\\n=== Military ===\\nThe United States Department of Defense applied deep learning to train robots in new tasks through observation.\\n\\n\\n=== Partial differential equations ===\\nPhysics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner. One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods relies on.\\n\\n\\n=== Image Reconstruction ===\\nImage reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging  and ultrasound imaging.\\n\\n\\n=== Epigenetic clock ===\\n\\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.\\n\\n\\n== Relation to human cognitive and brain development ==\\nDeep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant\\'s brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".A variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.Although a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.\\n\\n\\n== Commercial activity ==\\nFacebook\\'s AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.Google\\'s DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.\\nIn 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.As of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".\\n\\n\\n== Criticism and comment ==\\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\\n\\n\\n=== Theory ===\\n\\nA main criticism concerns the lack of theory surrounding some methods. Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear. (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.Others point out that deep learning should be looked at as a step towards realizing strong AI, not as an all-encompassing solution. Despite the power of deep learning methods, they still lack much of the functionality needed for realizing this goal entirely. Research psychologist Gary Marcus noted:\\n\\nRealistically, deep learning is only part of the larger challenge of building intelligent machines. Such techniques lack ways of representing causal relationships (...) have no obvious ways of performing logical inferences, and they are also still a long way from integrating abstract knowledge, such as information about what objects are, what they are for, and how they are typically used. The most powerful A.I. systems, like Watson (...) use techniques like deep learning as just one element in a very complicated ensemble of techniques, ranging from the statistical technique of Bayesian inference to deductive reasoning.\\n\\nIn further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian\\'s website.\\n\\n\\n=== Errors ===\\nSome deep learning architectures display problematic behaviors, such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014) and misclassifying minuscule perturbations of correctly classified images (2013). Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures. These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar decompositions of observed entities and events. Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition and artificial intelligence (AI).\\n\\n\\n=== Cyber threat ===\\nAs deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception. By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".In 2016 researchers used one ANN to doctor images in trial and error fashion, identify another\\'s focal points and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system. One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.Another group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.ANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.In 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".In \"data poisoning\", false data is continually smuggled into a machine learning system\\'s training set to prevent it from achieving mastery.\\n\\n\\n=== Data collection ethics ===\\nMost Deep Learning systems rely on training and verification data that is generated and/or annotated by humans. It has been argued in media philosophy that not only low-paid clickwork (e.g. on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such. The philosopher Rainer Mühlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.Mühlhoff argues that in most commercial end-user applications of Deep Learning such as Facebook\\'s face recognition system, the need for training data does not stop once an ANN is trained. Rather, there is a continued demand for human-generated verification data to constantly calibrate and update the ANN. For this purpose Facebook introduced the feature that once a user is automatically recognized in an image, they receive a notification. They can choose whether of not they like to be publicly labeled on the image, or tell Facebook that it is not them in the picture. This user interface is a mechanism to generate \"a constant stream of verification data\" to further train the network in real-time. As Mühlhoff argues, involvement of human users to generate training and verification data is so typical for most commercial end-user applications of Deep Learning that such systems may be referred to as \"human-aided artificial intelligence\".\\n\\n\\n== See also ==\\nApplications of artificial intelligence\\nComparison of deep learning software\\nCompressed sensing\\nDifferentiable programming\\nEcho state network\\nList of artificial intelligence projects\\nLiquid state machine\\nList of datasets for machine-learning research\\nReservoir computing\\nScale space and deep learning\\nSparse coding\\nStochastic parrot\\n\\n\\n== References ==\\n\\n\\n== Further reading ==',\n",
              " 'Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine). Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.A  data scientist is a professional who creates programming code and combines it with statistical knowledge to create insights from data.\\n\\n\\n== Foundations ==\\nData science is an interdisciplinary field focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains. The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business. Statistician Nathan Yau, drawing on Ben Fry, also links data science to human–computer interaction: users should be able to intuitively control and explore data. In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.\\n\\n\\n=== Relationship to statistics ===\\nMany statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics. Others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data. Vasant Dhar writes that statistics emphasizes quantitative data and description. In contrast, data science deals with quantitative and qualitative data (e.g., from images, text, sensors, transactions, customer information, etc.) and emphasizes prediction and action. Andrew Gelman of Columbia University has described statistics as a non-essential part of data science.Stanford professor David Donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data-science program. He describes data science as an applied field growing out of traditional statistics.\\n\\n\\n== Etymology ==\\n\\n\\n=== Early usage ===\\nIn 1962, John Tukey described a field he called \"data analysis\", which resembles modern data science. In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C. F. Jeff Wu used the term \"data science\" for the first time as an alternative name for statistics. Later, attendees at a 1992 statistics symposium at the University of Montpellier  II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.The term \"data science\" has been traced back to 1974, when Peter Naur proposed it as an alternative name to computer science. In 1996, the International Federation of Classification Societies became the first conference to specifically feature data science as a topic. However, the definition was still in flux. After the 1985 lecture at the Chinese Academy of Sciences in Beijing, in 1997 C. F. Jeff Wu again suggested that statistics should be renamed data science. He reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting or limited to describing data. In 1998, Hayashi Chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.During the 1990s, popular terms for the process of finding patterns in datasets (which were increasingly large) included \"knowledge discovery\" and \"data mining\".\\n\\n\\n=== Modern usage ===\\nIn 2012, technologists Thomas H. Davenport and DJ Patil declared \"Data Scientist: The Sexiest Job of the 21st Century\", a catchphrase that was picked up even by major-city newspapers like the New York Times and the Boston Globe. A decade later, they reaffirmed it, stating that \"the job is more in demand than ever with employers\".The modern conception of data science as an independent discipline is sometimes attributed to William S. Cleveland. In a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name. \"Data science\" became more widely used in the next few years: in 2002, the Committee on Data for Science and Technology launched the Data Science Journal. In 2003, Columbia University launched The Journal of Data Science. In 2014, the American Statistical Association\\'s Section on Statistical Learning and Data Mining changed its name to the Section on Statistical Learning and Data Science, reflecting the ascendant popularity of data science.The professional title of \"data scientist\" has been attributed to DJ Patil and Jeff Hammerbacher in 2008. Though it was used by the National Science Board in their 2005 report \"Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century\", it referred broadly to any key role in managing a digital data collection.There is still no consensus on the definition of data science, and it is considered by some to be a buzzword. Big data is a related marketing term. Data scientists are responsible for breaking down big data into usable information and creating software and algorithms that help companies and organizations determine optimal operations.\\n\\n\\n== Data Science and Data Analysis ==\\nData science and data analysis are both important disciplines in the field of data management and analysis, but they differ in several key ways. While both fields involve working with data, data science is more of an interdisciplinary field that involves the application of statistical, computational, and machine learning methods to extract insights from data and make predictions, while data analysis is more focused on the examination and interpretation of data to identify patterns and trends.Data analysis typically involves working with smaller, structured datasets to answer specific questions or solve specific problems. This can involve tasks such as data cleaning, data visualization, and exploratory data analysis to gain insights into the data and develop hypotheses about relationships between variables. Data analysts typically use statistical methods to test these hypotheses and draw conclusions from the data. For example, a data analyst might analyze sales data to identify trends in customer behavior and make recommendations for marketing strategies.Data science, on the other hand, is a more complex and iterative process that involves working with larger, more complex datasets that often require advanced computational and statistical methods to analyze. Data scientists often work with unstructured data such as text or images and use machine learning algorithms to build predictive models and make data-driven decisions. In addition to statistical analysis, data science often involves tasks such as data preprocessing, feature engineering, and model selection. For instance, a data scientist might develop a recommendation system for an e-commerce platform by analyzing user behavior patterns and using machine learning algorithms to predict user preferences.While data analysis focuses on extracting insights from existing data, data science goes beyond that by incorporating the development and implementation of predictive models to make informed decisions. Data scientists are often responsible for collecting and cleaning data, selecting appropriate analytical techniques, and deploying models in real-world scenarios. They work at the intersection of mathematics, computer science, and domain expertise to solve complex problems and uncover hidden patterns in large datasets.Despite these differences, data science and data analysis are closely related fields and often require similar skill sets. Both fields require a solid foundation in statistics, programming, and data visualization, as well as the ability to communicate findings effectively to both technical and non-technical audiences. Moreover, both fields benefit from critical thinking and domain knowledge, as understanding the context and nuances of the data is essential for accurate analysis and modeling.In summary, data analysis and data science are distinct yet interconnected disciplines within the broader field of data management and analysis. Data analysis focuses on extracting insights and drawing conclusions from structured data, while data science involves a more comprehensive approach that combines statistical analysis, computational methods, and machine learning to extract insights, build predictive models, and drive data-driven decision-making. Both fields play vital roles in leveraging the power of data to understand patterns, make informed decisions, and solve complex problems across various domains.\\n\\n\\n== History ==\\n\\n\\n== See also ==\\nOpen Data Science Conference\\nScientific Data\\nWomen in Data\\nPython (programming language)\\nR (programming language)\\nData engineering\\nBig data\\nMachine learning\\n\\n\\n== References ==',\n",
              " 'In mathematics and computer science, an algorithm ( ) is a finite sequence of rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning), achieving automation eventually. Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as \"memory\", \"search\" and \"stimulus\".In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\\n\\n\\n== History ==\\n\\n\\n=== Ancient algorithms ===\\nSince antiquity, step-by-step procedures for solving mathematical problems have been attested. This includes Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later; e.g. Shulba Sutras, Kerala School, and Brāhmasphuṭasiddhānta), The Ifa Oracle (around 500 BC), Greek mathematics (around 240 BC, e.g. sieve of Eratosthenes and Euclidean algorithm), and Arabic mathematics (9th century, e.g. cryptographic algorithms for code-breaking based on frequency analysis).\\n\\n\\n=== Al-Khwārizmī and the term algorithm ===\\nAround 825, Muḥammad ibn Mūsā al-Khwārizmī wrote kitāb al-ḥisāb al-hindī (\"Book of Indian computation\") and kitab al-jam\\' wa\\'l-tafriq al-ḥisāb al-hindī (\"Addition and subtraction in Indian arithmetic\"). Both of these texts are lost in the original Arabic at this time. (However, his other book on algebra remains.)In the early 12th century, Latin translations of said al-Khwarizmi texts involving the Hindu–Arabic numeral system and arithmetic appeared: Liber Alghoarismi de practica arismetrice (attributed to John of Seville) and Liber Algorismi de numero Indorum (attributed to Adelard of Bath). Hereby, alghoarismi or algorismi is the Latinization of Al-Khwarizmi\\'s name; the text starts with the phrase Dixit Algorismi (\"Thus spoke Al-Khwarizmi\").In 1240, Alexander of Villedieu writes a Latin text titled Carmen de Algorismo. It begins with:\\n\\nHaec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris.\\nwhich translates to:\\n\\nAlgorism is the art by which at present we use those Indian figures, which number two times five.\\nThe poem is a few hundred lines long and summarizes the art of calculating with the new styled Indian dice (Tali Indorum), or Hindu numerals.\\n\\n\\n=== English evolution of the word ===\\nAround 1230, the English word algorism is attested and then by Chaucer in 1391. English adopted the French term.In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, \"number\"; cf. \"arithmetic\"), the Latin word was altered to algorithmus.\\nIn 1656, in the English dictionary Glossographia, it says:\\n\\nAlgorism ([Latin] algorismus) the Art or use of Cyphers, or of numbering by Cyphers; skill in accounting.\\nAugrime ([Latin] algorithmus) skil in accounting or numbring.\\n\\nIn 1658, in the first edition of The New World of English Words, it says:\\n\\nAlgorithme, (a word compounded of Arabick and Spanish,) the art of reckoning by Cyphers.\\n\\nIn 1706, in the sixth edition of The New World of English Words, it says:\\n\\nAlgorithm, the Art of computing or reckoning by numbers, which contains the five principle Rules of Arithmetick, viz. Numeration, Addition, Subtraction, Multiplication and Division; to which may be added Extraction of Roots: It is also call\\'d Logistica Numeralis.\\nAlgorism, the practical Operation in the several Parts of Specious Arithmetick or Algebra; sometimes it is taken for the Practice of Common Arithmetick by the ten Numeral Figures.\\n\\nIn 1751, in the Young Algebraist\\'s Companion, Daniel Fenning contrasts the terms algorism and algorithm as follows:\\n\\nAlgorithm signifies the first Principles, and Algorism the practical Part, or knowing how to put the Algorithm in Practice.\\n\\nSince at least 1811, the term algorithm is attested to mean a \"step-by-step procedure\" in English.In 1842, in the Dictionary of Science, Literature and Art, it says:\\n\\nALGORITHM, signifies the art of computing in reference to some particular subject, or in some particular way; as the algorithm of numbers; the algorithm of the differential calculus.\\n\\n\\n=== Machine usage ===\\nIn 1928, a partial formalization of the modern concept of algorithms began with attempts to solve the Entscheidungsproblem (decision problem) posed by David Hilbert. Later formalizations were framed as attempts to define \"effective calculability\" or \"effective method\". Those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church\\'s lambda calculus of 1936, Emil Post\\'s Formulation 1 of 1936, and Alan Turing\\'s Turing machines of 1936–37 and 1939.\\n\\n\\n== Informal definition ==\\n\\nOne informal definition is \"a set of rules that precisely defines a sequence of operations\", which would include all computer programs (including programs that do not perform numeric calculations), and (for example) any prescribed bureaucratic procedure\\nor cook-book recipe.In general, a program is an algorithm only if it stops eventually—even though infinite loops may sometimes prove desirable.\\nA prototypical example of an algorithm is the Euclidean algorithm, which is used to determine the maximum common divisor of two integers; an example (there are others) is described by the flowchart above and as an example in a later section.\\nBoolos, Jeffrey & 1974, 1999 offer an informal meaning of the word \"algorithm\" in the following quotation:\\n\\nNo human being can write fast enough, or long enough, or small enough† ( †\"smaller and smaller without limit ... you\\'d be trying to write on molecules, on atoms, on electrons\") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols.\\nAn \"enumerably infinite set\" is one whose elements can be put into one-to-one correspondence with the integers. Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process that \"creates\" output integers from an arbitrary \"input\" integer or integers that, in theory, can be arbitrarily large. For example, an algorithm can be an algebraic equation such as y = m + n (i.e., two arbitrary \"input variables\" m and n that produce an output y), but various authors\\' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):\\n\\nPrecise instructions (in a language understood by \"the computer\") for a fast, efficient, \"good\" process that specifies the \"moves\" of \"the computer\" (machine or human, equipped with the necessary internally contained information and capabilities) to find, decode, and then process arbitrary input integers/symbols m and n, symbols + and = ... and \"effectively\" produce, in a \"reasonable\" time, output-integer y at a specified place and in a specified format.The concept of algorithm is also used to define the notion of decidability—a notion that is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related to the customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.\\nMost algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.\\n\\n\\n== Formalization ==\\nAlgorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform—in a specific order—to carry out a specified task, such as calculating employees\\' paychecks or printing students\\' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987), and Gurevich (2000):\\n\\n Minsky: \"But we will also maintain, with Turing ... that any procedure which could \"naturally\" be called effective, can, in fact, be realized by a (simple) machine. Although this may seem extreme, the arguments ... in its favor are hard to refute\".\\n Gurevich: \"… Turing\\'s informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine … according to Savage [1987], an algorithm is a computational process defined by a Turing machine\".Turing machines can define computational processes that do not terminate. The informal definitions of algorithms generally require that the algorithm always terminates. This requirement renders the task of deciding whether a formal procedure is an algorithm impossible in the general case—due to a major theorem of computability theory known as the halting problem.\\nTypically, when an algorithm is associated with processing information, data can be read from an input source, written to an output device and stored for further processing. Stored data is regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.\\nFor some of these computational processes, the algorithm must be rigorously defined and specified in the way it applies in all possible circumstances that could arise. This means that any conditional steps must be systematically dealt with, case by case; the criteria for each case must be clear (and computable).\\nBecause an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting \"from the top\" and going \"down to the bottom\"—an idea that is described more formally by flow of control.\\nSo far, the discussion on the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception—one that attempts to describe a task in discrete, \"mechanical\" terms. Associated with this conception of formalized algorithms is the assignment operation, which sets the value of a variable. It derives from the intuition of \"memory\" as a scratchpad. An example of such an assignment can be found below.\\nFor some alternate conceptions of what constitutes an algorithm, see functional programming and logic programming.\\n\\n\\n== Expressing algorithms ==\\nAlgorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, drakon-charts, programming languages or control tables (processed by interpreters). Natural language expressions of algorithms tend to be verbose and ambiguous and are rarely used for complex or technical algorithms. Pseudocode, flowcharts, drakon-charts and control tables are structured ways to express algorithms that avoid many of the ambiguities common in statements based on natural language. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer, but they are also often used as a way to define or document algorithms.\\nThere is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see finite-state machine, state-transition table and control table for more), as flowcharts and drakon-charts (see state diagram for more), or as a form of rudimentary machine code or assembly code called \"sets of quadruples\" (see Turing machine for more).\\nRepresentations of algorithms can be classified into three accepted levels of Turing machine description, as follows:\\n1 High-level description\\n\"...prose to describe an algorithm, ignoring the implementation details. At this level, we do not need to mention how the machine manages its tape or head.\"\\n2 Implementation description\\n\"...prose used to define the way the Turing machine uses its head and the way that it stores data on its tape. At this level, we do not give details of states or transition function.\"\\n3 Formal description\\nMost detailed, \"lowest level\", gives the Turing machine\\'s \"state table\".For an example of the simple algorithm \"Add m+n\" described in all three levels, see Examples.\\n\\n\\n== Design ==\\n\\nAlgorithm design refers to a method or a mathematical process for problem-solving and engineering algorithms. The design of algorithms is part of many solution theories, such as divide-and-conquer or dynamic programming within operation research. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, with examples including the template method pattern and the decorator pattern.\\nOne of the most important aspects of algorithm design is resource (run-time, memory usage) efficiency; the big O notation is used to describe e.g., an algorithm\\'s run-time growth as the size of its input increases.\\nTypical steps in the development of algorithms:\\n\\nProblem definition\\nDevelopment of a model\\nSpecification of the algorithm\\nDesigning an algorithm\\nChecking the correctness of the algorithm\\nAnalysis of algorithm\\nImplementation of algorithm\\nProgram testing\\nDocumentation preparation\\n\\n\\n== Computer algorithms ==\\n\"Elegant\" (compact) programs, \"good\" (fast) programs: The notion of \"simplicity and elegance\" appears informally in Knuth and precisely in Chaitin:\\n\\nKnuth: \" ... we want good algorithms in some loosely defined aesthetic sense. One criterion ... is the length of time taken to perform the algorithm .... Other criteria are adaptability of the algorithm to computers, its simplicity, and elegance, etc.\"Chaitin: \" ... a program is \\'elegant,\\' by which I mean that it\\'s the smallest possible program for producing the output that it does\"Chaitin prefaces his definition with: \"I\\'ll show you can\\'t prove that a program is \\'elegant\\'\"—such a proof would solve the Halting problem (ibid).\\nAlgorithm versus function computable by an algorithm: For a given function multiple algorithms may exist. This is true even without expanding the available instruction set available to the programmer. Rogers observes that \"It is ... important to distinguish between the notion of algorithm, i.e. procedure and the notion of function computable by algorithm, i.e. mapping yielded by procedure. The same function may have several different algorithms\".Unfortunately, there may be a tradeoff between goodness (speed) and elegance (compactness)—an elegant program may take more steps to complete a computation than one that is less elegant. An example that uses Euclid\\'s algorithm appears below.\\nComputers (and computors), models of computation: A computer (or human \"computer\") is a restricted type of machine, a \"discrete deterministic mechanical device\" that blindly follows its instructions. Melzak\\'s and Lambek\\'s primitive models reduced this notion to four elements: (i) discrete, distinguishable locations, (ii) discrete, indistinguishable counters (iii) an agent, and (iv) a list of instructions that are effective relative to the capability of the agent.Minsky describes a more congenial variation of Lambek\\'s \"abacus\" model in his \"Very Simple Bases for Computability\". Minsky\\'s machine proceeds sequentially through its five (or six, depending on how one counts) instructions unless either a conditional IF-THEN GOTO or an unconditional GOTO changes program flow out of sequence. Besides HALT, Minsky\\'s machine includes three assignment (replacement, substitution) operations: ZERO (e.g. the contents of the location replaced by 0: L ← 0), SUCCESSOR (e.g. L ← L+1), and DECREMENT (e.g. L ← L − 1). Rarely must a programmer write \"code\" with such a limited instruction set. But Minsky shows (as do Melzak and Lambek) that his machine is Turing complete with only four general types of instructions: conditional GOTO, unconditional GOTO, assignment/replacement/substitution, and HALT. However, a few different assignment instructions (e.g. DECREMENT, INCREMENT, and ZERO/CLEAR/EMPTY for a Minsky machine) are also required for Turing-completeness; their exact specification is somewhat up to the designer. The unconditional GOTO is convenient; it can be constructed by initializing a dedicated location to zero e.g. the instruction \" Z ← 0 \"; thereafter the instruction IF Z=0 THEN GOTO xxx is unconditional.\\nSimulation of an algorithm: computer (computor) language: Knuth advises the reader that \"the best way to learn an algorithm is to try it . . . immediately take pen and paper and work through an example\". But what about a simulation or execution of the real thing? The programmer must translate the algorithm into a language that the simulator/computer/computor can effectively execute. Stone gives an example of this: when computing the roots of a quadratic equation the computer must know how to take a square root. If they do not, then the algorithm, to be effective, must provide a set of rules for extracting a square root.This means that the programmer must know a \"language\" that is effective relative to the target computing agent (computer/computor).\\nBut what model should be used for the simulation? Van Emde Boas observes \"even if we base complexity theory on abstract instead of concrete machines, the arbitrariness of the choice of a model remains. It is at this point that the notion of simulation enters\". When speed is being measured, the instruction set matters. For example, the subprogram in Euclid\\'s algorithm to compute the remainder would execute much faster if the programmer had a \"modulus\" instruction available rather than just subtraction (or worse: just Minsky\\'s \"decrement\").\\nStructured programming, canonical structures: Per the Church–Turing thesis, any algorithm can be computed by a model known to be Turing complete, and per Minsky\\'s demonstrations, Turing completeness requires only four instruction types—conditional GOTO, unconditional GOTO, assignment, HALT. Kemeny and Kurtz observe that, while \"undisciplined\" use of unconditional GOTOs and conditional IF-THEN GOTOs can result in \"spaghetti code\", a programmer can write structured programs using only these instructions; on the other hand \"it is also possible, and not too hard, to write badly structured programs in a structured language\". Tausworthe augments the three Böhm-Jacopini canonical structures: SEQUENCE, IF-THEN-ELSE, and WHILE-DO, with two more: DO-WHILE and CASE. An additional benefit of a structured program is that it lends itself to proofs of correctness using mathematical induction.Canonical flowchart symbols: The graphical aid called a flowchart offers a way to describe and document an algorithm (and a computer program corresponding to it). Like the program flow of a Minsky machine, a flowchart always starts at the top of a page and proceeds down. Its primary symbols are only four: the directed arrow showing program flow, the rectangle (SEQUENCE, GOTO), the diamond (IF-THEN-ELSE), and the dot (OR-tie). The Böhm–Jacopini canonical structures are made of these primitive shapes. Sub-structures can \"nest\" in rectangles, but only if a single exit occurs from the superstructure. The symbols and their use to build the canonical structures are shown in the diagram.\\n\\n\\n== Examples ==\\n\\n\\n=== Algorithm example ===\\nOne of the simplest algorithms is to find the largest number in a list of numbers of random order. Finding the solution requires looking at every number in the list. From this follows a simple algorithm, which can be stated in a high-level description in English prose, as:\\nHigh-level description:\\n\\nIf there are no numbers in the set, then there is no highest number.\\nAssume the first number in the set is the largest number in the set.\\nFor each remaining number in the set: if this number is larger than the current largest number, consider this number to be the largest number in the set.\\nWhen there are no numbers left in the set to iterate over, consider the current largest number to be the largest number of the set.(Quasi-)formal description:\\nWritten in prose but much closer to the high-level language of a computer program, the following is the more formal coding of the algorithm in pseudocode or pidgin code:\\n\\n\\n=== Euclid\\'s algorithm ===\\n\\nIn mathematics, the Euclidean algorithm or Euclid\\'s algorithm, is an efficient method for computing the greatest common divisor (GCD) of two integers (numbers), the largest number that divides them both without a remainder. It is named after the ancient Greek mathematician Euclid, who first described it in his Elements (c.\\u2009300 BC). It is one of the oldest algorithms in common use. It can be used to reduce fractions to their simplest form, and is a part of many other number-theoretic and cryptographic calculations.\\n\\nEuclid poses the problem thus: \"Given two numbers not prime to one another, to find their greatest common measure\". He defines \"A number [to be] a multitude composed of units\": a counting number, a positive integer not including zero. To \"measure\" is to place a shorter measuring length s successively (q times) along longer length l until the remaining portion r is less than the shorter length s. In modern words, remainder r = l − q×s, q being the quotient, or remainder r is the \"modulus\", the integer-fractional part left over after the division.For Euclid\\'s method to succeed, the starting lengths must satisfy two requirements: (i) the lengths must not be zero, AND (ii) the subtraction must be \"proper\"; i.e., a test must guarantee that the smaller of the two numbers is subtracted from the larger (or the two can be equal so their subtraction yields zero).\\nEuclid\\'s original proof adds a third requirement: the two lengths must not be prime to one another. Euclid stipulated this so that he could construct a reductio ad absurdum proof that the two numbers\\' common measure is in fact the greatest. While Nicomachus\\' algorithm is the same as Euclid\\'s, when the numbers are prime to one another, it yields the number \"1\" for their common measure. So, to be precise, the following is really Nicomachus\\' algorithm.\\n\\n\\n==== Computer language for Euclid\\'s algorithm ====\\nOnly a few instruction types are required to execute Euclid\\'s algorithm—some logical tests (conditional GOTO), unconditional GOTO, assignment (replacement), and subtraction.\\n\\nA location is symbolized by upper case letter(s), e.g. S, A, etc.\\nThe varying quantity (number) in a location is written in lower case letter(s) and (usually) associated with the location\\'s name. For example, location L at the start might contain the number l = 3009.\\n\\n\\n==== An inelegant program for Euclid\\'s algorithm ====\\nThe following algorithm is framed as Knuth\\'s four-step version of Euclid\\'s and Nicomachus\\', but, rather than using division to find the remainder, it uses successive subtractions of the shorter length s from the remaining length r until r is less than s. The high-level description, shown in boldface, is adapted from Knuth 1973:2–4:\\nINPUT:\\n\\n1 [Into two locations L and S put the numbers l and s that represent the two lengths]:\\nINPUT L, S\\n2 [Initialize R: make the remaining length r equal to the starting/initial/input length l]:\\nR ← L\\n\\nE0: [Ensure r ≥ s.]\\n\\n3 [Ensure the smaller of the two numbers is in S and the larger in R]:\\nIF R > S THEN\\nthe contents of L is the larger number so skip over the exchange-steps 4, 5 and 6:\\nGOTO step 7\\nELSE\\nswap the contents of R and S.\\n4 L ← R (this first step is redundant, but is useful for later discussion).\\n5 R ← S\\n6 S ← L\\n\\nE1: [Find remainder]: Until the remaining length r in R is less than the shorter length s in S, repeatedly subtract the measuring number s in S from the remaining length r in R.\\n\\n7 IF S > R THEN\\ndone measuring so\\nGOTO 10\\nELSE\\nmeasure again,\\n8 R ← R − S\\n9 [Remainder-loop]:\\nGOTO 7.\\n\\nE2: [Is the remainder zero?]: EITHER (i) the last measure was exact, the remainder in R is zero, and the program can halt, OR (ii) the algorithm must continue: the last measure left a remainder in R less than measuring number in S.\\n\\n10 IF R = 0 THEN\\ndone so\\nGOTO step 15\\nELSE\\nCONTINUE TO step 11,\\n\\nE3: [Interchange s and r]: The nut of Euclid\\'s algorithm. Use remainder r to measure what was previously smaller number s; L serves as a temporary location.\\n\\n11 L ← R\\n12 R ← S\\n13 S ← L\\n14 [Repeat the measuring process]:\\nGOTO 7\\n\\nOUTPUT:\\n\\n15 [Done. S contains the greatest common divisor]:\\nPRINT S\\n\\nDONE:\\n\\n16 HALT, END, STOP.\\n\\n\\n==== An elegant program for Euclid\\'s algorithm ====\\nThe following version of Euclid\\'s algorithm requires only six core instructions to do what thirteen are required to do by \"Inelegant\"; worse, \"Inelegant\" requires more types of instructions. The flowchart of \"Elegant\" can be found at the top of this article. In the (unstructured) Basic language, the steps are numbered, and the instruction LET [] = [] is the assignment instruction symbolized by ←.\\n\\nHow \"Elegant\" works: instead of an outer \"Euclid loop\", \"Elegant\" calculates the remainder of a division using modulo and shifts the variables A and B in each iteration. The following algorithm can be used with programming languages from the C-family:\\n\\nThe standard function abs changes negative integer to positive integer\\nWhen input A or B has the value 0, the algorithm stops and the result is 0\\nIf input A is greater than input B, the algorithm will automatically swap variables A and B during the first iteration via modulo\\nThe iteration (a do while loop) starts and only stops when the variable B is set to 0:\\n% calculates the modulo of division A and B, which reduces the number (e.g.: 23 = 3 × 6 + remainder 5)\\nA is equated with B\\nB is equated with the modulo-result\\nThe iteration continues as long as B is greater than 0\\nWhen the iteration stops, variable A always contains the greatest common divisor\\n\\n\\n=== Testing the Euclid algorithms ===\\nDoes an algorithm do what its author wants it to do? A few test cases usually give some confidence in the core functionality. But tests are not enough. For test cases, one source uses 3009 and 884. Knuth suggested 40902, 24140. Another interesting case is the two relatively prime numbers 14157 and 5950.\\nBut \"exceptional cases\" must be identified and tested. Will \"Inelegant\" perform properly when R > S, S > R, R = S? Ditto for \"Elegant\": B > A, A > B, A = B? (Yes to all). What happens when one number is zero, both numbers are zero? (\"Inelegant\" computes forever in all cases; \"Elegant\" computes forever when A = 0.) What happens if negative numbers are entered? Fractional numbers? If the input numbers, i.e. the domain of the function computed by the algorithm/program, is to include only positive integers including zero, then the failures at zero indicate that the algorithm (and the program that instantiates it) is a partial function rather than a total function. A notable failure due to exceptions is the Ariane 5 Flight 501 rocket failure (June 4, 1996).\\nProof of program correctness by use of mathematical induction: Knuth demonstrates the application of mathematical induction to an \"extended\" version of Euclid\\'s algorithm, and he proposes \"a general method applicable to proving the validity of any algorithm\". Tausworthe proposes that a measure of the complexity of a program be the length of its correctness proof.\\n\\n\\n=== Measuring and improving the Euclid algorithms ===\\nElegance (compactness) versus goodness (speed): With only six core instructions, \"Elegant\" is the clear winner, compared to \"Inelegant\" at thirteen instructions. However, \"Inelegant\" is faster (it arrives at HALT in fewer steps). Algorithm analysis indicates why this is the case: \"Elegant\" does two conditional tests in every subtraction loop, whereas \"Inelegant\" only does one. As the algorithm (usually) requires many loop-throughs, on average much time is wasted doing a \"B = 0?\" test that is needed only after the remainder is computed.\\nCan the algorithms be improved?: Once the programmer judges a program \"fit\" and \"effective\"—that is, it computes the function intended by its author—then the question becomes, can it be improved?\\nThe compactness of \"Inelegant\" can be improved by the elimination of five steps. But Chaitin proved that compacting an algorithm cannot be automated by a generalized algorithm; rather, it can only be done heuristically; i.e., by exhaustive search (examples to be found at Busy beaver), trial and error, cleverness, insight, application of inductive reasoning, etc. Observe that steps 4, 5 and 6 are repeated in steps 11, 12 and 13. Comparison with \"Elegant\" provides a hint that these steps, together with steps 2 and 3, can be eliminated. This reduces the number of core instructions from thirteen to eight, which makes it \"more elegant\" than \"Elegant\", at nine steps.\\nThe speed of \"Elegant\" can be improved by moving the \"B=0?\" test outside of the two subtraction loops. This change calls for the addition of three instructions (B = 0?, A = 0?, GOTO). Now \"Elegant\" computes the example-numbers faster; whether this is always the case for any given A, B, and R, S would require a detailed analysis.\\n\\n\\n== Algorithmic analysis ==\\n\\nIt is frequently important to know how much of a particular resource (such as time or storage) is theoretically required for a given algorithm. Methods have been developed for the analysis of algorithms to obtain such quantitative answers (estimates); for example, an algorithm which adds up the elements of a list of n numbers would have a time requirement of \\n  \\n    \\n      \\n        O\\n        (\\n        n\\n        )\\n      \\n    \\n    {\\\\displaystyle O(n)}\\n  , using big O notation. At all times the algorithm only needs to remember two values: the sum of all the elements so far, and its current position in the input list. Therefore, it is said to have a space requirement of \\n  \\n    \\n      \\n        O\\n        (\\n        1\\n        )\\n      \\n    \\n    {\\\\displaystyle O(1)}\\n  , if the space required to store the input numbers is not counted, or \\n  \\n    \\n      \\n        O\\n        (\\n        n\\n        )\\n      \\n    \\n    {\\\\displaystyle O(n)}\\n   if it is counted.\\nDifferent algorithms may complete the same task with a different set of instructions in less or more time, space, or \\'effort\\' than others. For example, a binary search algorithm (with cost \\n  \\n    \\n      \\n        O\\n        (\\n        log\\n        \\u2061\\n        n\\n        )\\n      \\n    \\n    {\\\\displaystyle O(\\\\log n)}\\n  ) outperforms a sequential search (cost \\n  \\n    \\n      \\n        O\\n        (\\n        n\\n        )\\n      \\n    \\n    {\\\\displaystyle O(n)}\\n   ) when used for table lookups on sorted lists or arrays.\\n\\n\\n=== Formal versus empirical ===\\n\\nThe analysis, and study of algorithms is a discipline of computer science, and is often practiced abstractly without the use of a specific programming language or implementation. In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. Usually pseudocode is used for analysis as it is the simplest and most general representation. However, ultimately, most algorithms are usually implemented on particular hardware/software platforms and their algorithmic efficiency is eventually put to the test using real code. For the solution of a \"one off\" problem, the efficiency of a particular algorithm may not have significant consequences (unless n is extremely large) but for algorithms designed for fast interactive, commercial or long life scientific usage it may be critical. Scaling from small n to large n frequently exposes inefficient algorithms that are otherwise benign.\\nEmpirical testing is useful because it may uncover unexpected interactions that affect performance. Benchmarks may be used to compare before/after potential improvements to an algorithm after program optimization.\\nEmpirical tests cannot replace formal analysis, though, and are not trivial to perform in a fair manner.\\n\\n\\n=== Execution efficiency ===\\n\\nTo illustrate the potential improvements possible even in well-established algorithms, a recent significant innovation, relating to FFT algorithms (used heavily in the field of image processing), can decrease processing time up to 1,000 times for applications like medical imaging. In general, speed improvements depend on special properties of the problem, which are very common in practical applications. Speedups of this magnitude enable computing devices that make extensive use of image processing (like digital cameras and medical equipment) to consume less power.\\n\\n\\n== Classification ==\\nThere are various ways to classify algorithms, each with its own merits.\\n\\n\\n=== By implementation ===\\nOne way to classify algorithms is by implementation means.\\n\\nRecursion\\nA recursive algorithm is one that invokes (makes reference to) itself repeatedly until a certain condition (also known as termination condition) matches, which is a method common to functional programming. Iterative algorithms use repetitive constructs like loops and sometimes additional data structures like stacks to solve the given problems. Some problems are naturally suited for one implementation or the other. For example, towers of Hanoi is well understood using recursive implementation. Every recursive version has an equivalent (but possibly more or less complex) iterative version, and vice versa.\\nSerial, parallel or distributed\\nAlgorithms are usually discussed with the assumption that computers execute one instruction of an algorithm at a time. Those computers are sometimes called serial computers. An algorithm designed for such an environment is called a serial algorithm, as opposed to parallel algorithms or distributed algorithms. Parallel algorithms are algorithms that take advantage of computer architectures where multiple processors can work on a problem at the same time. Distributed algorithms are algorithms that use multiple machines connected with a computer network. Parallel and distributed algorithms divide the problem into more symmetrical or asymmetrical subproblems and collect the results back together. For example, a CPU would be an example of a parallel algorithm. The resource consumption in such algorithms is not only processor cycles on each processor but also the communication overhead between the processors. Some sorting algorithms can be parallelized efficiently, but their communication overhead is expensive. Iterative algorithms are generally parallelizable, but some problems have no parallel algorithms and are called inherently serial problems.\\nDeterministic or non-deterministic\\nDeterministic algorithms solve the problem with exact decision at every step of the algorithm whereas non-deterministic algorithms solve problems via guessing although typical guesses are made more accurate through the use of heuristics.\\nExact or approximate\\nWhile many algorithms reach an exact solution, approximation algorithms seek an approximation that is closer to the true solution. The approximation can be reached by either using a deterministic or a random strategy. Such algorithms have practical value for many hard problems. One of the examples of an approximate algorithm is the Knapsack problem, where there is a set of given items. Its goal is to pack the knapsack to get the maximum total value. Each item has some weight and some value. Total weight that can be carried is no more than some fixed number X. So, the solution must consider weights of items as well as their value.\\nQuantum algorithm\\nThey run on a realistic model of quantum computation. The term is usually used for those algorithms which seem inherently quantum, or use some essential feature of Quantum computing such as quantum superposition or quantum entanglement.\\n\\n\\n=== By design paradigm ===\\nAnother way of classifying algorithms is by their design methodology or paradigm. There is a certain number of paradigms, each different from the other. Furthermore, each of these categories includes many different types of algorithms. Some common paradigms are:\\n\\nBrute-force or exhaustive search\\nBrute force is a method of problem-solving that involves systematically trying every possible option until the optimal solution is found. This approach can be very time consuming, as it requires going through every possible combination of variables. However, it is often used when other methods are not available or too complex. Brute force can be used to solve a variety of problems, including finding the shortest path between two points and cracking passwords.\\nDivide and conquer\\nA divide-and-conquer algorithm repeatedly reduces an instance of a problem to one or more smaller instances of the same problem (usually recursively) until the instances are small enough to solve easily. One such example of divide and conquer is merge sorting. Sorting can be done on each segment of data after dividing data into segments and sorting of entire data can be obtained in the conquer phase by merging the segments. A simpler variant of divide and conquer is called a decrease-and-conquer algorithm, which solves an identical subproblem and uses the solution of this subproblem to solve the bigger problem. Divide and conquer divides the problem into multiple subproblems and so the conquer stage is more complex than decrease and conquer algorithms. An example of a decrease and conquer algorithm is the binary search algorithm.\\nSearch and enumeration\\nMany problems (such as playing chess) can be modeled as problems on graphs. A graph exploration algorithm specifies rules for moving around a graph and is useful for such problems. This category also includes search algorithms, branch and bound enumeration and backtracking.\\nRandomized algorithm\\nSuch algorithms make some choices randomly (or pseudo-randomly). They can be very useful in finding approximate solutions for problems where finding exact solutions can be impractical (see heuristic method below). For some of these problems, it is known that the fastest approximations must involve some randomness. Whether randomized algorithms with polynomial time complexity can be the fastest algorithms for some problems is an open question known as the P versus NP problem. There are two large classes of such algorithms:Monte Carlo algorithms return a correct answer with high-probability. E.g. RP is the subclass of these that run in polynomial time.\\nLas Vegas algorithms always return the correct answer, but their running time is only probabilistically bound, e.g. ZPP.Reduction of complexity\\nThis technique involves solving a difficult problem by transforming it into a better-known problem for which we have (hopefully) asymptotically optimal algorithms. The goal is to find a reducing algorithm whose complexity is not dominated by the resulting reduced algorithm\\'s. For example, one selection algorithm for finding the median in an unsorted list involves first sorting the list (the expensive portion) and then pulling out the middle element in the sorted list (the cheap portion). This technique is also known as transform and conquer.\\nBack tracking\\nIn this approach, multiple solutions are built incrementally and abandoned when it is determined that they cannot lead to a valid full solution.\\n\\n\\n=== Optimization problems ===\\nFor optimization problems there is a more specific classification of algorithms; an algorithm for such problems may fall into one or more of the general categories described above as well as into one of the following:\\n\\nLinear programming\\nWhen searching for optimal solutions to a linear function bound to linear equality and inequality constraints, the constraints of the problem can be used directly in producing the optimal solutions. There are algorithms that can solve any problem in this category, such as the popular simplex algorithm. Problems that can be solved with linear programming include the maximum flow problem for directed graphs. If a problem additionally requires that one or more of the unknowns must be an integer then it is classified in integer programming. A linear programming algorithm can solve such a problem if it can be proved that all restrictions for integer values are superficial, i.e., the solutions satisfy these restrictions anyway. In the general case, a specialized algorithm or an algorithm that finds approximate solutions is used, depending on the difficulty of the problem.\\nDynamic programming\\nWhen a problem shows optimal substructures—meaning the optimal solution to a problem can be constructed from optimal solutions to subproblems—and overlapping subproblems, meaning the same subproblems are used to solve many different problem instances, a quicker approach called dynamic programming avoids recomputing solutions that have already been computed. For example, Floyd–Warshall algorithm, the shortest path to a goal from a vertex in a weighted graph can be found by using the shortest path to the goal from all adjacent vertices. Dynamic programming and memoization go together. The main difference between dynamic programming and divide and conquer is that subproblems are more or less independent in divide and conquer, whereas subproblems overlap in dynamic programming. The difference between dynamic programming and straightforward recursion is in caching or memoization of recursive calls. When subproblems are independent and there is no repetition, memoization does not help; hence dynamic programming is not a solution for all complex problems. By using memoization or maintaining a table of subproblems already solved, dynamic programming reduces the exponential nature of many problems to polynomial complexity.\\nThe greedy method\\nA greedy algorithm is similar to a dynamic programming algorithm in that it works by examining substructures, in this case not of the problem but of a given solution. Such algorithms start with some solution, which may be given or have been constructed in some way, and improve it by making small modifications. For some problems they can find the optimal solution while for others they stop at local optima, that is, at solutions that cannot be improved by the algorithm but are not optimum. The most popular use of greedy algorithms is for finding the minimal spanning tree where finding the optimal solution is possible with this method. Huffman Tree, Kruskal, Prim, Sollin are greedy algorithms that can solve this optimization problem.\\nThe heuristic method\\nIn optimization problems, heuristic algorithms can be used to find a solution close to the optimal solution in cases where finding the optimal solution is impractical. These algorithms work by getting closer and closer to the optimal solution as they progress. In principle, if run for an infinite amount of time, they will find the optimal solution. Their merit is that they can find a solution very close to the optimal solution in a relatively short time. Such algorithms include local search, tabu search, simulated annealing, and genetic algorithms. Some of them, like simulated annealing, are non-deterministic algorithms while others, like tabu search, are deterministic. When a bound on the error of the non-optimal solution is known, the algorithm is further categorized as an approximation algorithm.\\n\\n\\n=== By field of study ===\\n\\nEvery field of science has its own problems and needs efficient algorithms. Related problems in one field are often studied together. Some example classes are search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, computational geometric algorithms, combinatorial algorithms, medical algorithms, machine learning, cryptography, data compression algorithms and parsing techniques.\\nFields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. For example, dynamic programming was invented for optimization of resource consumption in industry but is now used in solving a broad range of problems in many fields.\\n\\n\\n=== By complexity ===\\n\\nAlgorithms can be classified by the amount of time they need to complete compared to their input size:\\n\\nConstant time: if the time needed by the algorithm is the same, regardless of the input size. E.g. an access to an array element.\\nLogarithmic time: if the time is a logarithmic function of the input size. E.g. binary search algorithm.\\nLinear time: if the time is proportional to the input size. E.g. the traverse of a list.\\nPolynomial time: if the time is a power of the input size. E.g. the bubble sort algorithm has quadratic time complexity.\\nExponential time: if the time is an exponential function of the input size. E.g. Brute-force search.Some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. There are also mappings from some problems to other problems. Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.\\n\\n\\n=== Continuous algorithms ===\\nThe adjective \"continuous\" when applied to the word \"algorithm\" can mean:\\n\\nAn algorithm operating on data that represents continuous quantities, even though this data is represented by discrete approximations—such algorithms are studied in numerical analysis; or\\nAn algorithm in the form of a differential equation that operates continuously on the data, running on an analog computer.\\n\\n\\n== Algorithm = Logic + Control ==\\nIn logic programming, algorithms are viewed as having both \"a logic component, which specifies the knowledge to be  used in solving problems, and a control component, which determines the problem-solving strategies by means of which that knowledge is used.\"The Euclidean algorithm illustrates this view of an algorithm. Here is a logic programming representation, using :- to represent \"if\", and the relation gcd(A, B, C) to represent the function gcd(A, B) = C: \\n\\nIn the logic programming language Ciao the gcd relation can be represented directly in functional notation:\\n\\nThe Ciao implementation translates the functional notation into a relational representation in   Prolog, extracting the embedded subtractions, A-B and B-A, as separate conditions:\\n\\nThe resulting program has a purely logical (and \"declarative\") reading, as a recursive (or inductive) definition, which is independent of how the logic is used to solve problems:\\n\\nDifferent problem-solving strategies turn the logic into different algorithms. In theory, given a pair of integers A and B, forward (or \"bottom-up\") reasoning could be used to generate all instances of the gcd relation, terminating when the desired gcd of A and B is generated. Of course, forward reasoning is entirely useless in this case. But in other cases, such as the definition of the Fibonacci sequence and Datalog, forward reasoning can be an efficient problem solving strategy. (See for example the logic program for computing fibonacci numbers in Algorithm = Logic + Control).\\nIn contrast with the inefficiency of forward reasoning in this example, backward (or \"top-down\") reasoning using SLD resolution turns the logic into the Euclidean algorithm:\\n\\nOne of the advantages of the logic programming representation of the algorithm is that its purely logical reading makes it easier to verify that the algorithm is correct relative to the standard non-recursive definition of gcd. Here is the standard definition written in Prolog:\\n\\nThis definition, which is the specification of the Euclidean algorithm, is also executable in Prolog: Backward reasoning treats the specification as the brute-force algorithm that iterates through all of the integers C between 1 and A, checking whether C divides both A and B, and then for each such C iterates again through all of the integers D between 1 and A, until it finds a C such that C is greater than or equal to all of the D that also divide both A and B. Although this algorithm is hopelessly inefficient, it shows that formal specifications can often be written in logic programming form, and they can be executed by Prolog, to check that they correctly represent informal requirements.\\n\\n\\n== Legal issues ==\\n\\nAlgorithms, by themselves, are not usually patentable. In the United States, a claim consisting solely of simple manipulations of abstract concepts, numbers, or signals does not constitute \"processes\" (USPTO 2006), so algorithms are not patentable (as in Gottschalk v. Benson). However practical applications of algorithms are sometimes patentable. For example, in Diamond v. Diehr, the application of a simple feedback algorithm to aid in the curing of synthetic rubber was deemed patentable. The patenting of software is controversial, and there are criticized patents involving algorithms, especially data compression algorithms, such as Unisys\\'s LZW patent.\\nAdditionally, some cryptographic algorithms have export restrictions (see export of cryptography).\\n\\n\\n== History: Development of the notion of \"algorithm\" ==\\n\\n\\n=== Ancient Near East ===\\nThe earliest evidence of algorithms is found in the Babylonian mathematics of ancient Mesopotamia (modern Iraq). A Sumerian clay tablet found in Shuruppak near Baghdad and dated to c.\\u20092500 BC described the earliest division algorithm. During the Hammurabi dynasty c.\\u20091800 – c.\\u20091600 BC, Babylonian clay tablets described algorithms for computing formulas. Algorithms were also used in Babylonian astronomy. Babylonian clay tablets describe and employ algorithmic procedures to compute the time and place of significant astronomical events.Algorithms for arithmetic are also found in ancient Egyptian mathematics, dating back to the Rhind Mathematical Papyrus c.\\u20091550 BC. Algorithms were later used in ancient Hellenistic mathematics. Two examples are the Sieve of Eratosthenes, which was described in the Introduction to Arithmetic by Nicomachus,:\\u200aCh 9.2\\u200a and the Euclidean algorithm, which was first described in Euclid\\'s Elements (c.\\u2009300 BC).:\\u200aCh 9.1\\u200a\\n\\n\\n=== Discrete and distinguishable symbols ===\\nTally-marks: To keep track of their flocks, their sacks of grain and their money the ancients used tallying: accumulating stones or marks scratched on sticks or making discrete symbols in clay. Through the Babylonian and Egyptian use of marks and symbols, eventually Roman numerals and the abacus evolved (Dilson, p. 16–41). Tally marks appear prominently in unary numeral system arithmetic used in Turing machine and Post–Turing machine computations.\\n\\n\\n=== Manipulation of symbols as \"place holders\" for numbers: algebra ===\\nMuhammad ibn Mūsā al-Khwārizmī, a Persian mathematician, wrote the Al-jabr in the 9th century. The terms \"algorism\" and \"algorithm\" are derived from the name al-Khwārizmī, while the term \"algebra\" is derived from the book Al-jabr. In Europe, the word \"algorithm\" was originally used to refer to the sets of rules and techniques used by Al-Khwarizmi to solve algebraic equations, before later being generalized to refer to any set of rules or techniques. This eventually culminated in Leibniz\\'s notion of the calculus ratiocinator (c.\\u20091680):\\n\\nA good century and a half ahead of his time, Leibniz proposed an algebra of logic, an algebra that would specify the rules for manipulating logical concepts in the manner that ordinary algebra specifies the rules for manipulating numbers.\\n\\n\\n=== Cryptographic algorithms ===\\nThe first cryptographic algorithm for deciphering encrypted code was developed by Al-Kindi, a 9th-century Arab mathematician, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest codebreaking algorithm.\\n\\n\\n=== Mechanical contrivances with discrete states ===\\nThe clock: Bolter credits the invention of the weight-driven clock as \"The key invention [of Europe in the Middle Ages]\", in particular, the verge escapement that provides us with the tick and tock of a mechanical clock. \"The accurate automatic machine\" led immediately to \"mechanical automata\" beginning in the 13th century and finally to \"computational machines\"—the difference engine and analytical engines of Charles Babbage and Countess Ada Lovelace, mid-19th century. Lovelace is credited with the first creation of an algorithm intended for processing on a computer—Babbage\\'s analytical engine, the first device considered a real Turing-complete computer instead of just a calculator—and is sometimes called \"history\\'s first programmer\" as a result, though a full implementation of Babbage\\'s second device would not be realized until decades after her lifetime.\\nLogical machines 1870 – Stanley Jevons\\' \"logical abacus\" and \"logical machine\": The technical problem was to reduce Boolean equations when presented in a form similar to what is now known as Karnaugh maps. Jevons (1880) describes first a simple \"abacus\" of \"slips of wood furnished with pins, contrived so that any part or class of the [logical] combinations can be picked out mechanically ... More recently, however, I have reduced the system to a completely mechanical form, and have thus embodied the whole of the indirect process of inference in what may be called a Logical Machine\" His machine came equipped with \"certain moveable wooden rods\" and \"at the foot are 21 keys like those of a piano [etc.] ...\". With this machine he could analyze a \"syllogism or any other simple logical argument\".This machine he displayed in 1870 before the Fellows of the Royal Society. Another logician John Venn, however, in his 1881 Symbolic Logic, turned a jaundiced eye to this effort: \"I have no high estimate myself of the interest or importance of what are sometimes called logical machines ... it does not seem to me that any contrivances at present known or likely to be discovered really deserve the name of logical machines\"; see more at Algorithm characterizations. But not to be outdone he too presented \"a plan somewhat analogous, I apprehend, to Prof. Jevon\\'s abacus ... [And] [a]gain, corresponding to Prof. Jevons\\'s logical machine, the following contrivance may be described. I prefer to call it merely a logical-diagram machine ... but I suppose that it could do very completely all that can be rationally expected of any logical machine\".Jacquard loom, Hollerith punch cards, telegraphy and telephony – the electromechanical relay: Bell and Newell (1971) indicate that the Jacquard loom (1801), precursor to Hollerith cards (punch cards, 1887), and \"telephone switching technologies\" were the roots of a tree leading to the development of the first computers. By the mid-19th century the telegraph, the precursor of the telephone, was in use throughout the world, its discrete and distinguishable encoding of letters as \"dots and dashes\" a common sound. By the late 19th century the ticker tape (c.\\u20091870s) was in use, as was the use of Hollerith cards in the 1890 U.S. census. Then came the teleprinter (c.\\u20091910) with its punched-paper use of Baudot code on tape.\\nTelephone-switching networks of electromechanical relays (invented 1835) was behind the work of George Stibitz (1937), the inventor of the digital adding device. As he worked in Bell Laboratories, he observed the \"burdensome\\' use of mechanical calculators with gears. \"He went home one evening in 1937 intending to test his idea... When the tinkering was over, Stibitz had constructed a binary adding device\".The mathematician Martin Davis observes the particular importance of the electromechanical relay (with its two \"binary states\" open and closed):\\n\\nIt was only with the development, beginning in the 1930s, of electromechanical calculators using electrical relays, that machines were built having the scope Babbage had envisioned.\"\\n\\n\\n=== Mathematics during the 19th century up to the mid-20th century ===\\nSymbols and rules: In rapid succession, the mathematics of George Boole (1847, 1854), Gottlob Frege (1879), and Giuseppe Peano (1888–1889) reduced arithmetic to a sequence of symbols manipulated by rules. Peano\\'s The principles of arithmetic, presented by a new method (1888) was \"the first attempt at an axiomatization of mathematics in a symbolic language\".But Heijenoort gives Frege (1879) this kudos: Frege\\'s is \"perhaps the most important single work ever written in logic. ... in which we see a \"\\'formula language\\', that is a lingua characterica, a language written with special symbols, \"for pure thought\", that is, free from rhetorical embellishments ... constructed from specific symbols that are manipulated according to definite rules\". The work of Frege was further simplified and amplified by Alfred North Whitehead and Bertrand Russell in their Principia Mathematica (1910–1913).\\nThe paradoxes: At the same time a number of disturbing paradoxes appeared in the literature, in particular, the Burali-Forti paradox (1897), the Russell paradox (1902–03), and the Richard Paradox. The resultant considerations led to Kurt Gödel\\'s paper (1931)—he specifically cites the paradox of the liar—that completely reduces rules of recursion to numbers.\\nEffective calculability: In an effort to solve the Entscheidungsproblem defined precisely by Hilbert in 1928, mathematicians first set about to define what was meant by an \"effective method\" or \"effective calculation\" or \"effective calculability\" (i.e., a calculation that would succeed). In rapid succession the following appeared: Alonzo Church, Stephen Kleene and J.B. Rosser\\'s λ-calculus a finely honed definition of \"general recursion\" from the work of Gödel acting on suggestions of Jacques Herbrand (cf. Gödel\\'s Princeton lectures of 1934) and subsequent simplifications by Kleene. Church\\'s proof that the Entscheidungsproblem was unsolvable, Emil Post\\'s definition of effective calculability as a worker mindlessly following a list of instructions to move left or right through a sequence of rooms and while there either mark or erase a paper or observe the paper and make a yes-no decision about the next instruction. Alan Turing\\'s proof of that the Entscheidungsproblem was unsolvable by use of his \"a- [automatic-] machine\"—in effect almost identical to Post\\'s \"formulation\", J. Barkley Rosser\\'s definition of \"effective method\" in terms of \"a machine\". Kleene\\'s proposal of a precursor to \"Church thesis\" that he called \"Thesis I\", and a few years later Kleene\\'s renaming his Thesis \"Church\\'s Thesis\" and proposing \"Turing\\'s Thesis\".\\n\\n\\n=== Emil Post (1936) and Alan Turing (1936–37, 1939) ===\\nEmil Post (1936) described the actions of a \"computer\" (human being) as follows:\\n\\n\"...two concepts are involved: that of a symbol space in which the work leading from problem to answer is to be carried out, and a fixed unalterable set of directions.His symbol space would be\\n\\n\"a two-way infinite sequence of spaces or boxes ... The problem solver or worker is to move and work in this symbol space, being capable of being in, and operating in but one box at a time. ... a box is to admit of but two possible conditions, i.e., being empty or unmarked, and having a single mark in it, say a vertical stroke.\"One box is to be singled out and called the starting point. ... a specific problem is to be given in symbolic form by a finite number of boxes [i.e., INPUT] being marked with a stroke. Likewise, the answer [i.e., OUTPUT] is to be given in symbolic form by such a configuration of marked boxes...\"A set of directions applicable to a general problem sets up a deterministic process when applied to each specific problem. This process terminates only when it comes to the direction of type (C ) [i.e., STOP]\". See more at Post–Turing machineAlan Turing\\'s work preceded that of Stibitz (1937); it is unknown whether Stibitz knew of the work of Turing. Turing\\'s biographer believed that Turing\\'s use of a typewriter-like model derived from a youthful interest: \"Alan had dreamt of inventing typewriters as a boy; Mrs. Turing had a typewriter, and he could well have begun by asking himself what was meant by calling a typewriter \\'mechanical\\'\". Given the prevalence at the time of Morse code, telegraphy, ticker tape machines, and teletypewriters, it is quite possible that all were influences on Turing during his youth.\\nTuring—his model of computation is now called a Turing machine—begins, as did Post, with an analysis of a human computer that he whittles down to a simple set of basic motions and \"states of mind\". But he continues a step further and creates a machine as a model of computation of numbers.\\n\"Computing is normally done by writing certain symbols on paper. We may suppose this paper is divided into squares like a child\\'s arithmetic book...I assume then that the computation is carried out on one-dimensional paper, i.e., on a tape divided into squares. I shall also suppose that the number of symbols which may be printed is finite...\"The behavior of the computer at any moment is determined by the symbols which he is observing, and his \"state of mind\" at that moment. We may suppose that there is a bound B to the number of symbols or squares that the computer can observe at one moment. If he wishes to observe more, he must use successive observations. We will also suppose that the number of states of mind which need be taken into account is finite...\"Let us imagine that the operations performed by the computer to be split up into \\'simple operations\\' which are so elementary that it is not easy to imagine them further divided.\"Turing\\'s reduction yields the following:\\n\\n\"The simple operations must therefore include:\\n\"(a) Changes of the symbol on one of the observed squares\\n\"(b) Changes of one of the squares observed to another square within L squares of one of the previously observed squares.\"It may be that some of these change necessarily invoke a change of state of mind. The most general single operation must, therefore, be taken to be one of the following:\\n\\n\"(A) A possible change (a) of symbol together with a possible change of state of mind.\\n\"(B) A possible change (b) of observed squares, together with a possible change of state of mind\"\"We may now construct a machine to do the work of this computer.\"A few years later, Turing expanded his analysis (thesis, definition) with this forceful expression of it:\\n\\n\"A function is said to be \"effectively calculable\" if its values can be found by some purely mechanical process. Though it is fairly easy to get an intuitive grasp of this idea, it is nevertheless desirable to have some more definite, mathematical expressible definition ... [he discusses the history of the definition pretty much as presented above with respect to Gödel, Herbrand, Kleene, Church, Turing, and Post] ... We may take this statement literally, understanding by a purely mechanical process one which could be carried out by a machine. It is possible to give a mathematical description, in a certain normal form, of the structures of these machines. The development of these ideas leads to the author\\'s definition of a computable function, and to an identification of computability † with effective calculability...\\n\"† We shall use the expression \"computable function\" to mean a function calculable by a machine, and we let \"effectively calculable\" refer to the intuitive idea without particular identification with any one of these definitions\".\\n\\n\\n=== J. B. Rosser (1939) and S. C. Kleene (1943) ===\\nJ. Barkley Rosser defined an \"effective [mathematical] method\" in the following manner (italicization added):\\n\\n\"\\'Effective method\\' is used here in the rather special sense of a method each step of which is precisely determined and which is certain to produce the answer in a finite number of steps. With this special meaning, three different precise definitions have been given to date. [his footnote #5; see discussion immediately below]. The simplest of these to state (due to Post and Turing) says essentially that an effective method of solving certain sets of problems exists if one can build a machine which will then solve any problem of the set with no human intervention beyond inserting the question and (later) reading the answer. All three definitions are equivalent, so it doesn\\'t matter which one is used. Moreover, the fact that all three are equivalent is a very strong argument for the correctness of any one.\" (Rosser 1939:225–226)Rosser\\'s footnote No. 5 references the work of (1) Church and Kleene and their definition of λ-definability, in particular, Church\\'s use of it in his An Unsolvable Problem of Elementary Number Theory (1936); (2) Herbrand and Gödel and their use of recursion, in particular, Gödel\\'s use in his famous paper On Formally Undecidable Propositions of Principia Mathematica and Related Systems I (1931); and (3) Post (1936) and Turing (1936–37) in their mechanism-models of computation.\\nStephen C. Kleene defined as his now-famous \"Thesis I\" known as the Church–Turing thesis. But he did this in the following context (boldface in original):\\n\\n\"12. Algorithmic theories... In setting up a complete algorithmic theory, what we do is to describe a procedure, performable for each set of values of the independent variables, which procedure necessarily terminates and in such manner that from the outcome we can read a definite answer, \"yes\" or \"no,\" to the question, \"is the predicate value true?\"\" (Kleene 1943:273)\\n\\n\\n=== History after 1950 ===\\nA number of efforts have been directed toward further refinement of the definition of \"algorithm\", and activity is on-going because of issues surrounding, in particular, foundations of mathematics (especially the Church–Turing thesis) and philosophy of mind (especially arguments about artificial intelligence). For more, see Algorithm characterizations.\\n\\n\\n== See also ==\\n\\n\\n== Notes ==\\n\\n\\n== Bibliography ==\\n\\nZaslavsky, C. (1970). Mathematics of the Yoruba People and of Their Neighbors in Southern Nigeria. The Two-Year College Mathematics Journal, 1(2), 76–99. https://doi.org/10.2307/3027363\\n\\n\\n== Further reading ==\\n\\n\\n== External links ==\\n\\n\"Algorithm\". Encyclopedia of Mathematics. EMS Press. 2001 [1994].\\nAlgorithms at Curlie\\nWeisstein, Eric W. \"Algorithm\". MathWorld.\\nDictionary of Algorithms and Data Structures – National Institute of Standards and TechnologyAlgorithm repositoriesThe Stony Brook Algorithm Repository – State University of New York at Stony Brook\\nCollected Algorithms of the ACM – Associations for Computing Machinery\\nThe Stanford GraphBase Archived December 6, 2015, at the Wayback Machine – Stanford University',\n",
              " 'A programming language is a system of notation for writing computer programs.\\nA programming language is usually described in terms of its syntax (form) and semantics (meaning). These are usually defined by a formal language.A language usually has at least one implementation in the form of a compiler or interpreter, allowing programs written in the language to be executed.\\nProgramming language theory is the subfield of computer science that studies the design, implementation, analysis, characterization, and classification of programming languages.\\n\\n\\n== Definitions ==\\nThere are many considerations when defining what constitutes a programming language.\\n\\n\\n=== Computer languages vs programming languages ===\\nThe term computer language is sometimes used interchangeably with programming language. However, the usage of both terms varies among authors, including the exact scope of each. One usage describes programming languages as a subset of computer languages. Similarly, languages used in computing that have a different goal than expressing computer programs are generically designated computer languages. For instance, markup languages are sometimes referred to as computer languages to emphasize that they are not meant to be used for programming.\\nOne way of classifying computer languages is by the computations they are capable of expressing, as described by the theory of computation. The majority of practical programming languages are Turing complete, and all Turing complete languages can implement the same set of algorithms. ANSI/ISO SQL-92 and Charity are examples of languages that are not Turing complete, yet are often called programming languages. However, some authors restrict the term \"programming language\" to Turing complete languages.Another usage regards programming languages as theoretical constructs for programming abstract machines and computer languages as the subset thereof that runs on physical computers, which have finite hardware resources. John C. Reynolds emphasizes that formal specification languages are just as much programming languages as are the languages intended for execution. He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats.\\n\\n\\n=== Domain and target ===\\nIn most practical contexts, a programming language involves a computer; consequently, programming languages are usually defined and studied this way. Programming languages differ from natural languages in that natural languages are only used for interaction between people, while programming languages also allow humans to communicate instructions to machines.\\nThe domain of the language is also worth consideration. Markup languages like XML, HTML, or troff, which define structured data, are not usually considered programming languages. Programming languages may, however, share the syntax with markup languages if a computational semantics is defined. XSLT, for example, is a Turing complete language entirely using XML syntax. Moreover, LaTeX, which is mostly used for structuring documents, also contains a Turing complete subset.\\n\\n\\n=== Abstractions ===\\nProgramming languages usually contain abstractions for defining and manipulating data structures or controlling the flow of execution. The practical necessity that a programming language support adequate abstractions is expressed by the abstraction principle. This principle is sometimes formulated as a recommendation to the programmer to make proper use of such abstractions.\\n\\n\\n== History ==\\n\\n\\n=== Early developments ===\\nVery early computers, such as Colossus, were programmed without the help of a stored program, by modifying their circuitry or setting banks of physical controls.\\nSlightly later, programs could be written in machine language, where the programmer writes each instruction in a numeric form the hardware can execute directly. For example, the instruction to add the value in two memory locations might consist of 3 numbers: an \"opcode\" that selects the \"add\" operation, and two memory locations. The programs, in decimal or binary form, were read in from punched cards, paper tape, magnetic tape or toggled in on switches on the front panel of the computer. Machine languages were later termed first-generation programming languages (1GL).\\nThe next step was the development of the so-called second-generation programming languages (2GL) or assembly languages, which were still closely tied to the instruction set architecture of the specific computer. These served to make the program much more human-readable and relieved the programmer of tedious and error-prone address calculations.\\nThe first high-level programming languages, or third-generation programming languages (3GL), were written in the 1950s. An early high-level programming language to be designed for a computer was Plankalkül, developed for the German Z3 by Konrad Zuse between 1943 and 1945. However, it was not implemented until 1998 and 2000.John Mauchly\\'s Short Code, proposed in 1949, was one of the first high-level languages ever developed for an electronic computer. Unlike machine code, Short Code statements represented mathematical expressions in an understandable form. However, the program had to be translated into machine code every time it ran, making the process much slower than running the equivalent machine code.\\nAt the University of Manchester, Alick Glennie developed Autocode in the early 1950s. As a programming language, it used a compiler to automatically convert the language into machine code. The first code and compiler was developed in 1952 for the Mark 1 computer at the University of Manchester and is considered to be the first compiled high-level programming language.The second auto code was developed for the Mark 1 by R. A. Brooker in 1954 and was called the \"Mark 1 Autocode\". Brooker also developed an auto code for the Ferranti Mercury in the 1950s in conjunction with the University of Manchester. The version for the EDSAC 2 was devised by D. F. Hartley of University of Cambridge Mathematical Laboratory in 1961. Known as EDSAC 2 Autocode, it was a straight development from Mercury Autocode adapted for local circumstances and was noted for its object code optimization and source-language diagnostics which were advanced for the time. A contemporary but separate thread of development, Atlas Autocode was developed for the University of Manchester Atlas 1 machine.\\nIn 1954, FORTRAN was invented at IBM by John Backus. It was the first widely used high-level general-purpose programming language to have a functional implementation, as opposed to just a design on paper. It is still a popular language for high-performance computing and is used for programs that benchmark and rank the world\\'s fastest supercomputers.Another early programming language was devised by Grace Hopper in the US, called FLOW-MATIC. It was developed for the UNIVAC I at Remington Rand during the period from 1955 until 1959. Hopper found that business data processing customers were uncomfortable with mathematical notation, and in early 1955, she and her team wrote a specification for an English programming language and implemented a prototype. The FLOW-MATIC compiler became publicly available in early 1958 and was substantially complete in 1959. FLOW-MATIC was a major influence in the design of COBOL, since only it and its direct descendant AIMACO were in actual use at the time.\\n\\n\\n=== Refinement ===\\nThe increased use of high-level languages introduced a requirement for low-level programming languages or system programming languages. These languages, to varying degrees, provide facilities between assembly languages and high-level languages. They can be used to perform tasks that require direct access to hardware facilities but still provide higher-level control structures and error-checking.\\nThe period from the 1960s to the late 1970s brought the development of the major language paradigms now in use:\\n\\nAPL introduced array programming and influenced functional programming.\\nALGOL refined both structured procedural programming and the discipline of language specification; the \"Revised Report on the Algorithmic Language ALGOL 60\" became a model for how later language specifications were written.\\nLisp, implemented in 1958, was the first dynamically-typed functional programming language.\\nIn the 1960s, Simula was the first language designed to support object-oriented programming; in the mid-1970s, Smalltalk followed with the first \"purely\" object-oriented language.\\nC was developed between 1969 and 1973 as a system programming language for the Unix operating system and remains popular.\\nProlog, designed in 1972, was the first logic programming language.\\nIn 1978, ML built a polymorphic type system on top of Lisp, pioneering statically-typed functional programming languages.Each of these languages spawned descendants, and most modern programming languages count at least one of them in their ancestry.\\nThe 1960s and 1970s also saw considerable debate over the merits of structured programming, and whether programming languages should be designed to support it. Edsger Dijkstra, in a famous 1968 letter published in the Communications of the ACM, argued that Goto statements should be eliminated from all \"higher-level\" programming languages.\\n\\n\\n=== Consolidation and growth ===\\nThe 1980s were years of relative consolidation. C++ combined object-oriented and systems programming. The United States government standardized Ada, a systems programming language derived from Pascal and intended for use by defense contractors. In Japan and elsewhere, vast sums were spent investigating the so-called \"fifth-generation\" languages that incorporated logic programming constructs. The functional languages community moved to standardize ML and Lisp. Rather than inventing new paradigms, all of these movements elaborated upon the ideas invented in the previous decades.\\nOne important trend in language design for programming large-scale systems during the 1980s was an increased focus on the use of modules or large-scale organizational units of code. Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs.The rapid growth of the Internet in the mid-1990s created opportunities for new languages. Perl, originally a Unix scripting tool first released in 1987, became common in dynamic websites. Java came to be used for server-side programming, and bytecode virtual machines became popular again in commercial settings with their promise of \"Write once, run anywhere\" (UCSD Pascal had been popular for a time in the early 1980s). These developments were not fundamentally novel; rather, they were refinements of many existing languages and paradigms (although their syntax was often based on the C family of programming languages).\\nProgramming language evolution continues, in both industry and research. Current directions include security and reliability verification, new kinds of modularity (mixins, delegates, aspects), and database integration such as Microsoft\\'s LINQ.\\nFourth-generation programming languages (4GL) are computer programming languages that aim to provide a higher level of abstraction of the internal computer hardware details than 3GLs. Fifth-generation programming languages (5GL) are programming languages based on solving problems using constraints given to the program, rather than using an algorithm written by a programmer.\\n\\n\\n== Elements ==\\nAll programming languages have some primitive building blocks for the description of data and the processes or transformations applied to them (like the addition of two numbers or the selection of an item from a collection). These primitives are defined by syntactic and semantic rules which describe their structure and meaning respectively.\\n\\n\\n=== Syntax ===\\n\\nA programming language\\'s surface form is known as its syntax. Most programming languages are purely textual; they use sequences of text including words, numbers, and punctuation, much like written natural languages. On the other hand, some programming languages are more graphical in nature, using visual relationships between symbols to specify a program.\\nThe syntax of a language describes the possible combinations of symbols that form a syntactically correct program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Since most languages are textual, this article discusses textual syntax.\\nThe programming language syntax is usually defined using a combination of regular expressions (for lexical structure) and Backus–Naur form (for grammatical structure). Below is a simple grammar, based on Lisp:\\n\\nThis grammar specifies the following:\\n\\nan expression is either an atom or a list;\\nan atom is either a number or a symbol;\\na number is an unbroken sequence of one or more decimal digits, optionally preceded by a plus or minus sign;\\na symbol is a letter followed by zero or more of any characters (excluding whitespace); and\\na list is a matched pair of parentheses, with zero or more expressions inside it.The following are examples of well-formed token sequences in this grammar: 12345, () and (a b c232 (1)).\\nNot all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language\\'s rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.\\nUsing natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:\\n\\n\"Colorless green ideas sleep furiously.\" is grammatically well-formed but has no generally accepted meaning.\\n\"John is a married bachelor.\" is grammatically well-formed but expresses a meaning that cannot be true.The following C language fragment is syntactically correct, but performs operations that are not semantically defined (the operation *p >> 4 has no meaning for a value having a complex type and p->im is not defined because the value of p is the null pointer):\\n\\nIf the type declaration on the first line were omitted, the program would trigger an error on the undefined variable p during compilation. However, the program would still be syntactically correct since type declarations provide only semantic information.\\nThe grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The syntax of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars. Some languages, including Perl and Lisp, contain constructs that allow execution during the parsing phase. Languages that have constructs that allow the programmer to alter the behavior of the parser make syntax analysis an undecidable problem, and generally blur the distinction between parsing and execution. In contrast to Lisp\\'s macro system and Perl\\'s BEGIN blocks, which may contain general computations, C macros are merely string replacements and do not require code execution.\\n\\n\\n=== Semantics ===\\nThe term semantics refers to the meaning of languages, as opposed to their form (syntax).\\n\\n\\n==== Static semantics ====\\nA static semantics defines restrictions on the structure of valid texts that are hard or impossible to express in standard syntactic formalisms. For compiled languages, static semantics essentially include those semantic rules that can be checked at compile time. Examples include checking that every identifier is declared before it is used (in languages that require such declarations) or that the labels on the arms of a case statement are distinct. Many important restrictions of this type, like checking that identifiers are used in the appropriate context (e.g. not adding an integer to a function name), or that subroutine calls have the appropriate number and type of arguments, can be enforced by defining them as rules in a logic called a type system. Other forms of static analyses like data flow analysis may also be part of static semantics. Newer programming languages like Java and C# have definite assignment analysis, a form of data flow analysis, as part of their static semantics.\\n\\n\\n==== Dynamic semantics ====\\n\\nOnce data has been specified, the machine must be instructed to perform operations on the data. For example, the semantics may define the strategy by which expressions are evaluated to values, or the manner in which control structures conditionally execute statements. The dynamic semantics (also known as execution semantics) of a language defines how and when the various constructs of a language should produce a program behavior. There are many ways of defining execution semantics. Natural language is often used to specify the execution semantics of languages commonly used in practice. A significant amount of academic research went into formal semantics of programming languages, which allows execution semantics to be specified in a formal manner. Results from this field of research have seen limited application to programming language design and implementation outside academia.\\n\\n\\n=== Type system ===\\n\\nA type system defines how a programming language classifies values and expressions into types, how it can manipulate those types and how they interact. The goal of a type system is to verify and usually enforce a certain level of correctness in programs written in that language by detecting certain incorrect operations. Any decidable type system involves a trade-off: while it rejects many incorrect programs, it can also prohibit some correct, albeit unusual programs. In order to bypass this downside, a number of languages have type loopholes, usually unchecked casts that may be used by the programmer to explicitly allow a normally disallowed operation between different types. In most typed languages, the type system is used only to type check programs, but a number of languages, usually functional ones, infer types, relieving the programmer from the need to write type annotations. The formal design and study of type systems is known as type theory.\\n\\n\\n==== Typed versus untyped languages ====\\nA language is typed if the specification of every operation defines types of data to which the operation is applicable. For example, the data represented by \"this text between the quotes\" is a string, and in many programming languages dividing a number by a string has no meaning and will not be executed. The invalid operation may be detected when the program is compiled (\"static\" type checking) and will be rejected by the compiler with a compilation error message, or it may be detected while the program is running (\"dynamic\" type checking), resulting in a run-time exception. Many languages allow a function called an exception handler to handle this exception and, for example, always return \"-1\" as the result.\\nA special case of typed languages is the single-typed languages. These are often scripting or markup languages, such as REXX or SGML, and have only one data type–—most commonly character strings which are used for both symbolic and numeric data.\\nIn contrast, an untyped language, such as most assembly languages, allows any operation to be performed on any data, generally sequences of bits of various lengths. High-level untyped languages include BCPL, Tcl, and some varieties of Forth.\\nIn practice, while few languages are considered typed from the type theory (verifying or rejecting all operations), most modern languages offer a degree of typing. Many production languages provide means to bypass or subvert the type system, trading type safety for finer control over the program\\'s execution (see casting).\\n\\n\\n==== Static vis-à-vis dynamic typing ====\\nIn static typing, all expressions have their types determined before a program executes, typically at compile-time. For example, 1 and (2+2) are integer expressions; they cannot be passed to a function that expects a string or stored in a variable that is defined to hold dates.Statically-typed languages can be either manifestly typed or type-inferred. In the first case, the programmer must explicitly write types at certain textual positions (for example, at variable declarations). In the second case, the compiler infers the types of expressions and declarations based on context. Most mainstream statically-typed languages, such as C++, C#, and Java, are manifestly typed. Complete type inference has traditionally been associated with functional languages such as Haskell and ML. However, many manifestly-typed languages support partial type inference; for example, C++, Java, and C# all infer types in certain limited cases. Additionally, some programming languages allow for some types to be automatically converted to other types; for example, an int can be used where the program expects a float.\\nDynamic typing, also called latent typing, determines the type-safety of operations at run time; in other words, types are associated with run-time values rather than textual expressions. As with type-inferred languages, dynamically-typed languages do not require the programmer to write explicit type annotations on expressions. Among other things, this may permit a single variable to refer to values of different types at different points in the program execution. However, type errors cannot be automatically detected until a piece of code is actually executed, potentially making debugging more difficult. Lisp, Smalltalk, Perl, Python, JavaScript, and Ruby are all examples of dynamically-typed languages.\\n\\n\\n==== Weak and strong typing ====\\nWeak typing allows a value of one type to be treated as another, for example treating a string as a number. This can occasionally be useful, but it can also allow some kinds of program faults to go undetected at compile time and even at run time.\\nStrong typing prevents these program faults. An attempt to perform an operation on the wrong type of value raises an error. Strongly-typed languages are often termed type-safe or safe.\\nAn alternative definition for \"weakly typed\" refers to languages, such as Perl and JavaScript, which permit a large number of implicit type conversions. In JavaScript, for example, the expression 2 * x implicitly converts x to a number, and this conversion succeeds even if x is null, undefined, an Array, or a string of letters. Such implicit conversions are often useful, but they can mask programming errors. Strong and static are now generally considered orthogonal concepts, but usage in the literature differs. Some use the term strongly typed to mean strongly, statically typed, or, even more confusingly, to mean simply statically typed. Thus C has been called both strongly typed and weakly, statically typed.It may seem odd to some professional programmers that C could be \"weakly, statically typed\". However, the use of the generic pointer, the void* pointer, does allow casting pointers to other pointers without needing to do an explicit cast. This is extremely similar to somehow casting an array of bytes to any kind of datatype in C without using an explicit cast, such as (int) or (char).\\n\\n\\n=== Standard library and run-time system ===\\n\\nMost programming languages have an associated core library (sometimes known as the \"standard library\", especially if it is included as part of the published language standard), which is conventionally made available by all implementations of the language. Core libraries typically include definitions for commonly used algorithms, data structures, and mechanisms for input and output.\\nThe line between a language and its core library differs from language to language. In some cases, the language designers may treat the library as a separate entity from the language. However, a language\\'s core library is often treated as part of the language by its users, and some language specifications even require that this library be made available in all implementations. Indeed, some languages are designed so that the meanings of certain syntactic constructs cannot even be described without referring to the core library. For example, in Java, a string literal is defined as an instance of the java.lang.String class; similarly, in Smalltalk, an anonymous function expression (a \"block\") constructs an instance of the library\\'s BlockContext class. Conversely, Scheme contains multiple coherent subsets that suffice to construct the rest of the language as library macros, and so the language designers do not even bother to say which portions of the language must be implemented as language constructs, and which must be implemented as parts of a library.\\n\\n\\n== Design and implementation ==\\n\\nProgramming languages share properties with natural languages related to their purpose as vehicles for communication, having a syntactic form separate from its semantics, and showing language families of related languages branching one from another. But as artificial constructs, they also differ in fundamental ways from languages that have evolved through usage. A significant difference is that a programming language can be fully described and studied in its entirety since it has a precise and finite definition. By contrast, natural languages have changing meanings given by their users in different communities. While constructed languages are also artificial languages designed from the ground up with a specific purpose, they lack the precise and complete semantic definition that a programming language has.\\nMany programming languages have been designed from scratch, altered to meet new needs, and combined with other languages. Many have eventually fallen into disuse. Although there have been attempts to design one \"universal\" programming language that serves all purposes, all of them have failed to be generally accepted as filling this role. The need for diverse programming languages arises from the diversity of contexts in which languages are used:\\n\\nPrograms range from tiny scripts written by individual hobbyists to huge systems written by hundreds of programmers.\\nProgrammers range in expertise from novices who need simplicity above all else to experts who may be comfortable with considerable complexity.\\nPrograms must balance speed, size, and simplicity on systems ranging from microcontrollers to supercomputers.\\nPrograms may be written once and not change for generations, or they may undergo continual modification.\\nProgrammers may simply differ in their tastes: they may be accustomed to discussing problems and expressing them in a particular language.One common trend in the development of programming languages has been to add more ability to solve problems using a higher level of abstraction. The earliest programming languages were tied very closely to the underlying hardware of the computer. As new programming languages have developed, features have been added that let programmers express ideas that are more remote from simple translation into underlying hardware instructions. Because programmers are less tied to the complexity of the computer, their programs can do more computing with less effort from the programmer. This lets them write more functionality per time unit.\\nNatural-language programming has been proposed as a way to eliminate the need for a specialized language for programming. However, this goal remains distant and its benefits are open to debate. Edsger W. Dijkstra took the position that the use of a formal language is essential to prevent the introduction of meaningless constructs, and dismissed natural-language programming as \"foolish\". Alan Perlis was similarly dismissive of the idea. Hybrid approaches have been taken in Structured English and SQL.\\nA language\\'s designers and users must construct a number of artifacts that govern and enable the practice of programming. The most important of these artifacts are the language specification and implementation.\\n\\n\\n=== Specification ===\\n\\nThe specification of a programming language is an artifact that the language users and the implementors can use to agree upon whether a piece of source code is a valid program in that language, and if so what its behavior shall be.\\nA programming language specification can take several forms, including the following:\\n\\nAn explicit definition of the syntax, static semantics, and execution semantics of the language. While syntax is commonly specified using a formal grammar, semantic definitions may be written in natural language (e.g., as in the C language), or a formal semantics (e.g., as in Standard ML and Scheme specifications).\\nA description of the behavior of a translator for the language (e.g., the C++ and Fortran specifications). The syntax and semantics of the language have to be inferred from this description, which may be written in natural or formal language.\\nA reference or model implementation, sometimes written in the language being specified (e.g., Prolog or ANSI REXX). The syntax and semantics of the language are explicit in the behavior of the reference implementation.\\n\\n\\n=== Implementation ===\\n\\nAn implementation of a programming language provides a way to write programs in that language and execute them on one or more configurations of hardware and software. There are, broadly, two approaches to programming language implementation: compilation and interpretation. It is generally possible to implement a language using either technique.\\nThe output of a compiler may be executed by hardware or a program called an interpreter. In some implementations that make use of the interpreter approach, there is no distinct boundary between compiling and interpreting. For instance, some implementations of BASIC compile and then execute the source one line at a time.\\nPrograms that are executed directly on the hardware usually run much faster than those that are interpreted in software.One technique for improving the performance of interpreted programs is just-in-time compilation. Here the virtual machine, just before execution, translates the blocks of bytecode which are going to be used to machine code, for direct execution on the hardware.\\n\\n\\n== Proprietary languages ==\\nAlthough most of the most commonly used programming languages have fully open specifications and implementations, many programming languages exist only as proprietary programming languages with the implementation available only from a single vendor, which may claim that such a proprietary language is their intellectual property. Proprietary programming languages are commonly domain-specific languages or internal scripting languages for a single product; some proprietary languages are used only internally within a vendor, while others are available to external users.Some programming languages exist on the border between proprietary and open; for example, Oracle Corporation asserts proprietary rights to some aspects of the Java programming language, and Microsoft\\'s C# programming language, which has open implementations of most parts of the system, also has Common Language Runtime (CLR) as a closed environment.Many proprietary languages are widely used, in spite of their proprietary nature; examples include MATLAB, VBScript, and Wolfram Language. Some languages may make the transition from closed to open; for example, Erlang was originally Ericsson\\'s internal programming language.\\n\\n\\n== Use ==\\nThousands of different programming languages have been created, mainly in the computing field.\\nIndividual software projects commonly use five programming languages or more.Programming languages differ from most other forms of human expression in that they require a greater degree of precision and completeness. When using a natural language to communicate with other people, human authors and speakers can be ambiguous and make small errors, and still expect their intent to be understood. However, figuratively speaking, computers \"do exactly what they are told to do\", and cannot \"understand\" what code the programmer intended to write. The combination of the language definition, a program, and the program\\'s inputs must fully specify the external behavior that occurs when the program is executed, within the domain of control of that program. On the other hand, ideas about an algorithm can be communicated to humans without the precision required for execution by using pseudocode, which interleaves natural language with code written in a programming language.\\nA programming language provides a structured mechanism for defining pieces of data, and the operations or transformations that may be carried out automatically on that data. A programmer uses the abstractions present in the language to represent the concepts involved in a computation. These concepts are represented as a collection of the simplest elements available (called primitives). Programming is the process by which programmers combine these primitives to compose new programs, or adapt existing ones to new uses or a changing environment.\\nPrograms for a computer might be executed in a batch process without human interaction, or a user might type commands in an interactive session of an interpreter. In this case the \"commands\" are simply programs, whose execution is chained together. When a language can run its commands through an interpreter (such as a Unix shell or other command-line interface), without compiling, it is called a scripting language.\\n\\n\\n=== Measuring language usage ===\\nDetermining which is the most widely used programming language is difficult since the definition of usage varies by context. One language may occupy the greater number of programmer hours, a different one has more lines of code, and a third may consume the most CPU time. Some languages are very popular for particular kinds of applications. For example, COBOL is still strong in the corporate data center, often on large mainframes; Fortran in scientific and engineering applications; Ada in aerospace, transportation, military, real-time, and embedded applications; and C in embedded applications and operating systems. Other languages are regularly used to write many different kinds of applications.\\nVarious methods of measuring language popularity, each subject to a different bias over what is measured, have been proposed:\\n\\ncounting the number of job advertisements that mention the language\\nthe number of books sold that teach or describe the language\\nestimates of the number of existing lines of code written in the language –  which may underestimate languages not often found in public searches\\ncounts of language references (i.e., to the name of the language) found using a web search engine.Combining and averaging information from various internet sites, stackify.com reported the ten most popular programming languages (in descending order by overall popularity): Java, C, C++, Python, C#, JavaScript, VB .NET, R, PHP, and MATLAB.\\n\\n\\n== Dialects, flavors and implementations ==\\nA dialect of a programming language or a data exchange language is a (relatively small) variation or extension of the language that does not change its intrinsic nature. With languages such as Scheme and Forth, standards may be considered insufficient, inadequate, or illegitimate by implementors, so often they will deviate from the standard, making a new dialect. In other cases, a dialect is created for use in a domain-specific language, often a subset. In the Lisp world, most languages that use basic S-expression syntax and Lisp-like semantics are considered Lisp dialects, although they vary wildly as do, say, Racket and Clojure. As it is common for one language to have several dialects, it can become quite difficult for an inexperienced programmer to find the right documentation. The BASIC language has many dialects.\\n\\n\\n== Taxonomies ==\\n\\nThere is no overarching classification scheme for programming languages. A given programming language does not usually have a single ancestor language. Languages commonly arise by combining the elements of several predecessor languages with new ideas in circulation at the time. Ideas that originate in one language will diffuse throughout a family of related languages, and then leap suddenly across familial gaps to appear in an entirely different family.\\nThe task is further complicated by the fact that languages can be classified along multiple axes. For example, Java is both an object-oriented language (because it encourages object-oriented organization) and a concurrent language (because it contains built-in constructs for running multiple threads in parallel). Python is an object-oriented scripting language.In broad strokes, programming languages are classified by programming paradigm and intended domain of use, with general-purpose programming languages distinguished from domain-specific programming languages. Traditionally, programming languages have been regarded as describing computation in terms of imperative sentences, i.e. issuing commands. These are generally called imperative programming languages. A great deal of research in programming languages has been aimed at blurring the distinction between a program as a set of instructions and a program as an assertion about the desired answer, which is the main feature of declarative programming. More refined paradigms include procedural programming, object-oriented programming, functional programming, and logic programming; some languages are hybrids of paradigms or multi-paradigmatic. An assembly language is not so much a paradigm as a direct model of an underlying machine architecture. By purpose, programming languages might be considered general purpose, system programming languages, scripting languages, domain-specific languages, or concurrent/distributed languages (or a combination of these). Some general purpose languages were designed largely with educational goals.A programming language may also be classified by factors unrelated to the programming paradigm. For instance, most programming languages use English language keywords, while a minority do not. Other languages may be classified as being deliberately esoteric or not.\\n\\n\\n== See also ==\\n\\n\\n== References ==\\n\\n\\n== Further reading ==',\n",
              " 'An operating system (OS) is system software that manages computer hardware and software resources, and provides common services for computer programs.\\nTime-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, peripherals, and other resources.\\nFor hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer –  from cellular phones and video game consoles to web servers and supercomputers.\\nIn the personal computer market, as of September 2023, Microsoft Windows holds a dominant market share of around 68%. macOS by Apple Inc. is in second place (20%), and the varieties of Linux, including ChromeOS, are collectively in third place (7%). In the mobile sector (including smartphones and tablets), as of September 2023, Android\\'s share is 68.92%, followed by Apple\\'s iOS and iPadOS with 30.42%, and other operating systems with .6%. Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications. Security-focused operating systems also exist. Some operating systems have low system requirements (e.g. light-weight Linux distribution). Others may have higher system requirements.\\nSome operating systems require installation or may come pre-installed with purchased computers (OEM-installation), whereas others may run directly from media (i.e. live CD) or flash memory (i.e. USB stick).\\n\\n\\n== Types of operating systems ==\\n\\n\\n=== Single-tasking and multi-tasking ===\\nA single-tasking system can only run one program at a time, while a multi-tasking operating system allows more than one program to be running concurrently. This is achieved by time-sharing, where the available processor time is divided between multiple processes. These processes are each interrupted repeatedly in time slices by a task-scheduling subsystem of the operating system. Multi-tasking may be characterized in preemptive and cooperative types. In preemptive multitasking, the operating system slices the CPU time and dedicates a slot to each of the programs. Unix-like operating systems, such as Linux—as well as non-Unix-like, such as AmigaOS—support preemptive multitasking. Cooperative multitasking is achieved by relying on each process to provide time to the other processes in a defined manner. 16-bit versions of Microsoft Windows used cooperative multi-tasking; 32-bit versions of both Windows NT and Win9x used preemptive multi-tasking.\\n\\n\\n=== Single- and multi-user ===\\nSingle-user operating systems have no facilities to distinguish users but may allow multiple programs to run in tandem. A multi-user operating system extends the basic concept of multi-tasking with facilities that identify processes and resources, such as disk space, belonging to multiple users, and the system permits multiple users to interact with the system at the same time. Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources to multiple users.\\n\\n\\n=== Distributed ===\\nA distributed operating system manages a group of distinct, networked computers and makes them appear to be a single computer, as all computations are distributed (divided amongst the constituent computers).\\n\\n\\n=== Embedded ===\\nEmbedded operating systems are designed to be used in embedded computer systems. They are designed to operate on small machines with less autonomy (e.g. PDAs). They are very compact and extremely efficient by design and are able to operate with a limited amount of resources. Windows CE and Minix 3 are some examples of embedded operating systems.\\n\\n\\n=== Real-time ===\\nA real-time operating system is an operating system that guarantees to process events or data by a specific moment in time. A real-time operating system may be single- or multi-tasking, but when multitasking, it uses specialized scheduling algorithms so that a deterministic nature of behavior is achieved. Such an event-driven system switches between tasks based on their priorities or external events, whereas time-sharing operating systems switch tasks based on clock interrupts.\\n\\n\\n=== Library ===\\nA library operating system is one in which the services that a typical operating system provides, such as networking, are provided in the form of libraries and composed with the application and configuration code to construct a unikernel: a specialized, single address space, machine image that can be deployed to cloud or embedded environments.\\n\\n\\n== History ==\\n\\nEarly computers were built to perform a series of single tasks, like a calculator. Basic operating system features were developed in the 1950s, such as resident monitor functions that could automatically run different programs in succession to speed up processing. Operating systems did not exist in their modern and more complex forms until the early 1960s. Hardware features were added, that enabled use of runtime libraries, interrupts, and parallel processing. When personal computers became popular in the 1980s, operating systems were made for them similar in concept to those used on larger computers.\\nIn the 1940s, the earliest electronic digital systems had no operating systems. Electronic systems of this time were programmed on rows of mechanical switches or by jumper wires on plugboards. These were special-purpose systems that, for example, generated ballistics tables for the military or controlled the printing of payroll checks from data on punched paper cards. After programmable general-purpose computers were invented, machine languages(consisting of strings of the binary digits 0 and 1 on punched paper tape) were introduced that sped up the programming process (Stern, 1981).\\nIn the early 1950s, a computer could execute only one program at a time.  Each user had sole use of the computer for a limited period and would arrive at a scheduled time with their program and data on punched paper cards or punched tape. The program would be loaded into the machine, and the machine would be set to work until the program completed or crashed. Programs could generally be debugged via a front panel using toggle switches and panel lights. It is said that Alan Turing was a master of this on the early Manchester Mark 1 machine, and he was already deriving the primitive conception of an operating system from the principles of the universal Turing machine.Later machines came with libraries of programs, which would be linked to a user\\'s program to assist in operations such as input and output and compiling (generating machine code from human-readable symbolic code). This was the genesis of the modern-day operating system. However, machines still ran a single job at a time. At Cambridge University in England, the job queue was at one time a washing line (clothesline) from which tapes were hung with different colored clothes-pegs to indicate job priority.By the late 1950s, programs that one would recognize as an operating system were beginning to appear. Often pointed to as the earliest recognizable example is GM-NAA I/O, released in 1956 on the IBM 704. The first known example that actually referred to itself was the SHARE Operating System, a development of GM-NAA I/O, released in 1959. In a May 1960 paper describing the system, George Ryckman noted:\\n\\nThe development of computer operating systems have materially aided the problem of getting a program or series of programs on and off the computer efficiently.\\nOne of the more famous examples that is often found in discussions of early systems is the Atlas Supervisor, running on the  Atlas in 1962. It was referred to as such in a December 1961 article describing the system, but the context of \"the Operating System\" is more along the lines of \"the system operates in the fashion\". The Atlas team itself used the term \"supervisor\", which was widely used along with \"monitor\". Brinch Hansen described it as \"the most significant breakthrough in the history of operating systems.\"\\n\\n\\n=== Mainframes ===\\n\\nThrough the 1950s, many major features were pioneered in the field of operating systems on mainframe computers, including batch processing, input/output interrupting, buffering, multitasking, spooling, runtime libraries, link-loading, and programs for sorting records in files. These features were included or not included in application software at the option of application programmers, rather than in a separate operating system used by all applications.  In 1959, the SHARE Operating System was released as an integrated utility for the IBM 704, and later in the 709 and 7090 mainframes, although it was quickly supplanted by IBSYS/IBJOB on the 709, 7090 and 7094, which in turn influenced the later 7040-PR-150 (7040/7044) and 1410-PR-155 (1410/7010) operating systems.\\nDuring the 1960s, IBM\\'s OS/360 introduced the concept of a single OS spanning an entire product line, which was crucial for the success of the System/360 machines. IBM\\'s current mainframe operating systems are distant descendants of this original system and modern machines are backward compatible with applications written for OS/360.OS/360 also pioneered the concept that the operating system keeps track of all of the system resources that are used, including program and data space allocation in main memory and file space in secondary storage, and file locking during updates. When a process is terminated for any reason, all of these resources are re-claimed by the operating system.\\nThe alternative CP-67 system for the S/360-67 started a whole line of IBM operating systems focused on the concept of virtual machines. Other operating systems used on IBM S/360 series mainframes included systems developed by IBM: DOS/360 (Disk Operating System), TSS/360 (Time Sharing System), TOS/360 (Tape Operating System), BOS/360 (Basic Operating System), and ACP (Airline Control Program), as well as a few non-IBM systems: MTS (Michigan Terminal System), MUSIC (Multi-User System for Interactive Computing), and ORVYL (Stanford Timesharing System).\\nControl Data Corporation developed the SCOPE operating system in the 1960s, for batch processing. In cooperation with the University of Minnesota, the Kronos and later the NOS operating systems were developed during the 1970s, which supported simultaneous batch and timesharing use. Like many commercial timesharing systems, its interface was an extension of the Dartmouth BASIC operating systems, one of the pioneering efforts in timesharing and programming languages. In the late 1970s, Control Data and the University of Illinois developed the PLATO operating system, which used plasma panel displays and long-distance time sharing networks. Plato was remarkably innovative for its time, featuring real-time chat, and multi-user graphical games.\\nIn 1961, Burroughs Corporation introduced the B5000 with the MCP (Master Control Program) operating system. The B5000 was a stack machine designed to exclusively support high-level languages with no assembler; indeed, the MCP was the first OS to be written exclusively in a high-level language (ESPOL, a dialect of ALGOL). MCP also introduced many other ground-breaking innovations, such as being the first commercial implementation of virtual memory. MCP is still in use today in the Unisys company\\'s MCP/ClearPath line of computers.\\nUNIVAC, the first commercial computer manufacturer, produced a series of EXEC operating systems. Like all early main-frame systems, this batch-oriented system managed magnetic drums, disks, card readers and line printers. In the 1970s, UNIVAC produced the Real-Time Basic (RTB) system to support large-scale time sharing, also patterned after the Dartmouth BC system.\\nGeneral Electric developed General Electric Comprehensive Operating Supervisor (GECOS), which primarily supported batch processing. After its acquisition by Honeywell, it was renamed General Comprehensive Operating System (GCOS).\\nBell Labs, General Electric and MIT developed Multiplexed Information and Computing Service (Multics), which introduced the concept of ringed security privilege levels.\\nDigital Equipment Corporation developed many operating systems for its various computer lines, including TOPS-10 and TOPS-20 time-sharing systems for the 36-bit PDP-10 class systems. Before the widespread use of UNIX, TOPS-10 was a particularly popular system in universities, and in the early ARPANET community. RT-11 was a single-user real-time OS for the PDP-11 class minicomputer, and RSX-11 was the corresponding multi-user OS.\\nFrom the late 1960s through the late 1970s, several hardware capabilities evolved that allowed similar or ported software to run on more than one system. Early systems had utilized microprogramming to implement features on their systems in order to permit different underlying computer architectures to appear to be the same as others in a series. In fact, most 360s after the 360/40 (except the 360/44, 360/75, 360/91, 360/95 and 360/195) were microprogrammed implementations.\\nThe enormous investment in software for these systems made since the 1960s caused most of the original computer manufacturers to continue to develop compatible operating systems along with the hardware. Notable supported mainframe operating systems include:\\n\\nBurroughs MCP –  B5000, 1961 to Unisys Clearpath/MCP, present\\nIBM OS/360 –  IBM System/360, 1966 to IBM z/OS, present\\nIBM CP-67 –  IBM System/360, 1967 to IBM z/VM, present\\nUNIVAC EXEC 8 –  UNIVAC 1108, 1967, to OS 2200 Unisys Clearpath Dorado, present\\n\\n\\n=== Microcomputers ===\\nThe first microcomputers did not have the capacity or need for the elaborate operating systems that had been developed for mainframes and minis; minimalistic operating systems were developed, often loaded from ROM and known as monitors. One notable early disk operating system was CP/M, which was supported on many early microcomputers and was closely imitated by Microsoft\\'s MS-DOS, which became widely popular as the operating system chosen for the IBM PC (IBM\\'s version of it was called IBM DOS or PC DOS). In the 1980s, Apple Computer Inc. (now Apple Inc.) abandoned its popular Apple II series of microcomputers to introduce the Apple Macintosh computer with an innovative graphical user interface (GUI); the Macintosh ran the operating system later known as the (classic) Mac OS.\\nThe introduction of the Intel 80386 CPU chip in October 1985, with 32-bit architecture and paging capabilities, provided personal computers with the ability to run multitasking operating systems like those of earlier superminicomputers and mainframes. Microsoft responded to this progress by hiring Dave Cutler, who had developed the VMS operating system for Digital Equipment Corporation. He would lead the development of the Windows NT operating system, which continues to serve as the basis for Microsoft\\'s operating systems line. Steve Jobs, a co-founder of Apple Inc., started NeXT Computer Inc., which developed the NeXTSTEP operating system. NeXTSTEP would later be acquired by Apple Inc. and used, along with code from FreeBSD as the core of Mac OS X (macOS after latest name change).\\nThe GNU Project was started by activist and programmer Richard Stallman with the goal of creating a complete free software replacement to the proprietary UNIX operating system. While the project was highly successful in duplicating the functionality of various parts of UNIX, development of the GNU Hurd kernel proved to be unproductive. In 1991, Finnish computer science student Linus Torvalds, with cooperation from volunteers collaborating over the Internet, released the first version of the Linux kernel. It was soon merged with the GNU user space components and system software to form a complete operating system. Since then, the combination of the two major components has usually been referred to as simply \"Linux\" by the software industry, a naming convention that Stallman and the Free Software Foundation remain opposed to, preferring the name GNU/Linux. The Berkeley Software Distribution, known as BSD, is the UNIX derivative distributed by the University of California, Berkeley, starting in the 1970s. Freely distributed and ported to many minicomputers, it eventually also gained a following for use on PCs, mainly as FreeBSD, NetBSD and OpenBSD.\\n\\n\\n== Examples ==\\n\\n\\n=== Unix and Unix-like operating systems ===\\n\\nUnix was originally written in assembly language. Ken Thompson wrote B, mainly based on BCPL, based on his experience in the MULTICS project. B was replaced by C, and Unix, rewritten in C, developed into a large, complex family of inter-related operating systems which have been influential in every modern operating system (see History).\\nThe Unix-like family is a diverse group of operating systems, with several major sub-categories including System V, BSD, and Linux. The name \"UNIX\" is a trademark of The Open Group which licenses it for use with any operating system that has been shown to conform to their definitions. \"UNIX-like\" is commonly used to refer to the large set of operating systems which resemble the original UNIX.\\nUnix-like systems run on a wide variety of computer architectures. They are used heavily for servers in business, as well as workstations in academic and engineering environments. Free UNIX variants, such as Linux and BSD, are popular in these areas.\\nFive operating systems are certified by The Open Group (holder of the Unix trademark) as Unix. HP\\'s HP-UX and IBM\\'s AIX are both descendants of the original System V Unix and are designed to run only on their respective vendor\\'s hardware. In contrast, Sun Microsystems\\'s Solaris can run on multiple types of hardware, including x86 and SPARC servers, and PCs. Apple\\'s macOS, a replacement for Apple\\'s earlier (non-Unix) classic Mac OS, is a hybrid kernel-based BSD variant derived from NeXTSTEP, Mach, and FreeBSD. IBM\\'s z/OS UNIX System Services includes a shell and utilities based on Mortice Kerns\\' InterOpen products.\\nUnix interoperability was sought by establishing the POSIX standard. The POSIX standard can be applied to any operating system, although it was originally created for various Unix variants.\\n\\n\\n==== BSD and its descendants ====\\n\\nA subgroup of the Unix family is the Berkeley Software Distribution family, which includes FreeBSD, NetBSD, and OpenBSD. These operating systems are most commonly found on webservers, although they can also function as a personal computer OS. The Internet owes much of its existence to BSD, as many of the protocols now commonly used by computers to connect, send and receive data over a network were widely implemented and refined in BSD. The World Wide Web was also first demonstrated on a number of computers running an OS based on BSD called NeXTSTEP.\\nIn 1974, University of California, Berkeley installed its first Unix system. Over time, students and staff in the computer science department there began adding new programs to make things easier, such as text editors. When Berkeley received new VAX computers in 1978 with Unix installed, the school\\'s undergraduates modified Unix even more in order to take advantage of the computer\\'s hardware possibilities. The Defense Advanced Research Projects Agency of the US Department of Defense took interest, and decided to fund the project. Many schools, corporations, and government organizations took notice and started to use Berkeley\\'s version of Unix instead of the official one distributed by AT&T.\\nSteve Jobs, upon leaving Apple Inc. in 1985, formed NeXT Inc., a company that manufactured high-end computers running on a variation of BSD called NeXTSTEP. One of these computers was used by Tim Berners-Lee as the first webserver to create the World Wide Web.\\nDevelopers like Keith Bostic encouraged the project to replace any non-free code that originated with Bell Labs. Once this was done, however, AT&T sued. After two years of legal disputes, the BSD project spawned a number of free derivatives, such as NetBSD and FreeBSD (both in 1993), and OpenBSD (from NetBSD in 1995).\\n\\n\\n==== macOS ====\\n\\nmacOS (formerly \"Mac OS X\" and later \"OS X\")  is a line of open core graphical operating systems developed, marketed, and sold by Apple Inc., the latest of which is pre-loaded on all currently shipping Macintosh computers. macOS is the successor to the original classic Mac OS, which had been Apple\\'s primary operating system since 1984. Unlike its predecessor, macOS is a UNIX operating system built on technology that had been developed at NeXT through the second half of the 1980s and up until Apple purchased the company in early 1997.\\nThe operating system was first released in 1999 as Mac OS X Server 1.0, followed in March 2001 by a client version (Mac OS X v10.0 \"Cheetah\"). Since then, six more distinct \"client\" and \"server\" editions of macOS have been released, until the two were merged in OS X 10.7 \"Lion\".\\nPrior to its merging with macOS, the server edition –  macOS Server –  was architecturally identical to its desktop counterpart and usually ran on Apple\\'s line of Macintosh server hardware. macOS Server included work group management and administration software tools that provide simplified access to key network services, including a mail transfer agent, a Samba server, an LDAP server, a domain name server, and others. With Mac OS X v10.7 Lion, all server aspects of Mac OS X Server have been integrated into the client version and the product re-branded as \"OS X\" (dropping \"Mac\" from the name). The server tools are now offered as an application.\\n\\n\\n==== z/OS UNIX System Services ====\\nFirst introduced as the OpenEdition upgrade to MVS/ESA System Product Version 4 Release 3, announced February 1993 with support for POSIX and other standards. z/OS UNIX System Services is built on top of MVS services and cannot run independently. While IBM initially introduced OpenEdition to satisfy FIPS requirements, several z/OS component now require UNIX services, e.g., TCP/IP.\\n\\n\\n==== Linux ====\\n\\nThe Linux kernel originated in 1991, as a project of Linus Torvalds, while a university student in Finland. He posted information about his project on a newsgroup for computer students and programmers, and received support and assistance from volunteers who succeeded in creating a complete and functional kernel.\\nLinux is Unix-like, but was developed without any Unix code, unlike BSD and its variants. Because of its open license model, the Linux kernel code is available for study and modification, which resulted in its use on a wide range of computing machinery from supercomputers to smartwatches. Although estimates suggest that Linux is used on only 2.81% of all \"desktop\" (or laptop) PCs, it has been widely adopted for use in servers and embedded systems such as cell phones. \\nLinux has superseded Unix on many platforms and is used on most supercomputers, including all 500 most powerful supercomputers on the TOP500 list — having displaced all competitors by 2017. Linux is also commonly used on other small energy-efficient computers, such as smartphones and smartwatches. The Linux kernel is used in some popular distributions, such as Red Hat, Debian, Ubuntu, Linux Mint and Google\\'s Android, ChromeOS, and ChromiumOS.\\n\\n\\n=== Microsoft Windows ===\\n\\nMicrosoft Windows is a family of proprietary operating systems designed by Microsoft Corporation and primarily targeted to x86 architecture based computers.  As of 2022, its worldwide market share on all platforms was approximately 30%, and on the desktop/laptop platforms, its market share was approximately 75%.  The latest version is Windows 11.\\nMicrosoft Windows was first released in 1985, as an operating environment running on top of MS-DOS, which was the standard operating system shipped on most Intel architecture personal computers at the time. In 1995, Windows 95 was released which only used MS-DOS as a bootstrap. For backwards compatibility, Win9x could run real-mode MS-DOS and 16-bit Windows 3.x drivers. Windows ME, released in 2000, was the last version in the Win9x family. Later versions have all been based on the Windows NT kernel. Current client versions of Windows run on IA-32, x86-64 and Arm microprocessors. In the past, Windows NT supported additional architectures.\\nServer editions of Windows are widely used, however, Windows\\' usage on servers is not as widespread as on personal computers as Windows competes against Linux and BSD for server market share.ReactOS is a Windows-alternative operating system, which is being developed on the principles of Windows –  without using any of Microsoft\\'s code.\\n\\n\\n=== Other ===\\nThere have been many operating systems that were significant in their day but are no longer so, such as AmigaOS; OS/2 from IBM and Microsoft; classic Mac OS, the non-Unix precursor to Apple\\'s macOS; BeOS; XTS-300; RISC OS; MorphOS; Haiku; BareMetal and FreeMint. Some are still used in niche markets and continue to be developed as minority platforms for enthusiast communities and specialist applications.\\nThe z/OS operating system for IBM z/Architecture mainframe computers is still being used and developed, and \\nOpenVMS, formerly from DEC, is still under active development by VMS Software Inc.  The IBM i operating system for IBM AS/400 and IBM Power Systems midrange computers is also still being used and developed.\\nYet other operating systems are used almost exclusively in academia, for operating systems education or to do research on operating system concepts. A typical example of a system that fulfills both roles is MINIX, while for example Singularity is used purely for research. Another example is the Oberon System designed at ETH Zürich by Niklaus Wirth, Jürg Gutknecht and a group of students at the former Computer Systems Institute in the 1980s. It was used mainly for research, teaching, and daily work in Wirth\\'s group.\\nOther operating systems have failed to win significant market share, but have introduced innovations that have influenced mainstream operating systems, not least Bell Labs\\' Plan 9.\\n\\n\\n== Components ==\\nThe components of an operating system all exist in order to make the different parts of a computer work together. All user software needs to go through the operating system in order to use any of the hardware, whether it be as simple as a mouse or keyboard or as complex as an Internet component.\\n\\n\\n=== Kernel ===\\n\\nWith the aid of firmware and device drivers, the kernel provides the most basic level of control over all of the computer\\'s hardware devices. It manages memory access for programs in the RAM, it determines which programs get access to which hardware resources, it sets up or resets the CPU\\'s operating states for optimal operation at all times, and it organizes the data for long-term non-volatile storage with file systems on such media as disks, tapes, flash memory, etc.\\n\\n\\n==== Program execution ====\\nThe operating system provides an interface between an application program and the computer hardware, so that an application program can interact with the hardware only by obeying rules and procedures programmed into the operating system.  The operating system is also a set of services which simplify development and execution of application programs. Executing an application program typically involves the creation of a process by the operating system kernel, which assigns memory space and other resources, establishes a priority for the process in multi-tasking systems, loads program binary code into memory, and initiates execution of the application program, which then interacts with the user and with hardware devices. However, in some systems an application can request that the operating system execute another application within the same process, either as a subroutine or in a separate thread, e.g., the LINK and ATTACH facilities of OS/360 and successors.\\n\\n\\n==== Interrupts ====\\n\\nAn interrupt (also known as abort, exception, fault, signal and trap) provides an efficient way for most operating systems to react to the environment. Interrupts cause the central processing unit (CPU) to have a control flow change away from the currently running program to an interrupt handler, also known as an interrupt service routine (ISR). An interrupt service routine may cause the central processing unit (CPU) to have a context switch. The details of how a computer processes an interrupt vary from architecture to architecture, and the details of how interrupt service routines behave vary from operating system to operating system. However, several interrupt functions are common. The architecture and operating system must:\\ntransfer control to an interrupt service routine.\\nsave the state of the currently running process.\\nrestore the state after the interrupt is serviced.\\n\\n\\n===== Software interrupt =====\\nA software interrupt is a message to a process that an event has occurred. This contrasts with a hardware interrupt — which is a message to the central processing unit (CPU) that an event has occurred. Software interrupts are similar to hardware interrupts — there is a change away from the currently running process. Similarly, both hardware and software interrupts execute an interrupt service routine.\\nSoftware interrupts may be normally occurring events. It is expected that a time slice will occur, so the kernel will have to perform a context switch. A computer program may set a timer to go off after a few seconds in case too much data causes an algorithm to take too long.Software interrupts may be error conditions, such as a malformed machine instruction. However, the most common error conditions are division by zero and accessing an invalid memory address.Users can send messages to the kernel to modify the behavior of a currently running process. For example, in the command-line environment, pressing the interrupt character (usually Control-C) might terminate the currently running process.To generate software interrupts for x86 CPUs, the INT assembly language instruction is available. The syntax is INT X, where X is the offset number (in hexadecimal format) to the interrupt vector table.\\n\\n\\n===== Signal =====\\nTo generate software interrupts in Unix-like operating systems, the kill(pid,signum) system call will send a signal to another process. pid is the process identifier of the receiving process. signum is the signal number (in mnemonic format) to be sent. (The abrasive name of kill was chosen because early implementations only terminated the process.)In Unix-like operating systems, signals inform processes of the occurrence of asynchronous events. To communicate asynchronously, interrupts are required. One reason a process needs to asynchronously communicate to another process solves a variation of the classic reader/writer problem. The writer receives a pipe from the shell for its output to be sent to the reader\\'s input stream. The command-line syntax is alpha | bravo. alpha will write to the pipe when its computation is ready and then sleep in the wait queue. bravo will then be moved to the ready queue and soon will read from its input stream. The kernel will generate software interrupts to coordinate the piping.Signals may be classified into 7 categories. The categories are:\\n\\nwhen a process finishes normally.\\nwhen a process has an error exception.\\nwhen a process runs out of a system resource.\\nwhen a process executes an illegal instruction.\\nwhen a process sets an alarm event.\\nwhen a process is aborted from the keyboard.\\nwhen a process has a tracing alert for debugging.\\n\\n\\n===== Hardware interrupt =====\\nInput/Output (I/O) devices are slower than the CPU. Therefore, it would slow down the computer if the CPU had to wait for each I/O to finish. Instead, a computer may implement interrupts for I/O completion, avoiding the need for polling or busy waiting.Some computers require an interrupt for each character or word, costing a significant amount of CPU time. Direct memory access (DMA) is an architecture feature to allow devices to bypass the CPU and access main memory directly. (Separate from the architecture, a device may perform direct memory access to and from main memory either directly or via a bus.)\\n\\n\\n==== Input/Output ====\\n\\n\\n===== Interrupt-driven I/O =====\\nWhen a computer user types a key on the keyboard, typically the character appears immediately on the screen. Likewise, when a user moves a mouse, the cursor immediately moves across the screen. Each keystroke and mouse movement generates an interrupt called Interrupt-driven I/O. An interrupt-driven I/O occurs when a process causes an interrupt for every character or word transmitted.\\n\\n\\n===== Direct Memory Access =====\\nDevices such as hard disk drives, solid state drives, and magnetic tape drives can transfer data at a rate high enough that interrupting the CPU for every byte or word transferred, and having the CPU transfer the byte or word between the device and memory, would require too much CPU time.  Data is, instead, transferred between the device and memory independently of the CPU by hardware such as a channel or a direct memory access controller; an interrupt is delivered only when all the data is transferred.If a computer program executes a system call to perform a block I/O write operation, then the system call might execute the following instructions:\\n\\nSet the contents of the CPU\\'s registers (including the program counter) into the process control block.\\nCreate an entry in the device-status table. The operating system maintains this table to keep track of which processes are waiting for which devices. One field in the table is the memory address of the process control block.\\nPlace all the characters to be sent to the device into a memory buffer.\\nSet the memory address of the memory buffer to a predetermined device register.\\nSet the buffer size (an integer) to another predetermined register.\\nExecute the machine instruction to begin the writing.\\nPerform a context switch to the next process in the ready queue.While the writing takes place, the operating system will context switch to other processes as normal. When the device finishes writing, the device will interrupt the currently running process by asserting an interrupt request. The device will also place an integer onto the data bus. Upon accepting the interrupt request, the operating system will:\\n\\nPush the contents of the program counter (a register) followed by the status register onto the call stack.\\nPush the contents of the other registers onto the call stack. (Alternatively, the contents of the registers may be placed in a system table.)\\nRead the integer from the data bus. The integer is an offset to the interrupt vector table. The vector table\\'s instructions will then:Access the device-status table.\\nExtract the process control block.\\nPerform a context switch back to the writing process.When the writing process has its time slice expired, the operating system will:\\nPop from the call stack the registers other than the status register and program counter.\\nPop from the call stack the status register.\\nPop from the call stack the address of the next instruction, and set it back into the program counter.With the program counter now reset, the interrupted process will resume its time slice.\\n\\n\\n==== Modes ====\\n\\nModern computers support multiple modes of operation. CPUs with this capability offer at least two modes: user mode and supervisor mode. In general terms, supervisor mode operation allows unrestricted access to all machine resources, including all MPU instructions.  User mode operation sets limits on instruction use and typically disallows direct access to machine resources. CPUs might have other modes similar to user mode as well, such as the virtual modes in order to emulate older processor types, such as 16-bit processors on a 32-bit one, or 32-bit processors on a 64-bit one.\\nAt power-on or reset, the system begins in supervisor mode. Once an operating system kernel has been loaded and started, the boundary between user mode and supervisor mode (also known as kernel mode) can be established.\\nSupervisor mode is used by the kernel for low level tasks that need unrestricted access to hardware, such as controlling how memory is accessed, and communicating with devices such as disk drives and video display devices. User mode, in contrast, is used for almost everything else. Application programs, such as word processors and database managers, operate within user mode, and can only access machine resources by turning control over to the kernel, a process which causes a switch to supervisor mode.  Typically, the transfer of control to the kernel is achieved by executing a software interrupt instruction, such as the Motorola 68000 TRAP instruction.  The software interrupt causes the processor to switch from user mode to supervisor mode and begin executing code that allows the kernel to take control.\\nIn user mode, programs usually have access to a restricted set of processor instructions, and generally cannot execute any instructions that could potentially cause disruption to the system\\'s operation.  In supervisor mode, instruction execution restrictions are typically removed, allowing the kernel unrestricted access to all machine resources.\\nThe term \"user mode resource\" generally refers to one or more CPU registers, which contain information that the running program is not allowed to alter. Attempts to alter these resources generally cause a switch to supervisor mode, where the operating system can deal with the illegal operation the program was attempting; for example, by forcibly terminating (\"killing\") the program.\\n\\n\\n==== Memory management ====\\n\\nAmong other things, a multiprogramming operating system kernel must be responsible for managing all system memory which is currently in use by the programs. This ensures that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory.\\nCooperative memory management, used by many early operating systems, assumes that all programs make voluntary use of the kernel\\'s memory manager, and do not exceed their allocated memory. This system of memory management is almost never seen any more, since programs often contain bugs which can cause them to exceed their allocated memory. If a program fails, it may cause memory used by one or more other programs to be affected or overwritten. Malicious programs or viruses may purposefully alter another program\\'s memory, or may affect the operation of the operating system itself. With cooperative memory management, it takes only one misbehaved program to crash the system.\\nMemory protection enables the kernel to limit a process\\' access to the computer\\'s memory. Various methods of memory protection exist, including memory segmentation and paging. All methods require some level of hardware support (such as the 80286 MMU), which does not exist in all computers.\\nIn both segmentation and paging, certain protected mode registers specify to the CPU what memory address it should allow a running program to access. Attempts to access other addresses trigger an interrupt, which causes the CPU to re-enter supervisor mode, placing the kernel in charge. This is called a segmentation violation or Seg-V for short, and since it is both difficult to assign a meaningful result to such an operation, and because it is usually a sign of a misbehaving program, the kernel generally resorts to terminating the offending program, and reports the error.\\nWindows versions 3.1 through ME had some level of memory protection, but programs could easily circumvent the need to use it. A general protection fault would be produced, indicating a segmentation violation had occurred; however, the system would often crash anyway.\\n\\n\\n==== Virtual memory ====\\n\\nThe use of virtual memory addressing (such as paging or segmentation) means that the kernel can choose what memory each program may use at any given time, allowing the operating system to use the same memory locations for multiple tasks.\\nIf a program tries to access memory that is not in its current range of accessible memory, but nonetheless has been allocated to it, the kernel is interrupted in the same way as it would if the program were to exceed its allocated memory. (See section on memory management.) Under UNIX this kind of interrupt is referred to as a page fault.\\nWhen the kernel detects a page fault it generally adjusts the virtual memory range of the program which triggered it, granting it access to the memory requested. This gives the kernel discretionary power over where a particular application\\'s memory is stored, or even whether or not it has actually been allocated yet.\\nIn modern operating systems, memory which is accessed less frequently can be temporarily stored on a disk or other media to make that space available for use by other programs. This is called swapping, as an area of memory can be used by multiple programs, and what that memory area contains can be swapped or exchanged on demand.\\n\"Virtual memory\" provides the programmer or the user with the perception that there is a much larger amount of RAM in the computer than is really there.\\n\\n\\n==== Multitasking ====\\n\\nMultitasking refers to the running of multiple independent computer programs on the same computer, giving the appearance that it is performing the tasks at the same time. Since most computers can do at most one or two things at one time, this is generally done via time-sharing, which means that each program uses a share of the computer\\'s time to execute.\\nAn operating system kernel contains a scheduling program which determines how much time each process spends executing, and in which order execution control should be passed to programs. Control is passed to a process by the kernel, which allows the program access to the CPU and memory. Later, control is returned to the kernel through some mechanism, so that another program may be allowed to use the CPU. This so-called passing of control between the kernel and applications is called a context switch.\\nAn early model which governed the allocation of time to programs was called cooperative multitasking. In this model, when control is passed to a program by the kernel, it may execute for as long as it wants before explicitly returning control to the kernel. This means that a malicious or malfunctioning program may not only prevent any other programs from using the CPU, but it can hang the entire system if it enters an infinite loop.\\nModern operating systems extend the concepts of application preemption to device drivers and kernel code, so that the operating system has preemptive control over internal run-times as well.\\nThe philosophy governing preemptive multitasking is that of ensuring that all programs are given regular time on the CPU. This implies that all programs must be limited in how much time they are allowed to spend on the CPU without being interrupted. To accomplish this, modern operating system kernels make use of a timed interrupt. A protected mode timer is set by the kernel which triggers a return to supervisor mode after the specified time has elapsed. (See above sections on Interrupts and Dual Mode Operation.)\\nOn many single user operating systems cooperative multitasking is perfectly adequate, as home computers generally run a small number of well tested programs. AmigaOS is an exception, having preemptive multitasking from its first version. Windows NT was the first version of Microsoft Windows which enforced preemptive multitasking, but it did not reach the home user market until Windows XP (since Windows NT was targeted at professionals).\\n\\n\\n==== Disk access and file systems ====\\n\\nAccess to data stored on disks is a central feature of all operating systems. Computers store data on disks using files, which are structured in specific ways in order to allow for faster access, higher reliability, and to make better use of the drive\\'s available space. The specific way in which files are stored on a disk is called a file system, and enables files to have names and attributes. It also allows them to be stored in a hierarchy of directories or folders arranged in a directory tree.\\nEarly operating systems generally supported a single type of disk drive and only one kind of file system. Early file systems were limited in their capacity, speed, and in the kinds of file names and directory structures they could use. These limitations often reflected limitations in the operating systems they were designed for, making it very difficult for an operating system to support more than one file system.\\nWhile many simpler operating systems support a limited range of options for accessing storage systems, operating systems like UNIX and Linux support a technology known as a virtual file system or VFS. An operating system such as UNIX supports a wide array of storage devices, regardless of their design or file systems, allowing them to be accessed through a common application programming interface (API). This makes it unnecessary for programs to have any knowledge about the device they are accessing. A VFS allows the operating system to provide programs with access to an unlimited number of devices with an infinite variety of file systems installed on them, through the use of specific device drivers and file system drivers.\\nA connected storage device, such as a hard drive, is accessed through a device driver. The device driver understands the specific language of the drive and is able to translate that language into a standard language used by the operating system to access all disk drives. On UNIX, this is the language of block devices.\\nWhen the kernel has an appropriate device driver in place, it can then access the contents of the disk drive in raw format, which may contain one or more file systems. A file system driver is used to translate the commands used to access each specific file system into a standard set of commands that the operating system can use to talk to all file systems. Programs can then deal with these file systems on the basis of filenames, and directories/folders, contained within a hierarchical structure. They can create, delete, open, and close files, as well as gather various information about them, including access permissions, size, free space, and creation and modification dates.\\nVarious differences between file systems make supporting all file systems difficult. Allowed characters in file names, case sensitivity, and the presence of various kinds of file attributes makes the implementation of a single interface for every file system a daunting task. Operating systems tend to recommend using (and so support natively) file systems specifically designed for them; for example, NTFS in Windows and ReiserFS, Reiser4, ext3, ext4 and Btrfs in Linux. However, in practice, third party drivers are usually available to give support for the most widely used file systems in most general-purpose operating systems (for example, NTFS is available in Linux through NTFS-3g, and ext2/3 and ReiserFS are available in Windows through third-party software).\\nSupport for file systems is highly varied among modern operating systems, although there are several common file systems which almost all operating systems include support and drivers for. Operating systems vary on file system support and on the disk formats they may be installed on. Under Windows, each file system is usually limited in application to certain media; for example, CDs must use ISO 9660 or UDF, and as of Windows Vista, NTFS is the only file system which the operating system can be installed on.  It is possible to install Linux onto many types of file systems. Unlike other operating systems, Linux and UNIX allow any file system to be used regardless of the media it is stored in, whether it is a hard drive, a disc (CD, DVD...), a USB flash drive, or even contained within a file located on another file system.\\n\\n\\n==== Device drivers ====\\n\\nA device driver is a specific type of computer software developed to allow interaction with hardware devices. Typically this constitutes an interface for communicating with the device, through the specific computer bus or communications subsystem that the hardware is connected to, providing commands to or receiving data from the device, and on the other end, the requisite interfaces to the operating system and software applications. It is a specialized hardware-dependent computer program which is also operating system specific that enables another program, typically an operating system or applications software package or computer program running under the operating system kernel, to interact transparently with a hardware device, and usually provides the requisite interrupt handling necessary for any necessary asynchronous time-dependent hardware interfacing needs.\\nThe key design goal of device drivers is abstraction. Every model of hardware (even within the same class of device) is different. Newer models also are released by manufacturers that provide more reliable or better performance and these newer models are often controlled differently. Computers and their operating systems cannot be expected to know how to control every device, both now and in the future. To solve this problem, operating systems essentially dictate how every type of device should be controlled. The function of the device driver is then to translate these operating system mandated function calls into device specific calls. In theory a new device, which is controlled in a new manner, should function correctly if a suitable driver is available. This new driver ensures that the device appears to operate as usual from the operating system\\'s point of view.\\nUnder versions of Windows before Vista and versions of Linux before 2.6, all driver execution was co-operative, meaning that if a driver entered an infinite loop it would freeze the system. More recent revisions of these operating systems incorporate kernel preemption, where the kernel interrupts the driver to give it tasks, and then separates itself from the process until it receives a response from the device driver, or gives it more tasks to do.\\n\\n\\n=== Networking ===\\n\\nCurrently most operating systems support a variety of networking protocols, hardware, and applications for using them. This means that computers running dissimilar operating systems can participate in a common network for sharing resources such as computing, files, printers, and scanners using either wired or wireless connections. Networks can essentially allow a computer\\'s operating system to access the resources of a remote computer to support the same functions as it could if those resources were connected directly to the local computer. This includes everything from simple communication, to using networked file systems or even sharing another computer\\'s graphics or sound hardware. Some network services allow the resources of a computer to be accessed transparently, such as SSH which allows networked users direct access to a computer\\'s command line interface.\\nClient/server networking allows a program on a computer, called a client, to connect via a network to another computer, called a server. Servers offer (or host) various services to other network computers and users. These services are usually provided through ports or numbered access points beyond the server\\'s IP address. Each port number is usually associated with a maximum of one running program, which is responsible for handling requests to that port. A daemon, being a user program, can in turn access the local hardware resources of that computer by passing requests to the operating system kernel.\\nMany operating systems support one or more vendor-specific or open networking protocols as well, for example, SNA on IBM systems, DECnet on systems from Digital Equipment Corporation, and Microsoft-specific protocols (SMB) on Windows. Specific protocols for specific tasks may also be supported such as NFS for file access. Protocols like ESound, or esd can be easily extended over the network to provide sound from local applications, on a remote system\\'s sound hardware.\\n\\n\\n=== Security ===\\n\\nA computer being secure depends on a number of technologies working properly. A modern operating system provides access to a number of resources, which are available to software running on the system, and to external devices like networks via the kernel.The operating system must be capable of distinguishing between requests which should be allowed to be processed, and others which should not be processed. While some systems may simply distinguish between \"privileged\" and \"non-privileged\", systems commonly have a form of requester identity, such as a user name. To establish identity there may be a process of authentication. Often a username must be quoted, and each username may have a password. Other methods of authentication, such as magnetic cards or biometric data, might be used instead. In some cases, especially connections from the network, resources may be accessed with no authentication at all (such as reading files over a network share). Also covered by the concept of requester identity is authorization; the particular services and resources accessible by the requester once logged into a system are tied to either the requester\\'s user account or to the variously configured groups of users to which the requester belongs.In addition to the allow or disallow model of security, a system with a high level of security also offers auditing options. These would allow tracking of requests for access to resources (such as, \"who has been reading this file?\"). Internal security, or security from an already running program is only possible if all possibly harmful requests must be carried out through interrupts to the operating system kernel. If programs can directly access hardware and resources, they cannot be secured.External security involves a request from outside the computer, such as a login at a connected console or some kind of network connection. External requests are often passed through device drivers to the operating system\\'s kernel, where they can be passed onto applications, or carried out directly. Security of operating systems has long been a concern because of highly sensitive data held on computers, both of a commercial and military nature. The United States Government Department of Defense (DoD) created the Trusted Computer System Evaluation Criteria (TCSEC) which is a standard that sets basic requirements for assessing the effectiveness of security. This became of vital importance to operating system makers, because the TCSEC was used to evaluate, classify and select trusted operating systems being considered for the processing, storage and retrieval of sensitive or classified information.\\nNetwork services include offerings such as file sharing, print services, email, web sites, and file transfer protocols (FTP), most of which can have compromised security. At the front line of security are hardware devices known as firewalls or intrusion detection/prevention systems. At the operating system level, there are a number of software firewalls available, as well as intrusion detection/prevention systems. Most modern operating systems include a software firewall, which is enabled by default. A software firewall can be configured to allow or deny network traffic to or from a service or application running on the operating system. Therefore, one can install and be running an insecure service, such as Telnet or FTP, and not have to be threatened by a security breach because the firewall would deny all traffic trying to connect to the service on that port.\\nAn alternative strategy, and the only sandbox strategy available in systems that do not meet the Popek and Goldberg virtualization requirements, is where the operating system is not running user programs as native code, but instead either emulates a processor or provides a host for a p-code based system such as Java.\\nInternal security is especially relevant for multi-user systems; it allows each user of the system to have private files that the other users cannot tamper with or read. Internal security is also vital if auditing is to be of any use, since a program can potentially bypass the operating system, inclusive of bypassing auditing.\\n\\n\\n=== User interface ===\\n\\nEvery computer that is to be operated by an individual requires a user interface. The user interface is usually referred to as a shell and is essential if human interaction is to be supported.  The user interface views the directory structure and requests services from the operating system that will acquire data from input hardware devices, such as a keyboard, mouse or credit card reader, and requests operating system services to display prompts, status messages and such on output hardware devices, such as a video monitor or printer. The two most common forms of a user interface have historically been the command-line interface, where computer commands are typed out line-by-line, and the graphical user interface, where a visual environment (most commonly a WIMP) is present.\\n\\n\\n==== Graphical user interfaces ====\\nMost of the modern computer systems support graphical user interfaces (GUI), and often include them. In some computer systems, such as the original implementation of the classic Mac OS, the GUI is integrated into the kernel.\\nWhile technically a graphical user interface is not an operating system service, incorporating support for one into the operating system kernel can allow the GUI to be more responsive by reducing the number of context switches required for the GUI to perform its output functions. Other operating systems are modular, separating the graphics subsystem from the kernel and the Operating System. In the 1980s UNIX, VMS and many others had operating systems that were built this way. Linux and macOS are also built this way. Modern releases of Microsoft Windows such as Windows Vista implement a graphics subsystem that is mostly in user-space; however the graphics drawing routines of versions between Windows NT 4.0 and Windows Server 2003 exist mostly in kernel space. Windows 9x had very little distinction between the interface and the kernel.\\nMany computer operating systems allow the user to install or create any user interface they desire. The X Window System in conjunction with GNOME or KDE Plasma 5 is a commonly found setup on most Unix and Unix-like (BSD, Linux, Solaris) systems. A number of Windows shell replacements have been released for Microsoft Windows, which offer alternatives to the included Windows shell, but the shell itself cannot be separated from Windows.\\nNumerous Unix-based GUIs have existed over time, most derived from X11. Competition among the various vendors of Unix (HP, IBM, Sun) led to much fragmentation, though an effort to standardize in the 1990s to COSE and CDE failed for various reasons, and were eventually eclipsed by the widespread adoption of GNOME and K Desktop Environment. Prior to free software-based toolkits and desktop environments, Motif was the prevalent toolkit/desktop combination (and was the basis upon which CDE was developed).\\nGraphical user interfaces evolve over time. For example, Windows has modified its user interface almost every time a new major version of Windows is released, and the Mac OS GUI changed dramatically with the introduction of Mac OS X in 1999.\\n\\n\\n== Real-time operating systems ==\\n\\nA real-time operating system (RTOS) is an operating system intended for applications with fixed deadlines (real-time computing). Such applications include some small embedded systems, automobile engine controllers, industrial robots, spacecraft, industrial control, and some large-scale computing systems.\\nAn early example of a large-scale real-time operating system was Transaction Processing Facility developed by American Airlines and IBM for the Sabre Airline Reservations System.\\nEmbedded systems that have fixed deadlines use a real-time operating system such as VxWorks, PikeOS, eCos, QNX, MontaVista Linux and RTLinux. Windows CE is a real-time operating system that shares similar APIs to desktop Windows but shares none of desktop Windows\\' codebase. Symbian OS also has an RTOS kernel (EKA2) starting with version 8.0b.\\nSome embedded systems use operating systems such as Palm OS, BSD, and Linux, although such operating systems do not support real-time computing.\\n\\n\\n== Operating system development as a hobby ==\\n\\nA hobby operating system may be classified as one whose code has not been directly derived from an existing operating system, and has few users and active developers.In some cases, hobby development is in support of a \"homebrew\" computing device, for example, a simple single-board computer powered by a 6502 microprocessor.  Or, development may be for an architecture already in widespread use.  Operating system development may come from entirely new concepts, or may commence by modeling an existing operating system.  In either case, the hobbyist is her/his own developer, or may interact with a small and sometimes unstructured group of individuals who have like interests.\\nExamples of a hobby operating system include Syllable and TempleOS.\\n\\n\\n== Diversity of operating systems and portability ==\\nIf an application is written for use on a specific operating system, and is ported to another OS, the functionality required by that application may be implemented differently by that OS (the names of functions, meaning of arguments, etc.) requiring the application to be adapted, changed, or otherwise maintained.\\nThis cost in supporting operating systems diversity can be avoided by instead writing applications against software platforms such as Java or Qt. These abstractions have already borne the cost of adaptation to specific operating systems and their system libraries.\\nAnother approach is for operating system vendors to adopt standards. For example, POSIX and OS abstraction layers provide commonalities that reduce porting costs.\\n\\n\\n== Market share ==\\n\\n\\n== See also ==\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\n\\n\\n== External links ==\\n\\nOperating Systems at Curlie\\nMultics History and the history of operating systems',\n",
              " \"Page 'Computer Vision' does not exist on Wikipedia.\",\n",
              " 'Cryptography, or cryptology (from Ancient Greek: κρυπτός, romanized: kryptós \"hidden, secret\"; and γράφειν graphein, \"to write\", or -λογία -logia, \"study\", respectively), is the practice and study of techniques for secure communication in the presence of adversarial behavior. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, information security, electrical engineering, digital signal processing, physics, and others. Core concepts related to  information security (data confidentiality, data integrity, authentication, and non-repudiation) are also central to cryptography. Practical applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.\\nCryptography prior to the modern age was effectively synonymous with encryption, converting readable information (plaintext) to unintelligible nonsense text (ciphertext), which can only be read by reversing the process (decryption). The sender of an encrypted (coded) message shares the decryption (decoding) technique only with the intended recipients to preclude access from adversaries. The cryptography literature often uses the names \"Alice\" (or \"A\") for the sender, \"Bob\" (or \"B\") for the intended recipient, and \"Eve\" (or \"E\") for the eavesdropping adversary. Since the development of rotor cipher machines in World War I and the advent of computers in World War II, cryptography methods have become increasingly complex and their applications more varied.\\nModern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary. While it is theoretically possible to break into a well-designed system, it is infeasible in actual practice to do so. Such schemes, if well designed, are therefore termed \"computationally secure\". Theoretical advances (e.g., improvements in integer factorization algorithms) and faster computing technology require these designs to be continually reevaluated and, if necessary, adapted. Information-theoretically secure schemes that provably cannot be broken even with unlimited computing power, such as the one-time pad, are much more difficult to use in practice than the best theoretically breakable but computationally secure schemes.\\nThe growth of cryptographic technology has raised a number of legal issues in the Information Age. Cryptography\\'s potential for use as a tool for espionage and sedition has led many governments to classify it as a weapon and to limit or even prohibit its use and export. In some jurisdictions where the use of cryptography is legal, laws permit investigators to compel the disclosure of encryption keys for documents relevant to an investigation. Cryptography also plays a major role in digital rights management and copyright infringement disputes with regard to digital media.\\n\\n\\n== Terminology ==\\nThe first use of the term \"cryptograph\" (as opposed to \"cryptogram\") dates back to the 19th century—originating from \"The Gold-Bug,\" a story by Edgar Allan Poe.Until modern times, cryptography referred almost exclusively to \"encryption\", which is the process of converting ordinary information (called plaintext) into an unintelligible form (called ciphertext). Decryption is the reverse, in other words, moving from the unintelligible ciphertext back to plaintext. A cipher (or cypher) is a pair of algorithms that carry out the encryption and the reversing decryption. The detailed operation of a cipher is controlled both by the algorithm and, in each instance, by a \"key\". The key is a secret (ideally known only to the communicants), usually a string of characters (ideally short so it can be remembered by the user), which is needed to decrypt the ciphertext.  In formal mathematical terms, a \"cryptosystem\" is the ordered list of elements of finite possible plaintexts, finite possible cyphertexts, finite possible keys, and the encryption and decryption algorithms that correspond to each key.  Keys are important both formally and in actual practice, as ciphers without variable keys can be trivially broken with only the knowledge of the cipher used and are therefore useless (or even counter-productive) for most purposes. Historically, ciphers were often used directly for encryption or decryption without additional procedures such as authentication or integrity checks.\\nThere are two main types of cryptosystems: symmetric and asymmetric. In symmetric systems, the only ones known until the 1970s, the same secret key encrypts and decrypts a message. Data manipulation in symmetric systems is significantly faster than in asymmetric systems. Asymmetric systems use a \"public key\" to encrypt a message and a related \"private key\" to decrypt it. The advantage of asymmetric systems is that the public key can be freely published, allowing parties to establish secure communication without having a shared secret key.  In practice, asymmetric systems are used to first exchange a secret key, and then secure communication proceeds via a more efficient symmetric system using that key. Examples of asymmetric systems include Diffie–Hellman key exchange, RSA (Rivest–Shamir–Adleman), ECC (Elliptic Curve Cryptography), and Post-quantum cryptography. Secure symmetric algorithms include the commonly used AES (Advanced Encryption Standard) which replaced the older DES (Data Encryption Standard).  Insecure symmetric algorithms include children\\'s language tangling schemes such as Pig Latin or other cant, and all historical cryptographic schemes, however seriously intended, prior to the invention of the one-time pad early in the 20th century.\\nIn colloquial use, the term \"code\" is often used to mean any method of encryption or concealment of meaning. However, in cryptography, code has a more specific meaning: the replacement of a unit of plaintext (i.e., a meaningful word or phrase) with a code word (for example, \"wallaby\" replaces \"attack at dawn\").  A cypher, in contrast, is a scheme for changing or substituting an element below such a level (a letter, a syllable, or a pair of letters, etc.) in order to produce a cyphertext.\\nCryptanalysis is the term used for the study of methods for obtaining the meaning of encrypted information without access to the key normally required to do so; i.e., it is the study of how to \"crack\" encryption algorithms or their implementations.\\nSome use the terms \"cryptography\" and \"cryptology\" interchangeably in English, while others (including US military practice generally) use \"cryptography\" to refer specifically to the use and practice of cryptographic techniques and \"cryptology\" to refer to the combined study of cryptography and cryptanalysis. English is more flexible than several other languages in which \"cryptology\" (done by cryptologists) is always used in the second sense above. RFC 2828 advises that steganography is sometimes included in cryptology.The study of characteristics of languages that have some application in cryptography or cryptology (e.g. frequency data, letter combinations, universal patterns, etc.) is called cryptolinguistics. Cryptolingusitics is especially used in military intelligence applications for deciphering foreign communications.\\n\\n\\n== History ==\\n\\nBefore the modern era, cryptography focused on message confidentiality (i.e., encryption)—conversion of messages from a comprehensible form into an incomprehensible one and back again at the other end, rendering it unreadable by interceptors or eavesdroppers without secret knowledge (namely the key needed for decryption of that message). Encryption attempted to ensure secrecy in communications, such as those of spies, military leaders, and diplomats. In recent decades, the field has expanded beyond confidentiality concerns to include techniques for message integrity checking, sender/receiver identity authentication, digital signatures, interactive proofs and secure computation, among others.\\n\\n\\n=== Classic cryptography ===\\nThe main classical cipher types are transposition ciphers, which rearrange the order of letters in a message (e.g., \\'hello world\\' becomes \\'ehlol owrdl\\' in a trivially simple rearrangement scheme), and substitution ciphers, which systematically replace letters or groups of letters with other letters or groups of letters (e.g., \\'fly at once\\' becomes \\'gmz bu podf\\' by replacing each letter with the one following it in the Latin alphabet). Simple versions of either have never offered much confidentiality from enterprising opponents. An early substitution cipher was the Caesar cipher, in which each letter in the plaintext was replaced by a letter some fixed number of positions further down the alphabet. Suetonius reports that Julius Caesar used it with a shift of three to communicate with his generals. Atbash is an example of an early Hebrew cipher. The earliest known use of cryptography is some carved ciphertext on stone in Egypt (c.\\u20091900 BCE), but this may have been done for the amusement of literate observers rather than as a way of concealing information.\\nThe Greeks of Classical times are said to have known of ciphers (e.g., the scytale transposition cipher claimed to have been used by the Spartan military). Steganography (i.e., hiding even the existence of a message so as to keep it confidential) was also first developed in ancient times. An early example, from Herodotus, was a message tattooed on a slave\\'s shaved head and concealed under the regrown hair. More modern examples of steganography include the use of invisible ink, microdots, and digital watermarks to conceal information.\\nIn India, the 2000-year-old Kamasutra of Vātsyāyana speaks of two different kinds of ciphers called Kautiliyam and Mulavediya. In the Kautiliyam, the cipher letter substitutions are based on phonetic relations, such as vowels becoming consonants. In the Mulavediya, the cipher alphabet consists of pairing letters and using the reciprocal ones.In Sassanid Persia, there were two secret scripts, according to the Muslim author Ibn al-Nadim: the šāh-dabīrīya (literally \"King\\'s script\") which was used for official correspondence, and the rāz-saharīya which was used to communicate secret messages with other countries.David Kahn notes in The Codebreakers that modern cryptology originated among the Arabs, the first people to systematically document cryptanalytic methods. Al-Khalil (717–786) wrote the Book of Cryptographic Messages, which contains the first use of permutations and combinations to list all possible Arabic words with and without vowels.\\nCiphertexts produced by a classical cipher (and some modern ciphers) will reveal statistical information about the plaintext, and that information can often be used to break the cipher. After the discovery of frequency analysis, perhaps by the Arab mathematician and polymath Al-Kindi (also known as Alkindus) in the 9th century, nearly all such ciphers could be broken by an informed attacker. Such classical ciphers still enjoy popularity today, though mostly as puzzles (see cryptogram). Al-Kindi wrote a book on cryptography entitled Risalah fi Istikhraj al-Mu\\'amma (Manuscript for the Deciphering Cryptographic Messages), which described the first known use of frequency analysis cryptanalysis techniques.\\nLanguage letter frequencies may offer little help for some extended historical encryption techniques such as homophonic cipher that tend to flatten the frequency distribution. For those ciphers, language letter group (or n-gram) frequencies may provide an attack.\\nEssentially all ciphers remained vulnerable to cryptanalysis using the frequency analysis technique until the development of the polyalphabetic cipher, most clearly by Leon Battista Alberti around the year 1467, though there is some indication that it was already known to Al-Kindi. Alberti\\'s innovation was to use different ciphers (i.e., substitution alphabets) for various parts of a message (perhaps for each successive plaintext letter at the limit). He also invented what was probably the first automatic cipher device, a wheel that implemented a partial realization of his invention. In the Vigenère cipher, a polyalphabetic cipher, encryption uses a key word, which controls letter substitution depending on which letter of the key word is used. In the mid-19th century Charles Babbage showed that the Vigenère cipher was vulnerable to Kasiski examination, but this was first published about ten years later by Friedrich Kasiski.Although frequency analysis can be a powerful and general technique against many ciphers, encryption has still often been effective in practice, as many a would-be cryptanalyst was unaware of the technique. Breaking a message without using frequency analysis essentially required knowledge of the cipher used and perhaps of the key involved, thus making espionage, bribery, burglary, defection, etc., more attractive approaches to the cryptanalytically uninformed. It was finally explicitly recognized in the 19th century that secrecy of a cipher\\'s algorithm is not a sensible nor practical safeguard of message security; in fact, it was further realized that any adequate cryptographic scheme (including ciphers) should remain secure even if the adversary fully understands the cipher algorithm itself. Security of the key used should alone be sufficient for a good cipher to maintain confidentiality under an attack. This fundamental principle was first explicitly stated in 1883 by Auguste Kerckhoffs and is generally called Kerckhoffs\\'s Principle; alternatively and more bluntly, it was restated by Claude Shannon, the inventor of information theory and the fundamentals of theoretical cryptography, as Shannon\\'s Maxim—\\'the enemy knows the system\\'.\\nDifferent physical devices and aids have been used to assist with ciphers. One of the earliest may have been the scytale of ancient Greece, a rod supposedly used by the Spartans as an aid for a transposition cipher. In medieval times, other aids were invented such as the cipher grille, which was also used for a kind of steganography. With the invention of polyalphabetic ciphers came more sophisticated aids such as Alberti\\'s own cipher disk, Johannes Trithemius\\' tabula recta scheme, and Thomas Jefferson\\'s wheel cypher (not publicly known, and reinvented independently by Bazeries around 1900). Many mechanical encryption/decryption devices were invented early in the 20th century, and several patented, among them rotor machines—famously including the Enigma machine used by the German government and military from the late 1920s and during World War II. The ciphers implemented by better quality examples of these machine designs brought about a substantial increase in cryptanalytic difficulty after WWI.\\n\\n\\n=== Early computer-era cryptography ===\\nCryptanalysis of the new mechanical ciphering devices proved to be both difficult and laborious. In the United Kingdom, cryptanalytic efforts at Bletchley Park during WWII spurred the development of more efficient means for carrying out repetitive tasks, such as military code breaking (decryption). This culminated in the development of the Colossus, the world\\'s first fully electronic, digital, programmable computer, which assisted in the decryption of ciphers generated by the German Army\\'s Lorenz SZ40/42 machine.\\nExtensive open academic research into cryptography is relatively recent, beginning in the mid-1970s. In the early 1970s IBM personnel designed the Data Encryption Standard (DES) algorithm that became the first federal government cryptography standard in the United States. In 1976 Whitfield Diffie and Martin Hellman published the Diffie–Hellman key exchange algorithm. In 1977 the RSA algorithm was published in Martin Gardner\\'s Scientific American column. Since then, cryptography has become a widely used tool in communications, computer networks, and computer security generally.\\nSome modern cryptographic techniques can only keep their keys secret if certain mathematical problems are intractable, such as the integer factorization or the discrete logarithm problems, so there are deep connections with abstract mathematics. There are very few cryptosystems that are proven to be unconditionally secure. The one-time pad is one, and was proven to be so by Claude Shannon. There are a few important algorithms that have been proven secure under certain assumptions. For example, the infeasibility of factoring extremely large integers is the basis for believing that RSA is secure, and some other systems, but even so, proof of unbreakability is unavailable since the underlying mathematical problem remains open. In practice, these are widely used, and are believed unbreakable in practice by most competent observers.  There are systems similar to RSA, such as one by Michael O. Rabin that are provably secure provided factoring  n = pq is impossible;  it is quite unusable in practice. The discrete logarithm problem is the basis for believing some other cryptosystems are secure, and again, there are related, less practical systems that are provably secure relative to the solvability or insolvability discrete log problem.As well as being aware of cryptographic history, cryptographic algorithm and system designers must also sensibly consider probable future developments while working on their designs. For instance, continuous improvements in computer processing power have increased the scope of brute-force attacks, so when specifying key lengths, the required key lengths are similarly advancing. The potential impact of quantum computing are already being considered by some cryptographic system designers developing post-quantum cryptography. The announced imminence of small implementations of these machines may be making the need for preemptive caution rather more than merely speculative.\\n\\n\\n=== Modern cryptography ===\\nPrior to the early 20th century, cryptography was mainly concerned with linguistic and lexicographic patterns. Since then cryptography has broadened in scope, and now makes extensive use of mathematical subdisciplines, including information theory, computational complexity, statistics, combinatorics, abstract algebra, number theory, and finite mathematics. Cryptography is also a branch of engineering, but an unusual one since it deals with active, intelligent, and malevolent opposition; other kinds of engineering (e.g., civil or chemical engineering) need deal only with neutral natural forces. There is also active research examining the relationship between cryptographic problems and quantum physics.\\nJust as the development of digital computers and electronics helped in cryptanalysis, it made possible much more complex ciphers. Furthermore, computers allowed for the encryption of any kind of data representable in any binary format, unlike classical ciphers which only encrypted written language texts; this was new and significant. Computer use has thus supplanted linguistic cryptography, both for cipher design and cryptanalysis. Many computer ciphers can be characterized by their operation on binary bit sequences (sometimes in groups or blocks), unlike classical and mechanical schemes, which generally manipulate traditional characters (i.e., letters and digits) directly. However, computers have also assisted cryptanalysis, which has compensated to some extent for increased cipher complexity. Nonetheless, good modern ciphers have stayed ahead of cryptanalysis; it is typically the case that use of a quality cipher is very efficient (i.e., fast and requiring few resources, such as memory or CPU capability), while breaking it requires an effort many orders of magnitude larger, and vastly larger than that required for any classical cipher, making cryptanalysis so inefficient and impractical as to be effectively impossible.\\n\\n\\n== Modern cryptography ==\\n\\n\\n=== Symmetric-key cryptography ===\\n\\nSymmetric-key cryptography refers to encryption methods in which both the sender and receiver share the same key (or, less commonly, in which their keys are different, but related in an easily computable way). This was the only kind of encryption publicly known until June 1976.\\nSymmetric key ciphers are implemented as either block ciphers or stream ciphers. A block cipher enciphers input in blocks of plaintext as opposed to individual characters, the input form used by a stream cipher.\\nThe Data Encryption Standard (DES) and the Advanced Encryption Standard (AES) are block cipher designs that have been designated cryptography standards by the US government (though DES\\'s designation was finally withdrawn after the AES was adopted). Despite its deprecation as an official standard, DES (especially its still-approved and much more secure triple-DES variant) remains quite popular; it is used across a wide range of applications, from ATM encryption to e-mail privacy and secure remote access. Many other block ciphers have been designed and released, with considerable variation in quality. Many, even some designed by capable practitioners, have been thoroughly broken, such as FEAL.Stream ciphers, in contrast to the \\'block\\' type, create an arbitrarily long stream of key material, which is combined with the plaintext bit-by-bit or character-by-character, somewhat like the one-time pad. In a stream cipher, the output stream is created based on a hidden internal state that changes as the cipher operates. That internal state is initially set up using the secret key material. RC4 is a widely used stream cipher. Block ciphers can be used as stream ciphers by generating blocks of a keystream (in place of a Pseudorandom number generator) and applying an XOR operation to each bit of the plaintext with each bit of the keystream.Message authentication codes (MACs) are much like cryptographic hash functions, except that a secret key can be used to authenticate the hash value upon receipt; this additional complication blocks an attack scheme against bare digest algorithms, and so has been thought worth the effort. Cryptographic hash functions are a third type of cryptographic algorithm. They take a message of any length as input, and output a short, fixed-length hash, which can be used in (for example) a digital signature. For good hash functions, an attacker cannot find two messages that produce the same hash. MD4 is a long-used hash function that is now broken; MD5, a strengthened variant of MD4, is also widely used but broken in practice. The US National Security Agency developed the Secure Hash Algorithm series of MD5-like hash functions: SHA-0 was a flawed algorithm that the agency withdrew; SHA-1 is widely deployed and more secure than MD5, but cryptanalysts have identified attacks against it; the SHA-2 family improves on SHA-1, but is vulnerable to clashes as of 2011; and the US standards authority thought it \"prudent\" from a security perspective to develop a new standard to \"significantly improve the robustness of NIST\\'s overall hash algorithm toolkit.\" Thus, a hash function design competition was meant to select a new U.S. national standard, to be called SHA-3, by 2012. The competition ended on October 2, 2012, when the NIST announced that Keccak would be the new SHA-3 hash algorithm. Unlike block and stream ciphers that are invertible, cryptographic hash functions produce a hashed output that cannot be used to retrieve the original input data. Cryptographic hash functions are used to verify the authenticity of data retrieved from an untrusted source or to add a layer of security.\\n\\n\\n=== Public-key cryptography ===\\n\\nSymmetric-key cryptosystems use the same key for encryption and decryption of a message, although a message or group of messages can have a different key than others. A significant disadvantage of symmetric ciphers is the key management necessary to use them securely. Each distinct pair of communicating parties must, ideally, share a different key, and perhaps for each ciphertext exchanged as well. The number of keys required increases as the square of the number of network members, which very quickly requires complex key management schemes to keep them all consistent and secret.\\n\\nIn a groundbreaking 1976 paper, Whitfield Diffie and Martin Hellman proposed the notion of public-key (also, more generally, called asymmetric key) cryptography in which two different but mathematically related keys are used—a public key and a private key. A public key system is so constructed that calculation of one key (the \\'private key\\') is computationally infeasible from the other (the \\'public key\\'), even though they are necessarily related. Instead, both keys are generated secretly, as an interrelated pair. The historian David Kahn described public-key cryptography as \"the most revolutionary new concept in the field since polyalphabetic substitution emerged in the Renaissance\".In public-key cryptosystems, the public key may be freely distributed, while its paired private key must remain secret. In a public-key encryption system, the public key is used for encryption, while the private or secret key is used for decryption. While Diffie and Hellman could not find such a system, they showed that public-key cryptography was indeed possible by presenting the Diffie–Hellman key exchange protocol, a solution that is now widely used in secure communications to allow two parties to secretly agree on a shared encryption key.\\nThe X.509 standard defines the most commonly used format for public key certificates.Diffie and Hellman\\'s publication sparked widespread academic efforts in finding a practical public-key encryption system. This race was finally won in 1978 by Ronald Rivest, Adi Shamir, and Len Adleman, whose solution has since become known as the RSA algorithm.The Diffie–Hellman and RSA algorithms, in addition to being the first publicly known examples of high-quality public-key algorithms, have been among the most widely used. Other asymmetric-key algorithms include the Cramer–Shoup cryptosystem, ElGamal encryption, and various elliptic curve techniques.A document published in 1997 by the Government Communications Headquarters (GCHQ), a British intelligence organization, revealed that cryptographers at GCHQ had anticipated several academic developments. Reportedly, around 1970, James H. Ellis had conceived the principles of asymmetric key cryptography. In 1973, Clifford Cocks invented a solution that was very similar in design rationale to RSA. In 1974, Malcolm J. Williamson is claimed to have developed the Diffie–Hellman key exchange.\\nPublic-key cryptography is also used for implementing digital signature schemes. A digital signature is reminiscent of an ordinary signature; they both have the characteristic of being easy for a user to produce, but difficult for anyone else to forge. Digital signatures can also be permanently tied to the content of the message being signed; they cannot then be \\'moved\\' from one document to another, for any attempt will be detectable. In digital signature schemes, there are two algorithms: one for signing, in which a secret key is used to process the message (or a hash of the message, or both), and one for verification, in which the matching public key is used with the message to check the validity of the signature. RSA and DSA are two of the most popular digital signature schemes. Digital signatures are central to the operation of public key infrastructures and many network security schemes (e.g., SSL/TLS, many VPNs, etc.).Public-key algorithms are most often based on the computational complexity of \"hard\" problems, often from number theory. For example, the hardness of RSA is related to the integer factorization problem, while Diffie–Hellman and DSA are related to the discrete logarithm problem. The security of elliptic curve cryptography is based on number theoretic problems involving elliptic curves. Because of the difficulty of the underlying problems, most public-key algorithms involve operations such as modular multiplication and exponentiation, which are much more computationally expensive than the techniques used in most block ciphers, especially with typical key sizes. As a result, public-key cryptosystems are commonly hybrid cryptosystems, in which a fast high-quality symmetric-key encryption algorithm is used for the message itself, while the relevant symmetric key is sent with the message, but encrypted using a public-key algorithm. Similarly, hybrid signature schemes are often used, in which a cryptographic hash function is computed, and only the resulting hash is digitally signed.\\n\\n\\n=== Cryptographic hash functions ===\\nCryptographic hash functions are functions that take a variable-length input and return a fixed-length output, which can be used in, for example, a digital signature. For a hash function to be secure, it must be difficult to compute two inputs that hash to the same value (collision resistance) and to compute an input that hashes to a given output (preimage resistance). MD4 is a long-used hash function that is now broken; MD5, a strengthened variant of MD4, is also widely used but broken in practice. The US National Security Agency developed the Secure Hash Algorithm series of MD5-like hash functions: SHA-0 was a flawed algorithm that the agency withdrew; SHA-1 is widely deployed and more secure than MD5, but cryptanalysts have identified attacks against it; the SHA-2 family improves on SHA-1, but is vulnerable to clashes as of 2011; and the US standards authority thought it \"prudent\" from a security perspective to develop a new standard to \"significantly improve the robustness of NIST\\'s overall hash algorithm toolkit.\" Thus, a hash function design competition was meant to select a new U.S. national standard, to be called SHA-3, by 2012. The competition ended on October 2, 2012, when the NIST announced that Keccak would be the new SHA-3 hash algorithm. Unlike block and stream ciphers that are invertible, cryptographic hash functions produce a hashed output that cannot be used to retrieve the original input data. Cryptographic hash functions are used to verify the authenticity of data retrieved from an untrusted source or to add a layer of security.\\n\\n\\n=== Cryptanalysis ===\\n\\nThe goal of cryptanalysis is to find some weakness or insecurity in a cryptographic scheme, thus permitting its subversion or evasion.\\nIt is a common misconception that every encryption method can be broken. In connection with his WWII work at Bell Labs, Claude Shannon proved that the one-time pad cipher is unbreakable, provided the key material is truly random, never reused, kept secret from all possible attackers, and of equal or greater length than the message. Most ciphers, apart from the one-time pad, can be broken with enough computational effort by brute force attack, but the amount of effort needed may be exponentially dependent on the key size, as compared to the effort needed to make use of the cipher. In such cases, effective security could be achieved if it is proven that the effort required (i.e., \"work factor\", in Shannon\\'s terms) is beyond the ability of any adversary. This means it must be shown that no efficient method (as opposed to the time-consuming brute force method) can be found to break the cipher. Since no such proof has been found to date, the one-time-pad remains the only theoretically unbreakable cipher. Although well-implemented one-time-pad encryption cannot be broken, traffic analysis is still possible.\\nThere are a wide variety of cryptanalytic attacks, and they can be classified in any of several ways. A common distinction turns on what Eve (an attacker) knows and what capabilities are available. In a ciphertext-only attack, Eve has access only to the ciphertext (good modern cryptosystems are usually effectively immune to ciphertext-only attacks). In a known-plaintext attack, Eve has access to a ciphertext and its corresponding plaintext (or to many such pairs). In a chosen-plaintext attack, Eve may choose a plaintext and learn its corresponding ciphertext (perhaps many times); an example is gardening, used by the British during WWII. In a chosen-ciphertext attack, Eve may be able to choose ciphertexts and learn their corresponding plaintexts. Finally in a man-in-the-middle attack Eve gets in between Alice (the sender) and Bob (the recipient), accesses and modifies the traffic and then forwards it to the recipient. Also important, often overwhelmingly so, are mistakes (generally in the design or use of one of the protocols involved).\\n\\nCryptanalysis of symmetric-key ciphers typically involves looking for attacks against the block ciphers or stream ciphers that are more efficient than any attack that could be against a perfect cipher. For example, a simple brute force attack against DES requires one known plaintext and 255 decryptions, trying approximately half of the possible keys, to reach a point at which chances are better than even that the key sought will have been found. But this may not be enough assurance; a linear cryptanalysis attack against DES requires 243 known plaintexts (with their corresponding ciphertexts) and approximately 243 DES operations. This is a considerable improvement over brute force attacks.\\nPublic-key algorithms are based on the computational difficulty of various problems. The most famous of these are the difficulty of integer factorization of semiprimes and the difficulty of calculating discrete logarithms, both of which are not yet proven to be solvable in polynomial time (P) using only a classical Turing-complete computer. Much public-key cryptanalysis concerns designing algorithms in P that can solve these problems, or using other technologies, such as quantum computers. For instance, the best-known algorithms for solving the elliptic curve-based version of discrete logarithm are much more time-consuming than the best-known algorithms for factoring, at least for problems of more or less equivalent size. Thus, to achieve an equivalent strength of encryption, techniques that depend upon the difficulty of factoring large composite numbers, such as the RSA cryptosystem, require larger keys than elliptic curve techniques. For this reason, public-key cryptosystems based on elliptic curves have become popular since their invention in the mid-1990s.\\nWhile pure cryptanalysis uses weaknesses in the algorithms themselves, other attacks on cryptosystems are based on actual use of the algorithms in real devices, and are called side-channel attacks. If a cryptanalyst has access to, for example, the amount of time the device took to encrypt a number of plaintexts or report an error in a password or PIN character, they may be able to use a timing attack to break a cipher that is otherwise resistant to analysis. An attacker might also study the pattern and length of messages to derive valuable information; this is known as traffic analysis and can be quite useful to an alert adversary. Poor administration of a cryptosystem, such as permitting too short keys, will make any system vulnerable, regardless of other virtues. Social engineering and other attacks against humans (e.g., bribery, extortion, blackmail, espionage, rubber-hose cryptanalysis or torture) are usually employed due to being more cost-effective and feasible to perform in a reasonable amount of time compared to pure cryptanalysis by a high margin.\\n\\n\\n=== Cryptographic primitives ===\\nMuch of the theoretical work in cryptography concerns cryptographic primitives—algorithms with basic cryptographic properties—and their relationship to other cryptographic problems. More complicated cryptographic tools are then built from these basic primitives. These primitives provide fundamental properties, which are used to develop more complex tools called cryptosystems or cryptographic protocols, which guarantee one or more high-level security properties. Note, however, that the distinction between cryptographic primitives and cryptosystems, is quite arbitrary; for example, the RSA algorithm is sometimes considered a cryptosystem, and sometimes a primitive. Typical examples of cryptographic primitives include pseudorandom functions, one-way functions, etc.\\n\\n\\n=== Cryptosystems ===\\n\\nOne or more cryptographic primitives are often used to develop a more complex algorithm, called a cryptographic system, or cryptosystem. Cryptosystems (e.g., El-Gamal encryption) are designed to provide particular functionality (e.g., public key encryption) while guaranteeing certain security properties (e.g., chosen-plaintext attack (CPA) security in the random oracle model). Cryptosystems use the properties of the underlying cryptographic primitives to support the system\\'s security properties. As the distinction between primitives and cryptosystems is somewhat arbitrary, a sophisticated cryptosystem can be derived from a combination of several more primitive cryptosystems. In many cases, the cryptosystem\\'s structure involves back and forth communication among two or more parties in space (e.g., between the sender of a secure message and its receiver) or across time (e.g., cryptographically protected backup data). Such cryptosystems are sometimes called cryptographic protocols.\\nSome widely known cryptosystems include RSA, Schnorr signature, ElGamal encryption, and Pretty Good Privacy (PGP). More complex cryptosystems include electronic cash systems, signcryption systems, etc. Some more \\'theoretical\\' cryptosystems include interactive proof systems, (like zero-knowledge proofs), systems for secret sharing, etc.\\n\\n\\n=== Lightweight cryptography ===\\nLightweight cryptography (LWC) concerns cryptographic algorithms developed for a strictly constrained environment. The growth of Internet of Things (IoT) has spiked research into the development of lightweight algorithms that are better suited for the environment. An IoT environment requires strict constraints on power consumption, processing power, and security. Algorithms such as PRESENT, AES, and SPECK are examples of the many LWC algorithms that have been developed to achieve the standard set by the National Institute of Standards and Technology.\\n\\n\\n== Applications ==\\n\\nCryptography is widely used on the internet to help protect user-data and prevent eavesdropping. To ensure secrecy during transmission, many systems use private key cryptography to protect transmitted information. With public-key systems, one can maintain secrecy without a master key or a large number of keys. But, some algorithms like Bitlocker and Veracrypt are generally not private-public key cryptography. For example, Veracrypt uses a password hash to generate the single private key. However, it can be configured to run in public-private key systems. The C++ opensource encryption library OpenSSL provides free and opensource encryption software and tools. The most commonly used encryption cipher suit is AES, as it has hardware acceleration for all x86 based processors that has AES-NI. A close contender is ChaCha20-Poly1305, which is a stream cipher, however it is commonly used for mobile devices as they are ARM based which does not feature AES-NI instruction set extension.\\n\\n\\n=== Cybersecurity ===\\nCryptography can be used to secure communications by encrypting them. Websites use encryption via HTTPS. \"End-to-end\" encryption, where only sender and receiver can read messages, is implemented for email in Pretty Good Privacy and for secure messaging in general in WhatsApp, Signal and Telegram.Operating systems use encryption to keep passwords secret, conceal parts of the system, and ensure that software updates are truly from the system maker. Instead of storing plaintext passwords, computer systems store hashes thereof; then, when a user logs in, the system passes the given password through a cryptographic hash function and compares it to the hashed value on file. In this manner, neither the system nor an attacker has at any point access to the password in plaintext.Encryption is sometimes used to encrypt one\\'s entire drive. For example, University College London has implemented BitLocker (a program by Microsoft) to render drive data opaque without users logging in.\\n\\n\\n=== Cryptocurrencies and cryptoeconomics ===\\nCryptographic techniques enable cryptocurrency technologies, such as distributed ledger technologies (e.g., blockchains), which finance cryptoeconomics applications such as decentralized finance (DeFi). Key cryptographic techniques that enable cryptocurrencies and cryptoeconomics include, but are not limited to: cryptographic keys, cryptographic hash function, asymmetric (public key) encryption, Multi-Factor Authentication (MFA), End-to-End Encryption (E2EE), and Zero Knowledge Proofs (ZKP).\\n\\n\\n== Legal issues ==\\n\\n\\n=== Prohibitions ===\\nCryptography has long been of interest to intelligence gathering and law enforcement agencies. Secret communications may be criminal or even treasonous. Because of its facilitation of privacy, and the diminution of privacy attendant on its prohibition, cryptography is also of considerable interest to civil rights supporters. Accordingly, there has been a history of controversial legal issues surrounding cryptography, especially since the advent of inexpensive computers has made widespread access to high-quality cryptography possible.\\nIn some countries, even the domestic use of cryptography is, or has been, restricted. Until 1999, France significantly restricted the use of cryptography domestically, though it has since relaxed many of these rules. In China and Iran, a license is still required to use cryptography. Many countries have tight restrictions on the use of cryptography. Among the more restrictive are laws in Belarus, Kazakhstan, Mongolia, Pakistan, Singapore, Tunisia, and Vietnam.In the United States, cryptography is legal for domestic use, but there has been much conflict over legal issues related to cryptography. One particularly important issue has been the export of cryptography and cryptographic software and hardware. Probably because of the importance of cryptanalysis in World War II and an expectation that cryptography would continue to be important for national security, many Western governments have, at some point, strictly regulated export of cryptography. After World War II, it was illegal in the US to sell or distribute encryption technology overseas; in fact, encryption was designated as auxiliary military equipment and put on the United States Munitions List. Until the development of the personal computer, asymmetric key algorithms (i.e., public key techniques), and the Internet, this was not especially problematic. However, as the Internet grew and computers became more widely available, high-quality encryption techniques became well known around the globe.\\n\\n\\n=== Export controls ===\\n\\nIn the 1990s, there were several challenges to US export regulation of cryptography. After the source code for Philip Zimmermann\\'s Pretty Good Privacy (PGP) encryption program found its way onto the Internet in June 1991, a complaint by RSA Security (then called RSA Data Security, Inc.) resulted in a lengthy criminal investigation of Zimmermann by the US Customs Service and the FBI, though no charges were ever filed. Daniel J. Bernstein, then a graduate student at UC Berkeley, brought a lawsuit against the US government challenging some aspects of the restrictions based on free speech grounds. The 1995 case Bernstein v. United States ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.In 1996, thirty-nine countries signed the Wassenaar Arrangement, an arms control treaty that deals with the export of arms and \"dual-use\" technologies such as cryptography. The treaty stipulated that the use of cryptography with short key-lengths (56-bit for symmetric encryption, 512-bit for RSA) would no longer be export-controlled. Cryptography exports from the US became less strictly regulated as a consequence of a major relaxation in 2000; there are no longer very many restrictions on key sizes in US-exported mass-market software. Since this relaxation in US export restrictions, and because most personal computers connected to the Internet include US-sourced web browsers such as Firefox or Internet Explorer, almost every Internet user worldwide has potential access to quality cryptography via their browsers (e.g., via Transport Layer Security). The Mozilla Thunderbird and Microsoft Outlook E-mail client programs similarly can transmit and receive emails via TLS, and can send and receive email encrypted with S/MIME. Many Internet users do not realize that their basic application software contains such extensive cryptosystems. These browsers and email programs are so ubiquitous that even governments whose intent is to regulate civilian use of cryptography generally do not find it practical to do much to control distribution or use of cryptography of this quality, so even when such laws are in force, actual enforcement is often effectively impossible.\\n\\n\\n=== NSA involvement ===\\n\\nAnother contentious issue connected to cryptography in the United States is the influence of the National Security Agency on cipher development and policy. The NSA was involved with the design of DES during its development at IBM and its consideration by the National Bureau of Standards as a possible Federal Standard for cryptography. DES was designed to be resistant to differential cryptanalysis, a powerful and general cryptanalytic technique known to the NSA and IBM, that became publicly known only when it was rediscovered in the late 1980s. According to Steven Levy, IBM discovered differential cryptanalysis, but kept the technique secret at the NSA\\'s request. The technique became publicly known only when Biham and Shamir re-discovered and announced it some years later. The entire affair illustrates the difficulty of determining what resources and knowledge an attacker might actually have.\\nAnother instance of the NSA\\'s involvement was the 1993 Clipper chip affair, an encryption microchip intended to be part of the Capstone cryptography-control initiative. Clipper was widely criticized by cryptographers for two reasons. The cipher algorithm (called Skipjack) was then classified (declassified in 1998, long after the Clipper initiative lapsed). The classified cipher caused concerns that the NSA had deliberately made the cipher weak in order to assist its intelligence efforts. The whole initiative was also criticized based on its violation of Kerckhoffs\\'s Principle, as the scheme included a special escrow key held by the government for use by law enforcement (i.e. wiretapping).\\n\\n\\n=== Digital rights management ===\\n\\nCryptography is central to digital rights management (DRM), a group of techniques for technologically controlling use of copyrighted material, being widely implemented and deployed at the behest of some copyright holders. In 1998, U.S. President Bill Clinton signed the Digital Millennium Copyright Act (DMCA), which criminalized all production, dissemination, and use of certain cryptanalytic techniques and technology (now known or later discovered); specifically, those that could be used to circumvent DRM technological schemes. This had a noticeable impact on the cryptography research community since an argument can be made that any cryptanalytic research violated the DMCA. Similar statutes have since been enacted in several countries and regions, including the implementation in the EU Copyright Directive. Similar restrictions are called for by treaties signed by World Intellectual Property Organization member-states.\\nThe United States Department of Justice and FBI have not enforced the DMCA as rigorously as had been feared by some, but the law, nonetheless, remains a controversial one. Niels Ferguson, a well-respected cryptography researcher, has publicly stated that he will not release some of his research into an Intel security design for fear of prosecution under the DMCA. Cryptologist Bruce Schneier has argued that the DMCA encourages vendor lock-in, while inhibiting actual measures toward cyber-security. Both Alan Cox (longtime Linux kernel developer) and Edward Felten (and some of his students at Princeton) have encountered problems related to the Act. Dmitry Sklyarov was arrested during a visit to the US from Russia, and jailed for five months pending trial for alleged violations of the DMCA arising from work he had done in Russia, where the work was legal. In 2007, the cryptographic keys responsible for Blu-ray and HD DVD content scrambling were discovered and released onto the Internet. In both cases, the Motion Picture Association of America sent out numerous DMCA takedown notices, and there was a massive Internet backlash triggered by the perceived impact of such notices on fair use and free speech.\\n\\n\\n=== Forced disclosure of encryption keys ===\\n\\nIn the United Kingdom, the Regulation of Investigatory Powers Act gives UK police the powers to force suspects to decrypt files or hand over passwords that protect encryption keys. Failure to comply is an offense in its own right, punishable on conviction by a two-year jail sentence or up to five years in cases involving national security. Successful prosecutions have occurred under the Act; the first, in 2009, resulted in a term of 13 months\\' imprisonment. Similar forced disclosure laws in Australia, Finland, France, and India compel individual suspects under investigation to hand over encryption keys or passwords during a criminal investigation.\\nIn the United States, the federal criminal case of United States v. Fricosu addressed whether a search warrant can compel a person to reveal an encryption passphrase or password. The Electronic Frontier Foundation (EFF) argued that this is a violation of the protection from self-incrimination given by the Fifth Amendment. In 2012, the court ruled that under the All Writs Act, the defendant was required to produce an unencrypted hard drive for the court.In many jurisdictions, the legal status of forced disclosure remains unclear.\\nThe 2016 FBI–Apple encryption dispute concerns the ability of courts in the United States to compel manufacturers\\' assistance in unlocking cell phones whose contents are cryptographically protected.\\nAs a potential counter-measure to forced disclosure some cryptographic software supports plausible deniability, where the encrypted data is indistinguishable from unused random data (for example such as that of a drive which has been securely wiped).\\n\\n\\n== See also ==\\nCollision attack\\nComparison of cryptography libraries\\nCrypto Wars – Attempts to limit access to strong cryptography\\nEncyclopedia of Cryptography and Security – Book by Technische Universiteit Eindhoven\\nGlobal surveillance – Mass surveillance across national borders\\nIndistinguishability obfuscation – Type of cryptographic software obfuscation\\nInformation theory – Scientific study of digital information\\nOutline of cryptography – Overview of and topical guide to cryptography\\nList of cryptographers\\nList of important publications in cryptography\\nList of multiple discoveries\\nList of unsolved problems in computer science – List of unsolved computational problems\\nSecure cryptoprocessor\\nStrong cryptography – Term applied to cryptographic systems that are highly resistant to cryptanalysis\\nSyllabical and Steganographical Table – Eighteenth-century work believed to be the first cryptography chart – first cryptography chart\\nWorld Wide Web Consortium\\'s Web Cryptography API – World Wide Web Consortium cryptography standard\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\n\\n\\n== External links ==\\n\\n The dictionary definition of cryptography at Wiktionary\\n Media related to Cryptography at Wikimedia Commons\\nCryptography on In Our Time at the BBC\\nCrypto Glossary and Dictionary of Technical Cryptography\\nA Course in Cryptography by Raphael Pass & Abhi Shelat – offered at Cornell in the form of lecture notes.\\nFor more on the use of cryptographic elements in fiction, see: Dooley, John F., William and Marilyn Ingersoll Professor of Computer Science, Knox College (23 August 2012). \"Cryptology in Fiction\". Archived from the original on 29 July 2020. Retrieved 20 February 2015.{{cite web}}:  CS1 maint: multiple names: authors list (link)\\nThe George Fabyan Collection at the Library of Congress has early editions of works of seventeenth-century English literature, publications relating to cryptography.',\n",
              " 'Human–computer interaction (HCI) is research in the design and the use of computer technology, which focuses on the interfaces between people (users) and computers. HCI researchers observe the ways humans interact with computers and design technologies that allow humans to interact with computers in novel ways. A device that allows interaction between human being and a computer is known as a \"Human-computer Interface (HCI)\".\\nAs a field of research, human–computer interaction is situated at the intersection of computer science, behavioral sciences, design, media studies, and several other fields of study. The term was popularized by Stuart K. Card, Allen Newell, and Thomas P. Moran in their 1983 book, The Psychology of Human–Computer Interaction. The first known use was in 1975 by Carlisle. The term is intended to convey that, unlike other tools with specific and limited uses, computers have many uses which often involve an open-ended dialogue between the user and the computer. The notion of dialogue likens human–computer interaction to human-to-human interaction: an analogy that is crucial to theoretical considerations in the field.\\n\\n\\n== Introduction ==\\nHumans interact with computers in many ways, and the interface between the two is crucial to facilitating this interaction. HCI is also sometimes termed human–machine interaction (HMI), man-machine interaction (MMI) or computer-human interaction (CHI). Desktop applications, internet browsers, handheld computers, and computer kiosks make use of the prevalent graphical user interfaces (GUI) of today. Voice user interfaces (VUI) are used for speech recognition and synthesizing systems, and the emerging multi-modal and Graphical user interfaces (GUI) allow humans to engage with embodied character agents in a way that cannot be achieved with other interface paradigms. The growth in human–computer interaction field has led to an increase in the quality of interaction, and resulted in many new areas of research beyond. Instead of designing regular interfaces, the different research branches focus on the concepts of multimodality over unimodality, intelligent adaptive interfaces over command/action based ones, and active interfaces over passive interfaces.The Association for Computing Machinery (ACM) defines human–computer interaction as \"a discipline that is concerned with the design, evaluation, and implementation of interactive computing systems for human use and with the study of major phenomena surrounding them\". A key aspect of HCI is user satisfaction, also referred to as End-User Computing Satisfaction. It goes on to say:\\n\"Because human–computer interaction studies a human and a machine in communication, it draws from supporting knowledge on both the machine and the human side. On the machine side, techniques in computer graphics, operating systems, programming languages, and development environments are relevant. On the human side, communication theory, graphic and industrial design disciplines, linguistics, social sciences, cognitive psychology, social psychology, and human factors such as computer user satisfaction are relevant. And, of course, engineering and design methods are relevant.\"Due to the multidisciplinary nature of HCI, people with different backgrounds contribute to its success.\\nPoorly designed human-machine interfaces can lead to many unexpected problems. A classic example is the Three Mile Island accident, a nuclear meltdown accident, where investigations concluded that the design of the human-machine interface was at least partly responsible for the disaster. Similarly, accidents in aviation have resulted from manufacturers\\' decisions to use non-standard flight instruments or throttle quadrant layouts: even though the new designs were proposed to be superior in basic human-machine interaction, pilots had already ingrained the \"standard\" layout. Thus, the conceptually good idea had unintended results.\\n\\n\\n== Human–computer interface ==\\n\\nThe human–computer interface can be described as the point of communication between the human user and the computer. The flow of information between the human and computer is defined as the loop of interaction. The loop of interaction has several aspects to it, including:\\n\\nVisual Based: The visual-based human–computer interaction is probably the most widespread human–computer interaction (HCI) research area.\\nAudio-Based: The audio-based interaction between a computer and a human is another important area of HCI systems. This area deals with information acquired by different audio signals.\\nTask environment: The conditions and goals set upon the user.\\nMachine environment: The computer\\'s environment is connected to, e.g., a laptop in a college student\\'s dorm room.\\nAreas of the interface: Non-overlapping areas involve the processes related to humans and computers themselves, while the overlapping areas only involve the processes related to their interaction.\\nInput flow: The flow of information begins in the task environment when the user has some tasks requiring using their computer.\\nOutput: The flow of information that originates in the machine environment.\\nFeedback: Loops through the interface that evaluate, moderate, and confirm processes as they pass from the human through the interface to the computer and back.\\nFit: This matches the computer design, the user, and the task to optimize the human resources needed to accomplish the task.\\nVisual- Based HCI ----\\nFacial Expression Analysis: This area focuses on visually recognizing and analyzing emotions through facial expressions.\\nBody Movement Tracking (Large-scale): Researchers in this area concentrate on tracking and analyzing large-scale body movements.\\nGesture Recognition: Gesture recognition involves identifying and interpreting gestures made by users, often used for direct interaction with computers in command and action scenarios.\\nGaze Detection (Eyes Movement Tracking): Gaze detection involves tracking the movement of a user\\'s eyes and is primarily used to better understand the user\\'s attention, intent, or focus in context-sensitive situations.  While the specific goals of each area vary based on applications, they collectively contribute to enhancing human-computer interaction. Notably, visual approaches have been explored as alternatives or aids to other types of interactions, such as audio- and sensor-based methods. For example, lip reading or lip movement tracking has proven influential in correcting speech recognition errors.\\nAudio - Based HCI ----Audio-based interaction in human-computer interaction (HCI) is a crucial field focused on processing information acquired through various audio signals. While the nature of audio signals may be less diverse compared to visual signals, the information they provide can be highly reliable, valuable, and sometimes uniquely informative. The research areas within this domain include:\\nSpeech Recognition: This area centers on the recognition and interpretation of spoken language.\\nSpeaker Recognition: Researchers in this area concentrate on identifying and distinguishing different speakers.\\nAuditory Emotion Analysis: Efforts have been made to incorporate human emotions into intelligent human-computer interaction by analyzing emotional cues in audio signals.\\nHuman-Made Noise/Sign Detections: This involves recognizing typical human auditory signs like sighs, gasps, laughs, cries, etc., which contribute to emotion analysis and the design of more intelligent HCI systems.\\nMusical Interaction: A relatively new area in HCI, it involves generating and interacting with music, with applications in the art industry. This field is studied in both audio- and visual-based HCI systems.\\nSensor-Based HCI ----This section encompasses a diverse range of areas with broad applications, all of which involve the use of physical sensors to facilitate interaction between users and machines. These sensors can range from basic to highly sophisticated. The specific areas include:\\nPen-Based Interaction: Particularly relevant in mobile devices, focusing on pen gestures and handwriting recognition.\\nMouse & Keyboard: Well-established input devices discussed in Section 3.1, commonly used in computing.\\nJoysticks: Another established input device for interactive control, commonly used in gaming and simulations.\\nMotion Tracking Sensors and Digitizers: Cutting-edge technology that has revolutionized industries like film, animation, art, and gaming. These sensors, in forms like wearable cloth or joint sensors, enable more immersive interactions between computers and reality.\\nHaptic Sensors: Particularly significant in applications related to robotics and virtual reality, providing feedback based on touch. They play a crucial role in enhancing sensitivity and awareness in humanoid robots, as well as in medical surgery applications.\\nPressure Sensors: Also important in robotics, virtual reality, and medical applications, providing information based on pressure exerted on a surface.\\nTaste/Smell Sensors: Although less popular compared to other areas, research has been conducted in the field of sensors for taste and smell.  These sensors vary in their level of maturity, with some being well-established and others representing cutting-edge technologies.\\n\\n\\n== Goals for computers ==\\nHuman–computer interaction studies the ways in which humans make—or do not make—use of computational artifacts, systems, and infrastructures. Much of the research in this field seeks to improve the human–computer interaction by improving the usability of computer interfaces. How usability is to be precisely understood, how it relates to other social and cultural values, and when it is, and when it may not be a desirable property of computer interfaces is increasingly debated.Much of the research in the field of human–computer interaction takes an interest in:\\n\\nMethods for designing new computer interfaces, thereby optimizing a design for a desired property such as learnability, findability, the efficiency of use.\\nMethods for implementing interfaces, e.g., by means of software libraries.\\nMethods for evaluating and comparing interfaces with respect to their usability and other desirable properties.\\nMethods for studying human–computer use and its sociocultural implications more broadly.\\nMethods for determining whether or not the user is human or computer.\\nModels and theories of human–computer use as well as conceptual frameworks for the design of computer interfaces, such as cognitivist user models, Activity Theory, or ethnomethodological accounts of human–computer use.\\nPerspectives that critically reflect upon the values that underlie computational design, computer use, and HCI research practice.Visions of what researchers in the field seek to achieve might vary. When pursuing a cognitivist perspective, researchers of HCI may seek to align computer interfaces with the mental model that humans have of their activities. When pursuing a post-cognitivist perspective, researchers of HCI may seek to align computer interfaces with existing social practices or existing sociocultural values.\\nResearchers in HCI are interested in developing design methodologies, experimenting with devices, prototyping software, and hardware systems, exploring interaction paradigms, and developing models and theories of interaction.\\n\\n\\n== Design ==\\n\\n\\n=== Principles ===\\nThe following experimental design principles are considered, when evaluating a current user interface, or designing a new user interface:\\n\\nEarly focus is placed on the user(s) and task(s): How many users are needed to perform the task(s) is established and who the appropriate users should be is determined (someone who has never used the interface, and will not use the interface in the future, is most likely not a valid user). In addition, the task(s) the users will be performing and how often the task(s) need to be performed is defined.\\nEmpirical measurement: the interface is tested with real users who come in contact with the interface daily. The results can vary with the performance level of the user and the typical human–computer interaction may not always be represented. Quantitative usability specifics, such as the number of users performing the task(s), the time to complete the task(s), and the number of errors made during the task(s) are determined.\\nIterative design: After determining what users, tasks, and empirical measurements to include, the following iterative design steps are performed:\\nDesign the user interface\\nTest\\nAnalyze results\\nRepeatThe iterative design process is repeated until a sensible, user-friendly interface is created.\\n\\n\\n=== Methodologies ===\\nVarious strategies delineating methods for human–PC interaction design have developed since the conception of the field during the 1980s. Most plan philosophies come from a model for how clients, originators, and specialized frameworks interface. Early techniques treated clients\\' psychological procedures as unsurprising and quantifiable and urged plan specialists to look at subjective science to establish zones, (for example, memory and consideration) when structuring UIs. Present-day models, in general, center around a steady input and discussion between clients, creators, and specialists and push for specialized frameworks to be folded with the sorts of encounters clients need to have, as opposed to wrapping user experience around a finished framework.\\n\\nActivity theory: utilized in HCI to characterize and consider the setting where human cooperations with PCs occur. Action hypothesis gives a structure for reasoning about activities in these specific circumstances and illuminates the design of interactions from an action-driven perspective.\\nUser-centered design (UCD): a cutting-edge, broadly-rehearsed plan theory established on the possibility that clients must become the overwhelming focus in the plan of any PC framework. Clients, architects, and specialized experts cooperate to determine the requirements and restrictions of the client and make a framework to support these components. Frequently, client-focused plans are informed by ethnographic investigations of situations in which clients will associate with the framework. This training is like participatory design, which underscores the likelihood for end-clients to contribute effectively through shared plan sessions and workshops.\\nPrinciples of UI design: these standards may be considered during the design of a client interface: resistance, effortlessness, permeability, affordance, consistency, structure, and feedback.\\nValue sensitive design (VSD): a technique for building innovation that accounts for the individuals who utilize the design straightforwardly, and just as well for those who the design influences, either directly or indirectly. VSD utilizes an iterative planning process that includes three kinds of examinations: theoretical, exact, and specialized. Applied examinations target the understanding and articulation of the different parts of the design, and its qualities or any clashes that may emerge for the users of the design. Exact examinations are subjective or quantitative plans to explore things used to advise the creators\\' understanding regarding the clients\\' qualities, needs, and practices. Specialized examinations can include either investigation of how individuals use related advances or the framework plans.\\n\\n\\n== Display designs ==\\nDisplays are human-made artifacts designed to support the perception of relevant system variables and facilitate further processing of that information. Before a display is designed, the task that the display is intended to support must be defined (e.g., navigating, controlling, decision making, learning, entertaining, etc.). A user or operator must be able to process whatever information a system generates and displays; therefore, the information must be displayed according to principles to support perception, situation awareness, and understanding.\\n\\n\\n=== Thirteen principles of display design ===\\nChristopher Wickens et al. defined 13 principles of display design in their book An Introduction to Human Factors Engineering.These human perception and information processing principles can be utilized to create an effective display design. A reduction in errors, a reduction in required training time, an increase in efficiency, and an increase in user satisfaction are a few of the many potential benefits that can be achieved by utilizing these principles.\\nCertain principles may not apply to different displays or situations. Some principles may also appear to be conflicting, and there is no simple solution to say that one principle is more important than another. The principles may be tailored to a specific design or situation. Striking a functional balance among the principles is critical for an effective design.\\n\\n\\n==== Perceptual principles ====\\n1.\\tMake displays legible (or audible). A display\\'s legibility is critical and necessary for designing a usable display. If the characters or objects being displayed cannot be discernible, the operator cannot effectively use them.\\n2.\\tAvoid absolute judgment limits. Do not ask the user to determine the level of a variable based on a single sensory variable (e.g., color, size, loudness). These sensory variables can contain many possible levels.\\n3.\\tTop-down processing. Signals are likely perceived and interpreted by what is expected based on a user\\'s experience. If a signal is presented contrary to the user\\'s expectation, more physical evidence of that signal may need to be presented to assure that it is understood correctly.\\n4.\\tRedundancy gain. If a signal is presented more than once, it is more likely to be understood correctly. This can be done by presenting the signal in alternative physical forms (e.g., color and shape, voice and print, etc.), as redundancy does not imply repetition. A traffic light is a good example of redundancy, as color and position are redundant.\\n5.\\tSimilarity causes confusion: Use distinguishable elements. Signals that appear to be similar will likely be confused. The ratio of similar features to different features causes signals to be similar. For example, A423B9 is more similar to A423B8 than 92 is to 93. Unnecessarily similar features should be removed, and dissimilar features should be highlighted.\\n\\n\\n==== Mental model principles ====\\n6.\\tPrinciple of pictorial realism. A display should look like the variable that it represents (e.g., the high temperature on a thermometer shown as a higher vertical level). If there are multiple elements, they can be configured in a manner that looks like they would in the represented environment.\\n7.\\tPrinciple of the moving part. Moving elements should move in a pattern and direction compatible with the user\\'s mental model of how it actually moves in the system. For example, the moving element on an altimeter should move upward with increasing altitude.\\n\\n\\n==== Principles based on attention ====\\n8.\\tMinimizing information access cost or interaction cost. When the user\\'s attention is diverted from one location to another to access necessary information, there is an associated cost in time or effort. A display design should minimize this cost by allowing frequently accessed sources to be located at the nearest possible position. However, adequate legibility should not be sacrificed to reduce this cost.\\n9.\\tProximity compatibility principle. Divided attention between two information sources may be necessary for the completion of one task. These sources must be mentally integrated and are defined to have close mental proximity. Information access costs should be low, which can be achieved in many ways (e.g., proximity, linkage by common colors, patterns, shapes, etc.). However, close display proximity can be harmful by causing too much clutter.\\n10.\\tPrinciple of multiple resources. A user can more easily process information across different resources. For example, visual and auditory information can be presented simultaneously rather than presenting all visual or all auditory information.\\n\\n\\n==== Memory principles ====\\n11.\\tReplace memory with visual information: knowledge in the world. A user should not need to retain important information solely in working memory or retrieve it from long-term memory. A menu, checklist, or another display can aid the user by easing the use of their memory. However, memory use may sometimes benefit the user by eliminating the need to reference some knowledge globally (e.g., an expert computer operator would rather use direct commands from memory than refer to a manual). The use of knowledge in a user\\'s head and knowledge in the world must be balanced for an effective design.\\n12.\\tPrinciple of predictive aiding. Proactive actions are usually more effective than reactive actions. A display should eliminate resource-demanding cognitive tasks and replace them with simpler perceptual tasks to reduce the user\\'s mental resources. This will allow the user to focus on current conditions and to consider possible future conditions. An example of a predictive aid is a road sign displaying the distance to a certain destination.\\n13.\\tPrinciple of consistency. Old habits from other displays will easily transfer to support the processing of new displays if they are designed consistently. A user\\'s long-term memory will trigger actions that are expected to be appropriate. A design must accept this fact and utilize consistency among different displays.\\n\\n\\n== Current research ==\\nTopics in human–computer interaction include the following:\\n\\n\\n=== Social computing ===\\n\\nSocial computing is an interactive and collaborative behavior considered between technology and people. In recent years, there has been an explosion of social science research focusing on interactions as the unit of analysis, as there are a lot of social computing technologies that include blogs, emails,  social networking, quick messaging, and various others. Much of this research draws from psychology, social psychology, and sociology. For example, one study found out that people expected a computer with a man\\'s name to cost more than a machine with a woman\\'s name. Other research finds that individuals perceive their interactions with computers more negatively than humans, despite behaving the same way towards these machines.\\n\\n\\n=== Knowledge-driven human–computer interaction ===\\nIn human and computer interactions, a semantic gap usually exists between human and computer\\'s understandings towards mutual behaviors. Ontology, as a formal representation of domain-specific knowledge, can be used to address this problem by solving the semantic ambiguities between the two parties.\\n\\n\\n=== Emotions and human–computer interaction ===\\n\\nIn the interaction of humans and computers, research has studied how computers can detect, process, and react to human emotions to develop emotionally intelligent information systems. Researchers have suggested several \\'affect-detection channels\\'. The potential of telling human emotions in an automated and digital fashion lies in improvements to the effectiveness of human–computer interaction. The influence of emotions in human–computer interaction has been studied in fields such as financial decision-making using ECG and organizational knowledge sharing using eye-tracking and face readers as affect-detection channels. In these fields, it has been shown that affect-detection channels have the potential to detect human emotions and those information systems can incorporate the data obtained from affect-detection channels to improve decision models.\\n\\n\\n=== Brain–computer interfaces ===\\n\\nA brain–computer interface (BCI), is a direct communication pathway between an enhanced or wired brain and an external device. BCI differs from neuromodulation in that it allows for bidirectional information flow. BCIs are often directed at researching, mapping, assisting, augmenting, or repairing human cognitive or sensory-motor functions.\\n\\n\\n=== Security interactions ===\\nSecurity interactions are the study of interaction between humans and computers specifically as it pertains to information security.  Its aim, in plain terms, is to improve the usability of security features in end user applications.\\nUnlike HCI, which has roots in the early days of Xerox PARC during the 1970s, HCISec is a nascent field of study by comparison. Interest in this topic tracks with that of Internet security, which has become an area of broad public concern only in very recent years.\\nWhen security features exhibit poor usability, the following are common reasons:\\n\\nthey were added in casual afterthought\\nthey were hastily patched in to address newly discovered security bugs\\nthey address very complex use cases without the benefit of a software wizard\\ntheir interface designers lacked understanding of related security concepts\\ntheir interface designers were not usability experts (often meaning they were the application developers themselves)\\n\\n\\n== Factors of change ==\\nTraditionally, computer use was modeled as a human–computer dyad in which the two were connected by a narrow explicit communication channel, such as text-based terminals. Much work has been done to make the interaction between a computing system and a human more reflective of the multidimensional nature of everyday communication. Because of potential issues, human–computer interaction shifted focus beyond the interface to respond to observations as articulated by D. Engelbart: \"If ease of use were the only valid criterion, people would stick to tricycles and never try bicycles.\"How humans interact with computers continues to evolve rapidly. Human–computer interaction is affected by developments in computing. These forces include:\\n\\nDecreasing hardware costs leading to larger memory and faster systems\\nMiniaturization of hardware leading to portability\\nReduction in power requirements leading to portability\\nNew display technologies leading to the packaging of computational devices in new forms\\nSpecialized hardware leading to new functions\\nIncreased development of network communication and distributed computing\\nIncreasingly widespread use of computers, especially by people who are outside of the computing profession\\nIncreasing innovation in input techniques (e.g., voice, gesture, pen), combined with lowering cost, leading to rapid computerization by people formerly left out of the computer revolution.\\nWider social concerns leading to improved access to computers by currently disadvantaged groupsAs of 2010 the future for HCI is expected to include the following characteristics:\\n\\nUbiquitous computing and communication. Computers are expected to communicate through high-speed local networks, nationally over wide-area networks, and portably via infrared, ultrasonic, cellular, and other technologies. Data and computational services will be portably accessible from many if not most locations to which a user travels.\\nhigh-functionality systems. Systems can have large numbers of functions associated with them. There are so many systems that most users, technical or non-technical, do not have time to learn about traditionally (e.g., through thick user manuals).\\nThe mass availability of computer graphics. Computer graphics capabilities such as image processing, graphics transformations, rendering, and interactive animation become widespread as inexpensive chips become available for inclusion in general workstations and mobile devices.\\nMixed media. Commercial systems can handle images, voice, sounds, video, text, formatted data. These are exchangeable over communication links among users. The separate consumer electronics fields (e.g., stereo sets, DVD players, televisions) and computers are beginning to merge. Computer and print fields are expected to cross-assimilate.\\nHigh-bandwidth interaction. The rate at which humans and machines interact is expected to increase substantially due to the changes in speed, computer graphics, new media, and new input/output devices. This can lead to qualitatively different interfaces, such as virtual reality or computational video.\\nLarge and thin displays. New display technologies are maturing, enabling huge displays and displays that are thin, lightweight, and low in power use. This has large effects on portability and will likely enable developing paper-like, pen-based computer interaction systems very different in feel from present desktop workstations.\\nInformation utilities. Public information utilities (such as home banking and shopping) and specialized industry services (e.g., weather for pilots) are expected to proliferate. The proliferation rate can accelerate with the introduction of high-bandwidth interaction and the improvement in the quality of interfaces.\\n\\n\\n== Scientific conferences ==\\nOne of the main conferences for new research in human–computer interaction is the annually held Association for Computing Machinery\\'s (ACM) Conference on Human Factors in Computing Systems, usually referred to by its short name CHI (pronounced kai, or Khai). CHI is organized by ACM Special Interest Group on Computer-Human Interaction (SIGCHI). CHI is a large conference, with thousands of attendants, and is quite broad in scope. It is attended by academics, practitioners, and industry people, with company sponsors such as Google, Microsoft, and PayPal.\\nThere are also dozens of other smaller, regional, or specialized HCI-related conferences held around the world each year, including:\\n\\n\\n== See also ==\\nCAPTCHA\\nDigital Live Art\\nFeminist HCI\\nHCI Bibliography, a web-based project to provide a bibliography of Human Computer Interaction literature\\nInformation architecture\\nInformation design\\nMindfulness and technology\\nOutline of human–computer interaction\\nTuring test\\nUser experience design\\n Human–computer interaction portal\\n\\n\\n== Footnotes ==\\n\\n\\n== Further reading ==\\nAcademic overviews of the fieldJulie A. Jacko (Ed.). (2012). Human–Computer Interaction Handbook (3rd Edition). CRC Press. ISBN 1-4398-2943-8\\nAndrew Sears and Julie A. Jacko (Eds.). (2007). Human–Computer Interaction Handbook (2nd Edition). CRC Press. ISBN 0-8058-5870-9\\nJulie A. Jacko and Andrew Sears (Eds.). (2003). Human–Computer Interaction Handbook. Mahwah: Lawrence Erlbaum & Associates. ISBN 0-8058-4468-6\\nDix, A. (2004). Human–computer interaction (3rd ed.). Pearson Education. ISBN 0-1304-6109-1Historically important classicStuart K. Card, Thomas P. Moran, Allen Newell (1983): The Psychology of Human–Computer Interaction. Erlbaum, Hillsdale 1983 ISBN 0-89859-243-7Overviews of history of the fieldJonathan Grudin: A moving target: The evolution of human–computer interaction. In Andrew Sears and Julie A. Jacko (Eds.). (2007). Human–Computer Interaction Handbook (2nd Edition). CRC Press. ISBN 0-8058-5870-9\\nMyers, Brad (1998). \"A brief history of human–computer interaction technology\". Interactions. 5 (2): 44–54. CiteSeerX 10.1.1.23.2422. doi:10.1145/274430.274436. S2CID 8278771.\\nJohn M. Carroll: Human–Computer Interaction: History and Status. Encyclopedia Entry at Interaction-Design.org\\nCarroll, John M. (2010). \"Conceptualizing a possible discipline of human–computer interaction\". Interacting with Computers. 22 (1): 3–12. doi:10.1016/j.intcom.2009.11.008.\\nSara Candeias, S. and A. Veiga The dialogue between man and machine: the role of language theory and technology, Sandra M. Aluísio & Stella E. O. Tagnin, New Language Technologies, and Linguistic Research, A Two-Way Road: cap. 11. Cambridge Scholars Publishing. (ISBN 978-1-4438-5377-4)\\nSocial science and HCINass, Clifford; Fogg, B. J.; Moon, Youngme (1996). \"Can computers be teammates?\". International Journal of Human-Computer Studies. 45 (6): 669–678. doi:10.1006/ijhc.1996.0073.\\nNass, Clifford; Moon, Youngme (2000). \"Machines and mindlessness: Social responses to computers\". Journal of Social Issues. 56 (1): 81–103. doi:10.1111/0022-4537.00153. S2CID 15851410.\\nPosard, Marek N (2014). \"Status processes in human–computer interactions: Does gender matter?\". Computers in Human Behavior. 37: 189–195. doi:10.1016/j.chb.2014.04.025.\\nPosard, Marek N.; Rinderknecht, R. Gordon (2015). \"Do people like working with computers more than human beings?\". Computers in Human Behavior. 51: 232–238. doi:10.1016/j.chb.2015.04.057.Academic journalsACM Transactions on Computer-Human Interaction\\nBehaviour & Information Technology [1]\\nInteracting with Computers\\nInternational Journal of Human-Computer Interaction\\nInternational Journal of Human-Computer Studies\\nHuman–Computer Interaction [2] [3]Collection of papersRonald M. Baecker, Jonathan Grudin, William A. S. Buxton, Saul Greenberg (Eds.) (1995): Readings in human–computer interaction. Toward the Year 2000. 2. ed. Morgan Kaufmann, San Francisco 1995 ISBN 1-55860-246-1\\nMithun Ahamed, Developing a Message Interface Architecture for Android Operating Systems, (2015). [4]Treatments by one or few authors, often aimed at a more general audienceJakob Nielsen: Usability Engineering. Academic Press, Boston 1993 ISBN 0-12-518405-0\\nDonald A. Norman: The Psychology of Everyday Things. Basic Books, New York 1988 ISBN 0-465-06709-3\\nJef Raskin: The Humane Interface. New directions for designing interactive systems. Addison-Wesley, Boston 2000 ISBN 0-201-37937-6\\nBruce Tognazzini: Tog on Interface. Addison-Wesley, Reading 1991 ISBN 0-201-60842-1TextbooksAlan Dix, Janet Finlay, Gregory Abowd, and Russell Beale (2003): Human–Computer Interaction. 3rd Edition. Prentice Hall, 2003. http://hcibook.com/e3/ ISBN 0-13-046109-1\\nYvonne Rogers, Helen Sharp & Jenny Preece: Interaction Design: Beyond Human–Computer Interaction, 3rd ed. John Wiley & Sons Ltd., 2011 ISBN 0-470-66576-9\\nHelen Sharp, Yvonne Rogers & Jenny Preece: Interaction Design: Beyond Human–Computer Interaction, 2nd ed. John Wiley & Sons Ltd., 2007 ISBN 0-470-01866-6\\nMatt Jones (interaction designer) and Gary Marsden (2006). Mobile Interaction Design, John Wiley and Sons Ltd.\\n\\n\\n== External links ==\\n\\nBad Human Factors Designs\\nThe HCI Wiki Bibliography with over 100,000 publications.\\nThe HCI Bibliography Over 100,000 publications about HCI.\\nHuman-Centered Computing Education Digital Library\\nHCI Webliography',\n",
              " 'Software engineering is an engineering-based approach to software development.\\nA software engineer is a person who applies the engineering design process to design, develop, test, maintain, and evaluate computer software. The term programmer is sometimes used as a synonym, but may emphasize software implementation over design and can also lack connotations of engineering education or skills.Engineering techniques are used to inform the software development process, which involves the definition, implementation, assessment, measurement, management, change, and improvement of the software life cycle process itself. It heavily uses software configuration management, which is about systematically controlling changes to the configuration, and maintaining the integrity and traceability of the configuration and code throughout the system life cycle. Modern processes use software versioning.\\n\\n\\n== History ==\\n\\nBeginning in the 1960s, software engineering was seen as its own type of engineering. Additionally, the development of software engineering was seen as a struggle. It was difficult to keep up with the hardware which caused many problems for software engineers. Problems included software that was over budget, exceeded deadlines, required extensive debugging and maintenance, and unsuccessfully met the needs of consumers or was never even completed. In 1968 NATO held the first Software Engineering conference where issues related to software were addressed: guidelines and best practices for the development of software were established.The origins of the term software engineering have been attributed to various sources. The term  appeared in a list of services offered by companies in the June 1965 issue of \"Computers and Automation\" and was used more formally in the August 1966 issue of Communications of the ACM (Volume 9, number 8) \"letter to the ACM membership\" by the ACM President Anthony A. Oettinger. It is also associated with the title of a NATO conference in 1968 by Professor Friedrich L. Bauer. Margaret Hamilton described the discipline of \"software engineering\" during the Apollo missions to give what they were doing legitimacy.  At the time there was perceived to be a \"software crisis\". The 40th International Conference on Software Engineering (ICSE 2018) celebrates 50 years of \"Software Engineering\" with the Plenary Sessions\\' keynotes of Frederick Brooks and Margaret Hamilton.In 1984, the Software Engineering Institute (SEI) was established as a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania, United States. Watts Humphrey founded the SEI Software Process Program, aimed at understanding and managing the software engineering process.  The Process Maturity Levels introduced would become the Capability Maturity Model Integration for Development(CMMI-DEV), which has defined how the US Government evaluates the abilities of a software development team.\\nModern, generally accepted best-practices for software engineering have been collected by the ISO/IEC JTC 1/SC 7 subcommittee and published as the Software Engineering Body of Knowledge (SWEBOK). Software engineering is considered one of the major computing disciplines.\\n\\n\\n== Definitions and terminology ==\\nNotable definitions of software engineering include:\\n\\n\"The systematic application of scientific and technological knowledge, methods, and experience to the design, implementation, testing, and documentation of software\"—The Bureau of Labor Statistics—IEEE Systems and software engineering – Vocabulary\\n\"The application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software\"—IEEE Standard Glossary of Software Engineering Terminology\\n\"an engineering discipline that is concerned with all aspects of software production\"—Ian Sommerville\\n\"the establishment and use of sound engineering principles in order to economically obtain software that is reliable and works efficiently on real machines\"—Fritz Bauer\\n\"a branch of computer science that deals with the design, implementation, and maintenance of complex computer programs\"—Merriam-Webster\\n\"\\'software engineering\\' encompasses not just the act of writing code, but all of the tools and processes an organization uses to build and maintain that code over time. [...] Software engineering can be thought of as \\'programming integrated over time.\\'\"—Software Engineering at GoogleThe term has also been used less formally:\\n\\nas the informal contemporary term for the broad range of activities that were formerly called computer programming and systems analysis;\\nas the broad term for all aspects of the practice of computer programming, as opposed to the theory of computer programming, which is formally studied as a sub-discipline of computer science;\\nas the term embodying the advocacy of a specific approach to computer programming, one that urges that it be treated as an engineering discipline rather than an art or a craft, and advocates the codification of recommended practices.\\n\\n\\n=== Etymology of \"software engineer\" ===\\nMargaret Hamilton promoted the term \"software engineering\" during her work on the Apollo program. The term \"engineering\" was used to acknowledge that the work should be taken just as seriously as other contributions toward the advancement of technology. Hamilton details her use of the term:When I first came up with the term, no one had heard of it before, at least in our world. It was an ongoing joke for a long time. They liked to kid me about my radical ideas. It was a memorable day when one of the most respected hardware gurus explained to everyone in a meeting that he agreed with me that the process of building software should also be considered an engineering discipline, just like with hardware. Not because of his acceptance of the new \"term\" per se, but because we had earned his and the acceptance of the others in the room as being in an engineering field in its own right.\\n\\n\\n=== Suitability of the term ===\\nIndividual commentators have disagreed sharply on how to define software engineering or its legitimacy as an engineering discipline. David Parnas has said that software engineering is, in fact, a form of engineering. Steve McConnell has said that it is not, but that it should be. Donald Knuth has said that programming is an art and a science. Edsger W. Dijkstra claimed that the terms software engineering and software engineer have been misused  and should be considered harmful, particularly in the United States.\\n\\n\\n== Tasks in large scale projects ==\\n\\n\\n=== Software requirements ===\\n\\nRequirements engineering is about the elicitation, analysis, specification, and validation of requirements for software. Software requirements can be of three different types. There are functional requirements, non-functional requirements, and domain requirements. The operation of the software should be performed and the proper output should be expected for the user to use. Non-functional requirements deal with issues like portability, security, maintainability, reliability, scalability, performance, reusability, and flexibility. They are classified into the following types: interface constraints, performance constraints (such as response time, security, storage space, etc.), operating constraints, life cycle constraints (maintainability, portability, etc.), and economic constraints. Knowledge of how the system or software works is needed when it comes to specifying non-functional requirements. Domain requirements have to do with the characteristic of a certain category or domain of projects.\\n\\n\\n=== Software design ===\\n\\nSoftware design is about the process of defining the architecture, components, interfaces, and other characteristics of a system or component. This is also called software architecture. Software design is divided into three different levels of design. The three levels are interface design, architectural design, and detailed design. Interface design is the interaction between a system and its environment. This happens at a high level of abstraction along with the inner workings of the system. Architectural design has to do with the major components of a system and their responsibilities, properties, interfaces, and their relationships and interactions that occur between them. Detailed design is the internal elements of all the major system components, their properties, relationships, processing, and usually their algorithms and the data structures.\\n\\n\\n=== Software construction ===\\n\\nSoftware construction, the main activity of software development, is the combination of programming, unit testing, integration testing, and debugging so as to implement the design. Testing during this phase is generally performed by the programmer while the software is under construction, to verify what was just written and decide when the code is ready to be sent to the next step.\\n\\n\\n=== Software testing ===\\n\\nSoftware testing is an empirical, technical investigation conducted to provide stakeholders with information about the quality of the product or service under test, with different approaches such as unit testing and integration testing. It is one aspect of software quality. As a separate phase in software development, it is typically performed by quality assurance staff or a developer other than the one who wrote the code.\\n\\n\\n=== Software analysis ===\\n\\nSoftware analysis is the process of analyzing the behavior of computer programs regarding a property such as performance, robustness, and security It can be performed without executing the program (static program analysis), during runtime (dynamic program analysis) or in a combination of both.\\n\\n\\n=== Software maintenance ===\\n\\nSoftware maintenance refers to the activities required to provide cost-effective support after shipping the software product. Software maintenance is modifying and updating software applications after distribution to correct faults and to improve its performance. Software has a lot to do with the real world and when the real world changes, software maintenance is required. Software maintenance includes: error correction, optimization, deletion of unused and discarded features, and enhancement of features that already exist. Usually, maintenance takes up about 40% to 80% of the project cost therefore, focusing on maintenance keeps the costs down.\\n\\n\\n== Education ==\\nKnowledge of computer programming is a prerequisite for becoming a software engineer. In 2004 the IEEE Computer Society produced the SWEBOK, which has been published as ISO/IEC Technical Report 1979:2005, describing the body of knowledge that they recommend to be mastered by a graduate software engineer with four years of experience.\\nMany software engineers enter the profession by obtaining a university degree or training at a vocational school. One standard international curriculum for undergraduate software engineering degrees was defined by the Joint Task Force on Computing Curricula of the IEEE Computer Society and the Association for Computing Machinery, and updated in 2014. A number of universities have Software Engineering degree programs; as of 2010, there were 244 Campus Bachelor of Software Engineering programs, 70 Online programs, 230 Masters-level programs, 41 Doctorate-level programs, and 69 Certificate-level programs in the United States.\\nIn addition to university education, many companies sponsor internships for students wishing to pursue careers in information technology. These internships can introduce the student to interesting real-world tasks that typical software engineers encounter every day. Similar experience can be gained through military service in software engineering.\\n\\n\\n=== Software engineering degree programs ===\\nHalf of all practitioners today have degrees in computer science, information systems, or information technology. A small, but growing, number of practitioners have software engineering degrees. In 1987, the Department of Computing at Imperial College London introduced the first three-year software engineering Bachelor\\'s degree in the UK and the world; in the following year, the University of Sheffield established a similar program.  In 1996, the Rochester Institute of Technology established the first software engineering bachelor\\'s degree program in the United States, however, it did not obtain ABET accreditation until 2003, the same time as Rice University, Clarkson University, Milwaukee School of Engineering and Mississippi State University obtained theirs. In 1997, PSG College of Technology in Coimbatore, India was the first to start a five-year integrated Master of Science degree in Software Engineering.Since then, software engineering undergraduate degrees have been established at many universities. A standard international curriculum for undergraduate software engineering degrees, SE2004, was defined by a steering committee between 2001 and 2004 with funding from the Association for Computing Machinery and the IEEE Computer Society. As of 2004, in the U.S., about 50 universities offer software engineering degrees, which teach both computer science and engineering principles and practices. The first software engineering Master\\'s degree was established at Seattle University in 1979. Since then graduate software engineering degrees have been made available from many more universities.  Likewise in Canada, the Canadian Engineering Accreditation Board (CEAB) of the Canadian Council of Professional Engineers has recognized several software engineering programs.\\nIn 1998, the US Naval Postgraduate School (NPS) established the first doctorate program in Software Engineering in the world. Additionally, many online advanced degrees in Software Engineering have appeared such as the Master of Science in Software Engineering (MSE) degree offered through the Computer Science and Engineering Department at California State University, Fullerton. Steve McConnell opines that because most universities teach computer science rather than software engineering, there is a shortage of true software engineers. ETS (École de technologie supérieure) University and UQAM (Université du Québec à Montréal) were mandated by IEEE to develop the Software Engineering Body of Knowledge (SWEBOK), which has become an ISO standard describing the body of knowledge covered by a software engineer.\\n\\n\\n== Profession ==\\n\\nLegal requirements for the licensing or certification of professional software engineers vary around the world. In the UK, there is no licensing or legal requirement to assume or use the job title Software Engineer.  In some areas of Canada, such as Alberta, British Columbia, Ontario, and Quebec, software engineers can hold the Professional Engineer (P.Eng) designation and/or the Information Systems Professional (I.S.P.) designation. In Europe, Software Engineers can obtain the European Engineer (EUR ING) professional title. Software Engineers can also become professionally qualified as a Chartered Engineer through the British Computer Society.\\nIn the United States, the NCEES began offering a Professional Engineer exam for Software Engineering in 2013, thereby allowing Software Engineers to be licensed and recognized. NCEES ended the exam after April 2019 due to lack of participation. Mandatory licensing is currently still largely debated, and perceived as controversial.The IEEE Computer Society and the ACM, the two main US-based professional organizations of software engineering, publish guides to the profession of software engineering. The IEEE\\'s Guide to the Software Engineering Body of Knowledge – 2004 Version, or SWEBOK, defines the field and describes the knowledge the IEEE expects a practicing software engineer to have. The most current SWEBOK v3 is an updated version and was released in 2014. The IEEE also promulgates a \"Software Engineering Code of Ethics\".\\n\\n\\n=== Employment ===\\n\\nThere are an estimated 26.9 million professional software engineers in the world as of 2022, up from 21 million in 2016.Many software engineers work as employees or contractors. Software engineers work with businesses, government agencies (civilian or military), and non-profit organizations. Some software engineers work for themselves as freelancers. Some organizations have specialists to perform each of the tasks in the software development process. Other organizations require software engineers to do many or all of them. In large projects, people may specialize in only one role. In small projects, people may fill several or all roles at the same time. Many companies hire interns, often university or college students during a summer break, or externships. Specializations include analysts, architects, developers, testers, technical support, middleware analysts, project managers, software product managers, educators, and researchers.\\nMost software engineers and programmers work 40 hours a week, but about 15 percent of software engineers and 11 percent of programmers worked more than 50 hours a week in 2008. Potential injuries in these occupations are possible because like other workers who spend long periods sitting in front of a computer terminal typing at a keyboard, engineers and programmers are susceptible to eyestrain, back discomfort, and hand and wrist problems such as carpal tunnel syndrome.\\n\\n\\n==== United States ====\\nThe U. S. Bureau of Labor Statistics (BLS) counted 1,365,500 software developers holding jobs in the U.S. in 2018. Due to its relative newness as a field of study, formal education in software engineering is often taught as part of a computer science curriculum, and many software engineers hold computer science degrees. The BLS estimates from 2014 to 2024 that computer software engineering would increase by 17% . This is down from the 2012 to 2022 BLS estimate of 22% for software engineering. And, is further down from their 30% 2010 to 2020 BLS estimate. Due to this trend, job growth may not be as fast as during the last decade, as jobs that would have gone to computer software engineers in the United States would instead be outsourced to computer software engineers in countries such as India and other foreign countries. In addition, the BLS Job Outlook for Computer Programmers, the U.S. Bureau of Labor Statistics (BLS) Occupational Outlook predicts a decline of -7 percent from 2016 to 2026, a further decline of -9 percent from 2019 to 2029, a decline of -10 percent from 2021 to 2031. and then a decline of -11 percent from 2022 to 2032. Since computer programming can be done from anywhere in the world, companies sometimes hire programmers in countries where wages are lower. Furthermore, women in many software fields has also been declining over the years as compared to other engineering fields. Then there is the additional concern that recent advances in Artificial Intelligence might impact the demand for future generations of Software Engineers. However, this trend may change or slow in the future as many current software engineers in the U.S. market flee the profession or age out of the market in the next few decades.\\n\\n\\n=== Certification ===\\nThe Software Engineering Institute offers certifications on specific topics like security, process improvement and software architecture. IBM, Microsoft and other companies also sponsor their own certification examinations. Many IT certification programs are oriented toward specific technologies, and managed by the vendors of these technologies. These certification programs are tailored to the institutions that would employ people who use these technologies.\\nBroader certification of general software engineering skills is available through various professional societies. As of 2006, the IEEE had certified over 575 software professionals as a Certified Software Development Professional (CSDP). In 2008 they added an entry-level certification known as the Certified Software Development Associate (CSDA). The ACM had a professional certification program in the early 1980s, which was discontinued due to lack of interest. The ACM examined the possibility of professional certification of software engineers in the late 1990s, but eventually decided that such certification was inappropriate for the professional industrial practice of software engineering.In the U.K. the British Computer Society has developed a legally recognized professional certification called Chartered IT Professional (CITP), available to fully qualified members (MBCS). Software engineers may be eligible for membership of the British Computer Society or Institution of Engineering and Technology and so qualify to be considered for Chartered Engineer status through either of those institutions. In Canada the Canadian Information Processing Society has developed a legally recognized professional certification called Information Systems Professional (ISP). In Ontario, Canada, Software Engineers who graduate from a Canadian Engineering Accreditation Board (CEAB) accredited program, successfully complete PEO\\'s (Professional Engineers Ontario) Professional Practice Examination (PPE) and have at least 48 months of acceptable engineering experience are eligible to be licensed through the Professional Engineers Ontario and can become Professional Engineers P.Eng. The PEO does not recognize any online or distance education however; and does not consider Computer Science programs to be equivalent to software engineering programs despite the tremendous overlap between the two. This has sparked controversy and a certification war. It has also held the number of P.Eng holders for the profession exceptionally low. The vast majority of working professionals in the field hold a degree in CS, not SE. Given the difficult certification path for holders of non-SE degrees, most never bother to pursue the license.\\n\\n\\n=== Impact of globalization ===\\nThe initial impact of outsourcing, and the relatively lower cost of international human resources in developing third world countries led to a massive migration of software development activities from corporations in North America and Europe to India and later: China, Russia, and other developing countries. This approach had some flaws, mainly the distance / time zone difference that prevented human interaction between clients and developers and the massive job transfer. This had a negative impact on many aspects of the software engineering profession. For example, some students in the developed world avoid education related to software engineering because of the fear of offshore outsourcing (importing software products or services from other countries) and of being displaced by foreign visa workers. Although statistics do not currently show a threat to software engineering itself; a related career, computer programming does appear to have been affected. Nevertheless, the ability to smartly leverage offshore and near-shore resources via the follow-the-sun workflow has improved the overall operational capability of many organizations. When North Americans are leaving work, Asians are just arriving to work. When Asians are leaving work, Europeans are arriving to work. This provides a continuous ability to have human oversight on business-critical processes 24 hours per day, without paying overtime compensation or disrupting a key human resource, sleep patterns.\\nWhile global outsourcing has several advantages, global – and generally distributed – development can run into serious difficulties resulting from the distance between developers. This is due to the key elements of this type of distance that have been identified as geographical, temporal, cultural and communication (that includes the use of different languages and dialects of English in different locations). Research has been carried out in the area of global software development over the last 15 years and an extensive body of relevant work published that highlights the benefits and problems associated with the complex activity. As with other aspects of software engineering research is ongoing in this and related areas.\\n\\n\\n=== Prizes ===\\nThere are several prizes in the field of software engineering:\\nThe Codie awards is a yearly award issued by the Software and Information Industry Association for excellence in software development within the software industry.\\nJolt Awards are awards in the software industry.\\nStevens Award is a software engineering award given in memory of Wayne Stevens.\\nHarlan Mills Award for \"contributions to the theory and practice of the information sciences, focused on software engineering\".\\n\\n\\n== Criticism ==\\nSoftware engineering sees its practitioners as individuals who follow well-defined engineering approaches to problem-solving. These approaches are specified in various software engineering books and research papers, always with the connotations of predictability, precision, mitigated risk and professionalism. This perspective has led to calls for licensing, certification and codified bodies of knowledge as mechanisms for spreading the engineering knowledge and maturing the field.\\nSoftware engineering extends engineering and draws on the engineering model, i.e. engineering process, engineering project management, engineering requirements, engineering design, engineering construction, and engineering validation. The concept is so new that it is rarely understood, and it is widely misinterpreted, including in software engineering textbooks, papers, and among the communities of programmers and crafters.\\nOne of the core issues in software engineering is that its approaches are not empirical enough because a real-world validation of approaches is usually absent, or very limited and hence software engineering is often misinterpreted as feasible only in a \"theoretical environment.\"\\nEdsger Dijkstra, the founder of many of the concepts used within software development today, rejected the idea of \"software engineering\" up until his death in 2002, arguing that those terms were poor analogies for what\\nhe called the \"radical novelty\" of computer science:\\n\\nA number of these phenomena have been bundled under the name \"Software Engineering\". As economics is known as \"The Miserable Science\", software engineering should be known as \"The Doomed Discipline\", doomed because it cannot even approach its goal since its goal is self-contradictory. Software engineering, of course, presents itself as another worthy cause, but that is eyewash: if you carefully read its literature and analyse what its devotees actually do, you will discover that software engineering has accepted as its charter \"How to program if you cannot.\"\\n\\n\\n== See also ==\\n\\n\\n=== Study and practice ===\\nComputer science\\nData engineering\\nSoftware craftsmanship\\nSoftware development\\nRelease engineering\\n\\n\\n=== Roles ===\\nProgrammer\\nSystems analyst\\nSystems architect\\n\\n\\n=== Professional aspects ===\\nBachelor of Science in Information Technology\\nBachelor of Software Engineering\\nList of software engineering conferences\\nList of computer science journals (including software engineering journals)\\nSoftware Engineering Institute\\n\\n\\n== References ==\\n\\n\\n=== Citations ===\\n\\n\\n=== Sources ===\\n\\n\\n== Further reading ==\\nGuide to the Software Engineering Body of Knowledge (SWEBOK Guide): Version 3.0. Pierre Bourque, Richard E. Fairley (eds.). IEEE Computer Society. 2014. ISBN 978-0-7695-5166-1.{{cite book}}:  CS1 maint: others (link)\\nPressman, Roger S (2009). Software Engineering: A Practitioner\\'s Approach (7th ed.). Boston, Mass: McGraw-Hill. ISBN 978-0-07-337597-7.\\nSommerville, Ian (2010) [2010]. Software Engineering (9th ed.). Harlow, England: Pearson Education. ISBN 978-0-13-703515-1.\\nJalote, Pankaj (2005) [1991]. An Integrated Approach to Software Engineering (3rd ed.). Springer. ISBN 978-0-387-20881-7.\\nBruegge, Bernd; Dutoit, Allen (2009). Object-oriented software engineering : using UML, patterns, and Java (3rd ed.). Prentice Hall. ISBN 978-0-13-606125-0.\\nOshana, Robert (2019-06-21). Software engineering for embedded systems : methods, practical techniques, and applications (Second ed.). Kidlington, Oxford, United Kingdom. ISBN 978-0-12-809433-4.\\n\\n\\n== External links ==\\n\\nGuide to the Software Engineering Body of Knowledge\\nThe Open Systems Engineering and Software Development Life Cycle Framework Archived 2010-07-18 at the Wayback Machine OpenSDLC.org the integrated Creative Commons SDLC\\nSoftware Engineering Institute Carnegie Mellon',\n",
              " 'The Internet of things (IoT) describes devices with sensors, processing ability, software and other technologies that connect and exchange data with other devices and systems over the Internet or other communications networks. The Internet of things encompasses electronics, communication and computer science engineering. Internet of things has been considered a misnomer because devices do not need to be connected to the public internet, they only need to be connected to a network, and be individually addressable.The field has evolved due to the convergence of multiple technologies, including ubiquitous computing, commodity sensors, and increasingly powerful embedded systems, as well as machine learning. Older fields of embedded systems, wireless sensor networks, control systems, automation (including home and building automation), independently and collectively enable the Internet of things.  In the consumer market, IoT technology is most synonymous with \"smart home\" products, including devices and appliances (lighting fixtures, thermostats, home security systems, cameras, and other home appliances) that support one or more common ecosystems, and can be controlled via devices associated with that ecosystem, such as smartphones and smart speakers. IoT is also used in healthcare systems.There are a number of concerns about the risks in the growth of IoT technologies and products, especially in the areas of privacy and security, and consequently there have been industry and government moves to address these concerns, including the development of international and local standards, guidelines, and regulatory frameworks.\\n\\n\\n== History ==\\nThe main concept of a network of smart devices was discussed as early as 1982, with a modified Coca-Cola vending machine at Carnegie Mellon University becoming the first ARPANET-connected appliance, able to report its inventory and whether newly loaded drinks were cold or not. Mark Weiser\\'s 1991 paper on ubiquitous computing, \"The Computer of the 21st Century\", as well as academic venues such as UbiComp and PerCom produced the contemporary vision of the IOT. In 1994, Reza Raji described the concept in IEEE Spectrum as \"[moving] small packets of data to a large set of nodes, so as to integrate and automate everything from home appliances to entire factories\". Between 1993 and 1997, several companies proposed solutions like Microsoft\\'s at Work or Novell\\'s NEST. The field gained momentum when Bill Joy envisioned device-to-device communication as a part of his \"Six Webs\" framework, presented at the World Economic Forum at Davos in 1999.The concept of the \"Internet of things\" and the term itself, first appeared in a speech by Peter T. Lewis, to the Congressional Black Caucus Foundation 15th Annual Legislative Weekend in Washington, D.C., published in September 1985. According to Lewis, \"The Internet of Things, or IoT, is the integration of people, processes and technology with connectable devices and sensors to enable remote monitoring, status, manipulation and evaluation of trends of such devices.\"The term \"Internet of things\" was coined independently by Kevin Ashton of Procter & Gamble, later of MIT\\'s Auto-ID Center, in 1999, though he prefers the phrase \"Internet for things\". At that point, he viewed radio-frequency identification (RFID) as essential to the Internet of things, which would allow computers to manage all individual things. The main theme of the Internet of things is to embed short-range mobile transceivers in various gadgets and daily necessities to enable new forms of communication between people and things, and between things themselves.In 2004 Cornelius \"Pete\" Peterson, CEO of NetSilicon, predicted that, \"The next era of information technology will be dominated by [IoT] devices, and networked devices will ultimately gain in popularity and significance to the extent that they will far exceed the number of networked computers and workstations.\" Peterson believed that medical devices and industrial controls would become dominant applications of the technology.Defining the Internet of things as \"simply the point in time when more \\'things or objects\\' were connected to the Internet than people\", Cisco Systems estimated that the IoT was \"born\" between 2008 and 2009, with the things/people ratio growing from 0.08 in 2003 to 1.84 in 2010.\\n\\n\\n== Applications ==\\nThe extensive set of applications for IoT devices is often divided into consumer, commercial, industrial, and infrastructure spaces.\\n\\n\\n=== Consumers ===\\nA growing portion of IoT devices is created for consumer use, including connected vehicles, home automation, wearable technology, connected health, and appliances with remote monitoring capabilities.\\n\\n\\n==== Home automation ====\\nIoT devices are a part of the larger concept of home automation, which can include lighting, heating and air conditioning, media and security systems and camera systems. Long-term benefits could include energy savings by automatically ensuring lights and electronics are turned off or by making the residents in the home aware of usage.A smart home or automated home could be based on a platform or hubs that control smart devices and appliances. For instance, using Apple\\'s HomeKit, manufacturers can have their home products and accessories controlled by an application in iOS devices such as the iPhone and the Apple Watch. This could be a dedicated app or iOS native applications such as Siri. This can be demonstrated in the case of Lenovo\\'s Smart Home Essentials, which is a line of smart home devices that are controlled through Apple\\'s Home app or Siri without the need for a Wi-Fi bridge. There are also dedicated smart home hubs that are offered as standalone platforms to connect different smart home products. These include the Amazon Echo, Google Home, Apple\\'s HomePod, and Samsung\\'s SmartThings Hub. In addition to the commercial systems, there are many non-proprietary, open source ecosystems, including Home Assistant, OpenHAB and Domoticz.\\n\\n\\n==== Elder care ====\\nOne key application of a smart home is to assist the elderly and disabled. These home systems use assistive technology to accommodate an owner\\'s specific disabilities. Voice control can assist users with sight and mobility limitations while alert systems can be connected directly to cochlear implants worn by hearing-impaired users. They can also be equipped with additional safety features, including sensors that monitor for medical emergencies such as falls or seizures. Smart home technology applied in this way can provide users with more freedom and a higher quality of life.\\n\\n\\n=== Organizations ===\\nThe term \"Enterprise IoT\" refers to devices used in business and corporate settings. By 2019, it is estimated that the EIoT will account for 9.1 billion devices.\\n\\n\\n==== Medical and healthcare ====\\nThe Internet of Medical Things (IoMT) is an application of the IoT for medical and health-related purposes, data collection and analysis for research, and monitoring. The IoMT has been referenced as \"Smart Healthcare\", as the technology for creating a digitized healthcare system, connecting available medical resources and healthcare services.IoT devices can be used to enable remote health monitoring and emergency notification systems. These health monitoring devices can range from blood pressure and heart rate monitors to advanced devices capable of monitoring specialized implants, such as pacemakers, Fitbit electronic wristbands, or advanced hearing aids. Some hospitals have begun implementing \"smart beds\" that can detect when they are occupied and when a patient is attempting to get up. It can also adjust itself to ensure appropriate pressure and support are applied to the patient without the manual interaction of nurses. A 2015 Goldman Sachs report indicated that healthcare IoT devices \"can save the United States more than $300 billion in annual healthcare expenditures by increasing revenue and decreasing cost.\" Moreover, the use of mobile devices to support medical follow-up led to the creation of \\'m-health\\', used analyzed health statistics.\"Specialized sensors can also be equipped within living spaces to monitor the health and general well-being of senior citizens, while also ensuring that proper treatment is being administered and assisting people to regain lost mobility via therapy as well. These sensors create a network of intelligent sensors that are able to collect, process, transfer, and analyze valuable information in different environments, such as connecting in-home monitoring devices to hospital-based systems. Other consumer devices to encourage healthy living, such as connected scales or wearable heart monitors, are also a possibility with the IoT. End-to-end health monitoring IoT platforms are also available for antenatal and chronic patients, helping one manage health vitals and recurring medication requirements.Advances in plastic and fabric electronics fabrication methods have enabled ultra-low cost, use-and-throw IoMT sensors. These sensors, along with the required RFID electronics, can be fabricated on paper or e-textiles for wireless powered disposable sensing devices. Applications have been established for point-of-care medical diagnostics, where portability and low system-complexity is essential.As of 2018 IoMT was not only being applied in the clinical laboratory industry, but also in the healthcare and health insurance industries. IoMT in the healthcare industry is now permitting doctors, patients, and others, such as guardians of patients, nurses, families, and similar, to be part of a system, where patient records are saved in a database, allowing doctors and the rest of the medical staff to have access to patient information. IoMT in the insurance industry provides access to better and new types of dynamic information. This includes sensor-based solutions such as biosensors, wearables, connected health devices, and mobile apps to track customer behavior. This can lead to more accurate underwriting and new pricing models.The application of the IoT in healthcare plays a fundamental role in managing chronic diseases and in disease prevention and control. Remote monitoring is made possible through the connection of powerful wireless solutions. The connectivity enables health practitioners to capture patient\\'s data and apply complex algorithms in health data analysis.\\n\\n\\n==== Transportation ====\\nThe IoT can assist in the integration of communications, control, and information processing across various transportation systems. Application of the IoT extends to all aspects of transportation systems (i.e., the vehicle, the infrastructure, and the driver or user). Dynamic interaction between these components of a transport system enables inter- and intra-vehicular communication, smart traffic control, smart parking, electronic toll collection systems, logistics and fleet management, vehicle control, safety, and road assistance.\\n\\n\\n==== V2X communications ====\\n\\nIn vehicular communication systems, vehicle-to-everything communication (V2X), consists of three main components: vehicle-to-vehicle communication (V2V), vehicle-to-infrastructure communication (V2I) and vehicle to pedestrian communications (V2P). V2X is the first step to autonomous driving and connected road infrastructure.\\n\\n\\n==== Home automation ====\\nIoT devices can be used to monitor and control the mechanical, electrical and electronic systems used in various types of buildings (e.g., public and private, industrial, institutions, or residential) in home automation and building automation systems. In this context, three main areas are being covered in literature:\\nThe integration of the Internet with building energy management systems to create energy-efficient and IOT-driven \"smart buildings\".\\nThe possible means of real-time monitoring for reducing energy consumption and monitoring occupant behaviors.\\nThe integration of smart devices in the built environment and how they might be used in future applications.\\n\\n\\n=== Industrial ===\\n\\nAlso known as IIoT, industrial IoT devices acquire and analyze data from connected equipment, operational technology (OT), locations, and people. Combined with operational technology (OT) monitoring devices, IIoT helps regulate and monitor industrial systems. Also, the same implementation can be carried out for automated record updates of asset placement in industrial storage units as the size of the assets can vary from a small screw to the whole motor spare part, and misplacement of such assets can cause a loss of manpower time and money.\\n\\n\\n==== Manufacturing ====\\nThe IoT can connect various manufacturing devices equipped with sensing, identification, processing, communication, actuation, and networking capabilities. Network control and management of manufacturing equipment, asset and situation management, or manufacturing process control allow IoT to be used for industrial applications and smart manufacturing. IoT intelligent systems enable rapid manufacturing and optimization of new products and rapid response to product demands.Digital control systems to automate process controls, operator tools and service information systems to optimize plant safety and security are within the purview of the IIoT. IoT can also be applied to asset management via predictive maintenance, statistical evaluation, and measurements to maximize reliability. Industrial management systems can be integrated with smart grids, enabling energy optimization. Measurements, automated controls, plant optimization, health and safety management, and other functions are provided by networked sensors.In addition to general manufacturing, IoT is also used for processes in the industrialization of construction.\\n\\n\\n==== Agriculture ====\\nThere are numerous IoT applications in farming such as collecting data on temperature, rainfall, humidity, wind speed, pest infestation, and soil content. This data can be used to automate farming techniques, take informed decisions to improve quality and quantity, minimize risk and waste, and reduce the effort required to manage crops. For example, farmers can now monitor soil temperature and moisture from afar and even apply IoT-acquired data to precision fertilization programs. The overall goal is that data from sensors, coupled with the farmer\\'s knowledge and intuition about his or her farm, can help increase farm productivity, and also help reduce costs.\\nIn August 2018, Toyota Tsusho began a partnership with Microsoft to create fish farming tools using the Microsoft Azure application suite for IoT technologies related to water management. Developed in part by researchers from Kindai University, the water pump mechanisms use artificial intelligence to count the number of fish on a conveyor belt, analyze the number of fish, and deduce the effectiveness of water flow from the data the fish provide. The FarmBeats project from Microsoft Research that uses TV white space to connect farms is also a part of the Azure Marketplace now.\\n\\n\\n==== Maritime ====\\nIoT devices are in use to monitor the environments and systems of boats and yachts. Many pleasure boats are left unattended for days in summer, and months in winter so such devices provide valuable early alerts of boat flooding, fire, and deep discharge of batteries. The use of global internet data networks such as Sigfox, combined with long-life batteries, and microelectronics allows the engine rooms, bilge, and batteries to be constantly monitored and reported to connected Android & Apple applications for example.\\n\\n\\n=== Infrastructure ===\\nMonitoring and controlling operations of sustainable urban and rural infrastructures like bridges, railway tracks and on- and offshore wind farms is a key application of the IoT. The IoT infrastructure can be used for monitoring any events or changes in structural conditions that can compromise safety and increase risk. The IoT can benefit the construction industry by cost-saving, time reduction, better quality workday, paperless workflow and increase in productivity. It can help in taking faster decisions and saving money in Real-Time Data Analytics. It can also be used for scheduling repair and maintenance activities efficiently, by coordinating tasks between different service providers and users of these facilities. IoT devices can also be used to control critical infrastructure like bridges to provide access to ships. The usage of IoT devices for monitoring and operating infrastructure is likely to improve incident management and emergency response coordination, and quality of service, up-times and reduce costs of operation in all infrastructure-related areas. Even areas such as waste management can benefit from automation and optimization that could be brought in by the IoT.\\n\\n\\n==== Metropolitan scale deployments ====\\nThere are several planned or ongoing large-scale deployments of the IoT, to enable better management of cities and systems. For example, Songdo, South Korea, the first of its kind fully equipped and wired smart city, is gradually being built, with approximately 70 percent of the business district completed as of June 2018. Much of the city is planned to be wired and automated, with little or no human intervention.Another application is currently undergoing a project in Santander, Spain. For this deployment, two approaches have been adopted. This city of 180,000 inhabitants has already seen 18,000 downloads of its city smartphone app. The app is connected to 10,000 sensors that enable services like parking search, environmental monitoring, digital city agenda, and more. City context information is used in this deployment so as to benefit merchants through a spark deals mechanism based on city behavior that aims at maximizing the impact of each notification.Other examples of large-scale deployments underway include the Sino-Singapore Guangzhou Knowledge City; work on improving air and water quality, reducing noise pollution, and increasing transportation efficiency in San Jose, California; and smart traffic management in western Singapore. Using its RPMA (Random Phase Multiple Access) technology, San Diego-based Ingenu has built a nationwide public network for low-bandwidth data transmissions using the same unlicensed 2.4 gigahertz spectrum as Wi-Fi. Ingenu\\'s \"Machine Network\" covers more than a third of the US population across 35 major cities including San Diego and Dallas. French company, Sigfox, commenced building an Ultra Narrowband wireless data network in the San Francisco Bay Area in 2014, the first business to achieve such a deployment in the U.S. It subsequently announced it would set up a total of 4000 base stations to cover a total of 30 cities in the U.S. by the end of 2016, making it the largest IoT network coverage provider in the country thus far. Cisco also participates in smart cities projects. Cisco has started deploying technologies for Smart Wi-Fi, Smart Safety & Security, Smart Lighting, Smart Parking, Smart Transports, Smart Bus Stops, Smart Kiosks, Remote Expert for Government Services (REGS) and Smart Education in the five km area in the city of Vijaywada, India.Another example of a large deployment is the one completed by New York Waterways in New York City to connect all the city\\'s vessels and be able to monitor them live 24/7. The network was designed and engineered by Fluidmesh Networks, a Chicago-based company developing wireless networks for critical applications. The NYWW network is currently providing coverage on the Hudson River, East River, and Upper New York Bay. With the wireless network in place, NY Waterway is able to take control of its fleet and passengers in a way that was not previously possible. New applications can include security, energy and fleet management, digital signage, public Wi-Fi, paperless ticketing and others.\\n\\n\\n==== Energy management ====\\nSignificant numbers of energy-consuming devices (e.g. lamps, household appliances, motors, pumps, etc.) already integrate Internet connectivity, which can allow them to communicate with utilities not only to balance power generation but also helps optimize the energy consumption as a whole. These devices allow for remote control by users, or central management via a cloud-based interface, and enable functions like scheduling (e.g., remotely powering on or off heating systems, controlling ovens, changing lighting conditions etc.). The smart grid is a utility-side IoT application; systems gather and act on energy and power-related information to improve the efficiency of the production and distribution of electricity. Using advanced metering infrastructure (AMI) Internet-connected devices, electric utilities not only collect data from end-users, but also manage distribution automation devices like transformers.\\n\\n\\n==== Environmental monitoring ====\\nEnvironmental monitoring applications of the IoT typically use sensors to assist in environmental protection by monitoring air or water quality, atmospheric or soil conditions, and can even include areas like monitoring the movements of wildlife and their habitats. Development of resource-constrained devices connected to the Internet also means that other applications like earthquake or tsunami early-warning systems can also be used by emergency services to provide more effective aid. IoT devices in this application typically span a large geographic area and can also be mobile. It has been argued that the standardization that IoT brings to wireless sensing will revolutionize this area.Living Lab\\nAnother example of integrating the IoT is Living Lab which integrates and combines research and innovation processes, establishing within a public-private-people-partnership. There are currently 320 Living Labs that use the IoT to collaborate and share knowledge between stakeholders to co-create innovative and technological products. For companies to implement and develop IoT services for smart cities, they need to have incentives. The governments play key roles in smart city projects as changes in policies will help cities to implement the IoT which provides effectiveness, efficiency, and accuracy of the resources that are being used. For instance, the government provides tax incentives and cheap rent, improves public transports, and offers an environment where start-up companies, creative industries, and multinationals may co-create, share a common infrastructure and labor markets, and take advantage of locally embedded technologies, production process, and transaction costs. The relationship between the technology developers and governments who manage the city\\'s assets, is key to provide open access to resources to users in an efficient way.\\n\\n\\n=== Military ===\\n\\nThe Internet of Military Things (IoMT) is the application of IoT technologies in the military domain for the purposes of reconnaissance, surveillance, and other combat-related objectives. It is heavily influenced by the future prospects of warfare in an urban environment and involves the use of sensors, munitions, vehicles, robots, human-wearable biometrics, and other smart technology that is relevant on the battlefield.One of the examples of IOT devices used in the military is Xaver 1000 system. The Xaver 1000 was developed by Israel\\'s Camero Tech, which is the latest in the company\\'s line of \"through wall imaging systems\". The Xaver line uses millimeter wave (MMW) radar, or radar in the range of 30-300 gigahertz. It is equipped with an AI-based life target tracking system as well as its own 3D \\'sense-through-the-wall\\' technology.\\n\\n\\n==== Internet of Battlefield Things ====\\nThe Internet of Battlefield Things (IoBT) is a project initiated and executed by the U.S. Army Research Laboratory (ARL) that focuses on the basic science related to the IoT that enhance the capabilities of Army soldiers. In 2017, ARL launched the Internet of Battlefield Things Collaborative Research Alliance (IoBT-CRA), establishing a working collaboration between industry, university, and Army researchers to advance the theoretical foundations of IoT technologies and their applications to Army operations.\\n\\n\\n==== Ocean of Things ====\\nThe Ocean of Things project is a DARPA-led program designed to establish an Internet of things across large ocean areas for the purposes of collecting, monitoring, and analyzing environmental and vessel activity data. The project entails the deployment of about 50,000 floats that house a passive sensor suite that autonomously detect and track military and commercial vessels as part of a cloud-based network.\\n\\n\\n=== Product digitalization ===\\nThere are several applications of smart or active packaging in which a QR code or NFC tag is affixed on a product or its packaging. The tag itself is passive, however, it contains a unique identifier (typically a URL) which enables a user to access digital content about the product via a smartphone. Strictly speaking, such passive items are not part of the Internet of things, but they can be seen as enablers of digital interactions. The term \"Internet of Packaging\" has been coined to describe applications in which unique identifiers are used, to automate supply chains, and are scanned on large scale by consumers to access digital content. Authentication of the unique identifiers, and thereby of the product itself, is possible via a copy-sensitive digital watermark or copy detection pattern for scanning when scanning a QR code, while NFC tags can encrypt communication.\\n\\n\\n== Trends and characteristics ==\\nThe IoT\\'s major significant trend in recent years is the explosive growth of devices connected and controlled via the Internet. The wide range of applications for IoT technology mean that the specifics can be very different from one device to the next but there are basic characteristics shared by most.\\nThe IoT creates opportunities for more direct integration of the physical world into computer-based systems, resulting in efficiency improvements, economic benefits, and reduced human exertions.The number of IoT devices increased 31% year-over-year to 8.4 billion in the year 2017 and it is estimated that there will be 30 billion devices by 2020.\\n\\n\\n=== Intelligence ===\\nAmbient intelligence and autonomous control are not part of the original concept of the Internet of things. Ambient intelligence and autonomous control do not necessarily require Internet structures, either. However, there is a shift in research (by companies such as Intel) to integrate the concepts of the IoT and autonomous control, with initial outcomes towards this direction considering objects as the driving force for autonomous IoT. An approach in this context is deep reinforcement learning where most of IoT systems provide a dynamic and interactive environment. Training an agent (i.e., IoT device) to behave smartly in such an environment cannot be addressed by conventional machine learning algorithms such as supervised learning. By reinforcement learning approach, a learning agent can sense the environment\\'s state (e.g., sensing home temperature), perform actions (e.g., turn HVAC on or off) and learn through the maximizing accumulated rewards it receives in long term.\\nIoT intelligence can be offered at three levels: IoT devices, Edge/Fog nodes, and cloud computing. The need for intelligent control and decision at each level depends on the time sensitiveness of the IoT application. For example, an autonomous vehicle\\'s camera needs to make real-time obstacle detection to avoid an accident. This fast decision making would not be possible through transferring data from the vehicle to cloud instances and return the predictions back to the vehicle. Instead, all the operation should be performed locally in the vehicle. Integrating advanced machine learning algorithms including deep learning into IoT devices is an active research area to make smart objects closer to reality. Moreover, it is possible to get the most value out of IoT deployments through analyzing IoT data, extracting hidden information, and predicting control decisions. A wide variety of machine learning techniques have been used in IoT domain ranging from traditional methods such as regression, support vector machine, and random forest to advanced ones such as convolutional neural networks, LSTM, and variational autoencoder.In the future, the Internet of things may be a non-deterministic and open network in which auto-organized or intelligent entities (web services, SOA components) and virtual objects (avatars) will be interoperable and able to act independently (pursuing their own objectives or shared ones) depending on the context, circumstances or environments. Autonomous behavior through the collection and reasoning of context information as well as the object\\'s ability to detect changes in the environment (faults affecting sensors) and introduce suitable mitigation measures constitutes a major research trend, clearly needed to provide credibility to the IoT technology. Modern IoT products and solutions in the marketplace use a variety of different technologies to support such context-aware automation, but more sophisticated forms of intelligence are requested to permit sensor units and intelligent cyber-physical systems to be deployed in real environments.\\n\\n\\n=== Architecture ===\\nIoT system architecture, in its simplistic view, consists of three tiers: Tier 1: Devices, Tier 2: the Edge Gateway, and Tier 3: the Cloud. Devices include networked things, such as the sensors and actuators found in IoT equipment, particularly those that use protocols such as Modbus, Bluetooth, Zigbee, or proprietary protocols, to connect to an Edge Gateway. The Edge Gateway layer consists of sensor data aggregation systems called Edge Gateways that provide functionality, such as pre-processing of the data, securing connectivity to cloud, using systems such as WebSockets, the event hub, and, even in some cases, edge analytics or fog computing. Edge Gateway layer is also required to give a common view of the devices to the upper layers to facilitate in easier management. The final tier includes the cloud application built for IoT using the microservices architecture, which are usually polyglot and inherently secure in nature using HTTPS/OAuth. It includes various database systems that store sensor data, such as time series databases or asset stores using backend data storage systems (e.g. Cassandra, PostgreSQL). The cloud tier in most cloud-based IoT system features event queuing and messaging system that handles communication that transpires in all tiers. Some experts classified the three-tiers in the IoT system as edge, platform, and enterprise and these are connected by proximity network, access network, and service network, respectively.Building on the Internet of things, the web of things is an architecture for the application layer of the Internet of things looking at the convergence of data from IoT devices into Web applications to create innovative use-cases. In order to program and control the flow of information in the Internet of things, a predicted architectural direction is being called BPM Everywhere which is a blending of traditional process management with process mining and special capabilities to automate the control of large numbers of coordinated devices.\\n\\n\\n==== Network architecture ====\\nThe Internet of things requires huge scalability in the network space to handle the surge of devices. IETF 6LoWPAN can be used to connect devices to IP networks. With billions of devices being added to the Internet space, IPv6 will play a major role in handling the network layer scalability. IETF\\'s Constrained Application Protocol, ZeroMQ, and MQTT can provide lightweight data transport. In practice many groups of IoT devices are hidden behind gateway nodes and may not have unique addresses. Also the vision of everything-interconnected is not needed for most applications as it is mainly the data which need interconnecting at a higher layer.\\nFog computing is a viable alternative to prevent such a large burst of data flow through the Internet. The edge devices\\' computation power to analyze and process data is extremely limited. Limited processing power is a key attribute of IoT devices as their purpose is to supply data about physical objects while remaining autonomous. Heavy processing requirements use more battery power harming IoT\\'s ability to operate. Scalability is easy because IoT devices simply supply data through the internet to a server with sufficient processing power.\\n\\n\\n===== Decentralized IoT =====\\nDecentralized Internet of things, or decentralized IoT, is a modified IoT which utilizes fog computing to handle and balance requests of connected IoT devices in order to reduce loading on the cloud servers and improve responsiveness for latency-sensitive IoT applications like vital signs monitoring of patients, vehicle-to-vehicle communication of autonomous driving, and critical failure detection of industrial devices. Performance is improved, especially for huge IoT systems with millions of nodes.Conventional IoT is connected via a mesh network and led by a major head node (centralized controller). The head node decides how a data is created, stored, and transmitted. In contrast, decentralized IoT attempts to divide IoT systems into smaller divisions. The head node authorizes partial decision-making power to lower level sub-nodes under mutual agreed policy.Some approached to decentralized IoT attempts to address the limited bandwidth and hashing capacity of battery powered or wireless IoT devices via blockchain.\\n\\n\\n=== Complexity ===\\nIn semi-open or closed loops (i.e., value chains, whenever a global finality can be settled) the IoT will often be considered and studied as a complex system due to the huge number of different links, interactions between autonomous actors, and its capacity to integrate new actors. At the overall stage (full open loop) it will likely be seen as a chaotic environment (since systems always have finality). \\nAs a practical approach, not all elements on the Internet of things run in a global, public space. Subsystems are often implemented to mitigate the risks of privacy, control and reliability. For example, domestic robotics (domotics) running inside a smart home might only share data within and be available via a local network. Managing and controlling a high dynamic ad hoc IoT things/devices network is a tough task with the traditional networks architecture, Software Defined Networking (SDN) provides the agile dynamic solution that can cope with the special requirements of the diversity of innovative IoT applications.\\n\\n\\n=== Size considerations ===\\nThe exact scale of the Internet of things is unknown, with quotes of billions or trillions often quoted at the beginning of IoT articles. In 2015 there were 83 million smart devices in people\\'s homes. This number is expected to grow to 193 million devices by 2020.The figure of online capable devices grew 31% from 2016 to 2017 to reach 8.4 billion.\\n\\n\\n=== Space considerations ===\\nIn the Internet of things, the precise geographic location of a thing—and also the precise geographic dimensions of a thing—can be critical. Therefore, facts about a thing, such as its location in time and space, have been less critical to track because the person processing the information can decide whether or not that information was important to the action being taken, and if so, add the missing information (or decide to not take the action). (Note that some things on the Internet of things will be sensors, and sensor location is usually important.) The GeoWeb and Digital Earth are applications that become possible when things can become organized and connected by location. However, the challenges that remain include the constraints of variable spatial scales, the need to handle massive amounts of data, and an indexing for fast search and neighbour operations. On the Internet of things, if things are able to take actions on their own initiative, this human-centric mediation role is eliminated. Thus, the time-space context that we as humans take for granted must be given a central role in this information ecosystem. Just as standards play a key role on the Internet and the Web, geo-spatial standards will play a key role on the Internet of things.\\n\\n\\n=== A solution to \"basket of remotes\" ===\\nMany IoT devices have the potential to take a piece of this market. Jean-Louis Gassée (Apple initial alumni team, and BeOS co-founder) has addressed this topic in an article on Monday Note, where he predicts that the most likely problem will be what he calls the \"basket of remotes\" problem, where we\\'ll have hundreds of applications to interface with hundreds of devices that don\\'t share protocols for speaking with one another. For improved user interaction, some technology leaders are joining forces to create standards for communication between devices to solve this problem. Others are turning to the concept of predictive interaction of devices, \"where collected data is used to predict and trigger actions on the specific devices\" while making them work together.\\n\\n\\n=== Social Internet of things ===\\nSocial Internet of things (SIoT) is a new kind of IoT that focuses the importance of social interaction and relationship between IoT devices. SIoT is a pattern of how cross-domain IoT devices enabling application to application communication and collaboration without human intervention in order to serve their owners with autonomous services, and this only can be realized when gained low-level architecture support from both IoT software and hardware engineering.\\n\\n\\n==== Social Network for IoT Devices (Not Human) ====\\nIoT defines a device with an identity like a citizen in a community and connect them to the internet to provide services to its users. SIoT defines a social network for IoT devices only to interact with each other for different goals that to serve human.\\n\\n\\n==== How is SIoT different from IoT? ====\\nSIoT is different from the original IoT in terms of the collaboration characteristics. IoT is passive, it was set to serve for dedicated purposes with existing IoT devices in predetermined system. SIoT is active, it was programmed and managed by AI to serve for unplanned purposes with mix and match of potential IoT devices from different systems that benefit its users.\\n\\n\\n==== How does SIoT Work? ====\\nIoT devices built-in with sociability will broadcast their abilities or functionalities, and at the same time discovers, navigates and groups with other IoT devices in the same or nearby network for useful service compositions in order to help its users proactively in every day\\'s life especially during emergency.\\n\\n\\n==== Social IoT Examples ====\\nIoT-based smart home technology monitors health data of patients or aging adults by analyzing their physiological parameters and prompt the nearby health facilities when emergency medical services needed. In case emergency, automatically, ambulance of a nearest available hospital will be called with pickup location provided, ward assigned, patient\\'s health data will be transmitted to the emergency department, and display on the doctor\\'s computer immediately for further action.\\nIoT sensors on the vehicles, road and traffic lights monitor the conditions of the vehicles and drivers and alert when attention needed and also coordinate themselves automatically to ensure autonomous driving is working normally. Unfortunately if an accident happens, IoT camera will inform the nearest hospital and police station for help.\\n\\n\\n==== Social IoT Challenges ====\\nInternet of things is multifaceted and complicated. One of the main factors that hindering people from adopting and use Internet of things (IoT) based products and services is its complexity. Installation and setup is a challenge to people, therefore, there is a need for IoT devices to mix match and configure themselves automatically to provide different services at different situation.\\nSystem security always a concern for any technology, and it is more crucial for SIoT as not only security of oneself need to be considered but also the mutual trust mechanism between collaborative IoT devices from time to time, from place to place.\\nAnother critical challenge for SIoT is the accuracy and reliability of the sensors. At most of the circumstances, IoT sensors would need to respond in nanoseconds to avoid accidents, injury, and loss of life.\\n\\n\\n== Enabling technologies ==\\nThere are many technologies that enable the IoT. Crucial to the field is the network used to communicate between devices of an IoT installation, a role that several wireless or wired technologies may fulfill:\\n\\n\\n=== Addressability ===\\nThe original idea of the Auto-ID Center is based on RFID-tags and distinct identification through the Electronic Product Code. This has evolved into objects having an IP address or URI. An alternative view, from the world of the Semantic Web focuses instead on making all things (not just those electronic, smart, or RFID-enabled) addressable by the existing naming protocols, such as URI. The objects themselves do not converse, but they may now be referred to by other agents, such as powerful centralised servers acting for their human owners. Integration with the Internet implies that devices will use an IP address as a distinct identifier. Due to the limited address space of IPv4 (which allows for 4.3 billion different addresses), objects in the IoT will have to use the next generation of the Internet protocol (IPv6) to scale to the extremely large address space required.\\nInternet-of-things devices additionally will benefit from the stateless address auto-configuration present in IPv6, as it reduces the configuration overhead on the hosts, and the IETF 6LoWPAN header compression. To a large extent, the future of the Internet of things will not be possible without the support of IPv6; and consequently, the global adoption of IPv6 in the coming years will be critical for the successful development of the IoT in the future.\\n\\n\\n=== Application Layer ===\\nADRC defines an application layer protocol and supporting framework for implementing IoT applications.\\n\\n\\n=== Short-range wireless ===\\nBluetooth mesh networking – Specification providing a mesh networking variant to Bluetooth low energy (BLE) with an increased number of nodes and standardized application layer (Models).\\nLight-Fidelity (Li-Fi) – Wireless communication technology similar to the Wi-Fi standard, but using visible light communication for increased bandwidth.\\nNear-field communication (NFC) – Communication protocols enabling two electronic devices to communicate within a 4 cm range.\\nRadio-frequency identification (RFID) – Technology using electromagnetic fields to read data stored in tags embedded in other items.\\nWi-Fi – Technology for local area networking based on the IEEE 802.11 standard, where devices may communicate through a shared access point or directly between individual devices.\\nZigbee – Communication protocols for personal area networking based on the IEEE 802.15.4 standard, providing low power consumption, low data rate, low cost, and high throughput.\\nZ-Wave – Wireless communications protocol used primarily for home automation and security applications\\n\\n\\n=== Medium-range wireless ===\\nLTE-Advanced – High-speed communication specification for mobile networks. Provides enhancements to the LTE standard with extended coverage, higher throughput, and lower latency.\\n5G - 5G wireless networks can be used to achieve the high communication requirements of the IoT and connect a large number of IoT devices, even when they are on the move. There are three features of 5G that are each considered to be useful for supporting particular elements of IoT: enhanced mobile broadband (eMBB), massive machine type communications (mMTC) and ultra-reliable low latency communications (URLLC).\\n\\n\\n=== Long-range wireless ===\\nLow-power wide-area networking (LPWAN) – Wireless networks designed to allow long-range communication at a low data rate, reducing power and cost for transmission. Available LPWAN technologies and protocols: LoRaWan, Sigfox, NB-IoT, Weightless, RPMA, MIoTy.\\nVery small aperture terminal (VSAT) – Satellite communication technology using small dish antennas for narrowband and broadband data.\\n\\n\\n=== Wired ===\\nEthernet – General purpose networking standard using twisted pair and fiber optic links in conjunction with hubs or switches.\\nPower-line communication (PLC) – Communication technology using electrical wiring to carry power and data. Specifications such as HomePlug or G.hn utilize PLC for networking IoT devices.\\n\\n\\n=== Comparison of technologies by layer ===\\n\\nDifferent technologies have different roles in a protocol stack. Below is a simplified presentation of the roles of several popular communication technologies in IoT applications:\\n\\n\\n=== Standards and standards organizations ===\\nThis is a list of technical standards for the IoT, most of which are open standards, and the standards organizations that aspire to successfully setting them.\\n\\n\\n== Politics and civic engagement ==\\nSome scholars and activists argue that the IoT can be used to create new models of civic engagement if device networks can be open to user control and inter-operable platforms. Philip N. Howard, a professor and author, writes that political life in both democracies and authoritarian regimes will be shaped by the way the IoT will be used for civic engagement. For that to happen, he argues that any connected device should be able to divulge a list of the \"ultimate beneficiaries\" of its sensor data and that individual citizens should be able to add new organisations to the beneficiary list. In addition, he argues that civil society groups need to start developing their IoT strategy for making use of data and engaging with the public.\\n\\n\\n== Government regulation ==\\nOne of the key drivers of the IoT is data. The success of the idea of connecting devices to make them more efficient is dependent upon access to and storage & processing of data. For this purpose, companies working on the IoT collect data from multiple sources and store it in their cloud network for further processing. This leaves the door wide open for privacy and security dangers and single point vulnerability of multiple systems. The other issues pertain to consumer choice and ownership of data and how it is used. Though still in their infancy, regulations and governance regarding these issues of privacy, security, and data ownership continue to develop. IoT regulation depends on the country. Some examples of legislation that is relevant to privacy and data collection are: the US Privacy Act of 1974, OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data of 1980, and the EU Directive 95/46/EC of 1995.Current regulatory environment:\\nA report published by the Federal Trade Commission (FTC) in January 2015 made the following three recommendations:\\nData security – At the time of designing IoT companies should ensure that data collection, storage and processing would be secure at all times. Companies should adopt a \"defense in depth\" approach and encrypt data at each stage.\\nData consent – users should have a choice as to what data they share with IoT companies and the users must be informed if their data gets exposed.\\nData minimisation – IoT companies should collect only the data they need and retain the collected information only for a limited time.However, the FTC stopped at just making recommendations for now. According to an FTC analysis, the existing framework, consisting of the FTC Act, the Fair Credit Reporting Act, and the Children\\'s Online Privacy Protection Act, along with developing consumer education and business guidance, participation in multi-stakeholder efforts and advocacy to other agencies at the federal, state and local level, is sufficient to protect consumer rights.A resolution passed by the Senate in March 2015, is already being considered by the Congress. This resolution recognized the need for formulating a National Policy on IoT and the matter of privacy, security and spectrum. Furthermore, to provide an impetus to the IoT ecosystem, in March 2016, a bipartisan group of four Senators proposed a bill, The Developing Innovation and Growing the Internet of Things (DIGIT) Act, to direct the Federal Communications Commission to assess the need for more spectrum to connect IoT devices.\\nApproved on 28 September 2018, California Senate Bill No. 327 goes into effect on 1 January 2020. The bill requires \"a manufacturer of a connected device, as those terms are defined, to equip the device with a reasonable security feature or features that are appropriate to the nature and function of the device, appropriate to the information it may collect, contain, or transmit, and designed to protect the device and any information contained therein from unauthorized access, destruction, use, modification, or disclosure,\"\\nSeveral standards for the IoT industry are actually being established relating to automobiles because most concerns arising from use of connected cars apply to healthcare devices as well. In fact, the National Highway Traffic Safety Administration (NHTSA) is preparing cybersecurity guidelines and a database of best practices to make automotive computer systems more secure.A recent report from the World Bank examines the challenges and opportunities in government adoption of IoT. These include –\\n\\nStill early days for the IoT in government \\nUnderdeveloped policy and regulatory frameworks \\nUnclear business models, despite strong value proposition \\nClear institutional and capacity gap in government AND the private sector \\nInconsistent data valuation and management \\nInfrastructure a major barrier \\nGovernment as an enabler \\nMost successful pilots share common characteristics (public-private partnership, local, leadership)In early December 2021, the U.K. government introduced the Product Security and Telecommunications Infrastructure bill (PST), an effort to legislate IoT distributors, manufacturers, and importers to meet certain cybersecurity standards. The bill also seeks to improve the security credentials of consumer IoT devices.\\n\\n\\n== Criticism, problems and controversies ==\\n\\n\\n=== Platform fragmentation ===\\nThe IoT suffers from platform fragmentation, lack of interoperability and common technical standards a situation where the variety of IoT devices, in terms of both hardware variations and differences in the software running on them, makes the task of developing applications that work consistently between different inconsistent technology ecosystems hard. For example, wireless connectivity for IoT devices can be done using Bluetooth, Wi-Fi, Wi-Fi HaLow, Zigbee, Z-Wave, LoRa, NB-IoT, Cat M1 as well as completely custom proprietary radios – each with its own advantages and disadvantages; and unique support ecosystem.The IoT\\'s amorphous computing nature is also a problem for security, since patches to bugs found in the core operating system often do not reach users of older and lower-price devices. One set of researchers say that the failure of vendors to support older devices with patches and updates leaves more than 87% of active Android devices vulnerable.\\n\\n\\n=== Privacy, autonomy, and control ===\\nPhilip N. Howard, a professor and author, writes that the Internet of things offers immense potential for empowering citizens, making government transparent, and broadening information access. Howard cautions, however, that privacy threats are enormous, as is the potential for social control and political manipulation.Concerns about privacy have led many to consider the possibility that big data infrastructures such as the Internet of things and data mining are inherently incompatible with privacy. Key challenges of increased digitalization in the water, transport or energy sector are related to privacy and cybersecurity which necessitate an adequate response from research and policymakers alike.Writer Adam Greenfield claims that IoT technologies are not only an invasion of public space but are also being used to perpetuate normative behavior, citing an instance of billboards with hidden cameras that tracked the demographics of passersby who stopped to read the advertisement.\\nThe Internet of Things Council compared the increased prevalence of digital surveillance due to the Internet of things to the conceptual panopticon described by Jeremy Bentham in the 18th century. The assertion was defended by the works of French philosophers Michel Foucault and Gilles Deleuze. In Discipline and Punish: The Birth of the Prison, Foucault asserts that the panopticon was a central element of the discipline society developed during the Industrial Era. Foucault also argued that the discipline systems established in factories and school reflected Bentham\\'s vision of panopticism. In his 1992 paper \"Postscripts on the Societies of Control\", Deleuze wrote that the discipline society had transitioned into a control society, with the computer replacing the panopticon as an instrument of discipline and control while still maintaining the qualities similar to that of panopticism.Peter-Paul Verbeek, a professor of philosophy of technology at the University of Twente, Netherlands, writes that technology already influences our moral decision making, which in turn affects human agency, privacy and autonomy. He cautions against viewing technology merely as a human tool and advocates instead to consider it as an active agent.Justin Brookman, of the Center for Democracy and Technology, expressed concern regarding the impact of the IoT on consumer privacy, saying that \"There are some people in the commercial space who say, \\'Oh, big data – well, let\\'s collect everything, keep it around forever, we\\'ll pay for somebody to think about security later.\\' The question is whether we want to have some sort of policy framework in place to limit that.\"Tim O\\'Reilly believes that the way companies sell the IoT devices on consumers are misplaced, disputing the notion that the IoT is about gaining efficiency from putting all kinds of devices online and postulating that the \"IoT is really about human augmentation. The applications are profoundly different when you have sensors and data driving the decision-making.\"Editorials at WIRED have also expressed concern, one stating \"What you\\'re about to lose is your privacy. Actually, it\\'s worse than that. You aren\\'t just going to lose your privacy, you\\'re going to have to watch the very concept of privacy be rewritten under your nose.\"The American Civil Liberties Union (ACLU) expressed concern regarding the ability of IoT to erode people\\'s control over their own lives. The ACLU wrote that \"There\\'s simply no way to forecast how these immense powers – disproportionately accumulating in the hands of corporations seeking financial advantage and governments craving ever more control – will be used. Chances are big data and the Internet of Things will make it harder for us to control our own lives, as we grow increasingly transparent to powerful corporations and government institutions that are becoming more opaque to us.\"In response to rising concerns about privacy and smart technology, in 2007 the British Government stated it would follow formal Privacy by Design principles when implementing their smart metering program. The program would lead to replacement of traditional power meters with smart power meters, which could track and manage energy usage more accurately. However the British Computer Society is doubtful these principles were ever actually implemented. In 2009 the Dutch Parliament rejected a similar smart metering program, basing their decision on privacy concerns. The Dutch program later revised and passed in 2011.\\n\\n\\n=== Data storage ===\\nA challenge for producers of IoT applications is to clean, process and interpret the vast amount of data which is gathered by the sensors. There is a solution proposed for the analytics of the information referred to as Wireless Sensor Networks. These networks share data among sensor nodes that are sent to a distributed system for the analytics of the sensory data.Another challenge is the storage of this bulk data. Depending on the application, there could be high data acquisition requirements, which in turn lead to high storage requirements. Currently the Internet is already responsible for 5% of the total energy generated, and a \"daunting challenge to power\" IoT devices to collect and even store data still remains.Data silos, although a common challenge of legacy systems, still commonly occur with the implementation of IoT devices, particularly within manufacturing. As there are a lot of benefits to be gained from IoT and IIoT devices, the means in which the data is stored can present serious challenges without the principles of autonomy, transparency, and interoperability being considered. The challenges do not occur by the device itself, but the means in which databases are warehouses are set-up. These challenges were commonly identified in manufactures and enterprises which have begun upon digital transformation, and are part of the digital foundation, indicating that in order to receive the optimal benefits from IoT devices and for decision making, enterprises will have to first re-align their data storing methods. These challenges were identified by Keller (2021) when investigating the IT and application landscape of I4.0 implementation within German M&E manufactures.\\n\\n\\n=== Security ===\\nSecurity is the biggest concern in adopting Internet of things technology, with concerns that rapid development is happening without appropriate consideration of the profound security challenges involved and the regulatory changes that might be necessary. The rapid development of the Internet of Things (IoT) has allowed billions of devices to connect to the network. Due to too many connected devices and the limitation of communication security technology, various security issues gradually appear in the IoT.Most of the technical security concerns are similar to those of conventional servers, workstations and smartphones. These concerns include using weak authentication, forgetting to change default credentials, unencrypted messages sent between devices, SQL injections, Man-in-the-middle attacks, and poor handling of security updates. However, many IoT devices have severe operational limitations on the computational power available to them. These constraints often make them unable to directly use basic security measures such as implementing firewalls or using strong cryptosystems to encrypt their communications with other devices - and the low price and consumer focus of many devices makes a robust security patching system uncommon.Rather than conventional security vulnerabilities, fault injection attacks are on the rise and targeting IoT devices. A fault injection attack is a physical attack on a device to purposefully introduce faults in the system to change the intended behavior. Faults might happen unintentionally by environmental noises and electromagnetic fields. There are ideas stemmed from control-flow integrity (CFI) to prevent fault injection attacks and system recovery to a healthy state before the fault.Internet of things devices also have access to new areas of data, and can often control physical devices, so that even by 2014 it was possible to say that many Internet-connected appliances could already \"spy on people in their own homes\" including televisions, kitchen appliances, cameras, and thermostats. Computer-controlled devices in automobiles such as brakes, engine, locks, hood and trunk releases, horn, heat, and dashboard have been shown to be vulnerable to attackers who have access to the on-board network. In some cases, vehicle computer systems are Internet-connected, allowing them to be exploited remotely. By 2008 security researchers had shown the ability to remotely control pacemakers without authority. Later hackers demonstrated remote control of insulin pumps and implantable cardioverter defibrillators.Poorly secured Internet-accessible IoT devices can also be subverted to attack others. In 2016, a distributed denial of service attack powered by Internet of things devices running the Mirai malware took down a DNS provider and major web sites. The Mirai Botnet had infected roughly 65,000 IoT devices within the first 20 hours. Eventually the infections increased to around 200,000 to 300,000 infections. Brazil, Colombia and Vietnam made up of 41.5% of the infections. The Mirai Botnet had singled out specific IoT devices that consisted of DVRs, IP cameras, routers and printers. Top vendors that contained the most infected devices were identified as Dahua, Huawei, ZTE, Cisco, ZyXEL and MikroTik. In May 2017, Junade Ali, a Computer Scientist at Cloudflare noted that native DDoS vulnerabilities exist in IoT devices due to a poor implementation of the Publish–subscribe pattern. These sorts of attacks have caused security experts to view IoT as a real threat to Internet services.The U.S. National Intelligence Council in an unclassified report maintains that it would be hard to deny \"access to networks of sensors and remotely-controlled objects by enemies of the United States, criminals, and mischief makers... An open market for aggregated sensor data could serve the interests of commerce and security no less than it helps criminals and spies identify vulnerable targets. Thus, massively parallel sensor fusion may undermine social cohesion, if it proves to be fundamentally incompatible with Fourth-Amendment guarantees against unreasonable search.\" In general, the intelligence community views the Internet of things as a rich source of data.On 31 January 2019, the Washington Post wrote an article regarding the security and ethical challenges that can occur with IoT doorbells and cameras: \"Last month, Ring got caught allowing its team in Ukraine to view and annotate certain user videos; the company says it only looks at publicly shared videos and those from Ring owners who provide consent. Just last week, a California family\\'s Nest camera let a hacker take over and broadcast fake audio warnings about a missile attack, not to mention peer in on them, when they used a weak password.\"There have been a range of responses to concerns over security. The Internet of Things Security Foundation (IoTSF) was launched on 23 September 2015 with a mission to secure the Internet of things by promoting knowledge and best practice. Its founding board is made from technology providers and telecommunications companies. In addition, large IT companies are continually developing innovative solutions to ensure the security of IoT devices. In 2017, Mozilla launched Project Things, which allows to route IoT devices through a safe Web of Things gateway. As per the estimates from KBV Research, the overall IoT security market would grow at 27.9% rate during 2016–2022 as a result of growing infrastructural concerns and diversified usage of Internet of things.Governmental regulation is argued by some to be necessary to secure IoT devices and the wider Internet – as market incentives to secure IoT devices is insufficient. It was found that due to the nature of most of the IoT development boards, they generate predictable and weak keys which make it easy to be utilized by Man-in-the-middle attack. However, various hardening approaches were proposed by many researchers to resolve the issue of SSH weak implementation and weak keys.IoT security within the field of manufacturing presents different challenges, and varying perspectives. Within the EU and Germany, data protection is constantly referenced throughout manufacturing and digital policy particularly that of I4.0. However, the attitude towards data security differs from the enterprise perspective whereas there is an emphasis on less data protection in the form of GDPR as the data being collected from IoT devices in the manufacturing sector does not display personal details. Yet, research has indicated that manufacturing experts are concerned about \"data security for protecting machine technology from international competitors with the ever-greater push for interconnectivity\".\\n\\n\\n=== Safety ===\\nIoT systems are typically controlled by event-driven smart apps that take as input either sensed data, user inputs, or other external triggers (from the Internet) and command one or more actuators towards providing different forms of automation. Examples of sensors include smoke detectors, motion sensors, and contact sensors. Examples of actuators include smart locks, smart power outlets, and door controls. Popular control platforms on which third-party developers can build smart apps that interact wirelessly with these sensors and actuators include Samsung\\'s SmartThings, Apple\\'s HomeKit, and Amazon\\'s Alexa, among others.\\nA problem specific to IoT systems is that buggy apps, unforeseen bad app interactions, or device/communication failures, can cause unsafe and dangerous physical states, e.g., \"unlock the entrance door when no one is at home\" or \"turn off the heater when the temperature is below 0 degrees Celsius and people are sleeping at night\". Detecting flaws that lead to such states, requires a holistic view of installed apps, component devices, their configurations, and more importantly, how they interact. Recently, researchers from the University of California Riverside have proposed IotSan, a novel practical system that uses model checking as a building block to reveal \"interaction-level\" flaws by identifying events that can lead the system to unsafe states. They have evaluated IotSan on the Samsung SmartThings platform. From 76 manually configured systems, IotSan detects 147 vulnerabilities (i.e., violations of safe physical states/properties).\\n\\n\\n=== Design ===\\nGiven widespread recognition of the evolving nature of the design and management of the Internet of things, sustainable and secure deployment of IoT solutions must design for \"anarchic scalability\". Application of the concept of anarchic scalability can be extended to physical systems (i.e. controlled real-world objects), by virtue of those systems being designed to account for uncertain management futures. This hard anarchic scalability thus provides a pathway forward to fully realize the potential of Internet-of-things solutions by selectively constraining physical systems to allow for all management regimes without risking physical failure.Brown University computer scientist Michael Littman has argued that successful execution of the Internet of things requires consideration of the interface\\'s usability as well as the technology itself. These interfaces need to be not only more user-friendly but also better integrated: \"If users need to learn different interfaces for their vacuums, their locks, their sprinklers, their lights, and their coffeemakers, it\\'s tough to say that their lives have been made any easier.\"\\n\\n\\n=== Environmental sustainability impact ===\\nA concern regarding Internet-of-things technologies pertains to the environmental impacts of the manufacture, use, and eventual disposal of all these semiconductor-rich devices. Modern electronics are replete with a wide variety of heavy metals and rare-earth metals, as well as highly toxic synthetic chemicals. This makes them extremely difficult to properly recycle. Electronic components are often incinerated or placed in regular landfills. Furthermore, the human and environmental cost of mining the rare-earth metals that are integral to modern electronic components continues to grow. This leads to societal questions concerning the environmental impacts of IoT devices over their lifetime.\\n\\n\\n=== Intentional obsolescence of devices ===\\nThe Electronic Frontier Foundation has raised concerns that companies can use the technologies necessary to support connected devices to intentionally disable or \"brick\" their customers\\' devices via a remote software update or by disabling a service necessary to the operation of the device. In one example, home automation devices sold with the promise of a \"Lifetime Subscription\" were rendered useless after Nest Labs acquired Revolv and made the decision to shut down the central servers the Revolv devices had used to operate. As Nest is a company owned by Alphabet (Google\\'s parent company), the EFF argues this sets a \"terrible precedent for a company with ambitions to sell self-driving cars, medical devices, and other high-end gadgets that may be essential to a person\\'s livelihood or physical safety.\"Owners should be free to point their devices to a different server or collaborate on improved software. But such action violates the United States DMCA section 1201, which only has an exemption for \"local use\". This forces tinkerers who want to keep using their own equipment into a legal grey area. EFF thinks buyers should refuse electronics and software that prioritize the manufacturer\\'s wishes above their own.Examples of post-sale manipulations include Google Nest Revolv, disabled privacy settings on Android, Sony disabling Linux on PlayStation 3, enforced EULA on Wii U.\\n\\n\\n=== Confusing terminology ===\\nKevin Lonergan at Information Age, a business technology magazine, has referred to the terms surrounding the IoT as a \"terminology zoo\". The lack of clear terminology is not \"useful from a practical point of view\" and a \"source of confusion for the end user\". A company operating in the IoT space could be working in anything related to sensor technology, networking, embedded systems, or analytics. According to Lonergan, the term IoT was coined before smart phones, tablets, and devices as we know them today existed, and there is a long list of terms with varying degrees of overlap and technological convergence: Internet of things, Internet of everything (IoE), Internet of goods (supply chain), industrial Internet, pervasive computing, pervasive sensing, ubiquitous computing, cyber-physical systems (CPS), wireless sensor networks (WSN), smart objects, digital twin, cyberobjects or avatars, cooperating objects, machine to machine (M2M), ambient intelligence (AmI), Operational technology (OT), and information technology (IT). Regarding IIoT, an industrial sub-field of IoT, the Industrial Internet Consortium\\'s Vocabulary Task Group has created a \"common and reusable vocabulary of terms\" to ensure \"consistent terminology\" across publications issued by the Industrial Internet Consortium. IoT One has created an IoT Terms Database including a New Term Alert to be notified when a new term is published. As of March 2020, this database aggregates 807 IoT-related terms, while keeping material \"transparent and comprehensive\".\\n\\n\\n== Adoption barriers ==\\n\\n\\n=== Lack of interoperability and unclear value propositions ===\\nDespite a shared belief in the potential of the IoT, industry leaders and consumers are facing barriers to adopt IoT technology more widely. Mike Farley argued in Forbes that while IoT solutions appeal to early adopters, they either lack interoperability or a clear use case for end-users. A study by Ericsson regarding the adoption of IoT among Danish companies suggests that many struggle \"to pinpoint exactly where the value of IoT lies for them\".\\n\\n\\n=== Privacy and security concerns ===\\nAs for IoT, especially in regards to consumer IoT, information about a user\\'s daily routine is collected so that the \"things\" around the user can cooperate to provide better services that fulfill personal preference. When the collected information which describes a user in detail travels through multiple hops in a network, due to a diverse integration of services, devices and network, the information stored on a device is vulnerable to privacy violation by compromising nodes existing in an IoT network.For example, on 21 October 2016, a multiple distributed denial of service (DDoS) attacks systems operated by domain name system provider Dyn, which caused the inaccessibility of several websites, such as GitHub, Twitter, and others. This attack is executed through a botnet consisting of a large number of IoT devices including IP cameras, gateways, and even baby monitors.Fundamentally there are 4 security objectives that the IoT system requires: (1) data confidentiality: unauthorised parties cannot have access to the transmitted and stored data; (2) data integrity: intentional and unintentional corruption of transmitted and stored data must be detected; (3) non-repudiation: the sender cannot deny having sent a given message; (4) data availability: the transmitted and stored data should be available to authorised parties even with the denial-of-service (DOS) attacks.Information privacy regulations also require organisations to practice \"reasonable security\". California\\'s SB-327 Information privacy: connected devices \"would require a manufacturer of a connected device, as those terms are defined, to equip the device with a reasonable security feature or features that are appropriate to the nature and function of the device, appropriate to the information it may collect, contain, or transmit, and designed to protect the device and any information contained therein from unauthorised access, destruction, use, modification, or disclosure, as specified\". As each organisation\\'s environment is unique, it can prove challenging to demonstrate what \"reasonable security\" is and what potential risks could be involved for the business. Oregon\\'s HB 2395 Archived 30 September 2020 at the Wayback Machine also \"requires [a] person that manufactures, sells or offers to sell connected device] manufacturer to equip connected device with reasonable security features that protect connected device and information that connected device collects, contains, stores or transmits] stores from access, destruction, modification, use or disclosure that consumer does not authorise.\"According to antivirus provider Kaspersky, there were 639 million data breaches of IoT devices in 2020 and 1.5 billion breaches in the first six months of 2021.\\n\\n\\n=== Traditional governance structure ===\\nA study issued by Ericsson regarding the adoption of Internet of things among Danish companies identified a \"clash between IoT and companies\\' traditional governance structures, as IoT still presents both uncertainties and a lack of historical precedence.\" Among the respondents interviewed, 60 percent stated that they \"do not believe they have the organizational capabilities, and three of four do not believe they have the processes needed, to capture the IoT opportunity.\" This has led to a need to understand organizational culture in order to facilitate organizational design processes and to test new innovation management practices. A lack of digital leadership in the age of digital transformation has also stifled innovation and IoT adoption to a degree that many companies, in the face of uncertainty, \"were waiting for the market dynamics to play out\", or further action in regards to IoT \"was pending competitor moves, customer pull, or regulatory requirements\". Some of these companies risk being \"kodaked\" – \"Kodak was a market leader until digital disruption eclipsed film photography with digital photos\" – failing to \"see the disruptive forces affecting their industry\" and \"to truly embrace the new business models the disruptive change opens up\". Scott Anthony has written in Harvard Business Review that Kodak \"created a digital camera, invested in the technology, and even understood that photos would be shared online\" but ultimately failed to realize that \"online photo sharing was the new business, not just a way to expand the printing business.\"\\n\\n\\n=== Business planning and project management ===\\nAccording to 2018 study, 70–75% of IoT deployments were stuck in the pilot or prototype stage, unable to reach scale due in part to a lack of business planning.Even though scientists, engineers, and managers across the world are continuously working to create and exploit the benefits of IoT products, there are some flaws in the governance, management and implementation of such projects. Despite tremendous forward momentum in the field of information and other underlying technologies, IoT still remains a complex area and the problem of how IoT projects are managed still needs to be addressed. IoT projects must be run differently than simple and traditional IT, manufacturing or construction projects. Because IoT projects have longer project timelines, a lack of skilled resources and several security/legal issues, there is a need for new and specifically designed project processes. The following management techniques should improve the success rate of IoT projects:\\nA separate research and development phase \\nA Proof-of-Concept/Prototype before the actual project begins \\nProject managers with interdisciplinary technical knowledge \\nUniversally defined business and technical jargon\\n\\n\\n== See also ==\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== Bibliography ==\\n\\nAcharjya, D.P.; Geetha, M.K., eds. (2017). Internet of Things: Novel Advances and Envisioned Applications. Springer. p. 311. ISBN 9783319534725.\\nLi, S.; Xu, L.D., eds. (2017). Securing the Internet of Things. Syngress. p. 154. ISBN 9780128045053.\\nRowland, C.; Goodman, E.; Charlier, M.; et al., eds. (2015). Designing Connected Products: UX for the Consumer Internet of Things. O\\'Reilly Media. p. 726. ISBN 9781449372569.\\nThomas, Jayant; Traukina, Alena (2018). Industrial Internet Application Development: Simplify IIoT development using the elasticity of Public Cloud and Native Cloud Services. Packt Publishing. p. 25. ISBN 978-1788298599.\\nStephenson, W. David (2018). The Future Is Smart: how your company can capitalize on the Internet of Things--and win in a connected economy. HarperCollins Leadership. p. 250. ISBN 9780814439777.',\n",
              " 'A computer network is a set of computers sharing resources located on or provided by network nodes. Computers use common communication protocols over digital interconnections to communicate with each other. These interconnections are made up of telecommunication network technologies based on physically wired, optical, and wireless radio-frequency methods that may be arranged in a variety of network topologies.\\nThe nodes of a computer network can include personal computers, servers, networking hardware, or other specialized or general-purpose hosts. They are identified by network addresses and may have hostnames. Hostnames serve as memorable labels for the nodes and are rarely changed after initial assignment. Network addresses serve for locating and identifying the nodes by communication protocols such as the Internet Protocol.\\nComputer networks may be classified by many criteria, including the transmission medium used to carry signals, bandwidth, communications protocols to organize network traffic, the network size, the topology, traffic control mechanisms, and organizational intent.Computer networks support many applications and services, such as access to the World Wide Web, digital video and audio, shared use of application and storage servers, printers and fax machines, and use of email and instant messaging applications.\\n\\n\\n== History ==\\nComputer networking may be considered a branch of computer science, computer engineering, and telecommunications, since it relies on the theoretical and practical application of the related disciplines. Computer networking was influenced by a wide array of technology developments and historical milestones.\\n\\nIn the late 1950s, a network of computers was built for the U.S. military Semi-Automatic Ground Environment (SAGE) radar system using the Bell 101 modem. It was the first commercial modem for computers, released by AT&T Corporation in 1958. The modem allowed digital data to be transmitted over regular unconditioned telephone lines at a speed of 110 bits per second (bit/s).\\nIn 1959, Christopher Strachey filed a patent application for time-sharing and John McCarthy initiated the first project to implement time-sharing of user programs at MIT. Stratchey passed the concept on to J. C. R. Licklider at the inaugural UNESCO Information Processing Conference in Paris that year. McCarthy was instrumental in the creation of three of the earliest time-sharing systems (the Compatible Time-Sharing System in 1961, the BBN Time-Sharing System in 1962, and the Dartmouth Time Sharing System in 1963).\\nIn 1959, Anatoly Kitov proposed to the Central Committee of the Communist Party of the Soviet Union a detailed plan for the re-organisation of the control of the Soviet armed forces and of the Soviet economy on the basis of a network of computing centres. Kitov\\'s proposal was rejected, as later was the 1962 OGAS economy management network project.\\nIn 1960, the commercial airline reservation system semi-automatic business research environment (SABRE) went online with two connected mainframes.\\nIn 1963, J. C. R. Licklider sent a memorandum to office colleagues discussing the concept of the \"Intergalactic Computer Network\", a computer network intended to allow general communications among computer users.\\nThroughout the 1960s, Paul Baran and Donald Davies independently developed the concept of packet switching to transfer information between computers over a network. Davies pioneered the implementation of the concept. The NPL network, a local area network at the National Physical Laboratory (United Kingdom) used a line speed of 768 kbit/s and later high-speed T1 links (1.544 Mbit/s line rate).\\nIn 1965, Western Electric introduced the first widely used telephone switch that implemented computer control in the switching fabric.\\nIn 1969, the first four nodes of the ARPANET were connected using 50 kbit/s circuits between the University of California at Los Angeles, the Stanford Research Institute, the University of California at Santa Barbara, and the University of Utah. In the early 1970s, Leonard Kleinrock carried out mathematical work to model the performance of packet-switched networks, which underpinned the development of the ARPANET. His theoretical work on hierarchical routing in the late 1970s with student Farouk Kamoun remains critical to the operation of the Internet today.\\nIn 1972, commercial services were first deployed on public data networks in Europe, which began using X.25 in the late 1970s and spread across the globe. The underlying infrastructure was used for expanding TCP/IP networks in the 1980s.\\nIn 1973, the French CYCLADES network, directed by Louis Pouzin was the first to make the hosts responsible for the reliable delivery of data, rather than this being a centralized service of the network itself.\\nIn 1973, Peter Kirstein put internetworking into practice at University College London (UCL), connecting the ARPANET to British academic networks, the first international heterogeneous computer network.\\nIn 1973, Robert Metcalfe wrote a formal memo at Xerox PARC describing Ethernet, a networking system that was based on the Aloha network, developed in the 1960s by Norman Abramson and colleagues at the University of Hawaii. In July 1976, Robert Metcalfe and David Boggs published their paper \"Ethernet: Distributed Packet Switching for Local Computer Networks\" and collaborated on several patents received in 1977 and 1978.\\nIn 1974, Vint Cerf, Yogen Dalal, and Carl Sunshine published the Transmission Control Protocol (TCP) specification, RFC 675, coining the term Internet as a shorthand for internetworking.\\nIn 1976, John Murphy of Datapoint Corporation created ARCNET, a token-passing network first used to share storage devices.\\nIn 1977, the first long-distance fiber network was deployed by GTE in Long Beach, California.\\nIn 1977, Xerox Network Systems (XNS) was developed by Robert Metcalfe and Yogen Dalal at Xerox.\\nIn 1979, Robert Metcalfe pursued making Ethernet an open standard.\\nIn 1980, Ethernet was upgraded from the original 2.94 Mbit/s protocol to the 10 Mbit/s protocol, which was developed by Ron Crane, Bob Garner, Roy Ogus, and Yogen Dalal.\\nIn 1995, the transmission speed capacity for Ethernet increased from 10 Mbit/s to 100 Mbit/s. By 1998, Ethernet supported transmission speeds of 1 Gbit/s. Subsequently, higher speeds of up to 400 Gbit/s were added (as of 2018). The scaling of Ethernet has been a contributing factor to its continued use.\\n\\n\\n== Use ==\\nComputer networks extend interpersonal communications by electronic means with various technologies, such as email, instant messaging, online chat, voice and video telephone calls, and video conferencing. A network allows sharing of network and computing resources. Users may access and use resources provided by devices on the network, such as printing a document on a shared network printer or use of a shared storage device. A network allows sharing of files, data, and other types of information giving authorized users the ability to access information stored on other computers on the network. Distributed computing uses computing resources across a network to accomplish tasks.\\n\\n\\n== Network packet ==\\nMost modern computer networks use protocols based on packet-mode transmission. A network packet is a formatted unit of data carried by a packet-switched network.\\nPackets consist of two types of data: control information and user data (payload). The control information provides data the network needs to deliver the user data, for example, source and destination network addresses, error detection codes, and sequencing information. Typically, control information is found in packet headers and trailers, with payload data in between.\\nWith packets, the bandwidth of the transmission medium can be better shared among users than if the network were circuit switched. When one user is not sending packets, the link can be filled with packets from other users, and so the cost can be shared, with relatively little interference, provided the link is not overused. Often the route a packet needs to take through a network is not immediately available. In that case, the packet is queued and waits until a link is free.\\nThe physical link technologies of packet networks typically limit the size of packets to a certain maximum transmission unit (MTU). A longer message may be fragmented before it is transferred and once the packets arrive, they are reassembled to construct the original message.\\n\\n\\n== Network topology ==\\n\\nThe physical or geographic locations of network nodes and links generally have relatively little effect on a network, but the topology of interconnections of a network can significantly affect its throughput and reliability. With many technologies, such as bus or star networks, a single failure can cause the network to fail entirely. In general, the more interconnections there are, the more robust the network is; but the more expensive it is to install. Therefore, most network diagrams are arranged by their network topology which is the map of logical interconnections of network hosts.\\nCommon topologies are:\\n\\nBus network: all nodes are connected to a common medium along this medium. This was the layout used in the original Ethernet, called 10BASE5 and 10BASE2. This is still a common topology on the data link layer, although modern physical layer variants use point-to-point links instead, forming a star or a tree.\\nStar network: all nodes are connected to a special central node. This is the typical layout found in a small switched Ethernet LAN, where each client connects to a central network switch, and logically in a wireless LAN, where each wireless client associates with the central wireless access point.\\nRing network: each node is connected to its left and right neighbor node, such that all nodes are connected and that each node can reach each other node by traversing nodes left- or rightwards. Token ring networks, and the Fiber Distributed Data Interface (FDDI), made use of such a topology.\\nMesh network: each node is connected to an arbitrary number of neighbors in such a way that there is at least one traversal from any node to any other.\\nFully connected network: each node is connected to every other node in the network.\\nTree network: nodes are arranged hierarchically. This is the natural topology for a larger Ethernet network with multiple switches and without redundant meshing.The physical layout of the nodes in a network may not necessarily reflect the network topology. As an example, with FDDI, the network topology is a ring, but the physical topology is often a star, because all neighboring connections can be routed via a central physical location. Physical layout is not completely irrelevant, however, as common ducting and equipment locations can represent single points of failure due to issues like fires, power failures and flooding.\\n\\n\\n=== Overlay network ===\\nAn overlay network is a virtual network that is built on top of another network. Nodes in the overlay network are connected by virtual or logical links.  Each link corresponds to a path, perhaps through many physical links, in the underlying network. The topology of the overlay network may (and often does) differ from that of the underlying one. For example, many peer-to-peer networks are overlay networks.  They are organized as nodes of a virtual system of links that run on top of the Internet.Overlay networks have been around since the invention of networking when computer systems were connected over telephone lines using modems before any data network existed.\\nThe most striking example of an overlay network is the Internet itself. The Internet itself was initially built as an overlay on the telephone network. Even today, each Internet node can communicate with virtually any other through an underlying mesh of sub-networks of wildly different topologies and technologies. Address resolution and routing are the means that allow mapping of a fully connected IP overlay network to its underlying network.\\nAnother example of an overlay network is a distributed hash table, which maps keys to nodes in the network. In this case, the underlying network is an IP network, and the overlay network is a table (actually a map) indexed by keys.\\nOverlay networks have also been proposed as a way to improve Internet routing, such as through quality of service guarantees achieve higher-quality streaming media. Previous proposals such as IntServ, DiffServ, and IP multicast have not seen wide acceptance largely because they require modification of all routers in the network.  On the other hand, an overlay network can be incrementally deployed on end-hosts running the overlay protocol software, without cooperation from Internet service providers.  The overlay network has no control over how packets are routed in the underlying network between two overlay nodes, but it can control, for example, the sequence of overlay nodes that a message traverses before it reaches its destination.\\nFor example, Akamai Technologies manages an overlay network that provides reliable, efficient content delivery (a kind of multicast).  Academic research includes end system multicast, resilient routing and quality of service studies, among others.\\n\\n\\n== Network links ==\\n\\nThe transmission media (often referred to in the literature as the physical medium) used to link devices to form a computer network include electrical cable, optical fiber, and free space. In the OSI model, the software to handle the media is defined at layers 1 and 2 — the physical layer and the data link layer.\\nA widely adopted family that uses copper and fiber media in local area network (LAN) technology are collectively known as Ethernet. The media and protocol standards that enable communication between networked devices over Ethernet are defined by IEEE 802.3.  Wireless LAN standards use radio waves, others use infrared signals as a transmission medium. Power line communication uses a building\\'s power cabling to transmit data.\\n\\n\\n=== Wired ===\\nThe following classes of wired technologies are used in computer networking.\\n\\nCoaxial cable is widely used for cable television systems, office buildings, and other work-sites for local area networks. Transmission speed ranges from 200 million bits per second to more than 500 million bits per second.\\nITU-T G.hn technology uses existing home wiring (coaxial cable, phone lines and power lines) to create a high-speed local area network.\\nTwisted pair cabling is used for wired Ethernet and other standards. It typically consists of 4 pairs of copper cabling that can be utilized for both voice and data transmission. The use of two wires twisted together helps to reduce crosstalk and electromagnetic induction. The transmission speed ranges from 2 Mbit/s to 10 Gbit/s. Twisted pair cabling comes in two forms: unshielded twisted pair (UTP) and shielded twisted-pair (STP). Each form comes in several category ratings, designed for use in various scenarios.An optical fiber is a glass fiber. It carries pulses of light that represent data via lasers and optical amplifiers. Some advantages of optical fibers over metal wires are very low transmission loss and immunity to electrical interference. Using dense wave division multiplexing, optical fibers can simultaneously carry multiple streams of data on different wavelengths of light, which greatly increases the rate that data can be sent to up to trillions of bits per second. Optic fibers can be used for long runs of cable carrying very high data rates, and are used for undersea communications cables to interconnect continents. There are two basic types of fiber optics, single-mode optical fiber (SMF) and multi-mode optical fiber (MMF).  Single-mode fiber has the advantage of being able to sustain a coherent signal for dozens or even a hundred kilometers. Multimode fiber is cheaper to terminate but is limited to a few hundred or even only a few dozens of meters, depending on the data rate and cable grade.\\n\\n\\n=== Wireless ===\\n\\nNetwork connections can be established wirelessly using radio or other electromagnetic means of communication.\\n\\n Terrestrial microwave – Terrestrial microwave communication uses Earth-based transmitters and receivers resembling satellite dishes. Terrestrial microwaves are in the low gigahertz range, which limits all communications to line-of-sight. Relay stations are spaced approximately 40 miles (64 km) apart.\\nCommunications satellites – Satellites also communicate via microwave. The satellites are stationed in space, typically in geosynchronous orbit 35,400 km (22,000 mi) above the equator. These Earth-orbiting systems are capable of receiving and relaying voice, data, and TV signals.\\nCellular networks use several radio communications technologies. The systems divide the region covered into multiple geographic areas. Each area is served by a low-power transceiver.\\nRadio and spread spectrum technologies – Wireless LANs use a high-frequency radio technology similar to digital cellular. Wireless LANs use spread spectrum technology to enable communication between multiple devices in a limited area. IEEE 802.11 defines a common flavor of open-standards wireless radio-wave technology known as Wi-Fi.\\nFree-space optical communication uses visible or invisible light for communications. In most cases, line-of-sight propagation is used, which limits the physical positioning of communicating devices.\\nExtending the Internet to interplanetary dimensions via radio waves and optical means, the Interplanetary Internet.\\nIP over Avian Carriers was a humorous April fool\\'s Request for Comments, issued as RFC 1149. It was implemented in real life in 2001.The last two cases have a large round-trip delay time, which gives slow two-way communication but does not prevent sending large amounts of information (they can have high throughput).\\n\\n\\n== Network nodes ==\\n\\nApart from any physical transmission media, networks are built from additional basic system building blocks, such as network interface controllers, repeaters, hubs, bridges, switches, routers, modems, and firewalls. Any particular piece of equipment will frequently contain multiple building blocks and so may perform multiple functions.\\n\\n\\n=== Network interfaces ===\\n\\nA network interface controller (NIC) is computer hardware that connects the computer to the network media and has the ability to process low-level network information. For example, the NIC may have a connector for accepting a cable, or an aerial for wireless transmission and reception, and the associated circuitry.\\nIn Ethernet networks, each NIC has a unique Media Access Control (MAC) address—usually stored in the controller\\'s permanent memory. To avoid address conflicts between network devices, the Institute of Electrical and Electronics Engineers (IEEE) maintains and administers MAC address uniqueness. The size of an Ethernet MAC address is six octets. The three most significant octets are reserved to identify NIC manufacturers. These manufacturers, using only their assigned prefixes, uniquely assign the three least-significant octets of every Ethernet interface they produce.\\n\\n\\n=== Repeaters and hubs ===\\n\\nA repeater is an electronic device that receives a network signal, cleans it of unnecessary noise and regenerates it. The signal is retransmitted at a higher power level, or to the other side of obstruction so that the signal can cover longer distances without degradation. In most twisted-pair Ethernet configurations, repeaters are required for cable that runs longer than 100 meters. With fiber optics, repeaters can be tens or even hundreds of kilometers apart.\\nRepeaters work on the physical layer of the OSI model but still require a small amount of time to regenerate the signal. This can cause a propagation delay that affects network performance and may affect proper function. As a result, many network architectures limit the number of repeaters used in a network, e.g., the Ethernet 5-4-3 rule.\\nAn Ethernet repeater with multiple ports is known as an Ethernet hub. In addition to reconditioning and distributing network signals, a repeater hub assists with collision detection and fault isolation for the network. Hubs and repeaters in LANs have been largely obsoleted by modern network switches.\\n\\n\\n=== Bridges and switches ===\\n\\nNetwork bridges and network switches are distinct from a hub in that they only forward frames to the ports involved in the communication whereas a hub forwards to all ports. Bridges only have two ports but a switch can be thought of as a multi-port bridge. Switches normally have numerous ports, facilitating a star topology for devices, and for cascading additional switches.\\nBridges and switches operate at the data link layer (layer 2) of the OSI model and bridge traffic between two or more network segments to form a single local network. Both are devices that forward frames of data between ports based on the destination MAC address in each frame.\\nThey learn the association of physical ports to MAC addresses by examining the source addresses of received frames and only forward the frame when necessary. If an unknown destination MAC is targeted, the device broadcasts the request to all ports except the source, and discovers the location from the reply.\\nBridges and switches divide the network\\'s collision domain but maintain a single broadcast domain. Network segmentation through bridging and switching helps break down a large, congested network into an aggregation of smaller, more efficient networks.\\n\\n\\n=== Routers ===\\n\\nA router is an internetworking device that forwards packets between networks by processing the addressing or routing information included in the packet.  The routing information is often processed in conjunction with the routing table.  A router uses its routing table to determine where to forward packets and does not require broadcasting packets which is inefficient for very big networks.\\n\\n\\n=== Modems ===\\n\\nModems (modulator-demodulator) are used to connect network nodes via wire not originally designed for digital network traffic, or for wireless. To do this one or more carrier signals are modulated by the digital signal to produce an analog signal that can be tailored to give the required properties for transmission. Early modems modulated audio signals sent over a standard voice telephone line. Modems are still commonly used for telephone lines, using a digital subscriber line technology and cable television systems using DOCSIS technology.\\n\\n\\n=== Firewalls ===\\n\\nA firewall is a network device or software for controlling network security and access rules. Firewalls are inserted in connections between secure internal networks and potentially insecure external networks such as the Internet. Firewalls are typically configured to reject access requests from unrecognized sources while allowing actions from recognized ones. The vital role firewalls play in network security grows in parallel with the constant increase in cyber attacks.\\n\\n\\n== Communication protocols ==\\nA communication protocol is a set of rules for exchanging information over a network. Communication protocols have various characteristics.  They may be connection-oriented or connectionless, they may use circuit mode or packet switching, and they may use hierarchical addressing or flat addressing.\\nIn a protocol stack, often constructed per the OSI model, communications functions are divided up into protocol layers, where each layer leverages the services of the layer below it until the lowest layer controls the hardware that sends information across the media. The use of protocol layering is ubiquitous across the field of computer networking. An important example of a protocol stack is HTTP (the World Wide Web protocol) running over TCP over IP (the Internet protocols) over IEEE 802.11 (the Wi-Fi protocol). This stack is used between the wireless router and the home user\\'s personal computer when the user is surfing the web.\\nThere are many communication protocols, a few of which are described below.\\n\\n\\n=== Common protocols ===\\n\\n\\n==== Internet protocol suite ====\\nThe Internet protocol suite, also called TCP/IP, is the foundation of all modern networking. It offers connection-less and connection-oriented services over an inherently unreliable network traversed by datagram transmission using Internet protocol (IP). At its core, the protocol suite defines the addressing, identification, and routing specifications for Internet Protocol Version 4 (IPv4) and for IPv6, the next generation of the protocol with a much enlarged addressing capability. The Internet protocol suite is the defining set of protocols for the Internet.\\n\\n\\n==== IEEE 802 ====\\nIEEE 802 is a family of IEEE standards dealing with local area networks and metropolitan area networks. The complete IEEE 802 protocol suite provides a diverse set of networking capabilities. The protocols have a flat addressing scheme. They operate mostly at layers 1 and 2 of the OSI model.\\nFor example, MAC bridging (IEEE 802.1D) deals with the routing of Ethernet packets using a Spanning Tree Protocol. IEEE 802.1Q describes VLANs, and IEEE 802.1X defines a port-based Network Access Control protocol, which forms the basis for the authentication mechanisms used in VLANs (but it is also found in WLANs) – it is what the home user sees when the user has to enter a \"wireless access key\".\\n\\n\\n===== Ethernet =====\\nEthernet is a family of technologies used in wired LANs. It is described by a set of standards together called IEEE 802.3 published by the Institute of Electrical and Electronics Engineers.\\n\\n\\n===== Wireless LAN =====\\nWireless LAN based on the IEEE 802.11 standards, also widely known as WLAN or WiFi, is probably the most well-known member of the IEEE 802 protocol family for home users today. IEEE 802.11 shares many properties with wired Ethernet.\\n\\n\\n==== SONET/SDH ====\\nSynchronous optical networking (SONET) and Synchronous Digital Hierarchy (SDH) are standardized multiplexing protocols that transfer multiple digital bit streams over optical fiber using lasers. They were originally designed to transport circuit mode communications from a variety of different sources, primarily to support circuit-switched digital telephony. However, due to its protocol neutrality and transport-oriented features, SONET/SDH also was the obvious choice for transporting Asynchronous Transfer Mode (ATM) frames.\\n\\n\\n==== Asynchronous Transfer Mode ====\\nAsynchronous Transfer Mode (ATM) is a switching technique for telecommunication networks.  It uses asynchronous time-division multiplexing and encodes data into small, fixed-sized cells. This differs from other protocols such as the Internet protocol suite or Ethernet that use variable-sized packets or frames. ATM has similarities with both circuit and packet switched networking.  This makes it a good choice for a network that must handle both traditional high-throughput data traffic, and real-time, low-latency content such as voice and video. ATM uses a connection-oriented model in which a virtual circuit must be established between two endpoints before the actual data exchange begins.\\nATM still plays a role in the last mile, which is the connection between an Internet service provider and the home user.\\n\\n\\n==== Cellular standards ====\\nThere are a number of different digital cellular standards, including: Global System for Mobile Communications (GSM), General Packet Radio Service (GPRS), cdmaOne, CDMA2000, Evolution-Data Optimized (EV-DO), Enhanced Data Rates for GSM Evolution (EDGE), Universal Mobile Telecommunications System (UMTS), Digital Enhanced Cordless Telecommunications (DECT), Digital AMPS (IS-136/TDMA), and Integrated Digital Enhanced Network (iDEN).\\n\\n\\n=== Routing ===\\nRouting is the process of selecting network paths to carry network traffic. Routing is performed for many kinds of networks, including circuit switching networks and packet switched networks.\\nIn packet-switched networks, routing protocols direct packet forwarding through intermediate nodes. Intermediate nodes are typically network hardware devices such as routers, bridges, gateways, firewalls, or switches. General-purpose computers can also forward packets and perform routing, though because they lack specialized hardware, may offer limited performance. The routing process directs forwarding on the basis of routing tables, which maintain a record of the routes to various network destinations. Most routing algorithms use only one network path at a time. Multipath routing techniques enable the use of multiple alternative paths.\\nRouting can be contrasted with bridging in its assumption that network addresses are structured and that similar addresses imply proximity within the network. Structured addresses allow a single routing table entry to represent the route to a group of devices.  In large networks, the structured addressing used by routers outperforms unstructured addressing used by bridging. Structured IP addresses are used on the Internet. Unstructured MAC addresses are used for bridging on Ethernet and similar local area networks.\\n\\n\\n== Geographic scale ==\\nNetworks may be characterized by many properties or features, such as physical capacity, organizational purpose, user authorization, access rights, and others. Another distinct classification method is that of the physical extent or geographic scale.\\n\\n\\n=== Nanoscale network ===\\nA nanoscale network has key components implemented at the nanoscale, including message carriers, and leverages physical principles that differ from macroscale communication mechanisms. Nanoscale communication extends communication to very small sensors and actuators such as those found in biological systems and also tends to operate in environments that would be too harsh for other communication techniques.\\n\\n\\n=== Personal area network ===\\nA personal area network (PAN) is a computer network used for communication among computers and different information technological devices close to one person. Some examples of devices that are used in a PAN are personal computers, printers, fax machines, telephones, PDAs, scanners, and video game consoles. A PAN may include wired and wireless devices. The reach of a PAN typically extends to 10 meters. A wired PAN is usually constructed with USB and FireWire connections while technologies such as Bluetooth and infrared communication typically form a wireless PAN.\\n\\n\\n=== Local area network ===\\nA local area network (LAN) is a network that connects computers and devices in a limited geographical area such as a home, school, office building, or closely positioned group of buildings. Wired LANs are most commonly based on Ethernet technology.  Other networking technologies such as ITU-T G.hn also provide a way to create a wired LAN using existing wiring, such as coaxial cables, telephone lines, and power lines.A LAN can be connected to a wide area network (WAN) using a router. The defining characteristics of a LAN, in contrast to a WAN, include higher data transfer rates, limited geographic range, and lack of reliance on leased lines to provide connectivity. Current Ethernet or other IEEE 802.3 LAN technologies operate at data transfer rates up to and in excess of 100 Gbit/s, standardized by IEEE in 2010.\\n\\n\\n=== Home area network ===\\nA home area network (HAN) is a residential LAN used for communication between digital devices typically deployed in the home, usually a small number of personal computers and accessories, such as printers and mobile computing devices. An important function is the sharing of Internet access, often a broadband service through a cable Internet access or digital subscriber line (DSL) provider.\\n\\n\\n=== Storage area network ===\\nA storage area network (SAN) is a dedicated network that provides access to consolidated, block-level data storage. SANs are primarily used to make storage devices, such as disk arrays, tape libraries, and optical jukeboxes, accessible to servers so that the storage appears as locally attached devices to the operating system. A SAN typically has its own network of storage devices that are generally not accessible through the local area network by other devices. The cost and complexity of SANs dropped in the early 2000s to levels allowing wider adoption across both enterprise and small to medium-sized business environments.\\n\\n\\n=== Campus area network ===\\nA campus area network (CAN) is made up of an interconnection of LANs within a limited geographical area. The networking equipment (switches, routers) and transmission media (optical fiber, Cat5 cabling, etc.) are almost entirely owned by the campus tenant or owner (an enterprise, university, government, etc.).\\nFor example, a university campus network is likely to link a variety of campus buildings to connect academic colleges or departments, the library, and student residence halls.\\n\\n\\n=== Backbone network ===\\nA backbone network is part of a computer network infrastructure that provides a path for the exchange of information between different LANs or subnetworks.  A backbone can tie together diverse networks within the same building, across different buildings, or over a wide area. When designing a network backbone, network performance and network congestion are critical factors to take into account.  Normally, the backbone network\\'s capacity is greater than that of the individual networks connected to it.\\nFor example, a large company might implement a backbone network to connect departments that are located around the world. The equipment that ties together the departmental networks constitutes the network backbone. Another example of a backbone network is the Internet backbone, which is a massive, global system of fiber-optic cable and optical networking that carry the bulk of data between wide area networks (WANs), metro, regional, national and transoceanic networks.\\n\\n\\n=== Metropolitan area network ===\\nA metropolitan area network (MAN) is a large computer network that interconnects users with computer resources in a geographic region of the size of a metropolitan area.\\n\\n\\n=== Wide area network ===\\nA wide area network (WAN) is a computer network that covers a large geographic area such as a city, country, or spans even intercontinental distances.  A WAN uses a communications channel that combines many types of media such as telephone lines, cables, and airwaves. A WAN often makes use of transmission facilities provided by common carriers, such as telephone companies. WAN technologies generally function at the lower three layers of the OSI model: the physical layer, the data link layer, and the network layer.\\n\\n\\n=== Enterprise private network ===\\nAn enterprise private network is a network that a single organization builds to interconnect its office locations (e.g., production sites, head offices, remote offices, shops) so they can share computer resources.\\n\\n\\n=== Virtual private network ===\\nA virtual private network (VPN) is an overlay network in which some of the links between nodes are carried by open connections or virtual circuits in some larger network (e.g., the Internet) instead of by physical wires. The data link layer protocols of the virtual network are said to be tunneled through the larger network. One common application is secure communications through the public Internet, but a VPN need not have explicit security features, such as authentication or content encryption. VPNs, for example, can be used to separate the traffic of different user communities over an underlying network with strong security features.\\nVPN may have best-effort performance or may have a defined service level agreement (SLA) between the VPN customer and the VPN service provider.\\n\\n\\n=== Global area network ===\\nA global area network (GAN) is a network used for supporting mobile users across an arbitrary number of wireless LANs, satellite coverage areas, etc. The key challenge in mobile communications is handing off communications from one local coverage area to the next. In IEEE Project 802, this involves a succession of terrestrial wireless LANs.\\n\\n\\n== Organizational scope ==\\nNetworks are typically managed by the organizations that own them. Private enterprise networks may use a combination of intranets and extranets. They may also provide network access to the Internet, which has no single owner and permits virtually unlimited global connectivity.\\n\\n\\n=== Intranet ===\\nAn intranet is a set of networks that are under the control of a single administrative entity.  An intranet typically uses the Internet Protocol and IP-based tools such as web browsers and file transfer applications. The administrative entity limits the use of the intranet to its authorized users. Most commonly, an intranet is the internal LAN of an organization. A large intranet typically has at least one web server to provide users with organizational information.\\n\\n\\n=== Extranet ===\\nAn extranet is a network that is under the administrative control of a single organization but supports a limited connection to a specific external network.  For example, an organization may provide access to some aspects of its intranet to share data with its business partners or customers.  These other entities are not necessarily trusted from a security standpoint.  The network connection to an extranet is often, but not always, implemented via WAN technology.\\n\\n\\n=== Internet ===\\nAn internetwork is the connection of multiple different types of computer networks to form a single computer network using higher-layer network protocols and connecting them together using routers.\\nThe Internet is the largest example of internetwork. It is a global system of interconnected governmental, academic, corporate, public, and private computer networks. It is based on the networking technologies of the Internet protocol suite. It is the successor of the Advanced Research Projects Agency Network (ARPANET) developed by DARPA of the United States Department of Defense. The Internet utilizes copper communications and an optical networking backbone to enable the World Wide Web (WWW), the Internet of things, video transfer, and a broad range of information services.\\nParticipants on the Internet use a diverse array of methods of several hundred documented, and often standardized, protocols compatible with the Internet protocol suite and the IP addressing system administered by the Internet Assigned Numbers Authority and address registries. Service providers and large enterprises exchange information about the reachability of their address spaces through the Border Gateway Protocol (BGP), forming a redundant worldwide mesh of transmission paths.\\n\\n\\n=== Darknet ===\\nA darknet is an overlay network, typically running on the Internet, that is only accessible through specialized software. It is an anonymizing network where connections are made only between trusted peers — sometimes called friends (F2F) — using non-standard protocols and ports.\\nDarknets are distinct from other distributed peer-to-peer networks as sharing is anonymous (that is, IP addresses are not publicly shared), and therefore users can communicate with little fear of governmental or corporate interference.\\n\\n\\n== Network service ==\\nNetwork services are applications hosted by servers on a computer network, to provide some functionality for members or users of the network, or to help the network itself to operate.\\nThe World Wide Web, E-mail, printing and network file sharing are examples of well-known network services. Network services such as Domain Name System (DNS) give names for IP and MAC addresses (people remember names like nm.lan better than numbers like 210.121.67.18), and Dynamic Host Configuration Protocol (DHCP) to ensure that the equipment on the network has a valid IP address.Services are usually based on a service protocol that defines the format and sequencing of messages between clients and servers of that network service.\\n\\n\\n== Network performance ==\\n\\n\\n=== Bandwidth ===\\nBandwidth in bit/s may refer to consumed bandwidth, corresponding to achieved throughput or goodput, i.e., the average rate of successful data transfer through a communication path. The throughput is affected by processes such as bandwidth shaping, bandwidth management, bandwidth throttling, bandwidth cap and bandwidth allocation (using, for example, bandwidth allocation protocol and dynamic bandwidth allocation).\\n\\n\\n=== Network delay ===\\n\\nNetwork delay is a design and performance characteristic of a telecommunications network. It specifies the latency for a bit of data to travel across the network from one communication endpoint to another. Delay may differ slightly, depending on the location of the specific pair of communicating endpoints. Engineers usually report both the maximum and average delay, and they divide the delay into several components, the sum of which is the total delay:\\n\\nProcessing delay –  time it takes a router to process the packet header\\nQueuing delay –  time the packet spends in routing queues\\nTransmission delay –  time it takes to push the packet\\'s bits onto the link\\nPropagation delay –  time for a signal to propagate through the mediaA certain minimum level of delay is experienced by signals due to the time it takes to transmit a packet serially through a link. This delay is extended by more variable levels of delay due to network congestion. IP network delays can range from less than a microsecond to several hundred milliseconds.\\n\\n\\n=== Performance metrics ===\\nThe parameters that affect performance typically can include throughput, jitter, bit error rate and latency.\\nIn circuit-switched networks, network performance is synonymous with the grade of service. The number of rejected calls is a measure of how well the network is performing under heavy traffic loads. Other types of performance measures can include the level of noise and echo.\\nIn an Asynchronous Transfer Mode (ATM) network, performance can be measured by line rate, quality of service (QoS), data throughput, connect time, stability, technology, modulation technique, and modem enhancements.There are many ways to measure the performance of a network, as each network is different in nature and design. Performance can also be modeled instead of measured. For example, state transition diagrams are often used to model queuing performance in a circuit-switched network. The network planner uses these diagrams to analyze how the network performs in each state, ensuring that the network is optimally designed.\\n\\n\\n=== Network congestion ===\\nNetwork congestion occurs when a link or node is subjected to a greater data load than it is rated for, resulting in a deterioration of its quality of service. When networks are congested and queues become too full, packets have to be discarded, and so networks rely on re-transmission. Typical effects of congestion include queueing delay, packet loss or the blocking of new connections.  A consequence of these latter two is that incremental increases in offered load lead either to only a small increase in the network throughput or to a reduction in network throughput.\\nNetwork protocols that use aggressive retransmissions to compensate for packet loss tend to keep systems in a state of network congestion—even after the initial load is reduced to a level that would not normally induce network congestion. Thus, networks using these protocols can exhibit two stable states under the same level of load. The stable state with low throughput is known as congestive collapse.\\nModern networks use congestion control, congestion avoidance and traffic control techniques to try to avoid congestion collapse (i.e. endpoints typically slow down or sometimes even stop transmission entirely when the network is congested). These techniques include: exponential backoff in protocols such as 802.11\\'s CSMA/CA and the original Ethernet, window reduction in TCP, and fair queueing in devices such as routers. Another method to avoid the negative effects of network congestion is implementing priority schemes so that some packets are transmitted with higher priority than others. Priority schemes do not solve network congestion by themselves, but they help to alleviate the effects of congestion for some services. An example of this is 802.1p. A third method to avoid network congestion is the explicit allocation of network resources to specific flows. One example of this is the use of Contention-Free Transmission Opportunities (CFTXOPs) in the ITU-T G.hn standard, which provides high-speed (up to 1 Gbit/s) Local area networking over existing home wires (power lines, phone lines and coaxial cables).\\nFor the Internet, RFC 2914 addresses the subject of congestion control in detail.\\n\\n\\n=== Network resilience ===\\nNetwork resilience is \"the ability to provide and maintain an acceptable level of service in the face of faults and challenges to normal operation.\"\\n\\n\\n== Security ==\\n\\nComputer networks are also used by security hackers to deploy computer viruses or computer worms on devices connected to the network, or to prevent these devices from accessing the network via a denial-of-service attack.\\n\\n\\n=== Network security ===\\nNetwork Security consists of provisions and policies adopted by the network administrator to prevent and monitor unauthorized access, misuse, modification, or denial of the computer network and its network-accessible resources. Network security is the authorization of access to data in a network, which is controlled by the network administrator. Users are assigned an ID and password that allows them access to information and programs within their authority.  Network security is used on a variety of computer networks, both public and private, to secure daily transactions and communications among businesses, government agencies, and individuals.\\n\\n\\n=== Network surveillance ===\\nNetwork surveillance is the monitoring of data being transferred over computer networks such as the Internet. The monitoring is often done surreptitiously and may be done by or at the behest of governments, by corporations, criminal organizations, or individuals. It may or may not be legal and may or may not require authorization from a court or other independent agency.\\nComputer and network surveillance programs are widespread today, and almost all Internet traffic is or could potentially be monitored for clues to illegal activity.\\nSurveillance is very useful to governments and law enforcement to maintain social control, recognize and monitor threats, and prevent/investigate criminal activity. With the advent of programs such as the Total Information Awareness program, technologies such as high-speed surveillance computers and biometrics software, and laws such as the Communications Assistance For Law Enforcement Act, governments now possess an unprecedented ability to monitor the activities of citizens.However, many civil rights and privacy groups—such as Reporters Without Borders, the Electronic Frontier Foundation, and the American Civil Liberties Union—have expressed concern that increasing surveillance of citizens may lead to a mass surveillance society, with limited political and personal freedoms. Fears such as this have led to numerous lawsuits such as Hepting v. AT&T. The hacktivist group Anonymous has hacked into government websites in protest of what it considers \"draconian surveillance\".\\n\\n\\n=== End to end encryption ===\\nEnd-to-end encryption (E2EE) is a digital communications paradigm of uninterrupted protection of data traveling between two communicating parties. It involves the originating party encrypting data so only the intended recipient can decrypt it, with no dependency on third parties. End-to-end encryption prevents intermediaries, such as Internet service providers or application service providers, from discovering or tampering with communications. End-to-end encryption generally protects both confidentiality and integrity.\\nExamples of end-to-end encryption include HTTPS for web traffic, PGP for email, OTR for instant messaging, ZRTP for telephony, and TETRA for radio.\\nTypical server-based communications systems do not include end-to-end encryption. These systems can only guarantee the protection of communications between clients and servers, not between the communicating parties themselves. Examples of non-E2EE systems are Google Talk, Yahoo Messenger, Facebook, and Dropbox. Some such systems, for example, LavaBit and SecretInk, have even described themselves as offering \"end-to-end\" encryption when they do not. Some systems that normally offer end-to-end encryption have turned out to contain a back door that subverts negotiation of the encryption key between the communicating parties, for example Skype or Hushmail.\\nThe end-to-end encryption paradigm does not directly address risks at the endpoints of the communication themselves, such as the technical exploitation of clients, poor quality random number generators, or key escrow. E2EE also does not address traffic analysis, which relates to things such as the identities of the endpoints and the times and quantities of messages that are sent.\\n\\n\\n=== SSL/TLS ===\\n\\nThe introduction and rapid growth of e-commerce on the World Wide Web in the mid-1990s made it obvious that some form of authentication and encryption was needed. Netscape took the first shot at a new standard. At the time, the dominant web browser was Netscape Navigator. Netscape created a standard called secure socket layer (SSL). SSL requires a server with a certificate. When a client requests access to an SSL-secured server, the server sends a copy of the certificate to the client. The SSL client checks this certificate (all web browsers come with an exhaustive list of CA root certificates preloaded), and if the certificate checks out, the server is authenticated and the client negotiates a symmetric-key cipher for use in the session. The session is now in a very secure encrypted tunnel between the SSL server and the SSL client.\\n\\n\\n== Views of networks ==\\nUsers and network administrators typically have different views of their networks. Users can share printers and some servers from a workgroup, which usually means they are in the same geographic location and are on the same LAN, whereas a Network Administrator is responsible to keep that network up and running.  A community of interest has less of a connection of being in a local area and should be thought of as a set of arbitrarily located users who share a set of servers, and possibly also communicate via peer-to-peer technologies.\\nNetwork administrators can see networks from both physical and logical perspectives. The physical perspective involves geographic locations, physical cabling, and the network elements (e.g., routers, bridges and application layer gateways) that interconnect via the transmission media. Logical networks, called, in the TCP/IP architecture, subnets, map onto one or more transmission media. For example, a common practice in a campus of buildings is to make a set of LAN cables in each building appear to be a common subnet, using VLAN technology.\\nBoth users and administrators are aware, to varying extents, of the trust and scope characteristics of a network. Again using TCP/IP architectural terminology, an intranet is a community of interest under private administration usually by an enterprise, and is only accessible by authorized users (e.g. employees).  Intranets do not have to be connected to the Internet, but generally have a limited connection.  An extranet is an extension of an intranet that allows secure communications to users outside of the intranet (e.g. business partners, customers).Unofficially, the Internet is the set of users, enterprises, and content providers that are interconnected by Internet Service Providers (ISP). From an engineering viewpoint, the Internet is the set of subnets, and aggregates of subnets, that share the registered IP address space and exchange information about the reachability of those IP addresses using the Border Gateway Protocol. Typically, the human-readable names of servers are translated to IP addresses, transparently to users, via the directory function of the Domain Name System (DNS).\\nOver the Internet, there can be  business-to-business (B2B),  business-to-consumer (B2C) and consumer-to-consumer (C2C) communications. When money or sensitive information is exchanged, the communications are apt to be protected by some form of communications security mechanism.  Intranets and extranets can be securely superimposed onto the Internet, without any access by general Internet users and administrators, using secure Virtual Private Network (VPN) technology.\\n\\n\\n== Journals and newsletters ==\\nOpen Computer Science (open access journal)\\n\\n\\n== See also ==\\n\\n\\n== References ==\\n\\n This article incorporates public domain material from Federal Standard 1037C. General Services Administration. Archived from the original on 2022-01-22.\\n\\n\\n== Further reading ==\\nShelly, Gary, et al. \"Discovering Computers\" 2003 Edition.\\nWendell Odom, Rus Healy, Denise Donohue. (2010) CCIE Routing and Switching. Indianapolis, IN: Cisco Press\\nKurose James F and Keith W. Ross: Computer Networking: A Top-Down Approach Featuring the Internet, Pearson Education 2005.\\nWilliam Stallings, Computer Networking with Internet Protocols and Technology, Pearson Education 2004.\\nImportant publications in computer networks\\nNetwork Communication Architecture and Protocols: OSI Network Architecture 7 Layers Model\\nDimitri Bertsekas, and Robert Gallager, \"Data Networks,\" Prentice Hall, 1992.\\n\\n\\n== External links ==\\nNetworking at Curlie\\nIEEE Ethernet manufacturer information\\nA computer networking acronym guide',\n",
              " 'In computing, a database is an organized collection of data or a type of data store based on the use of a database management system (DBMS), the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a database system. Often the term \"database\" is also used loosely to refer to any of the DBMS, the database system or an application associated with the database.\\nSmall databases can be stored on a file system, while large databases are hosted on computer clusters or cloud storage. The design of databases spans formal techniques and practical considerations, including data modeling, efficient data representation and storage, query languages, security and privacy of sensitive data, and distributed computing issues, including supporting concurrent access and fault tolerance.\\nComputer scientists may classify database management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, collectively referred to as NoSQL, because they use different query languages.\\n\\n\\n== Terminology and overview ==\\nFormally, a \"database\" refers to a set of related data accessed through the use of a \"database management system\" (DBMS), which is an integrated set of computer software that allows users to interact with one or more databases and provides access to all of the data contained in the database (although restrictions may exist that limit access to particular data). The DBMS provides various functions that allow entry, storage and retrieval of large quantities of information and provides ways to manage how that information is organized.\\nBecause of the close relationship between them, the term \"database\" is often used casually to refer to both a database and the DBMS used to manipulate it.\\nOutside the world of professional information technology, the term database is often used to refer to any collection of related data (such as a spreadsheet or a card index) as size and usage requirements typically necessitate use of a database management system.Existing DBMSs provide various functions that allow management of a database and its data which can be classified into four main functional groups:\\n\\nData definition – Creation, modification and removal of definitions that define the organization of the data.\\nUpdate – Insertion, modification, and deletion of the actual data.\\nRetrieval – Providing information in a form directly usable or for further processing by other applications. The retrieved data may be made available in a form basically the same as it is stored in the database or in a new form obtained by altering or combining existing data from the database.\\nAdministration – Registering and monitoring users, enforcing data security, monitoring performance, maintaining data integrity, dealing with concurrency control, and recovering information that has been corrupted by some event such as an unexpected system failure.Both a database and its DBMS conform to the principles of a particular database model. \"Database system\" refers collectively to the database model, database management system, and database.Physically, database servers are dedicated computers that hold the actual databases and run only the DBMS and related software. Database servers are usually multiprocessor computers, with generous memory and RAID disk arrays used for stable storage. Hardware database accelerators, connected to one or more servers via a high-speed channel, are also used in large-volume transaction processing environments. DBMSs are found at the heart of most database applications. DBMSs may be built around a custom multitasking kernel with built-in networking support, but modern DBMSs typically rely on a standard operating system to provide these functions.Since DBMSs comprise a significant market, computer and storage vendors often take into account DBMS requirements in their own development plans.Databases and DBMSs can be categorized according to the database model(s) that they support (such as relational or XML), the type(s) of computer they run on (from a server cluster to a mobile phone), the query language(s) used to access the database (such as SQL or XQuery), and their internal engineering, which affects performance, scalability, resilience, and security.\\n\\n\\n== History ==\\nThe sizes, capabilities, and performance of databases and their respective DBMSs have grown in orders of magnitude. These performance increases were enabled by the technology progress in the areas of processors, computer memory, computer storage, and computer networks. The concept of a database was made possible by the emergence of direct access storage media such as magnetic disks, which became widely available in the mid-1960s; earlier systems relied on sequential storage of data on magnetic tape. The subsequent development of database technology can be divided into three eras based on data model or structure: navigational, SQL/relational, and post-relational.\\nThe two main early navigational data models were the hierarchical model and the CODASYL model (network model). These were characterized by the use of pointers (often physical disk addresses) to follow relationships from one record to another.\\nThe relational model, first proposed in 1970 by Edgar F. Codd, departed from this tradition by insisting that applications should search for data by content, rather than by following links. The relational model employs sets of ledger-style tables, each used for a different type of entity. Only in the mid-1980s did computing hardware become powerful enough to allow the wide deployment of relational systems (DBMSs plus applications). By the early 1990s, however, relational systems dominated in all large-scale data processing applications, and as of 2018 they remain dominant: IBM Db2, Oracle, MySQL, and Microsoft SQL Server are the most searched DBMS. The dominant database language, standardized SQL for the relational model, has influenced database languages for other data models.Object databases were developed in the 1980s to overcome the inconvenience of object–relational impedance mismatch, which led to the coining of the term \"post-relational\" and also the development of hybrid object–relational databases.\\nThe next generation of post-relational databases in the late 2000s became known as NoSQL databases, introducing fast key–value stores and document-oriented databases. A competing \"next generation\" known as NewSQL databases attempted new implementations that retained the relational/SQL model while aiming to match the high performance of NoSQL compared to commercially available relational DBMSs.\\n\\n\\n=== 1960s, navigational DBMS ===\\n\\nThe introduction of the term database coincided with the availability of direct-access storage (disks and drums) from the mid-1960s onwards. The term represented a contrast with the tape-based systems of the past, allowing shared interactive use rather than daily batch processing. The Oxford English Dictionary cites a 1962 report by the System Development Corporation of California as the first to use the term \"data-base\" in a specific technical sense.As computers grew in speed and capability, a number of general-purpose database systems emerged; by the mid-1960s a number of such systems had come into commercial use. Interest in a standard began to grow, and Charles Bachman, author of one such product, the Integrated Data Store (IDS), founded the Database Task Group within CODASYL, the group responsible for the creation and standardization of COBOL. In 1971, the Database Task Group delivered their standard, which generally became known as the CODASYL approach, and soon a number of commercial products based on this approach entered the market.\\nThe CODASYL approach offered applications the ability to navigate around a linked data set which was formed into a large network. Applications could find records by one of three methods:\\n\\nUse of a primary key (known as a CALC key, typically implemented by hashing)\\nNavigating relationships (called sets) from one record to another\\nScanning all the records in a sequential orderLater systems added B-trees to provide alternate access paths. Many CODASYL databases also added a declarative query language for end users (as distinct from the navigational API). However, CODASYL databases were complex and required significant training and effort to produce useful applications.\\nIBM also had its own DBMS in 1966, known as Information Management System (IMS). IMS was a development of software written for the Apollo program on the System/360. IMS was generally similar in concept to CODASYL, but used a strict hierarchy for its model of data navigation instead of CODASYL\\'s network model. Both concepts later became known as navigational databases due to the way data was accessed: the term was popularized by Bachman\\'s 1973 Turing Award presentation The Programmer as Navigator. IMS is classified by IBM as a hierarchical database. IDMS and Cincom Systems\\' TOTAL databases are classified as network databases. IMS remains in use as of 2014.\\n\\n\\n=== 1970s, relational DBMS ===\\nEdgar F. Codd worked at IBM in San Jose, California, in one of their offshoot offices that were primarily involved in the development of hard disk systems. He was unhappy with the navigational model of the CODASYL approach, notably the lack of a \"search\" facility. In 1970, he wrote a number of papers that outlined a new approach to database construction that eventually culminated in the groundbreaking A Relational Model of Data for Large Shared Data Banks.In this paper, he described a new system for storing and working with large databases. Instead of records being stored in some sort of linked list of free-form records as in CODASYL, Codd\\'s idea was to organize the data as a number of \"tables\", each table being used for a different type of entity. Each table would contain a fixed number of columns containing the attributes of the entity. One or more columns of each table were designated as a  primary key by which the rows of the table could be uniquely identified; cross-references between tables always used these primary keys, rather than disk addresses, and queries would join tables based on these key relationships, using a set of operations based on the mathematical system of relational calculus (from which the model takes its name). Splitting the data into a set of normalized tables (or relations) aimed to ensure that each \"fact\" was only stored once, thus simplifying update operations. Virtual tables called views could present the data in different ways for different users, but views could not be directly updated.\\nCodd used mathematical terms to define the model: relations, tuples, and domains rather than tables, rows, and columns. The terminology that is now familiar came from early implementations. Codd would later criticize the tendency for practical implementations to depart from the mathematical foundations on which the model was based.\\n\\nThe use of primary keys (user-oriented identifiers) to represent cross-table relationships, rather than disk addresses, had two primary motivations. From an engineering perspective, it enabled tables to be relocated and resized without expensive database reorganization. But Codd was more interested in the difference in semantics: the use of explicit identifiers made it easier to define update operations with clean mathematical definitions, and it also enabled query operations to be defined in terms of the established discipline of first-order predicate calculus; because these operations have clean mathematical properties, it becomes possible to rewrite queries in provably correct ways, which is the basis of query optimization. There is no loss of expressiveness compared with the hierarchic or network models, though the connections between tables are no longer so explicit.\\nIn the hierarchic and network models, records were allowed to have a complex internal structure. For example, the salary history of an employee might be represented as a \"repeating group\" within the employee record. In the relational model, the process of normalization led to such internal structures being replaced by data held in multiple tables, connected only by logical keys.\\nFor instance, a common use of a database system is to track information about users, their name, login information, various addresses and phone numbers. In the navigational approach, all of this data would be placed in a single variable-length record. In the relational approach, the data would be normalized into a user table, an address table and a phone number table (for instance). Records would be created in these optional tables only if the address or phone numbers were actually provided.\\nAs well as identifying rows/records using logical identifiers rather than disk addresses, Codd changed the way in which applications assembled data from multiple records. Rather than requiring applications to gather data one record at a time by navigating the links, they would use a declarative query language that expressed what data was required, rather than the access path by which it should be found. Finding an efficient access path to the data became the responsibility of the database management system, rather than the application programmer. This process, called query optimization, depended on the fact that queries were expressed in terms of mathematical logic.\\nCodd\\'s paper was picked up by two people at Berkeley, Eugene Wong and Michael Stonebraker. They started a project known as INGRES using funding that had already been allocated for a geographical database project and student programmers to produce code. Beginning in 1973, INGRES delivered its first test products which were generally ready for widespread use in 1979. INGRES was similar to System R in a number of ways, including the use of a \"language\" for data access, known as QUEL. Over time, INGRES moved to the emerging SQL standard.\\nIBM itself did one test implementation of the relational model, PRTV, and a production one, Business System 12, both now discontinued. Honeywell wrote MRDS for Multics, and now there are two new implementations: Alphora Dataphor and Rel. Most other DBMS implementations usually called relational are actually SQL DBMSs.\\nIn 1970, the University of Michigan began development of the MICRO Information Management System based on D.L. Childs\\' Set-Theoretic Data model. MICRO was used to manage very large data sets by the US Department of Labor, the U.S. Environmental Protection Agency, and researchers from the University of Alberta, the University of Michigan, and Wayne State University. It ran on IBM mainframe computers using the Michigan Terminal System. The system remained in production until 1998.\\n\\n\\n=== Integrated approach ===\\n\\nIn the 1970s and 1980s, attempts were made to build database systems with integrated hardware and software. The underlying philosophy was that such integration would provide higher performance at a lower cost. Examples were IBM System/38, the early offering of Teradata, and the Britton Lee, Inc. database machine.\\nAnother approach to hardware support for database management was ICL\\'s CAFS accelerator, a hardware disk controller with programmable search capabilities. In the long term, these efforts were generally unsuccessful because specialized database machines could not keep pace with the rapid development and progress of general-purpose computers. Thus most database systems nowadays are software systems running on general-purpose hardware, using general-purpose computer data storage. However, this idea is still pursued in certain applications by some companies like Netezza and Oracle (Exadata).\\n\\n\\n=== Late 1970s, SQL DBMS ===\\nIBM started working on a prototype system loosely based on Codd\\'s concepts as System R in the early 1970s. The first version was ready in 1974/5, and work then started on multi-table systems in which the data could be split so that all of the data for a record (some of which is optional) did not have to be stored in a single large \"chunk\". Subsequent multi-user versions were tested by customers in 1978 and 1979, by which time a standardized query language – SQL – had been added. Codd\\'s ideas were establishing themselves as both workable and superior to CODASYL, pushing IBM to develop a true production version of System R, known as SQL/DS, and, later, Database 2 (IBM Db2).\\nLarry Ellison\\'s Oracle Database (or more simply, Oracle) started from a different chain, based on IBM\\'s papers on System R. Though Oracle V1 implementations were completed in 1978, it was not until Oracle Version 2 when Ellison beat IBM to market in 1979.Stonebraker went on to apply the lessons from INGRES to develop a new database, Postgres, which is now known as PostgreSQL. PostgreSQL is often used for global mission-critical applications (the .org and .info domain name registries use it as their primary data store, as do many large companies and financial institutions).\\nIn Sweden, Codd\\'s paper was also read and Mimer SQL was developed in the mid-1970s at Uppsala University. In 1984, this project was consolidated into an independent enterprise.\\nAnother data model, the entity–relationship model, emerged in 1976 and gained popularity for database design as it emphasized a more familiar description than the earlier relational model. Later on, entity–relationship constructs were retrofitted as a data modeling construct for the relational model, and the difference between the two has become irrelevant.\\n\\n\\n=== 1980s, on the desktop ===\\nThe 1980s ushered in the age of desktop computing. The new computers empowered their users with spreadsheets like Lotus 1-2-3 and database software like dBASE. The dBASE product was lightweight and easy for any computer user to understand out of the box. C. Wayne Ratliff, the creator of dBASE, stated: \"dBASE was different from programs like BASIC, C, FORTRAN, and COBOL in that a lot of the dirty work had already been done. The data manipulation is done by dBASE instead of by the user, so the user can concentrate on what he is doing, rather than having to mess with the dirty details of opening, reading, and closing files, and managing space allocation.\" dBASE was one of the top selling software titles in the 1980s and early 1990s.\\n\\n\\n=== 1990s, object-oriented ===\\nThe 1990s, along with a rise in object-oriented programming, saw a growth in how data in various databases were handled. Programmers and designers began to treat the data in their databases as objects. That is to say that if a person\\'s data were in a database, that person\\'s attributes, such as their address, phone number, and age, were now considered to belong to that person instead of being extraneous data. This allows for relations between data to be related to objects and their attributes and not to individual fields. The term \"object–relational impedance mismatch\" described the inconvenience of translating between programmed objects and database tables. Object databases and object–relational databases attempt to solve this problem by providing an object-oriented language (sometimes as extensions to SQL) that programmers can use as alternative to purely relational SQL. On the programming side, libraries known as object–relational mappings (ORMs) attempt to solve the same problem.\\n\\n\\n=== 2000s, NoSQL and NewSQL ===\\n\\nXML databases are a type of structured document-oriented database that allows querying based on XML document attributes. XML databases are mostly used in applications where the data is conveniently viewed as a collection of documents, with a structure that can vary from the very flexible to the highly rigid: examples include scientific articles, patents, tax filings, and personnel records.\\nNoSQL databases are often very fast, do not require fixed table schemas, avoid join operations by storing denormalized data, and are designed to scale horizontally.\\nIn recent years, there has been a strong demand for massively distributed databases with high partition tolerance, but according to the CAP theorem, it is impossible for a distributed system to simultaneously provide consistency, availability, and partition tolerance guarantees. A distributed system can satisfy any two of these guarantees at the same time, but not all three. For that reason, many NoSQL databases are using what is called eventual consistency to provide both availability and partition tolerance guarantees with a reduced level of data consistency.\\nNewSQL is a class of modern relational databases that aims to provide the same scalable performance of NoSQL systems for online transaction processing (read-write) workloads while still using SQL and maintaining the ACID guarantees of a traditional database system.\\n\\n\\n== Use cases ==\\nDatabases are used to support internal operations of organizations and to underpin online interactions with customers and suppliers (see Enterprise software).\\nDatabases are used to hold administrative information and more specialized data, such as engineering data or economic models. Examples include computerized library systems, flight reservation systems, computerized parts inventory systems, and many content management systems that store websites as collections of webpages in a database.\\n\\n\\n== Classification ==\\nOne way to classify databases involves the type of their contents, for example: bibliographic, document-text, statistical, or multimedia objects. Another way is by their application area, for example: accounting, music compositions, movies, banking, manufacturing, or insurance. A third way is by some technical aspect, such as the database structure or interface type. This section lists a few of the adjectives used to characterize different kinds of databases.\\n\\nAn in-memory database is a database that primarily resides in main memory, but is typically backed-up by non-volatile computer data storage. Main memory databases are faster than disk databases, and so are often used where response time is critical, such as in telecommunications network equipment.\\nAn active database includes an event-driven architecture which can respond to conditions both inside and outside the database. Possible uses include security monitoring, alerting, statistics gathering and authorization. Many databases provide active database features in the form of database triggers.\\nA cloud database relies on cloud technology. Both the database and most of its DBMS reside remotely, \"in the cloud\", while its applications are both developed by programmers and later maintained and used by end-users through a web browser and Open APIs.\\nData warehouses archive data from operational databases and often from external sources such as market research firms. The warehouse becomes the central source of data for use by managers and other end-users who may not have access to operational data. For example, sales data might be aggregated to weekly totals and converted from internal product codes to use UPCs so that they can be compared with ACNielsen data. Some basic and essential components of data warehousing include extracting, analyzing, and mining data, transforming, loading, and managing data so as to make them available for further use.\\nA deductive database combines logic programming with a relational database.\\nA distributed database is one in which both the data and the DBMS span multiple computers.\\nA document-oriented database is designed for storing, retrieving, and managing document-oriented, or semi structured, information. Document-oriented databases are one of the main categories of NoSQL databases.\\nAn embedded database system is a DBMS which is tightly integrated with an application software that requires access to stored data in such a way that the DBMS is hidden from the application\\'s end-users and requires little or no ongoing maintenance.\\nEnd-user databases consist of data developed by individual end-users. Examples of these are collections of documents, spreadsheets, presentations, multimedia, and other files. Several products exist to support such databases.\\nA federated database system comprises several distinct databases, each with its own DBMS. It is handled as a single database by a federated database management system (FDBMS), which transparently integrates multiple autonomous DBMSs, possibly of different types (in which case it would also be a heterogeneous database system), and provides them with an integrated conceptual view.\\nSometimes the term multi-database is used as a synonym for federated database, though it may refer to a less integrated (e.g., without an FDBMS and a managed integrated schema) group of databases that cooperate in a single application. In this case, typically middleware is used for distribution, which typically includes an atomic commit protocol (ACP), e.g., the two-phase commit protocol, to allow distributed (global) transactions across the participating databases.\\nA graph database is a kind of NoSQL database that uses graph structures with nodes, edges, and properties to represent and store information. General graph databases that can store any graph are distinct from specialized graph databases such as triplestores and network databases.\\nAn array DBMS is a kind of NoSQL DBMS that allows modeling, storage, and retrieval of (usually large) multi-dimensional arrays such as satellite images and climate simulation output.\\nIn a hypertext or hypermedia database, any word or a piece of text representing an object, e.g., another piece of text, an article, a picture, or a film, can be hyperlinked to that object. Hypertext databases are particularly useful for organizing large amounts of disparate information. For example, they are useful for organizing online encyclopedias, where users can conveniently jump around the text. The World Wide Web is thus a large distributed hypertext database.\\nA knowledge base (abbreviated KB, kb or Δ) is a special kind of database for knowledge management, providing the means for the computerized collection, organization, and retrieval of knowledge. Also a collection of data representing problems with their solutions and related experiences.A mobile database can be carried on or synchronized from a mobile computing device.\\nOperational databases store detailed data about the operations of an organization. They typically process relatively high volumes of updates using transactions. Examples include customer databases that record contact, credit, and demographic information about a business\\'s customers, personnel databases that hold information such as salary, benefits, skills data about employees, enterprise resource planning systems that record details about product components, parts inventory, and financial databases that keep track of the organization\\'s money, accounting and financial dealings.\\nA parallel database seeks to improve performance through parallelization for tasks such as loading data, building indexes and evaluating queries.The major parallel DBMS architectures which are induced by the underlying hardware architecture are:\\nShared memory architecture, where multiple processors share the main memory space, as well as other data storage.\\nShared disk architecture, where each processing unit (typically consisting of multiple processors) has its own main memory, but all units share the other storage.\\nShared-nothing architecture, where each processing unit has its own main memory and other storage.Probabilistic databases employ fuzzy logic to draw inferences from imprecise data.\\nReal-time databases process transactions fast enough for the result to come back and be acted on right away.\\nA spatial database can store the data with multidimensional features. The queries on such data include location-based queries, like \"Where is the closest hotel in my area?\".\\nA temporal database has built-in time aspects, for example a temporal data model and a temporal version of SQL. More specifically the temporal aspects usually include valid-time and transaction-time.\\nA terminology-oriented database builds upon an object-oriented database, often customized for a specific field.\\nAn unstructured data database is intended to store in a manageable and protected way diverse objects that do not fit naturally and conveniently in common databases. It may include email messages, documents, journals, multimedia objects, etc. The name may be misleading since some objects can be highly structured. However, the entire possible object collection does not fit into a predefined structured framework. Most established DBMSs now support unstructured data in various ways, and new dedicated DBMSs are emerging.\\n\\n\\n== Database management system ==\\nConnolly and Begg define database management system (DBMS) as a \"software system that enables users to define, create, maintain and control access to the database\". Examples of DBMS\\'s include MySQL, MariaDB, PostgreSQL, Microsoft SQL Server, Oracle Database, and Microsoft Access.\\nThe DBMS acronym is sometimes extended to indicate the underlying database model, with RDBMS for the relational, OODBMS for the object (oriented) and ORDBMS for the object–relational model. Other extensions can indicate some other characteristics, such as DDBMS for a distributed database management systems.\\nThe functionality provided by a DBMS can vary enormously. The core functionality is the storage, retrieval and update of data. Codd proposed the following functions and services a fully-fledged general purpose DBMS should provide:\\nData storage, retrieval and update\\nUser accessible catalog or data dictionary describing the metadata\\nSupport for transactions and concurrency\\nFacilities for recovering the database should it become damaged\\nSupport for authorization of access and update of data\\nAccess support from remote locations\\nEnforcing constraints to ensure data in the database abides by certain rulesIt is also generally to be expected the DBMS will provide a set of utilities for such purposes as may be necessary to administer the database effectively, including import, export, monitoring, defragmentation and analysis utilities. The core part of the DBMS interacting between the database and the application interface sometimes referred to as the database engine.\\nOften DBMSs will have configuration parameters that can be statically and dynamically tuned, for example the maximum amount of main memory on a server the database can use. The trend is to minimize the amount of manual configuration, and for cases such as embedded databases the need to target zero-administration is paramount.\\nThe large major enterprise DBMSs have tended to increase in size and functionality and have involved up to thousands of human years of development effort throughout their lifetime.Early multi-user DBMS typically only allowed for the application to reside on the same computer with access via terminals or terminal emulation software. The client–server architecture was a development where the application resided on a client desktop and the database on a server allowing the processing to be distributed. This evolved into a multitier architecture incorporating application servers and web servers with the end user interface via a web browser with the database only directly connected to the adjacent tier.A general-purpose DBMS will provide public application programming interfaces (API) and optionally a processor for database languages such as SQL to allow applications to be written to interact with and manipulate the database. A special purpose DBMS may use a private API and be specifically customized and linked to a single application. For example, an email system performs many of the functions of a general-purpose DBMS such as message insertion, message deletion, attachment handling, blocklist lookup, associating messages an email address and so forth however these functions are limited to what is required to handle email.\\n\\n\\n== Application ==\\n\\nExternal interaction with the database will be via an application program that interfaces with the DBMS. This can range from a database tool that allows users to execute SQL queries textually or graphically, to a website that happens to use a database to store and search information.\\n\\n\\n=== Application program interface ===\\nA programmer will code interactions to the database (sometimes referred to as a datasource) via an application program interface (API) or via a database language. The particular API or language chosen will need to be supported by DBMS, possibly indirectly via a preprocessor or a bridging API. Some API\\'s aim to be database independent, ODBC being a commonly known example. Other common API\\'s include JDBC and ADO.NET.\\n\\n\\n== Database languages ==\\nDatabase languages are special-purpose languages, which allow one or more of the following tasks, sometimes distinguished as sublanguages:\\n\\nData control language (DCL) – controls access to data;\\nData definition language (DDL) – defines data types such as creating, altering, or dropping tables and the relationships among them;\\nData manipulation language (DML) – performs tasks such as inserting, updating, or deleting data occurrences;\\nData query language (DQL) – allows searching for information and computing derived information.Database languages are specific to a particular data model. Notable examples include:\\n\\nSQL combines the roles of data definition, data manipulation, and query in a single language. It was one of the first commercial languages for the relational model, although it departs in some respects from the relational model as described by Codd (for example, the rows and columns of a table can be ordered). SQL became a standard of the American National Standards Institute (ANSI) in 1986, and of the International Organization for Standardization (ISO) in 1987. The standards have been regularly enhanced since and are supported (with varying degrees of conformance) by all mainstream commercial relational DBMSs.\\nOQL is an object model language standard (from the Object Data Management Group). It has influenced the design of some of the newer query languages like JDOQL and EJB QL.\\nXQuery is a standard XML query language implemented by XML database systems such as MarkLogic and eXist, by relational databases with XML capability such as Oracle and Db2, and also by in-memory XML processors such as Saxon.\\nSQL/XML combines XQuery with SQL.A database language may also incorporate features like:\\n\\nDBMS-specific configuration and storage engine management\\nComputations to modify query results, like counting, summing, averaging, sorting, grouping, and cross-referencing\\nConstraint enforcement (e.g. in an automotive database, only allowing one engine type per car)\\nApplication programming interface version of the query language, for programmer convenience\\n\\n\\n== Storage ==\\n\\nDatabase storage is the container of the physical materialization of a database. It comprises the internal (physical) level in the database architecture. It also contains all the information needed (e.g., metadata, \"data about the data\", and internal data structures) to reconstruct the conceptual level and external level from the internal level when needed. Databases as digital objects contain three layers of information which must be stored: the data, the structure, and the semantics. Proper storage of all three layers is needed for future preservation and longevity of the database. Putting data into permanent storage is generally the responsibility of the database engine a.k.a. \"storage engine\". Though typically accessed by a DBMS through the underlying operating system (and often using the operating systems\\' file systems as intermediates for storage layout), storage properties and configuration settings are extremely important for the efficient operation of the DBMS, and thus are closely maintained by database administrators. A DBMS, while in operation, always has its database residing in several types of storage (e.g., memory and external storage). The database data and the additional needed information, possibly in very large amounts, are coded into bits. Data typically reside in the storage in structures that look completely different from the way the data look at the conceptual and external levels, but in ways that attempt to optimize (the best possible) these levels\\' reconstruction when needed by users and programs, as well as for computing additional types of needed information from the data (e.g., when querying the database).\\nSome DBMSs support specifying which character encoding was used to store data, so multiple encodings can be used in the same database.\\nVarious low-level database storage structures are used by the storage engine to serialize the data model so it can be written to the medium of choice. Techniques such as indexing may be used to improve performance. Conventional storage is row-oriented, but there are also column-oriented and correlation databases.\\n\\n\\n=== Materialized views ===\\n\\nOften storage redundancy is employed to increase performance. A common example is storing materialized views, which consist of frequently needed external views or query results. Storing such views saves the expensive computing them each time they are needed. The downsides of materialized views are the overhead incurred when updating them to keep them synchronized with their original updated database data, and the cost of storage redundancy.\\n\\n\\n=== Replication ===\\n\\nOccasionally a database employs storage redundancy by database objects replication (with one or more copies) to increase data availability (both to improve performance of simultaneous multiple end-user accesses to the same database object, and to provide resiliency in a case of partial failure of a distributed database). Updates of a replicated object need to be synchronized across the object copies. In many cases, the entire database is replicated.\\n\\n\\n=== Virtualization ===\\nWith data virtualization, the data used remains in its original locations and real-time access is established to allow analytics across multiple sources. This can aid in resolving some technical difficulties such as compatibility problems when combining data from various platforms, lowering the risk of error caused by faulty data, and guaranteeing that the newest data is used. Furthermore, avoiding the creation of a new database containing personal information can make it easier to comply with privacy regulations. However, with data virtualization, the connection to all necessary data sources must be operational as there is no local copy of the data, which is one of the main drawbacks of the approach.\\n\\n\\n== Security ==\\n\\nDatabase security deals with all various aspects of protecting the database content, its owners, and its users. It ranges from protection from intentional unauthorized database uses to unintentional database accesses by unauthorized entities (e.g., a person or a computer program).\\nDatabase access control deals with controlling who (a person or a certain computer program) are allowed to access what information in the database. The information may comprise specific database objects (e.g., record types, specific records, data structures), certain computations over certain objects (e.g., query types, or specific queries), or using specific access paths to the former (e.g., using specific indexes or other data structures to access information). Database access controls are set by special authorized (by the database owner) personnel that uses dedicated protected security DBMS interfaces.\\nThis may be managed directly on an individual basis, or by the assignment of individuals and privileges to groups, or (in the most elaborate models) through the assignment of individuals and groups to roles which are then granted entitlements. Data security prevents unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or subsets of it called \"subschemas\". For example, an employee database can contain all the data about an individual employee, but one group of users may be authorized to view only payroll data, while others are allowed access to only work history and medical data. If the DBMS provides a way to interactively enter and update the database, as well as interrogate it, this capability allows for managing personal databases.\\nData security in general deals with protecting specific chunks of data, both physically (i.e., from corruption, or destruction, or removal; e.g., see physical security), or the interpretation of them, or parts of them to meaningful information (e.g., by looking at the strings of bits that they comprise, concluding specific valid credit-card numbers; e.g., see data encryption).\\nChange and access logging records who accessed which attributes, what was changed, and when it was changed. Logging services allow for a forensic database audit later by keeping a record of access occurrences and changes. Sometimes application-level code is used to record changes rather than leaving this in the database. Monitoring can be set up to attempt to detect security breaches. Therefore, organizations must take database security seriously because of the many benefits it provides. Organizations will be safeguarded from security breaches and hacking activities like firewall intrusion, virus spread, and ransom ware. This helps in protecting the company\\'s essential information, which cannot be shared with outsiders at any cause.\\n\\n\\n== Transactions and concurrency ==\\n\\nDatabase transactions can be used to introduce some level of fault tolerance and data integrity after recovery from a crash. A database transaction is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring or releasing a lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction\\'s programmer via special transaction commands).\\nThe acronym ACID describes some ideal properties of a database transaction: atomicity, consistency, isolation, and durability.\\n\\n\\n== Migration ==\\n\\nA database built with one DBMS is not portable to another DBMS (i.e., the other DBMS cannot run it). However, in some situations, it is desirable to migrate a database from one DBMS to another. The reasons are primarily economical (different DBMSs may have different total costs of ownership or TCOs), functional, and operational (different DBMSs may have different capabilities). The migration involves the database\\'s transformation from one DBMS type to another. The transformation should maintain (if possible) the database related application (i.e., all related application programs) intact. Thus, the database\\'s conceptual and external architectural levels should be maintained in the transformation. It may be desired that also some aspects of the architecture internal level are maintained. A complex or large database migration may be a complicated and costly (one-time) project by itself, which should be factored into the decision to migrate. This is in spite of the fact that tools may exist to help migration between specific DBMSs. Typically, a DBMS vendor provides tools to help import databases from other popular DBMSs.\\n\\n\\n== Building, maintaining, and tuning ==\\n\\nAfter designing a database for an application, the next stage is building the database. Typically, an appropriate general-purpose DBMS can be selected to be used for this purpose. A DBMS provides the needed user interfaces to be used by database administrators to define the needed application\\'s data structures within the DBMS\\'s respective data model. Other user interfaces are used to select needed DBMS parameters (like security related, storage allocation parameters, etc.).\\nWhen the database is ready (all its data structures and other needed components are defined), it is typically populated with initial application\\'s data (database initialization, which is typically a distinct project; in many cases using specialized DBMS interfaces that support bulk insertion) before making it operational. In some cases, the database becomes operational while empty of application data, and data are accumulated during its operation.\\nAfter the database is created, initialized and populated it needs to be maintained. Various database parameters may need changing and the database may need to be tuned (tuning) for better performance; application\\'s data structures may be changed or added, new related application programs may be written to add to the application\\'s functionality, etc.\\n\\n\\n== Backup and restore ==\\n\\nSometimes it is desired to bring a database back to a previous state (for many reasons, e.g., cases when the database is found corrupted due to a software error, or if it has been updated with erroneous data). To achieve this, a backup operation is done occasionally or continuously, where each desired database state (i.e., the values of its data and their embedding in database\\'s data structures) is kept within dedicated backup files (many techniques exist to do this effectively). When it is decided by a database administrator to bring the database back to this state (e.g., by specifying this state by a desired point in time when the database was in this state), these files are used to restore that state.\\n\\n\\n== Static analysis ==\\nStatic analysis techniques for software verification can be applied also in the scenario of query languages. In particular, the *Abstract interpretation framework has been extended to the field of query languages for relational databases as a way to support sound approximation techniques. The semantics of query languages can be tuned according to suitable abstractions of the concrete domain of data. The abstraction of relational database systems has many interesting applications, in particular, for security purposes, such as fine-grained access control, watermarking, etc.\\n\\n\\n== Miscellaneous features ==\\nOther DBMS features might include:\\n\\nDatabase logs – This helps in keeping a history of the executed functions.\\nGraphics component for producing graphs and charts, especially in a data warehouse system.\\nQuery optimizer – Performs query optimization on every query to choose an efficient query plan (a partial order (tree) of operations) to be executed to compute the query result. May be specific to a particular storage engine.\\nTools or hooks for database design, application programming, application program maintenance, database performance analysis and monitoring, database configuration monitoring, DBMS hardware configuration (a DBMS and related database may span computers, networks, and storage units) and related database mapping (especially for a distributed DBMS), storage allocation and database layout monitoring, storage migration, etc.Increasingly, there are calls for a single system that incorporates all of these core functionalities into the same build, test, and deployment framework for database management and source control. Borrowing from other developments in the software industry, some market such offerings as \"DevOps for database\".\\n\\n\\n== Design and modeling ==\\n\\nThe first task of a database designer is to produce a conceptual data model that reflects the structure of the information to be held in the database. A common approach to this is to develop an entity–relationship model, often with the aid of drawing tools. Another popular approach is the Unified Modeling Language. A successful data model will accurately reflect the possible state of the external world being modeled: for example, if people can have more than one phone number, it will allow this information to be captured. Designing a good conceptual data model requires a good understanding of the application domain; it typically involves asking deep questions about the things of interest to an organization, like \"can a customer also be a supplier?\", or \"if a product is sold with two different forms of packaging, are those the same product or different products?\", or \"if a plane flies from New York to Dubai via Frankfurt, is that one flight or two (or maybe even three)?\". The answers to these questions establish definitions of the terminology used for entities (customers, products, flights, flight segments) and their relationships and attributes.\\nProducing the conceptual data model sometimes involves input from business processes, or the analysis of workflow in the organization. This can help to establish what information is needed in the database, and what can be left out. For example, it can help when deciding whether the database needs to hold historic data as well as current data.\\nHaving produced a conceptual data model that users are happy with, the next stage is to translate this into a schema that implements the relevant data structures within the database. This process is often called logical database design, and the output is a logical data model expressed in the form of a schema. Whereas the conceptual data model is (in theory at least) independent of the choice of database technology, the logical data model will be expressed in terms of a particular database model supported by the chosen DBMS. (The terms data model and database model are often used interchangeably, but in this article we use data model for the design of a specific database, and database model for the modeling notation used to express that design).\\nThe most popular database model for general-purpose databases is the relational model, or more precisely, the relational model as represented by the SQL language. The process of creating a logical database design using this model uses a methodical approach known as normalization. The goal of normalization is to ensure that each elementary \"fact\" is only recorded in one place, so that insertions, updates, and deletions automatically maintain consistency.\\nThe final stage of database design is to make the decisions that affect performance, scalability, recovery, security, and the like, which depend on the particular DBMS. This is often called physical database design, and the output is the physical data model. A key goal during this stage is data independence, meaning that the decisions made for performance optimization purposes should be invisible to end-users and applications. There are two types of data independence: Physical data independence and logical data independence. Physical design is driven mainly by performance requirements, and requires a good knowledge of the expected workload and access patterns, and a deep understanding of the features offered by the chosen DBMS.\\nAnother aspect of physical database design is security. It involves both defining access control to database objects as well as defining security levels and methods for the data itself.\\n\\n\\n=== Models ===\\n\\nA database model is a type of data model that determines the logical structure of a database and fundamentally determines in which manner data can be stored, organized, and manipulated. The most popular example of a database model is the relational model (or the SQL approximation of relational), which uses a table-based format.\\nCommon logical data models for databases include:\\n\\nNavigational databases\\nHierarchical database model\\nNetwork model\\nGraph database\\nRelational model\\nEntity–relationship model\\nEnhanced entity–relationship model\\nObject model\\nDocument model\\nEntity–attribute–value model\\nStar schemaAn object–relational database combines the two related structures.\\nPhysical data models include:\\n\\nInverted index\\nFlat fileOther models include:\\n\\nMultidimensional model\\nArray model\\nMultivalue modelSpecialized models are optimized for particular types of data:\\n\\nXML database\\nSemantic model\\nContent store\\nEvent store\\nTime series model\\n\\n\\n=== External, conceptual, and internal views ===\\nA database management system provides three views of the database data:\\n\\nThe external level defines how each group of end-users sees the organization of data in the database. A single database can have any number of views at the external level.\\nThe conceptual level (or logical level) unifies the various external views into a compatible global view. It provides the synthesis of all the external views. It is out of the scope of the various database end-users, and is rather of interest to database application developers and database administrators.\\nThe internal level (or physical level) is the internal organization of data inside a DBMS. It is concerned with cost, performance, scalability and other operational matters. It deals with storage layout of the data, using storage structures such as indexes to enhance performance. Occasionally it stores data of individual views (materialized views), computed from generic data, if performance justification exists for such redundancy. It balances all the external views\\' performance requirements, possibly conflicting, in an attempt to optimize overall performance across all activities.While there is typically only one conceptual and internal view of the data, there can be any number of different external views. This allows users to see database information in a more business-related way rather than from a technical, processing viewpoint. For example, a financial department of a company needs the payment details of all employees as part of the company\\'s expenses, but does not need details about employees that are in the interest of the human resources department. Thus different departments need different views of the company\\'s database.\\nThe three-level database architecture relates to the concept of data independence which was one of the major initial driving forces of the relational model. The idea is that changes made at a certain level do not affect the view at a higher level. For example, changes in the internal level do not affect application programs written using conceptual level interfaces, which reduces the impact of making physical changes to improve performance.\\nThe conceptual view provides a level of indirection between internal and external. On the one hand it provides a common view of the database, independent of different external view structures, and on the other hand it abstracts away details of how the data are stored or managed (internal level). In principle every level, and even every external view, can be presented by a different data model. In practice usually a given DBMS uses the same data model for both the external and the conceptual levels (e.g., relational model). The internal level, which is hidden inside the DBMS and depends on its implementation, requires a different level of detail and uses its own types of data structure types.\\n\\n\\n== Research ==\\nDatabase technology has been an active research topic since the 1960s, both in academia and in the research and development groups of companies (for example IBM Research). Research activity includes theory and development of prototypes. Notable research topics have included models, the atomic transaction concept, related concurrency control techniques, query languages and query optimization methods, RAID, and more.\\nThe database research area has several dedicated academic journals (for example, ACM Transactions on Database Systems-TODS, Data and Knowledge Engineering-DKE) and annual conferences (e.g., ACM SIGMOD, ACM PODS, VLDB, IEEE ICDE).\\n\\n\\n== See also ==\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== Sources ==\\n\\n\\n== Further reading ==\\nLing Liu and Tamer M. Özsu (Eds.) (2009).  \"Encyclopedia of Database Systems, 4100 p. 60 illus. ISBN 978-0-387-49616-0.\\nGray, J. and Reuter, A. Transaction Processing: Concepts and Techniques, 1st edition,  Morgan Kaufmann Publishers, 1992.\\nKroenke, David M. and David J. Auer. Database Concepts. 3rd ed. New York: Prentice, 2007.\\nRaghu Ramakrishnan and Johannes Gehrke, Database Management Systems.\\nAbraham Silberschatz, Henry F. Korth, S. Sudarshan, Database System Concepts.\\nLightstone, S.; Teorey, T.; Nadeau, T. (2007). Physical Database Design: the database professional\\'s guide to exploiting indexes, views, storage, and more. Morgan Kaufmann Press. ISBN 978-0-12-369389-1.\\nTeorey, T.; Lightstone, S. and Nadeau, T. Database Modeling & Design: Logical Design, 4th edition, Morgan Kaufmann Press, 2005. ISBN 0-12-685352-5.\\nCMU Database courses playlist\\nMIT OCW 6.830 | Fall 2010 | Database Systems\\nBerkeley CS W186\\n\\n\\n== External links ==\\n\\nDB File extension – information about files with the DB extension',\n",
              " 'Computer security, cyber security, digital security or information technology security (IT security) is the protection of computer systems and networks from attacks by malicious actors that may result in unauthorized information disclosure, theft of, or damage to hardware, software, or data, as well as from the disruption or misdirection of the services they provide.The field is significant due to the expanded reliance on computer systems, the Internet, and wireless network standards such as Bluetooth and Wi-Fi. Also, due to the growth of smart devices, including smartphones, televisions, and the various devices that constitute the Internet of things (IoT). Cybersecurity is one of the most significant challenges of the contemporary world, due to both the complexity of information systems and the societies they support. Security is of especially high importance for systems that govern large-scale systems with far-reaching physical effects, such as power distribution, elections, and finance.\\n\\n\\n== Vulnerabilities and attacks ==\\n\\nA vulnerability is a weakness in design, implementation, operation, or internal control of a computer or system. Most of the vulnerabilities that have been discovered are documented in the Common Vulnerabilities and Exposures (CVE) database. An exploitable vulnerability is one for which at least one working attack or exploit exists. Vulnerabilities can be researched, reverse-engineered, hunted, or exploited using automated tools or customized scripts.Various people or parties are vulnerable to cyber attacks, however different groups are likely to experience different types of attacks more than others.In April 2023 the United Kingdom Department for Science, Innovation & Technology realised a report on cyber attacks over the last 12 months. They surveyed 2,263 UK businesses, 1,174 UK registered charities and 554 education institutions. The research found that \"32% of businesses and 24% of charities overall recall any breaches or attacks from the last 12 months.\" This figures were much higher for \"medium businesses (59%), large businesses (69%) and high-income charities with £500,000 or more in annual income (56%).\" Yet, although medium or large businesses are more often the victims, since larger companies have generally improved their security over the last decade, small and midsize businesses (SMBs) have also become increasing vulnerable as they often \"do not have advanced tools to defend the business.\" SMBs are most likely to be affected by malware, ransomware, phishing, man-in-the-middle attacks, and Denial-of Service (DoS) Attacks.Normal people working for a business or simply using the internet are most likely to be affected by \"un-targeted\" cyber attacks. These are where attackers indiscriminately target as many devices, services or users as possible. They do this using techniques that take advantage of the \"openness\" of the Internet. These strategies mostly include phishing, ransomware, water holing and scanning.To secure a computer system, it is important to understand the attacks that can be made against it, and these threats can typically be classified into one of the following categories:\\n\\n\\n=== Backdoor ===\\nA backdoor in a computer system, a cryptosystem, or an algorithm, is any secret method of bypassing normal authentication or security controls. These weaknesses may exist for many reasons, including original design or poor configuration. Due to the nature of backdoors, they are of greater concern to companies and databases as opposed to individuals.\\nBackdoors may be added by an authorized party to allow some legitimate access, or by an attacker for malicious reasons. However, criminals often use malware to install backdoors, giving them remote administrative access to a system. Once they have access, cybercriminals can \"modify files, steal personal information, install unwanted software, and even take control of the entire computer.\"Backdoors can be very hard to detect, and are usually discovered by someone who has access to the application source code or intimate knowledge of the operating system of the computer.  \\n\\n\\n=== Denial-of-service attack ===\\nDenial of service attacks (DoS) are designed to make a machine or network resource unavailable to its intended users. Attackers can deny service to individual victims, such as by deliberately entering a wrong password enough consecutive times to cause the victim\\'s account to be locked, or they may overload the capabilities of a machine or network and block all users at once. While a network attack from a single IP address can be blocked by adding a new firewall rule, many forms of Distributed denial of service (DDoS) attacks are possible, where the attack comes from a large number of points – and defending is much more difficult. Such attacks can originate from the zombie computers of a botnet or from a range of other possible techniques, including distributed reflective denial of service (DRDoS), where innocent systems are fooled into sending traffic to the victim. With such attacks, the amplification factor makes the attack easier for the attacker because they have to use little bandwidth themselves.\\nTo understand why attackers may carry out these attacks, see the \\'attacker motivation\\' section. \\n\\n\\n=== Direct-access attacks ===\\nA direct-access attack is when an unauthorized user (an attacker) gains physical access to a computer, most likely to directly copy data from it or to steal information. Attackers may also compromise security by making operating system modifications, installing software worms, keyloggers, covert listening devices or using wireless microphones. Even when the system is protected by standard security measures, these may be bypassed by booting another operating system or tool from a CD-ROM or other bootable media. Disk encryption and Trusted Platform Module are designed to prevent these attacks.\\nDirect service attackers are related in concept to direct memory attacks that allows an attacker to gain direct access to a computer’s memory. The attacks \"take advantage of a feature of modern computers that allow certain devices, such as external hard drives, graphics cards or network cards, to access the computer’s memory directly.\"To help prevent these attacks, computer users must ensure that they have a strong passwords, that their computer is locked at all times when they are not using it, and that they keep their computer with them at all times when traveling.\\n\\n\\n=== Eavesdropping ===\\nEavesdropping is the act of surreptitiously listening to a private computer conversation (communication), usually between hosts on a network. It typically occurs when a user connects to a network where traffic is not secured or encrypted and sends sensitive business data to a colleague, which when listened to by an attacker could be exploited. Data transmitted across an \"open network\" gives an attacker the opportunity to exploit a vulnerability and intercept it via various methods.\\nUnlike malware, direct-access attacks, or other forms of cyber attacks, eavesdropping attacks are unlikely to negatively affect the performance of networks or devices, making them difficult to notice. In fact, \"the attacker does not need to have any ongoing connection to the software at all. He or she can insert the software onto a compromised device, perhaps by direct insertion or perhaps by a virus or other malware, and then come back some time later to retrieve any data that is found or trigger the software to send the data at some determined time.\"Using a virtual private network (VPN), which encrypts data between two points, is one of the most common forms of protection against eavesdropping. Using the best form of encryption possible for wireless networks is best practice, as well as using HTTPS instead of the unencrypted HTTP.Programs such as Carnivore and NarusInSight have been used by the Federal Bureau of Investigation (FBI) and NSA to eavesdrop on the systems of internet service providers. Even machines that operate as a closed system (i.e., with no contact with the outside world) can be eavesdropped upon by monitoring the faint electromagnetic transmissions generated by the hardware. TEMPEST is a specification by the NSA referring to these attacks.\\n\\n\\n=== Malware ===\\nMalicious software (malware) is any software code or computer program \"intentionally written to harm a computer system or its users.\" Once present on a computer, it can leak sensitive details such as personal information, business information and passwords, can give control of the system to the attacker, and can corrupt or delete data permanently. Another type of malware is ransomware, which is when \"malware installs itself onto a victim’s machine, encrypts their files, and then turns around and demands a ransom (usually in Bitcoin) to return that data to the user.\"Types of malware include some of the following:\\n\\nViruses are a specific type of malware, and are normally a malicious code that hijacks software with the intension to \"do damage and spread copies of itself.\" Copies are made with the aim to spread to other programs on a computer.\\nWorms are similar to viruses, however viruses can only function when a user runs (opens) a comprised program. Worms therefore are self-replicating malware that spread between programs, apps and devices without the need for human interaction.\\nTrojan horses are programs that pretend to be helpful or hide themselves within desired or legitimate software to \"trick users into installing them.\" Once installed, a RAT (remote access trojan) can create a secret backdoor on the affected device.\\nSpyware is a type of malware that secretly gathers information on an infected computers and transmits the sensitive information back to the attacker. One of the most common forms of spyware are known as keyloggers, which is a kind of malware which recorders all of a users keyboard inputs/keystrokes, used to \"allow hackers to harvest usernames, passwords, bank account and credit card numbers.\"\\nScareware, as the name suggests, is a form of malware which uses social engineering (manipulation) to scare, shock, trigger anxiety, or suggest the perception of a threat in order to manipulate users into buying or installing unwanted software. These attacks often begin with a \"sudden pop-up with an urgent message, usually warning the user that they\\'ve broken the law or their device has a virus.\"\\n\\n\\n=== Multi-vector, polymorphic attacks ===\\nSurfacing in 2017, a new class of multi-vector, polymorphic cyber threats combined several types of attacks and changed form to avoid cybersecurity controls as they spread.\\nMulti-vector polymorphic attacks, as the name describes, are both multi-vectored and polymorphic. Firstly, they are a singular offensive that involves multiple methods of attack. In this sense, they are “multi-vectored (i.e. the attack can use multiple means of propagation such as via the Web, email and applications.\" However,  they are also multi-staged, meaning that “they can infiltrate networks and move laterally inside the network.” The attacks can be polymorphic, meaning that the cyberattacks used such as viruses, worms or trojans “constantly change (“morph”) making it nearly impossible to detect them using signature-based defences.”\\n\\n\\n=== Phishing ===\\nPhishing is the attempt of acquiring sensitive information such as usernames, passwords, and credit card details directly from users by deceiving the users. Phishing is typically carried out by email spoofing, instant messaging, text message, or on a phone call, and it often directs users to enter details at a fake website whose look and feel are almost identical to the legitimate one. The fake website often asks for personal information, such as login details and passwords. This information can then be used to gain access to the individual\\'s real account on the real website. \\nPreying on a victim\\'s trust, phishing can be classified as a form of social engineering. Attackers are using creative ways to gain access to real accounts. A common scam is for attackers to send fake electronic invoices to individuals showing that they recently purchased music, apps, or others, and instructing them to click on a link if the purchases were not authorized. A more strategic type of phishing is spear-phishing which leverages personal or organization-specific details to make the attacker appear like a trusted source. Spear-phishing attacks target specific individuals, rather than the broad net cast by phishing attempts.\\n\\n\\n=== Privilege escalation ===\\nPrivilege escalation describes a situation where an attacker with some level of restricted access is able to, without authorization, elevate their privileges or access level. For example, a standard computer user may be able to exploit a vulnerability in the system to gain access to restricted data; or even become root and have full unrestricted access to a system. The severity of attacks can range from attacks simply sending an unsolicited email to a ransomware attack on large amounts of data. Privilege escalation usually starts with social engineering techniques, often phishing.Privilege escalation can be separated into to strategies, horizontal and vertical privilege escalation:\\n\\nHorizontal escalation (or account takeover) is where an attacker gains access to a normal user account that has relatively low-level privileges. This may be through stealing the user’s username and password. Once they have access, they have gained a “foothold,” and using this foothold the attacker then may move around the network of users at this same lower level, gaining access to information of this similar privilege.\\nVertical escalation however targets people higher up in a company and often with more administrative power, such as an employee in IT with a higher privilege. Using this privileged account will then enable to attacker to invade other accounts.\\n\\n\\n=== Side-channel attack ===\\n\\nAny computational system affects its environment in some form. This effect it has on its environment includes a wide range of criteria, which can range from electromagnetic radiation to residual effect on RAM cells which as a consequence make a Cold boot attack possible, to hardware implementation faults that allow for access and or guessing of other values that normally should be inaccessible. In Side-channel attack scenarios, the attacker would gather such information about a system or network to guess its internal state and as a result access the information which is assumed by the victim to be secure.\\n\\n\\n=== Social engineering ===\\nSocial engineering, in the context of computer security, aims to convince a user to disclose secrets such as passwords, card numbers, etc. or grant physical access by, for example, impersonating a senior executive, bank, a contractor, or a customer. This generally involves exploiting people\\'s trust, and relying on their cognitive biases. A common scam involves emails sent to accounting and finance department personnel, impersonating their CEO and urgently requesting some action. One of the main techniques of social engineering are phishing attacks. \\nIn early 2016, the FBI reported that such business email compromise (BEC) scams had cost US businesses more than $2 billion in about two years.In May 2016, the Milwaukee Bucks NBA team was the victim of this type of cyber scam with a perpetrator impersonating the team\\'s president Peter Feigin, resulting in the handover of all the team\\'s employees\\' 2015 W-2 tax forms.\\n\\n\\n=== Spoofing ===\\n\\nSpoofing is an act of pretending to be a valid entity through the falsification of data (such as an IP address or username), in order to gain access to information or resources that one is otherwise unauthorized to obtain. Spoofing is closely related to phishing. There are several types of spoofing, including:\\n\\nEmail spoofing, is where an attacker forges the sending (From, or source) address of an email.\\nIP address spoofing, where an attacker alters the source IP address in a network packet to hide their identity or impersonate another computing system.\\nMAC spoofing, where an attacker modifies the Media Access Control (MAC) address of their network interface controller to obscure their identity, or to pose as another.\\nBiometric spoofing, where an attacker produces a fake biometric sample to pose as another user.\\nAddress Resolution Protocol (ARP) spoofing, where an attacker sends spoofed address resolution protocol onto a local area network to associate their Media Access Control address with a different host\\'s IP address. This causes data to be sent to the attacker rather than the intended host.In 2018, the cybersecurity firm Trellix published research on the life-threatening risk of spoofing in the healthcare industry.\\n\\n\\n=== Tampering ===\\nTampering describes a malicious modification or alteration of data. An intentional but unauthorized act resulting in the modification of a system, components of systems, its intended behavior, or data. So-called Evil Maid attacks and security services planting of surveillance capability into routers are examples.\\n\\n\\n=== HTML smuggling ===\\nHTML files can carry payloads concealed as benign, inert data in order to defeat content filters. These payloads can be reconstructed on the other side of the filter.HTML smuggling allows an attacker to \"smuggle\" a malicious code inside a particular HTML or web page.\\n\\n\\n== Information security culture ==\\nEmployee behavior can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness toward information security within an organization. Information security culture is the \"...totality of patterns of behavior in an organization that contributes to the protection of information of all kinds.\"Andersson and Reimers (2014) found that employees often do not see themselves as part of their organization\\'s information security effort and often take actions that impede organizational changes. Indeed, the Verizon Data Breach Investigations Report 2020, which examined 3,950 security breaches, discovered 30% of cybersecurity incidents involved internal actors within a company. Research shows information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change\", authors commented, \"It\\'s a never-ending process, a cycle of evaluation and change or maintenance.\" To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\\nPre-evaluation: To identify the awareness of information security within employees and to analyze the current security policies.\\nStrategic planning: To come up with a better awareness program, clear targets need to be set. Assembling a team of skilled professionals is helpful to achieve it.\\nOperative planning: A good security culture can be established based on internal communication, management buy-in, security awareness and a training program.\\nImplementation: Four stages should be used to implement the information security culture. They are:Commitment of the management\\nCommunication with organizational members\\nCourses for all organizational members\\nCommitment of the employeesPost-evaluation: To assess the success of the planning and implementation, and to identify unresolved areas of concern.\\n\\n\\n== Computer protection (countermeasures) ==\\nIn computer security, a countermeasure is an action, device, procedure or technique that reduces a threat, a vulnerability, or an attack by eliminating or preventing it, by minimizing the harm it can cause, or by discovering and reporting it so that corrective action can be taken.Some common countermeasures are listed in the following sections:\\n\\n\\n=== Security by design ===\\n\\nSecurity by design, or alternately secure by design, means that the software has been designed from the ground up to be secure. In this case, security is considered a main feature.\\nSome of the techniques in this approach include:\\n\\nThe principle of least privilege, where each part of the system has only the privileges that are needed for its function. That way, even if an attacker gains access to that part, they only have limited access to the whole system.\\nAutomated theorem proving to prove the correctness of crucial software subsystems.\\nCode reviews and unit testing, approaches to make modules more secure where formal correctness proofs are not possible.\\nDefense in depth, where the design is such that more than one subsystem needs to be violated to compromise the integrity of the system and the information it holds.\\nDefault secure settings, and design to fail secure rather than fail insecure (see fail-safe for the equivalent in safety engineering). Ideally, a secure system should require a deliberate, conscious, knowledgeable and free decision on the part of legitimate authorities in order to make it insecure.\\nAudit trails track system activity so that when a security breach occurs, the mechanism and extent of the breach can be determined. Storing audit trails remotely, where they can only be appended to, can keep intruders from covering their tracks.\\nFull disclosure of all vulnerabilities, to ensure that the window of vulnerability is kept as short as possible when bugs are discovered.\\n\\n\\n=== Security architecture ===\\nThe Open Security Architecture organization defines IT security architecture as \"the design artifacts that describe how the security controls (security countermeasures) are positioned, and how they relate to the overall information technology architecture. These controls serve the purpose to maintain the system\\'s quality attributes: confidentiality, integrity, availability, accountability and assurance services\".Techopedia defines security architecture as \"a unified security design that addresses the necessities and potential risks involved in a certain scenario or environment. It also specifies when and where to apply security controls. The design process is generally reproducible.\" The key attributes of security architecture are:\\nthe relationship of different components and how they depend on each other.\\ndetermination of controls based on risk assessment, good practices, finances, and legal matters.\\nthe standardization of controls.Practicing security architecture provides the right foundation to systematically address business, IT and security concerns in an organization.\\n\\n\\n=== Security measures ===\\nA state of computer security is the conceptual ideal, attained by the use of the three processes: threat prevention, detection, and response. These processes are based on various policies and system components, which include the following:\\n\\nUser account access controls and cryptography can protect systems files and data, respectively.\\nFirewalls are by far the most common prevention systems from a network security perspective as they can (if properly configured) shield access to internal network services, and block certain kinds of attacks through packet filtering. Firewalls can be both hardware and software-based.\\nIntrusion Detection System (IDS) products are designed to detect network attacks in-progress and assist in post-attack forensics, while audit trails and logs serve a similar function for individual systems.\\nResponse is necessarily defined by the assessed security requirements of an individual system and may cover the range from simple upgrade of protections to notification of legal authorities, counter-attacks, and the like. In some special cases, the complete destruction of the compromised system is favored, as it may happen that not all the compromised resources are detected.\\nCyber security awareness training to cope with cyber threats and attacks.\\nForward web proxy solutions can prevent the client to visit malicious web pages and inspect the content before downloading to the client machines.Today, computer security consists mainly of preventive measures, like firewalls or an exit procedure. A firewall can be defined as a way of filtering network data between a host or a network and another network, such as the Internet, and can be implemented as software running on the machine, hooking into the network stack (or, in the case of most UNIX-based operating systems such as Linux, built into the operating system kernel) to provide real-time filtering and blocking. Another implementation is a so-called physical firewall, which consists of a separate machine filtering network traffic. Firewalls are common amongst machines that are permanently connected to the Internet.\\nSome organizations are turning to big data platforms, such as Apache Hadoop, to extend data accessibility and machine learning to detect advanced persistent threats.However, relatively few organizations maintain computer systems with effective detection systems, and fewer still have organized response mechanisms in place. As a result, as Reuters pointed out in 2010: \"Companies for the first time report they are losing more through electronic theft of data than physical stealing of assets\".In order to ensure adequate security, the confidentiality, integrity and availability of a network, better known as the CIA triad, must be protected and is considered the foundation to information security. To achieve those objectives, administrative, physical and technical security measures should be employed. The amount of security afforded to an asset can only be determined when its value is known.\\n\\n\\n=== Vulnerability management ===\\n\\nVulnerability management is the cycle of identifying, remediating or mitigating vulnerabilities, especially in software and firmware. Vulnerability management is integral to computer security and network security.\\nVulnerabilities can be discovered with a vulnerability scanner, which analyzes a computer system in search of known vulnerabilities, such as open ports, insecure software configuration, and susceptibility to malware.  In order for these tools to be effective, they must be kept up to date with every new update the vendor release.  Typically, these updates will scan for the new vulnerabilities that were introduced recently.\\nBeyond vulnerability scanning, many organizations contract outside security auditors to run regular penetration tests against their systems to identify vulnerabilities. In some sectors, this is a contractual requirement.\\n\\n\\n=== Reducing vulnerabilities ===\\nInformation technology security assessment aims to assess systems for risk and to predict and test for their vulnerabilities.\\nWhile formal verification of the correctness of computer systems is possible, it is not yet common. Operating systems formally verified include seL4, and SYSGO\\'s PikeOS – but these make up a very small percentage of the market.\\nTwo factor authentication is a method for mitigating unauthorized access to a system or sensitive information. It requires something you know; a password or PIN, and something you have; a card, dongle, cellphone, or another piece of hardware. This increases security as an unauthorized person needs both of these to gain access.\\nSocial engineering and direct computer access (physical) attacks can only be prevented by non-computer means, which can be difficult to enforce, relative to the sensitivity of the information. Training is often involved to help mitigate this risk, but even in highly disciplined environments (e.g. military organizations), social engineering attacks can still be difficult to foresee and prevent.\\nInoculation, derived from inoculation theory, seeks to prevent social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.It is possible to reduce an attacker\\'s chances by keeping systems up to date with security patches and updates, using a security scanner and/or hiring people with expertise in security, though none of these guarantee the prevention of an attack. The effects of data loss/damage can be reduced by careful backing up and insurance.\\n\\n\\n=== Hardware protection mechanisms ===\\n\\nWhile hardware may be a source of insecurity, such as with microchip vulnerabilities maliciously introduced during the manufacturing process, hardware-based or assisted computer security also offers an alternative to software-only computer security. Using devices and methods such as dongles, trusted platform modules, intrusion-aware cases, drive locks, disabling USB ports, and mobile-enabled access may be considered more secure due to the physical access (or sophisticated backdoor access) required in order to be compromised. Each of these is covered in more detail below.\\n\\nUSB dongles are typically used in software licensing schemes to unlock software capabilities, but they can also be seen as a way to prevent unauthorized access to a computer or other device\\'s software. The dongle, or key, essentially creates a secure encrypted tunnel between the software application and the key. The principle is that an encryption scheme on the dongle, such as Advanced Encryption Standard (AES) provides a stronger measure of security since it is harder to hack and replicate the dongle than to simply copy the native software to another machine and use it. Another security application for dongles is to use them for accessing web-based content such as cloud software or Virtual Private Networks (VPNs). In addition, a USB dongle can be configured to lock or unlock a computer.\\nTrusted platform modules (TPMs) secure devices by integrating cryptographic capabilities onto access devices, through the use of microprocessors, or so-called computers-on-a-chip. TPMs used in conjunction with server-side software offer a way to detect and authenticate hardware devices, preventing unauthorized network and data access.\\nComputer case intrusion detection refers to a device, typically a push-button switch, which detects when a computer case is opened. The firmware or BIOS is programmed to show an alert to the operator when the computer is booted up the next time.\\nDrive locks are essentially software tools to encrypt hard drives, making them inaccessible to thieves. Tools exist specifically for encrypting external drives as well.\\nDisabling USB ports is a security option for preventing unauthorized and malicious access to an otherwise secure computer. Infected USB dongles connected to a network from a computer inside the firewall are considered by the magazine Network World as the most common hardware threat facing computer networks.\\nDisconnecting or disabling peripheral devices ( like camera, GPS, removable storage etc.), that are not in use.\\nMobile-enabled access devices are growing in popularity due to the ubiquitous nature of cell phones. Built-in capabilities such as Bluetooth, the newer Bluetooth low energy (LE), near-field communication (NFC) on non-iOS devices and biometric validation such as thumbprint readers, as well as QR code reader software designed for mobile devices, offer new, secure ways for mobile phones to connect to access control systems. These control systems provide computer security and can also be used for controlling access to secure buildings.\\nIOMMUs allow for hardware-based sandboxing of components in mobile and desktop computers by utilizing direct memory access protections.\\nPhysical Unclonable Functions (PUFs) can be used as a digital fingerprint or a unique identifier to integrated circuits and hardware, providing users the ability to secure the hardware supply chains going into their systems.\\n\\n\\n=== Secure operating systems ===\\n\\nOne use of the term computer security refers to technology that is used to implement secure operating systems. In the 1980s, the United States Department of Defense (DoD) used the \"Orange Book\" standards, but the current international standard ISO/IEC 15408, Common Criteria defines a number of progressively more stringent Evaluation Assurance Levels. Many common operating systems meet the EAL4 standard of being \"Methodically Designed, Tested and Reviewed\", but the formal verification required for the highest levels means that they are uncommon. An example of an EAL6 (\"Semiformally Verified Design and Tested\") system is INTEGRITY-178B, which is used in the Airbus A380\\nand several military jets.\\n\\n\\n=== Secure coding ===\\n\\nIn software engineering, secure coding aims to guard against the accidental introduction of security vulnerabilities. It is also possible to create software designed from the ground up to be secure. Such systems are secure by design. Beyond this, formal verification aims to prove the correctness of the algorithms underlying a system;\\nimportant for cryptographic protocols for example.\\n\\n\\n=== Capabilities and access control lists ===\\n\\nWithin computer systems, two of the main security models capable of enforcing privilege separation are access control lists (ACLs) and role-based access control (RBAC).\\nAn access-control list (ACL), with respect to a computer file system, is a list of permissions associated with an object. An ACL specifies which users or system processes are granted access to objects, as well as what operations are allowed on given objects.\\nRole-based access control is an approach to restricting system access to authorized users,  used by the majority of enterprises with more than 500 employees, and can implement mandatory access control (MAC) or discretionary access control (DAC).\\nA further approach, capability-based security has been mostly restricted to research operating systems. Capabilities can, however, also be implemented at the language level, leading to a style of programming that is essentially a refinement of standard object-oriented design. An open-source project in the area is the E language.\\n\\n\\n=== End user security training ===\\nThe end-user is widely recognized as the weakest link in the security chain and it is estimated that more than 90% of security incidents and breaches involve some kind of human error. Among the most commonly recorded forms of errors and misjudgment are poor password management, sending emails containing sensitive data and attachments to the wrong recipient, the inability to recognize misleading URLs and to identify fake websites and dangerous email attachments.  A common mistake that users make is saving their user id/password in their browsers to make it easier to log in to banking sites.  This is a gift to attackers who have obtained access to a machine by some means.  The risk may be mitigated by the use of two-factor authentication.As the human component of cyber risk is particularly relevant in determining the global cyber risk an organization is facing, security awareness training, at all levels, not only provides formal compliance with regulatory and industry mandates but is considered essential in reducing cyber risk and protecting individuals and companies from the great majority of cyber threats.\\nThe focus on the end-user represents a profound cultural change for many security practitioners, who have traditionally approached cybersecurity exclusively from a technical perspective, and moves along the lines suggested by major security centers to develop a culture of cyber awareness within the organization, recognizing that a security-aware user provides an important line of defense against cyber attacks.\\n\\n\\n=== Digital hygiene ===\\nRelated to end-user training, digital hygiene or cyber hygiene is a fundamental principle relating to information security and, as the analogy with personal hygiene shows, is the equivalent of establishing simple routine measures to minimize the risks from cyber threats. The assumption is that good cyber hygiene practices can give networked users another layer of protection, reducing the risk that one vulnerable node will be used to either mount attacks or compromise another node or network, especially from common cyberattacks. Cyber hygiene should also not be mistaken for proactive cyber defence, a military term.As opposed to a purely technology-based defense against threats, cyber hygiene mostly regards routine measures that are technically simple to implement and mostly dependent on discipline or education. It can be thought of as an abstract list of tips or measures that have been demonstrated as having a positive effect on personal and/or collective digital security. As such, these measures can be performed by laypeople, not just security experts.\\nCyber hygiene relates to personal hygiene as computer viruses relate to biological viruses (or pathogens). However, while the term computer virus was coined almost simultaneously with the creation of the first working computer viruses, the term cyber hygiene is a much later invention, perhaps as late as 2000 by Internet pioneer Vint Cerf. It has since been adopted by the Congress and Senate of the United States, the FBI, EU institutions and heads of state.\\n\\n\\n=== Difficulty of responding to breaches ===\\nResponding to attempted security breaches is often very difficult for a variety of reasons, including:\\n\\nIdentifying attackers is difficult, as they may operate through proxies, temporary anonymous dial-up accounts, wireless connections, and other anonymizing procedures which make back-tracing difficult -  and are often located in another jurisdiction. If they successfully breach security, they have also often gained enough administrative access to enable them to delete logs to cover their tracks.\\nThe sheer number of attempted attacks, often by automated vulnerability scanners and computer worms, is so large that organizations cannot spend time pursuing each.\\nLaw enforcement officers often lack the skills, interest or budget to pursue attackers. In addition, the identification of attackers across a network may require logs from various points in the network and in many countries, which may be difficult or time-consuming to obtain.Where an attack succeeds and a breach occurs, many jurisdictions now have in place mandatory security breach notification laws.\\n\\n\\n=== Types of security and privacy ===\\n\\n\\n== Systems at risk ==\\nThe growth in the number of computer systems and the increasing reliance upon them by individuals, businesses, industries, and governments means that there are an increasing number of systems at risk.\\n\\n\\n=== Financial systems ===\\nThe computer systems of financial regulators and financial institutions like the U.S. Securities and Exchange Commission, SWIFT, investment banks, and commercial banks are prominent hacking targets for cybercriminals interested in manipulating markets and making illicit gains. Websites and apps that accept or store credit card numbers, brokerage accounts, and bank account information are also prominent hacking targets, because of the potential for immediate financial gain from transferring money, making purchases, or selling the information on the black market. In-store payment systems and ATMs have also been tampered with in order to gather customer account data and PINs.\\nThe UCLA Internet Report: Surveying the Digital Future (2000) found that the privacy of personal data created barriers to online sales and that more than nine out of 10 internet users were somewhat or very concerned about credit card security.The most common web technologies for improving security between browsers and websites are named SSL (Secure Sockets Layer), and its successor TLS (Transport Layer Security), identity management and authentication services, and domain name services allow companies and consumers to engage in secure communications and commerce. Several versions of SSL and TLS are commonly used today in applications such as web browsing, e-mail, internet faxing, instant messaging, and VoIP (voice-over-IP). There are various interoperable implementations of these technologies, including at least one implementation that is  open source. Open source allows anyone to view the application\\'s source code, and look for and report vulnerabilities.\\nThe credit card companies Visa and MasterCard cooperated to develop the secure EMV chip which is embedded in credit cards. Further developments include the Chip Authentication Program where banks give customers hand-held card readers to perform online secure transactions. Other developments in this arena include the development of technology such as Instant Issuance which has enabled shopping mall kiosks acting on behalf of banks to issue on-the-spot credit cards to interested customers.\\n\\n\\n=== Utilities and industrial equipment ===\\nComputers control functions at many utilities, including coordination of telecommunications, the power grid, nuclear power plants, and valve opening and closing in water and gas networks. The Internet is a potential attack vector for such machines if connected, but the Stuxnet worm demonstrated that even equipment controlled by computers not connected to the Internet can be vulnerable. In 2014, the Computer Emergency Readiness Team, a division of the Department of Homeland Security, investigated 79 hacking incidents at energy companies.\\n\\n\\n=== Aviation ===\\nThe aviation industry is very reliant on a series of complex systems which could be attacked. A simple power outage at one airport can cause repercussions worldwide, much of the system relies on radio transmissions which could be disrupted, and controlling aircraft over oceans is especially dangerous because radar surveillance only extends 175 to 225 miles offshore. There is also potential for attack from within an aircraft.In Europe, with the (Pan-European Network Service) and NewPENS, and in the US with the NextGen program, air navigation service providers are moving to create their own dedicated networks.\\nMany modern passports are now biometric passports, containing an embedded microchip that stores a digitized photograph and personal information such as name, gender, and date of birth. In addition, more countries are introducing facial recognition technology to reduce identity-related fraud. The introduction of the ePassport has assisted border officials in verifying the identity of the passport holder, thus allowing for quick passenger processing. Plans are under way in the US, the UK, and Australia to introduce SmartGate kiosks with both retina and fingerprint recognition technology. The airline industry is moving from the use of traditional paper tickets towards the use of electronic tickets (e-tickets). These have been made possible by advances in online credit card transactions in partnership with the airlines. Long-distance bus companies are also switching over to e-ticketing transactions today.\\nThe consequences of a successful attack range from loss of confidentiality to loss of system integrity, air traffic control outages, loss of aircraft, and even loss of life.\\n\\n\\n=== Consumer devices ===\\nDesktop computers and laptops are commonly targeted to gather passwords or financial account information or to construct a botnet to attack another target. Smartphones, tablet computers, smart watches, and other mobile devices such as quantified self devices like activity trackers have sensors such as cameras, microphones, GPS receivers, compasses, and accelerometers which could be exploited, and may collect personal information, including sensitive health information. WiFi, Bluetooth, and cell phone networks on any of these devices could be used as attack vectors, and sensors might be remotely activated after a successful breach.The increasing number of home automation devices such as the Nest thermostat are also potential targets.\\n\\n\\n=== Healthcare ===\\nToday many health-care providers and health insurance companies use the internet to provide enhanced products and services, for example through use of tele-health to potentially offer better quality and access to healthcare, or fitness trackers to lower insurance premiums.\\nThe health care company Humana partners with WebMD, Oracle Corporation, EDS and Microsoft to enable its members to access their health care records, as well as to provide an overview of health care plans. Patient records are increasingly being placed on secure in-house networks, alleviating the need for extra storage space.\\n\\n\\n=== Large corporations ===\\nLarge corporations are common targets. In many cases attacks are aimed at financial gain through identity theft and involve data breaches. Examples include the loss of millions of clients\\' credit card and financial details by Home Depot, Staples, Target Corporation, and Equifax.Medical records have been targeted in general identify theft, health insurance fraud, and impersonating patients to obtain prescription drugs for recreational purposes or resale. Although cyber threats continue to increase, 62% of all organizations did not increase security training for their business in 2015.Not all attacks are financially motivated, however: security firm HBGary Federal had a serious series of attacks in 2011 from hacktivist group Anonymous in retaliation for the firm\\'s CEO claiming to have infiltrated their group, and Sony Pictures was hacked in 2014 with the apparent dual motive of embarrassing the company through data leaks and crippling the company by wiping workstations and servers.\\n\\n\\n=== Automobiles ===\\n\\nVehicles are increasingly computerized, with engine timing, cruise control, anti-lock brakes, seat belt tensioners, door locks, airbags and advanced driver-assistance systems on many models. Additionally, connected cars may use WiFi and Bluetooth to communicate with onboard consumer devices and the cell phone network. Self-driving cars are expected to be even more complex. All of these systems carry some security risks, and such issues have gained wide attention.Simple examples of risk include a malicious compact disc being used as an attack vector, and the car\\'s onboard microphones being used for eavesdropping. However, if access is gained to a car\\'s internal controller area network, the danger is much greater – and in a widely publicized 2015 test, hackers remotely carjacked a vehicle from 10 miles away and drove it into a ditch.Manufacturers are reacting in numerous ways, with Tesla in 2016 pushing out some security fixes over the air into its cars\\' computer systems. In the area of autonomous vehicles, in September 2016 the United States Department of Transportation announced some initial safety standards, and called for states to come up with uniform policies.Additionally, e-Drivers’ licenses are being developed using the same technology. For example, Mexico’s licensing authority (ICV) has used a smart card platform to issue the first e-Drivers’ licenses to the city of Monterrey, in the state of Nuevo León.\\n\\n\\n=== Shipping ===\\nShipping companies have adopted RFID (Radio Frequency Identification) technology as an efficient, digitally secure, tracking device. Unlike a barcode, RFID can be read up to 20 feet away. RFID is used by FedEx and UPS.\\n\\n\\n=== Government ===\\nGovernment and military computer systems are commonly attacked by activists and foreign powers. Local and regional government infrastructure such as traffic light controls, police and intelligence agency communications, personnel records, as well as student records.The FBI, CIA, and Pentagon, all utilize secure controlled access technology for any of their buildings. However, the use of this form of technology is spreading into the entrepreneurial world. More and more companies are taking advantage of the development of digitally secure controlled access technology. GE\\'s ACUVision, for example, offers a single panel platform for access control, alarm monitoring and digital recording.\\n\\n\\n=== Internet of things and physical vulnerabilities ===\\nThe Internet of things (IoT) is the network of physical objects such as devices, vehicles, and buildings that are embedded with electronics, software, sensors, and network connectivity that enables them to collect and exchange data. Concerns have been raised that this is being developed without appropriate consideration of the security challenges involved.While the IoT creates opportunities for more direct integration of the physical world into computer-based systems,\\nit also provides opportunities for misuse. In particular, as the Internet of Things spreads widely, cyberattacks are likely to become an increasingly physical (rather than simply virtual) threat. If a front door\\'s lock is connected to the Internet, and can be locked/unlocked from a phone, then a criminal could enter the home at the press of a button from a stolen or hacked phone. People could stand to lose much more than their credit card numbers in a world controlled by IoT-enabled devices. Thieves have also used electronic means to circumvent non-Internet-connected hotel door locks.An attack that targets physical infrastructure and/or human lives is sometimes referred to as a cyber-kinetic attack. As IoT devices and appliances gain currency, cyber-kinetic attacks can become pervasive and significantly damaging.\\n\\n\\n=== Medical systems ===\\n\\nMedical devices have either been successfully attacked or had potentially deadly vulnerabilities demonstrated, including both in-hospital diagnostic equipment and implanted devices including pacemakers and insulin pumps. There are many reports of hospitals and hospital organizations getting hacked, including ransomware attacks, Windows XP exploits, viruses, and data breaches of sensitive data stored on hospital servers. On 28 December 2016 the US Food and Drug Administration released its recommendations for how medical device manufacturers should maintain the security of Internet-connected devices – but no structure for enforcement.\\n\\n\\n=== Energy sector ===\\nIn distributed generation systems, the risk of a cyber attack is real, according to Daily Energy Insider. An attack could cause a loss of power in a large area for a long period of time, and such an attack could have just as severe consequences as a natural disaster. The District of Columbia is considering creating a Distributed Energy Resources (DER) Authority within the city, with the goal being for customers to have more insight into their own energy use and giving the local electric utility, Pepco, the chance to better estimate energy demand. The D.C. proposal, however, would \"allow third-party vendors to create numerous points of energy distribution, which could potentially create more opportunities for cyber attackers to threaten the electric grid.\"\\n\\n\\n=== Telecommunications ===\\nPerhaps the most widely known digitally secure telecommunication device is the SIM (Subscriber Identity Module) card, a device that is embedded in most of the world’s cellular devices before any service can be obtained. The SIM card is just the beginning of this digitally secure environment.\\nThe Smart Card Web Servers draft standard (SCWS) defines the interfaces to an HTTP server in a smart card. Tests are being conducted to secure OTA (\"over-the-air\") payment and credit card information from and to a mobile phone. \\nCombination SIM/DVD devices are being developed through Smart Video Card technology which embeds a DVD-compliant optical disc into the card body of a regular SIM card.\\nOther telecommunication developments involving digital security include mobile signatures, which use the embedded SIM card to generate a legally binding electronic signature.\\n\\n\\n== Cost and impact of security breaches ==\\nSerious financial damage has been caused by security breaches, but because there is no standard model for estimating the cost of an incident, the only data available is that which is made public by the organizations involved. \"Several computer security consulting firms produce estimates of total worldwide losses attributable to virus and worm attacks and to hostile digital acts in general. The 2003 loss estimates by these firms range from $13 billion (worms and viruses only) to $226 billion (for all forms of covert attacks). The reliability of these estimates is often challenged; the underlying methodology is basically anecdotal.\"However, reasonable estimates of the financial cost of security breaches can actually help organizations make rational investment decisions. According to the classic Gordon-Loeb Model analyzing the optimal investment level in information security, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber/information security breach).\\n\\n\\n== Attacker motivation ==\\nAs with physical security, the motivations for breaches of computer security vary between attackers. Some are thrill-seekers or vandals, some are activists, others are criminals looking for financial gain. State-sponsored attackers are now common and well resourced but started with amateurs such as Markus Hess who hacked for the KGB, as recounted by Clifford Stoll in The Cuckoo\\'s Egg.\\nAttackers motivations can vary for all types of attacks from pleasure to for political goals. For example, \"hacktivists\" may target a company a company or organisation that carries out activities they do not agree with. This would be to create bad publicity for the company by having its website crash. \\nHigh capability hackers, often with larger backing or state sponsorship, may attack based on the demands of their financial backers. These attacks are more likely to attempt more serious attack. An example of a more serious attack was the 2015 Ukraine power grid hack, which reportedly utilised the spear-phising, destruction of files, and denial-of-service attacks to carry out the full attack.Additionally, recent attacker motivations can be traced back to extremist organizations seeking to gain political advantage or disrupt social agendas. The growth of the internet, mobile technologies, and inexpensive computing devices have led to a rise in capabilities but also to the risk to environments that are deemed as vital to operations. All critical targeted environments are susceptible to compromise and this has led to a series of proactive studies on how to migrate the risk by taking into consideration motivations by these types of actors. Several stark differences exist between the hacker motivation and that of nation state actors seeking to attack based on an ideological preference.A standard part of threat modeling for any particular system is to identify what might motivate an attack on that system, and who might be motivated to breach it. The level and detail of precautions will vary depending on the system to be secured. A home personal computer, bank, and classified military network face very different threats, even when the underlying technologies in use are similar.\\n\\n\\n== Computer security incident management ==\\nComputer security incident management is an organized approach to addressing and managing the aftermath of a computer security incident or compromise with the goal of preventing a breach or thwarting a cyberattack. An incident that is not identified and managed at the time of intrusion typically escalates to a more damaging event such as a data breach or system failure. The intended outcome of a computer security incident response plan is to contain the incident, limit damage and assist recovery to business as usual. Responding to compromises quickly can mitigate exploited vulnerabilities, restore services and processes and minimize losses.\\nIncident response planning allows an organization to establish a series of best practices to stop an intrusion before it causes damage. Typical incident response plans contain a set of written instructions that outline the organization\\'s response to a cyberattack. Without a documented plan in place, an organization may not successfully detect an intrusion or compromise and stakeholders may not understand their roles, processes and procedures during an escalation, slowing the organization\\'s response and resolution.\\nThere are four key components of a computer security incident response plan:\\n\\nPreparation: Preparing stakeholders on the procedures for handling computer security incidents or compromises\\nDetection and analysis: Identifying and investigating suspicious activity to confirm a security incident, prioritizing the response based on impact and coordinating notification of the incident\\nContainment, eradication and recovery: Isolating affected systems to prevent escalation and limit impact, pinpointing the genesis of the incident, removing malware, affected systems and bad actors from the environment and restoring systems and data when a threat no longer remains\\nPost incident activity: Post mortem analysis of the incident, its root cause and the organization\\'s response with the intent of improving the incident response plan and future response efforts.\\n\\n\\n== Notable attacks and breaches ==\\n\\nSome illustrative examples of different types of computer security breaches are given below.\\n\\n\\n=== Robert Morris and the first computer worm ===\\n\\nIn 1988, 60,000 computers were connected to the Internet, and most were mainframes, minicomputers and professional workstations. On 2 November 1988, many started to slow down, because they were running a malicious code that demanded processor time and that spread itself to other computers – the first internet computer worm. The software was traced back to 23-year-old Cornell University graduate student Robert Tappan Morris who said \"he wanted to count how many machines were connected to the Internet\".\\n\\n\\n=== Rome Laboratory ===\\nIn 1994, over a hundred intrusions were made by unidentified crackers into the Rome Laboratory, the US Air Force\\'s main command and research facility. Using trojan horses, hackers were able to obtain unrestricted access to Rome\\'s networking systems and remove traces of their activities. The intruders were able to obtain classified files, such as air tasking order systems data and furthermore able to penetrate connected networks of National Aeronautics and Space Administration\\'s Goddard Space Flight Center, Wright-Patterson Air Force Base, some Defense contractors, and other private sector organizations, by posing as a trusted Rome center user.\\n\\n\\n=== TJX customer credit card details ===\\nIn early 2007, American apparel and home goods company TJX announced that it was the victim of an unauthorized computer systems intrusion and that the hackers had accessed a system that stored data on credit card, debit card, check, and merchandise return transactions.\\n\\n\\n=== Stuxnet attack ===\\nIn 2010, the computer worm known as Stuxnet reportedly ruined almost one-fifth of Iran\\'s nuclear centrifuges. It did so by disrupting industrial programmable logic controllers (PLCs) in a targeted attack. This is generally believed to have been launched by Israel and the United States to disrupt Iran\\'s nuclear program – although neither has publicly admitted this.\\n\\n\\n=== Global surveillance disclosures ===\\n\\nIn early 2013, documents provided by Edward Snowden were published by The Washington Post and The Guardian exposing the massive scale of NSA global surveillance. There were also indications that the NSA may have inserted a backdoor in a NIST standard for encryption. This standard was later withdrawn due to widespread criticism. The NSA additionally were revealed to have tapped the links between Google\\'s data centers.\\n\\n\\n=== Target and Home Depot breaches ===\\nA Ukrainian hacker known as Rescator broke into Target Corporation computers in 2013, stealing roughly 40 million credit cards, and then Home Depot computers in 2014, stealing between 53 and 56 million credit card numbers. Warnings were delivered at both corporations, but ignored; physical security breaches using self checkout machines are believed to have played a large role. \"The malware utilized is absolutely unsophisticated and uninteresting,\" says Jim Walter, director of threat intelligence operations at security technology company McAfee – meaning that the heists could have easily been stopped by existing antivirus software had administrators responded to the warnings. The size of the thefts has resulted in major attention from state and Federal United States authorities and the investigation is ongoing.\\n\\n\\n=== Office of Personnel Management data breach ===\\nIn April 2015, the Office of Personnel Management discovered it had been hacked more than a year earlier in a data breach, resulting in the theft of approximately 21.5 million personnel records handled by the office. The Office of Personnel Management hack has been described by federal officials as among the largest breaches of government data in the history of the United States. Data targeted in the breach included personally identifiable information such as Social Security numbers, names, dates and places of birth, addresses, and fingerprints of current and former government employees as well as anyone who had undergone a government background check. It is believed the hack was perpetrated by Chinese hackers.\\n\\n\\n=== Ashley Madison breach ===\\n\\nIn July 2015, a hacker group is known as The Impact Team successfully breached the extramarital relationship website Ashley Madison, created by Avid Life Media. The group claimed that they had taken not only company data but user data as well. After the breach, The Impact Team dumped emails from the company\\'s CEO, to prove their point, and threatened to dump customer data unless the website was taken down permanently. When Avid Life Media did not take the site offline the group released two more compressed files, one 9.7GB and the second 20GB. After the second data dump, Avid Life Media CEO Noel Biderman resigned; but the website remained to function.\\n\\n\\n=== Colonial Pipeline ransomware attack ===\\n\\nIn June 2021, the cyber attack took down the largest fuel pipeline in the U.S. and led to shortages across the East Coast.\\n\\n\\n== Legal issues and global regulation ==\\nInternational legal issues of cyber attacks are complicated in nature. There is no global base of common rules to judge, and eventually punish, cybercrimes and cybercriminals - and where security firms or agencies do locate the cybercriminal behind the creation of a particular piece of malware or form of cyber attack, often the local authorities cannot take action due to lack of laws under which to prosecute. Proving attribution for cybercrimes and cyberattacks is also a major problem for all law enforcement agencies. \"Computer viruses switch from one country to another, from one jurisdiction to another – moving around the world, using the fact that we don\\'t have the capability to globally police operations like this. So the Internet is as if someone [had] given free plane tickets to all the online criminals of the world.\" The use of techniques such as dynamic DNS, fast flux and bullet proof servers add to the difficulty of investigation and enforcement.\\n\\n\\n== Role of government ==\\nThe role of the government is to make regulations to force companies and organizations to protect their systems, infrastructure and information from any cyberattacks, but also to protect its own national infrastructure such as the national power-grid.The government\\'s regulatory role in cyberspace is complicated. For some, cyberspace was seen as a virtual space that was to remain free of government intervention, as can be seen in many of today\\'s libertarian blockchain and bitcoin discussions.Many government officials and experts think that the government should do more and that there is a crucial need for improved regulation, mainly due to the failure of the private sector to solve efficiently the cybersecurity problem. R. Clarke said during a panel discussion at the RSA Security Conference in San Francisco, he believes that the \"industry only responds when you threaten regulation. If the industry doesn\\'t respond (to the threat), you have to follow through.\" On the other hand, executives from the private sector agree that improvements are necessary, but think that government intervention would affect their ability to innovate efficiently. Daniel R. McCarthy analyzed this public-private partnership in cybersecurity and reflected on the role of cybersecurity in the broader constitution of political order.On 22 May 2020, the UN Security Council held its second ever informal meeting on cybersecurity to focus on cyber challenges to international peace. According to UN Secretary-General António Guterres, new technologies are too often used to violate rights.\\n\\n\\n== International actions ==\\nMany different teams and organizations exist, including:\\n\\nThe Forum of Incident Response and Security Teams (FIRST) is the global association of CSIRTs. The US-CERT, AT&T, Apple, Cisco, McAfee, Microsoft are all members of this international team.\\nThe Council of Europe helps protect societies worldwide from the threat of cybercrime through the Convention on Cybercrime.\\nThe purpose of the Messaging Anti-Abuse Working Group (MAAWG) is to bring the messaging industry together to work collaboratively and to successfully address the various forms of messaging abuse, such as spam, viruses, denial-of-service attacks and other messaging exploitations. France Telecom, Facebook, AT&T, Apple, Cisco, Sprint are some of the members of the MAAWG.\\nENISA : The European Network and Information Security Agency (ENISA) is an agency of the European Union with the objective to improve network and information security in the European Union.\\n\\n\\n=== Europe ===\\nOn 14 April 2016, the European Parliament and the Council of the European Union adopted the General Data Protection Regulation (GDPR). The GDPR, which came into force on 25 May 2018, grants individuals within the European Union (EU) and the European Economic Area (EEA) the right to the protection of personal data. The regulation requires that any entity that processes personal data incorporate data protection by design and by default. It also requires that certain organizations appoint a Data Protection Officer (DPO).\\n\\n\\n== National actions ==\\n\\n\\n=== Computer emergency response teams ===\\n\\nMost countries have their own computer emergency response team to protect network security.\\n\\n\\n==== Canada ====\\nSince 2010, Canada has had a cybersecurity strategy. This functions as a counterpart document to the National Strategy and Action Plan for Critical Infrastructure. The strategy has three main pillars: securing government systems, securing vital private cyber systems, and helping Canadians to be secure online. There is also a Cyber Incident Management Framework to provide a coordinated response in the event of a cyber incident.The Canadian Cyber Incident Response Centre (CCIRC) is responsible for mitigating and responding to threats to Canada\\'s critical infrastructure and cyber systems. It provides support to mitigate cyber threats, technical support to respond & recover from targeted cyber attacks, and provides online tools for members of Canada\\'s critical infrastructure sectors. It posts regular cybersecurity bulletins & operates an online reporting tool where individuals and organizations can report a cyber incident.To inform the general public on how to protect themselves online, Public Safety Canada has partnered with STOP.THINK.CONNECT, a coalition of non-profit, private sector, and government organizations, and launched the Cyber Security Cooperation Program. They also run the GetCyberSafe portal for Canadian citizens, and Cyber Security Awareness Month during October.Public Safety Canada aims to begin an evaluation of Canada\\'s cybersecurity strategy in early 2015.\\n\\n\\n==== China ====\\nChina\\'s Central Leading Group for Internet Security and Informatization (Chinese: 中央网络安全和信息化领导小组) was established on 27 February 2014. This Leading Small Group (LSG) of the Chinese Communist Party is headed by General Secretary Xi Jinping himself and is staffed with relevant Party and state decision-makers. The LSG was created to overcome the incoherent policies and overlapping responsibilities that characterized China\\'s former cyberspace decision-making mechanisms. The LSG oversees policy-making in the economic, political, cultural, social and military fields as they relate to network security and IT strategy. This LSG also coordinates major policy initiatives in the international arena that promote norms and standards favored by the Chinese government and that emphasizes the principle of national sovereignty in cyberspace.\\n\\n\\n==== Germany ====\\nBerlin starts National Cyber Defense Initiative: On 16 June 2011, the German Minister for Home Affairs, officially opened the new German NCAZ (National Center for Cyber Defense) Nationales Cyber-Abwehrzentrum located in Bonn. The NCAZ closely cooperates with BSI (Federal Office for Information Security) Bundesamt für Sicherheit in der Informationstechnik, BKA (Federal Police Organisation) Bundeskriminalamt (Deutschland), BND (Federal Intelligence Service) Bundesnachrichtendienst, MAD (Military Intelligence Service) Amt für den Militärischen Abschirmdienst and other national organizations in Germany taking care of national security aspects. According to the Minister, the primary task of the new organization founded on 23 February 2011, is to detect and prevent attacks against the national infrastructure and mentioned incidents like Stuxnet. Germany has also established the largest research institution for IT security in Europe, the Center for Research in Security and Privacy (CRISP) in Darmstadt.\\n\\n\\n==== India ====\\nSome provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000.The National Cyber Security Policy 2013 is a policy framework by the Ministry of Electronics and Information Technology (MeitY) which aims to protect the public and private infrastructure from cyberattacks, and safeguard \"information, such as personal information (of web users), financial and banking information and sovereign data\". CERT- In is the nodal agency which monitors the cyber threats in the country. The post of National Cyber Security Coordinator has also been created in the Prime Minister\\'s Office (PMO).\\nThe Indian Companies Act 2013 has also introduced cyber law and cybersecurity obligations on the part of Indian directors. Some provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000 Update in 2013.\\n\\n\\n==== South Korea ====\\nFollowing cyberattacks in the first half of 2013, when the government, news media, television stations, and bank websites were compromised, the national government committed to the training of 5,000 new cybersecurity experts by 2017. The South Korean government blamed its northern counterpart for these attacks, as well as incidents that occurred in 2009, 2011, and 2012, but Pyongyang denies the accusations.\\n\\n\\n==== United States ====\\n\\n\\n===== Legislation =====\\nThe 1986 18 U.S.C. § 1030, the Computer Fraud and Abuse Act is the key legislation. It prohibits unauthorized access or damage of protected computers as defined in 18 U.S.C. § 1030(e)(2). Although various other measures have been proposed – none has succeeded.\\nIn 2013, executive order 13636 Improving Critical Infrastructure Cybersecurity was signed, which prompted the creation of the NIST Cybersecurity Framework.\\nIn response to the Colonial Pipeline ransomware attack President Joe Biden signed Executive Order 14028 on May 12, 2021, to increase software security standards for sales to the government, tighten detection and security on existing systems, improve information sharing and training, establish a Cyber Safety Review Board, and improve incident response.\\n\\n\\n===== Standardized government testing services =====\\nThe General Services Administration (GSA) has standardized the penetration test service as a pre-vetted support service, to rapidly address potential vulnerabilities, and stop adversaries before they impact US federal, state and local governments. These services are commonly referred to as Highly Adaptive Cybersecurity Services (HACS).\\n\\n\\n===== Agencies =====\\nThe Department of Homeland Security has a dedicated division responsible for the response system, risk management program and requirements for cybersecurity in the United States called the National Cyber Security Division. The division is home to US-CERT operations and the National Cyber Alert System. The National Cybersecurity and Communications Integration Center brings together government organizations responsible for protecting computer networks and networked infrastructure.The third priority of the FBI is to: \"Protect the United States against cyber-based attacks and high-technology crimes\", and they, along with the National White Collar Crime Center (NW3C), and the Bureau of Justice Assistance (BJA) are part of the multi-agency task force, The Internet Crime Complaint Center, also known as IC3.In addition to its own specific duties, the FBI participates alongside non-profit organizations such as InfraGard.The Computer Crime and Intellectual Property Section (CCIPS) operates in the United States Department of Justice Criminal Division. The CCIPS is in charge of investigating computer crime and intellectual property crime and is specialized in the search and seizure of digital evidence in computers and networks. In 2017, CCIPS published A Framework for a Vulnerability Disclosure Program for Online Systems to help organizations \"clearly describe authorized vulnerability disclosure and discovery conduct, thereby substantially reducing the likelihood that such described activities will result in a civil or criminal violation of law under the Computer Fraud and Abuse Act (18 U.S.C. § 1030).\"The United States Cyber Command, also known as USCYBERCOM, \"has the mission to direct, synchronize, and coordinate cyberspace planning and operations to defend and advance national interests in collaboration with domestic and international partners.\" It has no role in the protection of civilian networks.The U.S. Federal Communications Commission\\'s role in cybersecurity is to strengthen the protection of critical communications infrastructure, to assist in maintaining the reliability of networks during disasters, to aid in swift recovery after, and to ensure that first responders have access to effective communications services.The Food and Drug Administration has issued guidance for medical devices, and the National Highway Traffic Safety Administration is concerned with automotive cybersecurity. After being criticized by the Government Accountability Office, and following successful attacks on airports and claimed attacks on airplanes, the Federal Aviation Administration has devoted funding to securing systems on board the planes of private manufacturers, and the Aircraft Communications Addressing and Reporting System. Concerns have also been raised about the future Next Generation Air Transportation System.The US Department of Defense (DoD) issued DoD Directive 8570 in 2004, supplemented by DoD Directive 8140, requiring all DoD employees and all DoD contract personnel involved in information assurance roles and activities to earn and maintain various industry Information Technology (IT) certifications in an effort to ensure that all DoD personnel involved in network infrastructure defense have minimum levels of IT industry recognized knowledge, skills and abilities (KSA). Andersson and Reimers (2019) report these certifications range from CompTIA\\'s A+ and Security+ through the ICS2.org\\'s CISSP, etc.\\n\\n\\n===== Computer emergency readiness team =====\\nComputer emergency response team is a name given to expert groups that handle computer security incidents. In the US, two distinct organizations exist, although they do work closely together.\\n\\nUS-CERT: part of the National Cyber Security Division of the United States Department of Homeland Security.\\nCERT/CC: created by the Defense Advanced Research Projects Agency (DARPA) and run by the Software Engineering Institute (SEI).\\n\\n\\n== Modern warfare ==\\n\\nThere is growing concern that cyberspace will become the next theater of warfare. As Mark Clayton from The Christian Science Monitor wrote in a 2015 article titled \"The New Cyber Arms Race\":\\n\\nIn the future, wars will not just be fought by soldiers with guns or with planes that drop bombs. They will also be fought with the click of a mouse a half a world away that unleashes carefully weaponized computer programs that disrupt or destroy critical industries like utilities, transportation, communications, and energy. Such attacks could also disable military networks that control the movement of troops, the path of jet fighters, the command and control of warships.\\nThis has led to new terms such as cyberwarfare and cyberterrorism. The United States Cyber Command was created in 2009 and many other countries have similar forces.\\nThere are a few critical voices that question whether cybersecurity is as significant a threat as it is made out to be.\\n\\n\\n== Careers ==\\nCybersecurity is a fast-growing field of IT concerned with reducing organizations\\' risk of hack or data breaches. According to research from the Enterprise Strategy Group, 46% of organizations say that they have a \"problematic shortage\" of cybersecurity skills in 2016, up from 28% in 2015. Commercial, government and non-governmental organizations all employ cybersecurity professionals. The fastest increases in demand for cybersecurity workers are in industries managing increasing volumes of consumer data such as finance, health care, and retail. However, the use of the term cybersecurity is more prevalent in government job descriptions.Typical cybersecurity job titles and descriptions include:\\n\\n\\n=== Security analyst ===\\nAnalyzes and assesses vulnerabilities in the infrastructure (software, hardware, networks), investigates using available tools and countermeasures to remedy the detected vulnerabilities and recommends solutions and best practices. Analyzes and assesses damage to the data/infrastructure as a result of security incidents, examines available recovery tools and processes, and recommends solutions. Tests for compliance with security policies and procedures. May assist in the creation, implementation, or management of security solutions.\\n\\n\\n=== Security engineer ===\\nPerforms security monitoring, security and data/logs analysis, and forensic analysis, to detect security incidents, and mount the incident response. Investigates and utilizes new technologies and processes to enhance security capabilities and implement improvements. May also review code or perform other security engineering methodologies.\\n\\n\\n=== Security architect ===\\nDesigns a security system or major components of a security system, and may head a security design team building a new security system.\\n\\n\\n=== Chief Information Security Officer (CISO) ===\\nA high-level management position responsible for the entire information security division/staff. The position may include hands-on technical work.\\n\\n\\n=== Chief Security Officer (CSO) ===\\nA high-level management position responsible for the entire security division/staff. A newer position is now deemed needed as security risks grow.\\n\\n\\n=== Data Protection Officer (DPO) ===\\nA DPO is tasked with monitoring compliance with the UK GDPR and other data protection laws, our data protection policies, awareness-raising, training, and audits.\\n\\n\\n=== Security Consultant/Specialist/Intelligence ===\\nBroad titles that encompass any one or all of the other roles or titles tasked with protecting computers, networks, software, data or information systems against viruses, worms, spyware, malware, intrusion detection, unauthorized access, denial-of-service attacks, and an ever-increasing list of attacks by hackers acting as individuals or as part of organized crime or foreign governments.Student programs are also available for people interested in beginning a career in cybersecurity. Meanwhile, a flexible and effective option for information security professionals of all experience levels to keep studying is online security training, including webcasts. A wide range of certified courses are also available.In the United Kingdom, a nationwide set of cybersecurity forums, known as the U.K Cyber Security Forum, were established supported by the Government\\'s cybersecurity strategy in order to encourage start-ups and innovation and to address the skills gap identified by the U.K Government.\\nIn Singapore, the Cyber Security Agency has issued a Singapore Operational Technology (OT) Cybersecurity Competency Framework (OTCCF). The framework defines emerging cybersecurity roles in Operational Technology. The OTCCF was endorsed by the Infocomm Media Development Authority (IMDA). It outlines the different OT cybersecurity job positions as well as the technical skills and core competencies necessary. It also depicts the many career paths available, including vertical and lateral advancement opportunities.\\n\\n\\n== Terminology ==\\nThe following terms used with regards to computer security are explained below:\\n\\nAccess authorization restricts access to a computer to a group of users through the use of authentication systems. These systems can protect either the whole computer, such as through an interactive login screen, or individual services, such as a FTP server. There are many methods for identifying and authenticating users, such as passwords, identification cards, smart cards, and biometric systems.\\nAnti-virus software consists of computer programs that attempt to identify, thwart, and eliminate computer viruses and other malicious software (malware).\\nApplications are executable code, so general corporate practice is to restrict or block users the power to install them; to install them only when there is a demonstrated need (e.g. software needed to perform assignments); to install only those which are known to be reputable (preferably with access to the computer code used to create the application,- and to reduce the attack surface by installing as few as possible. They are typically run with least privilege, with a robust process in place to identify, test and install any released security patches or updates for them.\\nFor example, programs can be installed into an individual user\\'s account, which limits the program\\'s potential access, as well as being a means control which users have specific exceptions to policy.  In Linux], FreeBSD, OpenBSD, and other Unix-like operating systems there is an option to further restrict an application using chroot or other means of restricting the application to its own \\'sandbox\\'.  For example. Linux provides namespaces, and Cgroups to further restrict the access of an application to system resources.\\nGeneralized security frameworks such as SELinux or AppArmor help administrators control access.\\nJava and other languages which compile to Java byte code and run in the Java virtual machine can have their access to other applications controlled at the virtual machine level.\\nSome software can be run in software containers which can even provide their own set of system libraries, limiting the software\\'s, or anyone controlling it, access to the server\\'s versions of the libraries.\\nAuthentication techniques can be used to ensure that communication end-points are who they say they are.\\nAutomated theorem proving and other verification tools can be used to enable critical algorithms and code used in secure systems to be mathematically proven to meet their specifications.\\nBackups are one or more copies kept of important computer files. Typically, multiple copies will be kept at different locations so that if a copy is stolen or damaged, other copies will still exist.\\nCapability and access control list techniques can be used to ensure privilege separation and mandatory access control. Capabilities vs. ACLs discusses their use.\\nChain of trust techniques can be used to attempt to ensure that all software loaded has been certified as authentic by the system\\'s designers.\\nConfidentiality is the nondisclosure of information except to another authorized person.\\nCryptographic techniques can be used to defend data in transit between systems, reducing the probability that the data exchange between systems can be intercepted or modified.\\nCyberwarfare is an Internet-based conflict that involves politically motivated attacks on information and information systems. Such attacks can, for example, disable official websites and networks, disrupt or disable essential services, steal or alter classified data, and cripple financial systems.\\nData integrity is the accuracy and consistency of stored data, indicated by an absence of any alteration in data between two updates of a data record.Encryption is used to protect the confidentiality of a message. Cryptographically secure ciphers are designed to make any practical attempt of breaking them infeasible. Symmetric-key ciphers are suitable for bulk encryption using shared keys, and public-key encryption using digital certificates can provide a practical solution for the problem of securely communicating when no key is shared in advance.\\nEndpoint security software aids networks in preventing malware infection and data theft at network entry points made vulnerable by the prevalence of potentially infected devices such as laptops, mobile devices, and USB drives.\\nFirewalls serve as a gatekeeper system between networks, allowing only traffic that matches defined rules. They often include detailed logging, and may include intrusion detection and intrusion prevention features. They are near-universal between company local area networks and the Internet, but can also be used internally to impose traffic rules between networks if network segmentation is configured.\\nA hacker is someone who seeks to breach defenses and exploit weaknesses in a computer system or network.\\nHoney pots are computers that are intentionally left vulnerable to attack by crackers. They can be used to catch crackers and to identify their techniques.\\nIntrusion-detection systems are devices or software applications that monitor networks or systems for malicious activity or policy violations.\\nA microkernel is an approach to operating system design which has only the near-minimum amount of code running at the most privileged level – and runs other elements of the operating system such as device drivers, protocol stacks and file systems, in the safer, less privileged user space.\\nPinging. The standard ping application can be used to test if an IP address is in use. If it is, attackers may then try a port scan to detect which services are exposed.\\nA port scan is used to probe an IP address for open ports to identify accessible network services and applications.\\nA key logger is spyware that silently captures and stores each keystroke that a user types on the computer\\'s keyboard.\\nSocial engineering is the use of deception to manipulate individuals to breach security.\\nLogic bombs is a type of malware added to a legitimate program that lies dormant until it is triggered by a specific event.\\nZero trust security means that no one is trusted by default from inside or outside the network, and verification is required from everyone trying to gain access to resources on the network.\\n\\n\\n== History ==\\nSince the Internet\\'s arrival and with the digital transformation initiated in recent years, the notion of cybersecurity has become a familiar subject in both our professional and personal lives. Cybersecurity and cyber threats have been consistently present for the last 60 years of technological change. In the 1970s and 1980s, computer security was mainly limited to academia until the conception of the Internet, where, with increased connectivity, computer viruses and network intrusions began to take off. After the spread of viruses in the 1990s, the 2000s marked the institutionalization of organized attacks such as distributed denial of service. This led to the formalization of cybersecurity as a professional discipline.The April 1967 session organized by Willis Ware at the Spring Joint Computer Conference, and the later publication of the Ware Report, were foundational moments in the history of the field of computer security. Ware\\'s work straddled the intersection of material, cultural, political, and social concerns.A 1977 NIST publication introduced the CIA triad of confidentiality, integrity, and availability as a clear and simple way to describe key security goals. While still relevant, many more elaborate frameworks have since been proposed.However, in the 1970s and 1980s, there were no grave computer threats because computers and the internet were still developing, and security threats were easily identifiable. More often, threats came from malicious insiders who gained unauthorized access to sensitive documents and files. Although malware and network breaches existed during the early years, they did not use them for financial gain. By the second half of the 1970s, established computer firms like IBM started offering commercial access control systems and computer security software products.One of the earliest examples of an attack on a computer network was the computer worm Creeper written by Bob Thomas at BBN, which propagated through the ARPANET in 1971. The program was purely experimental in nature and carried no malicious payload. A later program, Reaper, was created by Ray Tomlinson in 1972 and used to destroy Creeper.Between September 1986 and June 1987, a group of German hackers performed the first documented case of cyber espionage. The group hacked into American defense contractors, universities, and military base networks and sold gathered information to the Soviet KGB. The group was led by Markus Hess, who was arrested on 29 June 1987. He was convicted of espionage (along with two co-conspirators) on 15 Feb 1990.\\nIn 1988, one of the first computer worms, called the Morris worm, was distributed via the Internet. It gained significant mainstream media attention.In 1993, Netscape started developing the protocol SSL, shortly after the National Center for Supercomputing Applications (NCSA) launched Mosaic 1.0, the first web browser, in 1993. Netscape had SSL version 1.0 ready in 1994, but it was never released to the public due to many serious security vulnerabilities. These weaknesses included replay attacks and a vulnerability that allowed hackers to alter unencrypted communications sent by users. However, in February 1995, Netscape launched Version 2.0. The National Security Agency (NSA) is responsible for the protection of U.S. information systems and also for collecting foreign intelligence. The agency analyzes commonly used software and system configurations to find security flaws, which it can use for offensive purposes against competitors of the United States.NSA contractors created and sold click-and-shoot attack tools to US agencies and close allies, but eventually, the tools made their way to foreign adversaries. In 2016, NSAs own hacking tools were hacked, and they have been used by Russia and North Korea. NSA\\'s employees and contractors have been recruited at high salaries by adversaries, anxious to compete in cyberwarfare. In 2007, the United States and Israel began exploiting security flaws in the Microsoft Windows operating system to attack and damage equipment used in Iran to refine nuclear materials. Iran responded by heavily investing in their own cyberwarfare capability, which it began using against the United States.\\n\\n\\n== Notable scholars ==\\n\\n\\n== See also ==\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nBranch, Jordan (24 September 2020). \"What\\'s in a Name? Metaphors and Cybersecurity\". International Organization. Cambridge University Press (CUP). 75 (1): 39–70. doi:10.1017/s002081832000051x. ISSN 0020-8183. S2CID 224886794.\\nCostigan, Sean; Hennessy, Michael (2016). Cybersecurity: A Generic Reference Curriculum (PDF). NATO. ISBN 978-9284501960. Archived (PDF) from the original on 10 March 2017.\\nFuller, Christopher J (11 June 2018). \"The Roots of the United States\\' Cyber (In)Security\" (DOC). Diplomatic History. Oxford University Press (OUP). 43 (1): 157–185. doi:10.1093/dh/dhy038. ISSN 0145-2096.\\nBob, Yonah Jeremy (21 August 2021). \"Ex-IDF cyber intel. official reveals secrets behind cyber offense\". The Jerusalem Post.\\nKim, Peter (2014). The Hacker Playbook: Practical Guide To Penetration Testing. Seattle: CreateSpace Independent Publishing Platform. ISBN 978-1494932633.\\nLee, Newton (2015). Counterterrorism and Cybersecurity: Total Information Awareness (2nd ed.). Springer. ISBN 978-3319172439.\\nMontagnani, Maria Lillà; Cavallo, Mirta Antonella (2018). \"Cybersecurity and Liability in a Big Data World\". Market and Competition Law Review. Elsevier BV. 2 (2): 71–98. doi:10.2139/ssrn.3220475. ISSN 1556-5068. S2CID 216704215. SSRN 3220475.\\nShariati, Marzieh; Bahmani, Faezeh; Shams, Fereidoon (2011). \"Enterprise information security, a review of architectures and frameworks from interoperability perspective\". Procedia Computer Science. Elsevier BV. 3: 537–543. doi:10.1016/j.procs.2010.12.089. ISSN 1877-0509.\\nSinger, P. W.; Friedman, Allan (2014). Cybersecurity and Cyberwar: What Everyone Needs to Know. Oxford University Press. ISBN 978-0199918119.\\nWu, Chwan-Hwa (John); Irwin, J. David (2013). Introduction to Computer Networks and Cybersecurity. Boca Raton: CRC Press. ISBN 978-1466572133.\\n\\n\\n== External links ==\\n\\nComputer security at Curlie',\n",
              " 'Cricket is a bat-and-ball game played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps. The batting side scores runs by striking the ball bowled at one of the wickets with the bat and then running between the wickets, while the bowling and fielding side tries to prevent this (by preventing the ball from leaving the field, and getting the ball to either wicket) and dismiss each batter (so they are \"out\"). Means of dismissal include being bowled, when the ball hits the stumps and dislodges the bails, and by the fielding side either catching the ball after it is hit by the bat, but before it hits the ground, or hitting a wicket with the ball before a batter can cross the crease in front of the wicket. When ten batters have been dismissed, the innings ends and the teams swap roles. The game is adjudicated by two umpires, aided by a third umpire and match referee in international matches. They communicate with two off-field scorers who record the match\\'s statistical information.\\nForms of cricket range from Twenty20 (also known as T20), with each team batting for a single innings of 20 overs (each \"over\" being a set of 6 fair opportunities for the batting team to score) and the game generally lasting three to four hours, to Test matches played over five days. Traditionally cricketers play in all-white kit, but in limited overs cricket they wear club or team colours. In addition to the basic kit, some players wear protective gear to prevent injury caused by the ball, which is a hard, solid spheroid made of compressed leather with a slightly raised sewn seam enclosing a cork core layered with tightly wound string.\\nThe earliest known definite reference to cricket is to it being played in South East England in the mid-16th century. It spread globally with the expansion of the British Empire, with the first international matches in the second half of the 19th century. The game\\'s governing body is the International Cricket Council (ICC), which has over 100 members, twelve of which are full members who play Test matches. The game\\'s rules, the Laws of Cricket, are maintained by Marylebone Cricket Club (MCC) in London. The sport is followed primarily in South Asia, Australia, New Zealand, the United Kingdom, Southern Africa and the West Indies.Women\\'s cricket, which is organised and played separately, has also achieved international standard. \\nThe most successful side playing international cricket is Australia, which has won eight One Day International trophies, including six World Cups, more than any other country and has been the top-rated Test side more than any other country.\\n\\n\\n== History ==\\n\\n\\n=== Origins ===\\n\\nCricket is one of many games in the \"club ball\" sphere that basically involve hitting a ball with a hand-held implement; others include baseball (which shares many similarities with cricket, both belonging in the more specific bat-and-ball games category), golf, hockey, tennis, squash, badminton and table tennis. In cricket\\'s case, a key difference is the existence of a solid target structure, the wicket (originally, it is thought, a \"wicket gate\" through which sheep were herded), that the batter must defend. The cricket historian Harry Altham identified three \"groups\" of \"club ball\" games: the \"hockey group\", in which the ball is driven to and from between two targets (the goals); the \"golf group\", in which the ball is driven towards an undefended target (the hole); and the \"cricket group\", in which \"the ball is aimed at a mark (the wicket) and driven away from it\".It is generally believed that cricket originated as a children\\'s game in the south-eastern counties of England, sometime during the medieval period. Although there are claims for prior dates, the earliest definite reference to cricket being played comes from evidence given at a court case in Guildford in January 1597 (Old Style, equating to January 1598 in the modern calendar). The case concerned ownership of a certain plot of land and the court heard the testimony of a 59-year-old coroner, John Derrick, who gave witness that:\\nBeing a scholler in the ffree schoole of Guldeford hee and diverse of his fellows did runne and play there at creckett and other plaies.\\nGiven Derrick\\'s age, it was about half a century earlier when he was at school and so it is certain that cricket was being played c.\\u20091550 by boys in Surrey. The view that it was originally a children\\'s game is reinforced by Randle Cotgrave\\'s 1611 English-French dictionary in which he defined the noun \"crosse\" as \"the crooked staff wherewith boys play at cricket\" and the verb form \"crosser\" as \"to play at cricket\".One possible source for the sport\\'s name is the Old English word \"cryce\" (or \"cricc\") meaning a crutch or staff. In Samuel Johnson\\'s Dictionary, he derived cricket from \"cryce, Saxon, a stick\". In Old French, the word \"criquet\" seems to have meant a kind of club or stick. Given the strong medieval trade connections between south-east England and the County of Flanders when the latter belonged to the Duchy of Burgundy, the name may have been derived from the Middle Dutch (in use in Flanders at the time) \"krick\"(-e), meaning a stick (crook). Another possible source is the Middle Dutch word \"krickstoel\", meaning a long low stool used for kneeling in church and which resembled the long low wicket with two stumps used in early cricket. According to Heiner Gillmeister, a European language expert of Bonn University, \"cricket\" derives from the Middle Dutch phrase for hockey, met de (krik ket)sen (i.e., \"with the stick chase\"). Gillmeister has suggested that not only the name but also the sport itself may be of Flemish origin.\\n\\n\\n=== Growth of amateur and professional cricket in England ===\\nAlthough the main object of the game has always been to score the most runs, the early form of cricket differed from the modern game in certain key technical aspects; the North American variant of cricket known as wicket retained many of these aspects. The ball was bowled underarm by the bowler and along the ground towards a batter armed with a bat that in shape resembled a hockey stick; the batter defended a low, two-stump wicket; and runs were called notches because the scorers recorded them by notching tally sticks.In 1611, the year Cotgrave\\'s dictionary was published, ecclesiastical court records at Sidlesham in Sussex state that two parishioners, Bartholomew Wyatt and Richard Latter, failed to attend church on Easter Sunday because they were playing cricket. They were fined 12d each and ordered to do penance. This is the earliest mention of adult participation in cricket and it was around the same time that the earliest known organised inter-parish or village match was played – at Chevening, Kent. In 1624, a player called Jasper Vinall died after he was accidentally struck on the head during a match between two parish teams in Sussex.Cricket remained a low-key local pursuit for much of the 17th century. It is known, through numerous references found in the records of ecclesiastical court cases, to have been proscribed at times by the Puritans before and during the Commonwealth. The problem was nearly always the issue of Sunday play as the Puritans considered cricket to be \"profane\" if played on the Sabbath, especially if large crowds or gambling were involved.According to the social historian Derek Birley, there was a \"great upsurge of sport after the Restoration\" in 1660. Several members of the court of King Charles II took a strong interest in cricket during that era. Gambling on sport became a problem significant enough for Parliament to pass the 1664 Gambling Act, limiting stakes to £100 which was, in any case, a colossal sum exceeding the annual income of 99% of the population. Along with horse racing, as well as prizefighting and other types of blood sport, cricket was perceived to be a gambling sport. Rich patrons made matches for high stakes, forming teams in which they engaged the first professional players. By the end of the century, cricket had developed into a major sport that was spreading throughout England and was already being taken abroad by English mariners and colonisers – the earliest reference to cricket overseas is dated 1676. A 1697 newspaper report survives of \"a great cricket match\" played in Sussex \"for fifty guineas apiece\" – this is the earliest known contest that is generally considered a First Class match.The patrons, and other players from the social class known as the \"gentry\", began to classify themselves as \"amateurs\" to establish a clear distinction from the professionals, who were invariably members of the working class, even to the point of having separate changing and dining facilities. The gentry, including such high-ranking nobles as the Dukes of Richmond, exerted their honour code of noblesse oblige to claim rights of leadership in any sporting contests they took part in, especially as it was necessary for them to play alongside their \"social inferiors\" if they were to win their bets. In time, a perception took hold that the typical amateur who played in first-class cricket, until 1962 when amateurism was abolished, was someone with a public school education who had then gone to one of Cambridge or Oxford University – society insisted that such people were \"officers and gentlemen\" whose destiny was to provide leadership. In a purely financial sense, the cricketing amateur would theoretically claim expenses for playing while his professional counterpart played under contract and was paid a wage or match fee; in practice, many amateurs claimed more than actual expenditure and the derisive term \"shamateur\" was coined to describe the practice.\\n\\n\\n=== English cricket in the 18th and 19th centuries ===\\nThe game underwent major development in the 18th century to become England\\'s national sport. Its success was underwritten by the twin necessities of patronage and betting. Cricket was prominent in London as early as 1707 and, in the middle years of the century, large crowds flocked to matches on the Artillery Ground in Finsbury. The single wicket form of the sport attracted huge crowds and wagers to match, its popularity peaking in the 1748 season. Bowling underwent an evolution around 1760 when bowlers began to pitch the ball instead of rolling or skimming it towards the batter. This caused a revolution in bat design because, to deal with the bouncing ball, it was necessary to introduce the modern straight bat in place of the old \"hockey stick\" shape.The Hambledon Club was founded in the 1760s and, for the next twenty years until the formation of Marylebone Cricket Club (MCC) and the opening of Lord\\'s Old Ground in 1787, Hambledon was both the game\\'s greatest club and its focal point. MCC quickly became the sport\\'s premier club and the custodian of the Laws of Cricket. New Laws introduced in the latter part of the 18th century included the three stump wicket and leg before wicket (lbw).The 19th century saw underarm bowling superseded by first roundarm and then overarm bowling. Both developments were controversial. Organisation of the game at county level led to the creation of the county clubs, starting with Sussex in 1839. In December 1889, the eight leading county clubs formed the official County Championship, which began in 1890.\\nThe most famous player of the 19th century was W. G. Grace, who started his long and influential career in 1865. It was especially during the career of Grace that the distinction between amateurs and professionals became blurred by the existence of players like him who were nominally amateur but, in terms of their financial gain, de facto professional. Grace himself was said to have been paid more money for playing cricket than any professional.The last two decades before the First World War have been called the \"Golden Age of cricket\". It is a nostalgic name prompted by the collective sense of loss resulting from the war, but the period did produce some great players and memorable matches, especially as organised competition at county and Test level developed.\\n\\n\\n=== Cricket becomes an international sport ===\\nIn 1844, the first-ever international match took place between what were essentially club teams, from the United States and Canada, in Toronto; Canada won. In 1859, a team of English players went to North America on the first overseas tour. Meanwhile, the British Empire had been instrumental in spreading the game overseas and by the middle of the 19th century it had become well established in Australia, the Caribbean, British India (which includes present-day Pakistan and Bangladesh), New Zealand, North America and South Africa.In 1862, an English team made the first tour of Australia. The first Australian team to travel overseas consisted of Aboriginal stockmen which toured England in 1868.In 1876–77, an England team took part in what was retrospectively recognized as the first-ever Test match at the Melbourne Cricket Ground against Australia. The rivalry between England and Australia gave birth to The Ashes in 1882, and this has remained Test cricket\\'s most famous contest. Test cricket began to expand in 1888–89 when South Africa played England.\\n\\n\\n=== World cricket in the 20th century ===\\nThe inter-war years were dominated by Australia\\'s Don Bradman, statistically the greatest Test batter of all time. Test cricket continued to expand during the 20th century with the addition of the West Indies (1928), New Zealand (1930) and India (1932) before the Second World War and then Pakistan (1952), Sri Lanka (1982), Zimbabwe (1992), Bangladesh (2000), Ireland and Afghanistan (both 2018) in the post-war period. South Africa was banned from international cricket from 1970 to 1992 as part of the apartheid boycott.\\n\\n\\n=== The rise of limited overs cricket ===\\nCricket entered a new era in 1963 when English counties introduced the limited overs variant. As it was sure to produce a result, limited overs cricket was lucrative and the number of matches increased. The first Limited Overs International was played in 1971 and the governing International Cricket Council (ICC), seeing its potential, staged the first limited overs Cricket World Cup in 1975. In the 21st century, a new limited overs form, Twenty20, made an immediate impact. On 22 June 2017, Afghanistan and Ireland became the 11th and 12th ICC full members, enabling them to play Test cricket.\\n\\n\\n== Laws and gameplay ==\\n\\nIn cricket, the rules of the game are specified in a code called The Laws of Cricket (hereinafter called \"the Laws\") which has a global remit. There are 42 Laws (always written with a capital \"L\"). The earliest known version of the code was drafted in 1744 and, since 1788, it has been owned and maintained by its custodian, the Marylebone Cricket Club (MCC) in London.\\n\\n\\n=== Playing area ===\\n\\nCricket is a bat-and-ball game played on a cricket field (see image of cricket pitch and creases) between two teams of eleven players each. The field is usually circular or oval in shape and the edge of the playing area is marked by a boundary, which may be a fence, part of the stands, a rope, a painted line or a combination of these; the boundary must if possible be marked along its entire length.In the approximate centre of the field is a rectangular pitch (see image, below) on which a wooden target called a wicket is sited at each end; the wickets are placed 22 yards (20 m) apart. The pitch is a flat surface 10 feet (3.0 m) wide, with very short grass that tends to be worn away as the game progresses (cricket can also be played on artificial surfaces, notably matting). Each wicket is made of three wooden stumps topped by two bails.\\nAs illustrated, the pitch is marked at each end with four white painted lines: a bowling crease, a popping crease and two return creases. The three stumps are aligned centrally on the bowling crease, which is eight feet eight inches long. The popping crease is drawn four feet in front of the bowling crease and parallel to it; although it is drawn as a twelve-foot line (six feet either side of the wicket), it is, in fact, unlimited in length. The return creases are drawn at right angles to the popping crease so that they intersect the ends of the bowling crease; each return crease is drawn as an eight-foot line, so that it extends four feet behind the bowling crease, but is also, in fact, unlimited in length.\\n\\n\\n=== Match structure and closure ===\\n\\nBefore a match begins, the team captains (who are also players) toss a coin to decide which team will bat first and so take the first innings. Innings is the term used for each phase of play in the match. In each innings, one team bats, attempting to score runs, while the other team bowls and fields the ball, attempting to restrict the scoring and dismiss the batters. When the first innings ends, the teams change roles; there can be two to four innings depending upon the type of match. A match with four scheduled innings is played over three to five days; a match with two scheduled innings is usually completed in a single day. During an innings, all eleven members of the fielding team take the field, but usually only two members of the batting team are on the field at any given time. The exception to this is if a batter has any type of illness or injury restricting his or her ability to run, in this case the batter is allowed a runner who can run between the wickets when the batter hits a scoring run or runs, though this does not apply in international cricket. The order of batters is usually announced just before the match, but it can be varied.The main objective of each team is to score more runs than their opponents but, in some forms of cricket, it is also necessary to dismiss all of the opposition batters in their final innings in order to win the match, which would otherwise be drawn. If the team batting last is all out having scored fewer runs than their opponents, they are said to have \"lost by n runs\" (where n is the difference between the aggregate number of runs scored by the teams). If the team that bats last scores enough runs to win, it is said to have \"won by n wickets\", where n is the number of wickets left to fall. For example, a team that passes its opponents\\' total having lost six wickets (i.e., six of their batters have been dismissed) have won the match \"by four wickets\".In a two-innings-a-side match, one team\\'s combined first and second innings total may be less than the other side\\'s first innings total. The team with the greater score is then said to have \"won by an innings and n runs\", and does not need to bat again: n is the difference between the two teams\\' aggregate scores. If the team batting last is all out, and both sides have scored the same number of runs, then the match is a tie; this result is quite rare in matches of two innings a side with only 62 happening in first-class matches from the earliest known instance in 1741 until January 2017. In the traditional form of the game, if the time allotted for the match expires before either side can win, then the game is declared a draw.If the match has only a single innings per side, then usually a maximum number of overs applies to each innings. Such a match is called a \"limited overs\" or \"one-day\" match, and the side scoring more runs wins regardless of the number of wickets lost, so that a draw cannot occur. In some cases, ties are broken by having each team bat for a one-over innings known as a Super Over; subsequent Super Overs may be played if the first Super Over ends in a tie. If this kind of match is temporarily interrupted by bad weather, then a complex mathematical formula, known as the Duckworth–Lewis–Stern method after its developers, is often used to recalculate a new target score. A one-day match can also be declared a \"no-result\" if fewer than a previously agreed number of overs have been bowled by either team, in circumstances that make normal resumption of play impossible; for example, wet weather.In all forms of cricket, the umpires can abandon the match if bad light or rain makes it impossible to continue. There have been instances of entire matches, even Test matches scheduled to be played over five days, being lost to bad weather without a ball being bowled: for example, the third Test of the 1970/71 series in Australia.\\n\\n\\n==== Innings ====\\n\\nThe innings (ending with \\'s\\' in both singular and plural form) is the term used for each phase of play during a match. Depending on the type of match being played, each team has either one or two innings. Sometimes all eleven members of the batting side take a turn to bat but, for various reasons, an innings can end before they have all done so. The innings terminates if the batting team is \"all out\", a term defined by the Laws: \"at the fall of a wicket or the retirement of a batter, further balls remain to be bowled but no further batter is available to come in\". In this situation, one of the batters has not been dismissed and is termed not out; this is because he has no partners left and there must always be two active batters while the innings is in progress.\\nAn innings may end early while there are still two not out batters:\\nthe batting team\\'s captain may declare the innings closed even though some of his players have not had a turn to bat: this is a tactical decision by the captain, usually because he believes his team have scored sufficient runs and need time to dismiss the opposition in their innings\\nthe set number of overs (i.e., in a limited overs match) have been bowled\\nthe match has ended prematurely due to bad weather or running out of time\\nin the final innings of the match, the batting side has reached its target and won the game.\\n\\n\\n===== Overs =====\\n\\nThe Laws state that, throughout an innings, \"the ball shall be bowled from each end alternately in overs of 6 balls\". The name \"over\" came about because the umpire calls \"Over!\" when six balls have been bowled. At this point, another bowler is deployed at the other end, and the fielding side changes ends while the batters do not. A bowler cannot bowl two successive overs, although a bowler can (and usually does) bowl alternate overs, from the same end, for several overs which are termed a \"spell\". The batters do not change ends at the end of the over, and so the one who was non-striker is now the striker and vice versa. The umpires also change positions so that the one who was at \"square leg\" now stands behind the wicket at the non-striker\\'s end and vice versa.\\n\\n\\n=== Clothing and equipment ===\\n\\nThe wicket-keeper (a specialised fielder behind the batter) and the batters wear protective gear because of the hardness of the ball, which can be delivered at speeds of more than 145 kilometres per hour (90 mph) and presents a major health and safety concern. Protective clothing includes pads (designed to protect the knees and shins), batting gloves or wicket-keeper\\'s gloves for the hands, a safety helmet for the head and a box for male players inside the trousers (to protect the crotch area). Some batters wear additional padding inside their shirts and trousers such as thigh pads, arm pads, rib protectors and shoulder pads. The only fielders allowed to wear protective gear are those in positions very close to the batter (i.e., if they are alongside or in front of him), but they cannot wear gloves or external leg guards.Subject to certain variations, on-field clothing generally includes a collared shirt with short or long sleeves; long trousers; woolen pullover (if needed); cricket cap (for fielding) or a safety helmet; and spiked shoes or boots to increase traction. The kit is traditionally all white and this remains the case in Test and first-class cricket but, in limited overs cricket, team colours are worn instead.\\n\\n\\n==== Bat and ball ====\\n\\nThe essence of the sport is that a bowler delivers (i.e., bowls) the ball from his or her end of the pitch towards the batter who, armed with a bat, is \"on strike\" at the other end (see next sub-section: Basic gameplay).\\nThe bat is made of wood, usually Salix alba (white willow), and has the shape of a blade topped by a cylindrical handle. The blade must not be more than 4.25 inches (10.8 cm) wide and the total length of the bat not more than 38 inches (97 cm). There is no standard for the weight, which is usually between 2 lb 7 oz and 3 lb (1.1 and 1.4 kg).The ball is a hard leather-seamed spheroid, with a circumference of 9 inches (23 cm). The ball has a \"seam\": six rows of stitches attaching the leather shell of the ball to the string and cork interior. The seam on a new ball is prominent and helps the bowler propel it in a less predictable manner. During matches, the quality of the ball deteriorates to a point where it is no longer usable;  during the course of this deterioration, its behaviour in flight will change and can influence the outcome of the match. Players will, therefore, attempt to modify the ball\\'s behaviour by modifying its physical properties. Polishing the ball and wetting it with sweat or saliva is legal, even when the polishing is deliberately done on one side only to increase the ball\\'s swing through the air, but the acts of rubbing other substances into the ball, scratching the surface or picking at the seam are illegal ball tampering.\\n\\n\\n=== Player roles ===\\n\\n\\n==== Basic gameplay: bowler to batter ====\\nDuring normal play, thirteen players and two umpires are on the field. Two of the players are batters and the rest are all eleven members of the fielding team. The other nine players in the batting team are off the field in the pavilion. The image with overlay below shows what is happening when a ball is being bowled and which of the personnel are on or close to the pitch.\\nIn the photo, the two batters (3 & 8; wearing yellow) have taken position at each end of the pitch (6). Three members of the fielding team (4, 10 & 11; wearing dark blue) are in shot. One of the two umpires (1; wearing white hat) is stationed behind the wicket (2) at the bowler\\'s (4) end of the pitch. The bowler (4) is bowling the ball (5) from his end of the pitch to the batter (8) at the other end who is called the \"striker\". The other batter (3) at the bowling end is called the \"non-striker\". The wicket-keeper (10), who is a specialist, is positioned behind the striker\\'s wicket (9) and behind him stands one of the fielders in a position called \"first slip\" (11). While the bowler and the first slip are wearing conventional kit only, the two batters and the wicket-keeper are wearing protective gear including safety helmets, padded gloves and leg guards (pads).\\nWhile the umpire (1) in shot stands at the bowler\\'s end of the pitch, his colleague stands in the outfield, usually in or near the fielding position called \"square leg\", so that he is in line with the popping crease (7) at the striker\\'s end of the pitch. The bowling crease (not numbered) is the one on which the wicket is located between the return creases (12). The bowler (4) intends to hit the wicket (9) with the ball (5) or, at least, to prevent the striker (8) from scoring runs. The striker (8) intends, by using his bat, to defend his wicket and, if possible, to hit the ball away from the pitch in order to score runs.\\nSome players are skilled in both batting and bowling, or as either of these as well as wicket-keeping, so are termed all-rounders.  Bowlers are classified according to their style, generally as fast bowlers, seam bowlers or spinners. Batters are classified according to whether they are right-handed or left-handed.\\n\\n\\n==== Fielding ====\\n\\nOf the eleven fielders, three are in shot in the image above. The other eight are elsewhere on the field, their positions determined on a tactical basis by the captain or the bowler. Fielders often change position between deliveries, again as directed by the captain or bowler.If a fielder is injured or becomes ill during a match, a substitute is allowed to field instead of him, but the substitute cannot bowl or act as a captain, except in the case of concussion substitutes in international cricket. The substitute leaves the field when the injured player is fit to return. The Laws of Cricket were updated in 2017 to allow substitutes to act as wicket-keepers.\\n\\n\\n==== Bowling and dismissal ====\\n\\nMost bowlers are considered specialists in that they are selected for the team because of their skill as a bowler, although some are all-rounders and even specialist batters bowl occasionally. The specialists bowl several times during an innings but may not bowl two overs consecutively. If the captain wants a bowler to \"change ends\", another bowler must temporarily fill in so that the change is not immediate.A bowler reaches his delivery stride by means of a \"run-up\" and an over is deemed to have begun when the bowler starts his run-up for the first delivery of that over, the ball then being \"in play\". Fast bowlers, needing momentum, take a lengthy run up while bowlers with a slow delivery take no more than a couple of steps before bowling. The fastest bowlers can deliver the ball at a speed of over 145 kilometres per hour (90 mph) and they sometimes rely on sheer speed to try to defeat the batter, who is forced to react very quickly. Other fast bowlers rely on a mixture of speed and guile by making the ball seam or swing (i.e. curve) in flight. This type of delivery can deceive a batter into miscuing his shot, for example, so that the ball just touches the edge of the bat and can then be \"caught behind\" by the wicket-keeper or a slip fielder. At the other end of the bowling scale is the spin bowler who bowls at a relatively slow pace and relies entirely on guile to deceive the batter. A spinner will often \"buy his wicket\" by \"tossing one up\" (in a slower, steeper parabolic path) to lure the batter into making a poor shot. The batter has to be very wary of such deliveries as they are often \"flighted\" or spun so that the ball will not behave quite as he expects and he could be \"trapped\" into getting himself out. In between the pacemen and the spinners are the medium paced seamers who rely on persistent accuracy to try to contain the rate of scoring and wear down the batter\\'s concentration.There are nine ways in which a batter can be dismissed: five relatively common and four extremely rare. The common forms of dismissal are bowled, caught, leg before wicket (lbw), run out and stumped. Rare methods are hit wicket, hit the ball twice, obstructing the field and timed out. The Laws state that the fielding team, usually the bowler in practice, must appeal for a dismissal before the umpire can give his decision. If the batter is out, the umpire raises a forefinger and says \"Out!\"; otherwise, he will shake his head and say \"Not out\". There is, effectively, a tenth method of dismissal, retired out, which is not an on-field dismissal as such but rather a retrospective one for which no fielder is credited.\\n\\n\\n==== Batting, runs and extras ====\\n\\nBatters take turns to bat via a batting order which is decided beforehand by the team captain and presented to the umpires, though the order remains flexible when the captain officially nominates the team. Substitute batters are generally not allowed, except in the case of concussion substitutes in international cricket.In order to begin batting the batter first adopts a batting stance. Standardly, this involves adopting a slight crouch with the feet pointing across the front of the wicket, looking in the direction of the bowler, and holding the bat so it passes over the feet and so its tip can rest on the ground near to the toes of the back foot.A skilled batter can use a wide array of \"shots\" or \"strokes\" in both defensive and attacking mode. The idea is to hit the ball to the best effect with the flat surface of the bat\\'s blade. If the ball touches the side of the bat it is called an \"edge\". The batter does not have to play a shot and can allow the ball to go through to the wicketkeeper. Equally, he does not have to attempt a run when he hits the ball with his bat. Batters do not always seek to hit the ball as hard as possible, and a good player can score runs just by making a deft stroke with a turn of the wrists or by simply \"blocking\" the ball but directing it away from fielders so that he has time to take a run. A wide variety of shots are played, the batter\\'s repertoire including strokes named according to the style of swing and the direction aimed: e.g., \"cut\", \"drive\", \"hook\", \"pull\".The batter on strike (i.e. the \"striker\") must prevent the ball hitting the wicket, and try to score runs by hitting the ball with his bat so that he and his partner have time to run from one end of the pitch to the other before the fielding side can return the ball. To register a run, both runners must touch the ground behind the popping crease with either their bats or their bodies (the batters carry their bats as they run). Each completed run increments the score of both the team and the striker.\\nThe decision to attempt a run is ideally made by the batter who has the better view of the ball\\'s progress, and this is communicated by calling: usually \"yes\", \"no\" or \"wait\". More than one run can be scored from a single hit: hits worth one to three runs are common, but the size of the field is such that it is usually difficult to run four or more. To compensate for this, hits that reach the boundary of the field are automatically awarded four runs if the ball touches the ground en route to the boundary or six runs if the ball clears the boundary without touching the ground within the boundary. In these cases the batters do not need to run. Hits for five are unusual and generally rely on the help of \"overthrows\" by a fielder returning the ball. \\nIf an odd number of runs is scored by the striker, the two batters have changed ends, and the one who was non-striker is now the striker. Only the striker can score individual runs, but all runs are added to the team\\'s total.Additional runs can be gained by the batting team as extras (called \"sundries\" in Australia) due to errors made by the fielding side. This is achieved in four ways: no-ball, a penalty of one extra conceded by the bowler if he breaks the rules; wide, a penalty of one extra conceded by the bowler if he bowls so that the ball is out of the batter\\'s reach; bye, an extra awarded if the batter misses the ball and it goes past the wicket-keeper and gives the batters time to run in the conventional way; leg bye, as for a bye except that the ball has hit the batter\\'s body, though not his bat. If the bowler has conceded a no-ball or a wide, his team incurs an additional penalty because that ball (i.e., delivery) has to be bowled again and hence the batting side has the opportunity to score more runs from this extra ball.\\n\\n\\n==== Specialist roles ====\\n\\nThe captain is often the most experienced player in the team, certainly the most tactically astute, and can possess any of the main skillsets as a batter, a bowler or a wicket-keeper. Within the Laws, the captain has certain responsibilities in terms of nominating his players to the umpires before the match and ensuring that his players conduct themselves \"within the spirit and traditions of the game as well as within the Laws\".The wicket-keeper (sometimes called simply the \"keeper\") is a specialist fielder subject to various rules within the Laws about his equipment and demeanour. He is the only member of the fielding side who can effect a stumping and is the only one permitted to wear gloves and external leg guards.Depending on their primary skills, the other ten players in the team tend to be classified as specialist batters or specialist bowlers. Generally, a team will include five or six specialist batters and four or five specialist bowlers, plus the wicket-keeper.\\n\\n\\n=== Umpires and scorers ===\\n\\nThe game on the field is regulated by the two umpires, one of whom stands behind the wicket at the bowler\\'s end, the other in a position called \"square leg\" which is about 15–20 metres away from the batter on strike and in line with the popping crease on which he is taking guard. The umpires have several responsibilities including adjudication on whether a ball has been correctly bowled (i.e., not a no-ball or a wide); when a run is scored; whether a batter is out (the fielding side must first appeal to the umpire, usually with the phrase \"How\\'s that?\" or \"Owzat?\"); when intervals start and end; and the suitability of the pitch, field and weather for playing the game. The umpires are authorised to interrupt or even abandon a match due to circumstances likely to endanger the players, such as a damp pitch or deterioration of the light.Off the field in televised matches, there is usually a third umpire who can make decisions on certain incidents with the aid of video evidence. The third umpire is mandatory under the playing conditions for Test and Limited Overs International matches played between two ICC full member countries. These matches also have a match referee whose job is to ensure that play is within the Laws and the spirit of the game.The match details, including runs and dismissals, are recorded by two official scorers, one representing each team. The scorers are directed by the hand signals of an umpire (see image, right). For example, the umpire raises a forefinger to signal that the batter is out (has been dismissed); he raises both arms above his head if the batter has hit the ball for six runs. The scorers are required by the Laws to record all runs scored, wickets taken and overs bowled; in practice, they also note significant amounts of additional data relating to the game.A match\\'s statistics are summarised on a scorecard. Prior to the popularisation of scorecards, most scoring was done by men sitting on vantage points cuttings notches on tally sticks and runs were originally called notches. According to Rowland Bowen, the earliest known scorecard templates were introduced in 1776 by T. Pratt of Sevenoaks and soon came into general use. It is believed that scorecards were printed and sold at Lord\\'s for the first time in 1846.\\n\\n\\n=== Spirit of the Game ===\\n\\nBesides observing the Laws, cricketers must respect the \"Spirit of Cricket\", a concept encompassing sportsmanship, fair play and mutual respect. This spirit has long been considered an integral part of the sport but is only nebulously defined. Amidst concern that the spirit was weakening, in 2000 a Preamble was added to the Laws instructing all participants to play within the spirit of the game. The Preamble was last updated in 2017, now opening with the line:\\n\"Cricket owes much of its appeal and enjoyment to the fact that it should be played not only\\naccording to the Laws, but also within the Spirit of Cricket\".\\nThe Preamble is a short statement intended to emphasise the \"positive behaviours that make cricket an exciting game that encourages leadership, friendship, and teamwork.\" Its second line states that \"the major responsibility for ensuring fair play rests with the captains, but extends to all players, match officials and, especially in junior cricket, teachers, coaches and parents.\"The umpires are the sole judges of fair and unfair play. They are required under the Laws to intervene in case of dangerous or unfair play or in cases of unacceptable conduct by a player.\\nPrevious versions of the Spirit identified actions that were deemed contrary (for example, appealing knowing that the batter is not out) but all specifics are now covered in the Laws of Cricket, the relevant governing playing regulations and disciplinary codes, or left to the judgement of the umpires, captains, their clubs and governing bodies. The terse expression of the Spirit of Cricket now avoids the diversity of cultural conventions that exist in the detail of sportsmanship – or its absence.\\n\\n\\n== Women\\'s cricket ==\\n\\nWomen\\'s cricket was first recorded in Surrey in 1745. International development began at the start of the 20th century and the first Test match was played between Australia and England in December 1934. The following year, New Zealand joined them, and in 2007 Netherland became the tenth women\\'s Test nation when they made their debut against South Africa. In 1958, the International Women\\'s Cricket Council was founded (it merged with the ICC in 2005). In 1973, the first Cricket World Cup of any kind took place when a Women\\'s World Cup was held in England.  In 2005, the International Women\\'s Cricket Council was merged with the International Cricket Council (ICC) to form one unified body to help manage and develop cricket. The ICC Women\\'s Rankings were launched on 1 October 2015 covering all three formats of women\\'s cricket. In October 2018 following the ICC\\'s decision to award T20 International status to all members, the Women\\'s rankings were split into separate ODI (for Full Members) and T20I lists.\\n\\n\\n== Governance ==\\n\\nThe International Cricket Council (ICC), which has its headquarters in Dubai, is the global governing body of cricket. It was founded as the Imperial Cricket Conference in 1909 by representatives from England, Australia and South Africa, renamed the International Cricket Conference in 1965 and took up its current name in 1989. The ICC in 2017 has 105 member nations, twelve of which hold full membership and can play Test cricket. The ICC is responsible for the organisation and governance of cricket\\'s major international tournaments, notably the men\\'s and women\\'s versions of the Cricket World Cup. It also appoints the umpires and referees that officiate at all sanctioned Test matches, Limited Overs Internationals and Twenty20 Internationals.\\nEach member nation has a national cricket board which regulates cricket matches played in its country, selects the national squad, and organises home and away tours for the national team. In the West Indies, which for cricket purposes is a federation of nations, these matters are addressed by Cricket West Indies.The table below lists the ICC full members and their national cricket boards:\\n\\n\\n== Forms of cricket ==\\n\\nCricket is a multi-faceted sport with multiple formats that can effectively be divided into first-class cricket, limited overs cricket and, historically, single wicket cricket. \\nThe highest standard is Test cricket (always written with a capital \"T\") which is in effect the international version of first-class cricket and is restricted to teams representing the twelve countries that are full members of the ICC (see above). Although the term \"Test match\" was not coined until much later, Test cricket is deemed to have begun with two matches between Australia and England in the 1876–77 Australian season; since 1882, most Test series between England and Australia have been played for a trophy known as The Ashes. The term \"first-class\", in general usage, is applied to top-level domestic cricket. Test matches are played over five days and first-class over three to four days; in all of these matches, the teams are allotted two innings each and the draw is a valid result.Limited overs cricket is always scheduled for completion in a single day, and the teams are allotted one innings each. There are two main types: List A which normally allows fifty overs per team; and Twenty20 in which the teams have twenty overs each. Both of the limited overs forms are played internationally as Limited Overs Internationals (LOI) and Twenty20 Internationals (T20I). List A was introduced in England in the 1963 season as a knockout cup contested by the first-class county clubs. In 1969, a national league competition was established. The concept was gradually introduced to the other leading cricket countries and the first limited overs international was played in 1971. In 1975, the first Cricket World Cup took place in England. Twenty20 is a new variant of limited overs itself with the purpose being to complete the match within about three to four hours, usually in an evening session. The first Twenty20 World Championship was held in 2007. In addition, a few full-member cricket boards have decided to start leagues that are played in the T10 format, in which games are intended to last approximately 90 minutes. Limited overs matches cannot be drawn, although a tie is possible and an unfinished match is a \"no result\".Single wicket was popular in the 18th and 19th centuries and its matches were generally considered top-class. In this form, although each team may have from one to six players, there is only one batter in at a time and he must face every delivery bowled while his innings lasts. Single wicket has rarely been played since limited overs cricket began. Matches tended to have two innings per team like a full first-class one and they could end in a draw.\\n\\n\\n== Competitions ==\\nCricket is played at both the international and domestic level. There is one major international championship per format, and top-level domestic competitions mirror the three main international formats. There are now a number of T20 leagues, which have spawned a \"T20 freelancer\" phenomenon.\\n\\n\\n=== International competitions ===\\n\\nMost international matches are played as parts of \\'tours\\', when one nation travels to another for a number of weeks or months, and plays a number of matches of various sorts against the host nation. Sometimes a perpetual trophy is awarded to the winner of the Test series, the most famous of which is The Ashes.\\nThe ICC also organises competitions that are for several countries at once, including the Cricket World Cup, ICC T20 World Cup and ICC Champions Trophy. A league competition for Test matches played as part of normal tours, the ICC World Test Championship, had been proposed several times, and its first instance began in 2019. A league competition for ODIs, the ICC Cricket World Cup Super League, began in August 2020 and lasted only for one edition. The ICC maintains Test rankings, ODI rankings and T20 rankings systems for the countries which play these forms of cricket.\\nCompetitions for member nations of the ICC with Associate status include the ICC Intercontinental Cup, for first-class cricket matches, and the World Cricket League for one-day matches, the final matches of which now also serve as the ICC World Cup Qualifier.\\nThe game\\'s only appearance in an Olympic Games was the 1900 Olympics. However, it is scheduled to make a return, with the T20 format of the game, in the 2028 Summer Olympics in Los Angeles.\\n\\n\\n=== National competitions ===\\n\\n\\n==== First-class ====\\n\\nFirst-class cricket in England is played for the most part by the 18 county clubs which contest the County Championship. The concept of a champion county has existed since the 18th century but the official competition was not established until 1890. The most successful club has been Yorkshire, who had won 32 official titles (plus one shared) as of 2019.Australia established its national first-class championship in 1892–93 when the Sheffield Shield was introduced. In Australia, the first-class teams represent the various states. New South Wales has the highest number of titles.\\nThe other ICC full members have national championship trophies called the Ahmad Shah Abdali 4-day Tournament (Afghanistan); the National Cricket League (Bangladesh); the Ranji Trophy (India); the Inter-Provincial Championship (Ireland); the Plunket Shield (New Zealand); the Quaid-e-Azam Trophy (Pakistan); the Currie Cup (South Africa); the Premier Trophy (Sri Lanka); the Shell Shield (West Indies); and the Logan Cup (Zimbabwe).\\n\\n\\n==== Limited overs ====\\n\\n\\n==== Other ====\\n\\n\\n=== Club and school cricket ===\\n\\nThe world\\'s earliest known cricket match was a village cricket meeting in Kent which has been deduced from a 1640 court case recording a \"cricketing\" of \"the Weald and the Upland\" versus \"the Chalk Hill\" at Chevening \"about thirty years since\" (i.e., c.\\u20091611). Inter-parish contests became popular in the first half of the 17th century and continued to develop through the 18th with the first local leagues being founded in the second half of the 19th.At the grassroots level, local club cricket is essentially an amateur pastime for those involved but still usually involves teams playing in competitions at weekends or in the evening. Schools cricket, first known in southern England in the 17th century, has a similar scenario and both are widely played in the countries where cricket is popular. Although there can be variations in game format, compared with professional cricket, the Laws are always observed and club/school matches are therefore formal and competitive events. The sport has numerous informal variants such as French cricket. On the North American side, in 2023, Monroe Township High School, in Monroe Township, Middlesex County, New Jersey, launched the first U.S. high school cricket club.\\n\\n\\n== Culture ==\\n\\n\\n=== Influence on everyday life ===\\nCricket has had a broad impact on popular culture, both in the Commonwealth of Nations and elsewhere. It has, for example, influenced the lexicon of these nations, especially the English language, with various phrases such as \"that\\'s not cricket\" (that\\'s unfair), \"had a good innings\" (lived a long life) and \"sticky wicket\". \"On a sticky wicket\" (aka \"sticky dog\" or \"glue pot\") is a metaphor used to describe a difficult circumstance. It originated as a term for difficult batting conditions in cricket, caused by a damp and soft pitch.\\n\\n\\n=== In the arts and popular culture ===\\n\\nCricket is the subject of works by noted English poets, including William Blake and Lord Byron. Beyond a Boundary (1963), written by Trinidadian C. L. R. James, is often named the best book on any sport ever written.\\nIn the visual arts, notable cricket paintings include Albert Chevallier Tayler\\'s Kent vs Lancashire at Canterbury (1907) and Russell Drysdale\\'s The Cricketers (1948), which has been called \"possibly the most famous Australian painting of the 20th century.\" French impressionist Camille Pissarro painted cricket on a visit to England in the 1890s. Francis Bacon, an avid cricket fan, captured a batter in motion. Caribbean artist Wendy Nanan\\'s cricket images are featured in a limited edition first day cover for Royal Mail\\'s \"World of Invention\" stamp issue, which celebrated the London Cricket Conference 1–3 March 2007, first international workshop of its kind and part of the celebrations leading up to the 2007 Cricket World Cup.In music, many calypsos make reference to the Sport of Cricket.\\n\\n\\n=== Influence on other sports ===\\nCricket has close historical ties with Australian rules football and many players have competed at top levels in both sports. In 1858, prominent Australian cricketer Tom Wills called for the formation of a \"foot-ball club\" with \"a code of laws\" to keep cricketers fit during the off-season. The Melbourne Football Club was founded the following year, and Wills and three other members codified the first laws of the game. It is typically played on modified cricket fields.In England, a number of association football clubs owe their origins to cricketers who sought to play football as a means of keeping fit during the winter months. Derby County was founded as a branch of the Derbyshire County Cricket Club in 1884; Aston Villa (1874) and Everton (1876) were both founded by members of church cricket teams. Sheffield United\\'s Bramall Lane ground was, from 1854, the home of the Sheffield Cricket Club, and then of Yorkshire; it was not used for football until 1862 and was shared by Yorkshire and Sheffield United from 1889 to 1973.In the late 19th century, a former cricketer, English-born Henry Chadwick of Brooklyn, New York, was credited with devising the baseball box score (which he adapted from the cricket scorecard) for reporting game events. The first box score appeared in an 1859 issue of the Clipper. The statistical record is so central to the game\\'s \"historical essence\" that Chadwick is sometimes referred to as \"the Father of Baseball\" because he facilitated the popularity of the sport in its early days.\\n\\n\\n== See also ==\\nGlossary of cricket terms\\nWillow and StumpyRelated sports\\n\\nStreet cricket\\nBete-ombro – Brazilian version\\nPlaquita – Dominican version\\nBaseball\\nComparison of baseball and cricket\\nStoolball\\n\\n\\n== Footnotes ==\\n\\n\\n== Citations ==\\n\\n\\n== Sources ==\\n\\n\\n== Further reading ==\\nGuha, Ramachandra (2002). A Corner of a Foreign Field: The Indian History of a British Sport. London: Picador. ISBN 0-330-49117-2. OCLC 255899689.\\n\\n\\n== External links ==\\n\\nCricket at Curlie\\nInternational Cricket Council (ICC)\\nESPNcricinfo\\n\"Cricket\". Encyclopædia Britannica Online',\n",
              " 'Love encompasses a range of strong and positive emotional and mental states, from the most sublime virtue or good habit, the deepest interpersonal affection, to the simplest pleasure. An example of this range of meanings is that the love of a mother differs from the love of a spouse, which differs from the love for food. Most commonly, love refers to a feeling of strong attraction and emotional attachment.Love is considered to be both positive and negative, with its virtue representing human kindness, compassion, and affection—\"the unselfish, loyal and benevolent concern for the good of another\"—and its vice representing a human moral flaw akin to vanity, selfishness, amour-propre, and egotism, potentially leading people into a type of mania, obsessiveness, or codependency. It may also describe compassionate and affectionate actions towards other humans, oneself, or animals. In its various forms, love acts as a major facilitator of interpersonal relationships and, owing to its central psychological importance, is one of the most common themes in the creative arts. Love has been postulated to be a function that keeps human beings together against menaces and to facilitate the continuation of the species.Ancient Greek philosophers identified six forms of love: familial love (storge), friendly love or platonic love (philia), romantic love (eros), self-love (philautia), guest love (xenia), and divine or unconditional love (agape). Modern authors have distinguished further varieties of love: unrequited love, empty love, companionate love, consummate love, infatuated love, amour de soi, and courtly love. Numerous cultures have also distinguished Ren, Yuanfen, Mamihlapinatapai, Cafuné, Kama, Bhakti, Mettā, Ishq, Chesed, Amore, Charity, Saudade (and other variants or symbioses of these states), as culturally unique words, definitions, or expressions of love in regard to specified \"moments\" currently lacking in the English language.The color wheel theory of love defines three primary, three secondary, and nine tertiary love styles, describing them in terms of the traditional color wheel. The triangular theory of love suggests intimacy, passion, and commitment are core components of love. Love has additional religious or spiritual meaning. This diversity of uses and meanings, combined with the complexity of the feelings involved, makes love unusually difficult to consistently define, compared to other emotional states.\\n\\n\\n== Definitions ==\\nThe word \"love\" can have a variety of related but distinct meanings in different contexts. Many other languages use multiple words to express some of the different concepts that in English are denoted as \"love\"; one example is the plurality of Greek concepts for \"love\" (agape, eros, philia, storge). Cultural differences in conceptualizing love make it difficult to establish a universal definition.Although the nature or essence of love is a subject of frequent debate, different aspects of the word can be clarified by determining what is not love (antonyms of \"love\"). Love, as a general expression of positive sentiment (a stronger form of like), is commonly contrasted with hate (or neutral apathy). As a less sexual and more emotionally intimate form of romantic attachment, love is commonly contrasted with lust. As an interpersonal relationship with romantic overtones, love is sometimes contrasted with friendship, although the word love is often applied to close friendships or platonic love. (Further possible ambiguities come with usages like \"girlfriend\", \"boyfriend\" and \"just good friends\".)\\n\\n Abstractly discussed, love usually refers to a feeling one person experiences for another person. Love often involves caring for, or identifying with, a person or thing (cf. vulnerability and care theory of love), including oneself (cf. narcissism). In addition to cross-cultural differences in understanding love, ideas about love have also changed greatly over time. Some historians date modern conceptions of romantic love to courtly Europe during or after the Middle Ages, although the prior existence of romantic attachments is attested by ancient love poetry.The complex and abstract nature of love often reduces its discourse to a thought-terminating cliché. Several common proverbs regard love, from Virgil\\'s \"Love conquers all\" to The Beatles\\' \"All You Need Is Love\". St. Thomas Aquinas, following Aristotle, defines love as \"to will the good of another.\" Bertrand Russell describes love as a condition of \"absolute value,\" as opposed to relative value. Philosopher Gottfried Leibniz said that love is \"to be delighted by the happiness of another.\" Meher Baba stated that in love there is a \"feeling of unity\" and an \"active appreciation of the intrinsic worth of the object of love.\" Biologist Jeremy Griffith defines love as \"unconditional selflessness\".\\n\\n\\n== Impersonal ==\\nPeople can have a profound dedication and immense appreciation for an object, principle, or objective, thereby experiencing a sense of love towards it. For example, compassionate outreach and volunteer workers\\' \"love\" of their cause may sometimes be born not of interpersonal love but impersonal love, altruism, and strong spiritual or political convictions. People can also \"love\" material objects, animals, or activities if they invest themselves in bonding or otherwise identifying with those things. If sexual passion is also involved, then this feeling is called paraphilia.\\n\\n\\n== Interpersonal ==\\nInterpersonal love refers to love between human beings. It is a much more potent sentiment than liking a person. Unrequited love refers to feelings of love that are not reciprocated. Interpersonal love is most closely associated with interpersonal relationships. Such love might exist between family members, friends, and couples. There are also a number of psychological disorders related to love, such as erotomania.\\nThroughout history, philosophy and religion have speculated about the phenomenon of love. In the 20th century, the science of psychology has studied the subject. The sciences of anthropology, neuroscience, and biology have also added to the understanding of the concept of love.\\n\\n\\n=== Biological basis ===\\n\\nBiological models of sex tend to view love as a mammalian drive, much like hunger or thirst. Helen Fisher, an anthropologist and human behavior researcher, divides the experience of love into three partly overlapping stages: lust, attraction, and attachment. Lust is the feeling of sexual desire; romantic attraction determines what partners mates find attractive and pursue, conserving time and energy by choosing; and attachment involves sharing a home, parental duties, mutual defense, and in humans involves feelings of safety and security. Three distinct neural circuitries, including neurotransmitters, and three behavioral patterns, are associated with these three romantic styles.\\nLust is the initial passionate sexual desire that promotes mating, and involves the increased release of hormones such as testosterone and estrogen. These effects rarely last more than a few weeks or months. Attraction is the more individualized and romantic desire for a specific candidate for mating, which develops out of lust as commitment to an individual mate forms. Recent studies in neuroscience have indicated that as people fall in love, the brain consistently releases a certain set of chemicals, including the neurotransmitter hormones dopamine, norepinephrine, and serotonin, the same compounds released by amphetamine, stimulating the brain\\'s pleasure center and leading to side effects such as increased heart rate, reduced appetite and sleep, and an intense feeling of excitement. Research indicates that this stage generally lasts from one and a half to three years.Since the lust and attraction stages are both considered temporary, a third stage is needed to account for long-term relationships. Attachment is the bonding that promotes relationships lasting for many years and even decades. Attachment is generally based on commitments such as marriage and children, or mutual friendship based on things like shared interests. It has been linked to higher levels of the chemicals oxytocin and vasopressin, to a greater degree than what is found in short-term relationships. Enzo Emanuele and coworkers reported the protein molecule known as the nerve growth factor (NGF) has high levels when people first fall in love, but these return to previous levels after one year.\\n\\n\\n=== Psychological basis ===\\n\\nPsychology depicts love as a cognitive and social phenomenon. Psychologist Robert Sternberg formulated a triangular theory of love in which love has three components: intimacy, commitment, and passion. Intimacy is when two people share confidences and various details of their personal lives, and is usually shown in friendships and romantic love affairs. Commitment is the expectation that the relationship is permanent. Passionate love is shown in infatuation as well as romantic love. All forms of love are viewed as varying combinations of these three components. Non-love does not include any of these components. Liking only includes intimacy. Infatuated love only includes passion. Empty love only includes commitment. Romantic love includes both intimacy and passion. Companionate love includes intimacy and commitment. Fatuous love includes passion and commitment. Consummate love includes all three components.American psychologist Zick Rubin sought to define love by psychometrics in the 1970s. His work identifies a different set of three factors that constitute love: attachment, caring, and intimacy.Following developments in electrical theories such as Coulomb\\'s law, which showed that positive and negative charges attract, analogs in human life were envisioned, such as \"opposites attract\". Research on human mating has generally found this not to be true when it comes to character and personality—people tend to like people similar to themselves. However, in a few unusual and specific domains, such as immune systems, it seems that humans prefer others who are unlike themselves (e.g., with an orthogonal immune system), perhaps because this will lead to a baby that has the best of both worlds.In recent years, various human bonding theories have been developed, described in terms of attachments, ties, bonds, and affinities.\\nSome Western authorities disaggregate into two main components, the altruistic and the narcissistic. This view is represented in the works of Scott Peck, whose work in the field of applied psychology explored the definitions of love and evil. Peck maintains that love is a combination of the \"concern for the spiritual growth of another\" and simple narcissism. In combination, love is an activity, not simply a feeling.\\nPsychologist Erich Fromm maintained in his book The Art of Loving that love is not merely a feeling but is also actions, and that in fact the \"feeling\" of love is superficial in comparison to one\\'s commitment to love via a series of loving actions over time. Fromm held that love is ultimately not a feeling at all, but rather is a commitment to, and adherence to, loving actions towards another, oneself, or many others, over a sustained duration. Fromm also described love as a conscious choice that in its early stages might originate as an involuntary feeling, but which then later no longer depends on those feelings, but rather depends only on conscious commitment.\\n\\n\\n=== Evolutionary basis ===\\nEvolutionary psychology has attempted to provide various reasons for love as a survival tool. Humans are dependent on parental help for a large portion of their lifespans compared to other mammals. Love has therefore been seen as a mechanism to promote parental support of children for this extended time period. Furthermore, researchers as early as Charles Darwin identified unique features of human love compared to other mammals and credited love as a major factor for creating social support systems that enabled the development and expansion of the human species. Another factor may be that sexually transmitted diseases can cause, among other effects, permanently reduced fertility, injury to the fetus, and increase complications during childbirth. This would favor monogamous relationships over polygamy.\\n\\n\\n=== Adaptive benefit ===\\nInterpersonal love between a man and woman provides an evolutionary adaptive benefit since it facilitates mating and sexual reproduction. However, some organisms can reproduce asexually without mating. Understanding the adaptive benefit of interpersonal love depends on understanding the adaptive benefit of sexual reproduction as opposed to asexual reproduction. Richard Michod reviewed evidence that love, and consequently sexual reproduction, provides two major adaptive advantages. First, sexual reproduction facilitates repair of damages in the DNA that is passed from parent to progeny (during meiosis, a key stage of the sexual process). Second, a gene in either parent may contain a harmful mutation, but in the progeny produced by sexual reproduction, expression of a harmful mutation introduced by one parent is likely to be masked by expression of the unaffected homologous gene from the other parent.\\n\\n\\n=== Comparison of scientific models ===\\nBiological models of love tend to see it as a mammalian drive, similar to hunger or thirst. Psychology sees love as more of a social and cultural phenomenon. Love is influenced by hormones (such as oxytocin), neurotrophins (such as NGF), and pheromones, and how people think and behave in love is influenced by their conceptions of love. The conventional view in biology is that there are two major drives in love: sexual attraction and attachment. Attachment between adults is presumed to work on the same principles that lead an infant to become attached to its mother. The traditional psychological view sees love as being a combination of companionate love and passionate love. Passionate love is intense longing, and is often accompanied by physiological arousal (shortness of breath, rapid heart rate); companionate love is affection and a feeling of intimacy not accompanied by physiological arousal.\\n\\n\\n== Cultural views ==\\n\\n\\n=== Ancient Greek ===\\n\\nGreek distinguishes several different senses in which the word \"love\" is used. Ancient Greeks identified four forms of love: kinship or familiarity (storge), friendship and/or platonic desire (philia), sexual and/or romantic desire (eros), and self-emptying or divine love (agape). Modern authors have distinguished further varieties of romantic love. However, with Greek (as with many other languages), it has been historically difficult to separate the meanings of these words totally. At the same time, the Ancient Greek text of the Bible has examples of the verb agapo having the same meaning as phileo.\\n\\nAgape (ἀγάπη agápē)\\nlove in modern-day Greek. The term s\\'agapo means I love you in Greek. The word agapo is the verb I love. It generally refers to a \"pure,\" ideal type of love, rather than the physical attraction suggested by eros. However, there are some examples of agape used to mean the same as eros. It has also been translated as \"love of the soul.\"Eros (ἔρως érōs)\\n(from the Greek deity Eros) is passionate love, with sensual desire and longing. The Greek word erota means in love. Plato refined his own definition. Although eros is initially felt for a person, with contemplation it becomes an appreciation of the beauty within that person, or even becomes appreciation of beauty itself. Eros helps the soul recall knowledge of beauty and contributes to an understanding of spiritual truth. Lovers and philosophers are all inspired to seek truth by eros. Some translations list it as \"love of the body\".Philia (φιλία philía)\\ndispassionate virtuous love, was a concept addressed and developed by Aristotle in his Nicomachean Ethics Book VIII. It includes loyalty to friends, family, and community, and requires virtue, equality, and familiarity. Philia is motivated by practical reasons; one or both of the parties benefit from the relationship. It can also mean \"love of the mind.\"Storge (στοργή storgē)\\nnatural affection, like that felt by parents for offspringXenia (ξενία xenía)\\nhospitality, was an extremely important practice in ancient Greece. It was an almost ritualized friendship formed between a host and his guest, who could previously have been strangers. The host fed and provided quarters for the guest, who was expected to repay only with gratitude. The importance of this can be seen throughout Greek mythology—in particular, Homer\\'s Iliad and Odyssey.\\n\\n\\n=== Ancient Roman (Latin) ===\\nThe Latin language has several verbs corresponding to the English word \"love.\" amō is the basic verb meaning I love, with the infinitive amare (\"to love\") as it still is in Italian today. The Romans used it both in an affectionate sense as well as in a romantic or sexual sense. From this verb come amans—a lover, amator, \"professional lover,\" often with the accessory notion of lechery—and amica, \"girlfriend\" in the English sense, often being applied euphemistically to a prostitute. The corresponding noun is amor (the significance of this term for the Romans is well illustrated in the fact, that the name of the city, Rome—in Latin: Roma—can be viewed as an anagram for amor, which was used as the secret name of the City in wide circles in ancient times), which is also used in the plural form to indicate love affairs or sexual adventures. This same root also produces amicus—\"friend\"—and amicitia, \"friendship\" (often based to mutual advantage, and corresponding sometimes more closely to \"indebtedness\" or \"influence\"). Cicero wrote a treatise called On Friendship (de Amicitia), which discusses the notion at some length. Ovid wrote a guide to dating called Ars Amatoria (The Art of Love), which addresses, in depth, everything from extramarital affairs to overprotective parents.\\nLatin sometimes uses amāre where English would simply say to like. This notion, however, is much more generally expressed in Latin by the terms placere or delectāre, which are used more colloquially, the latter used frequently in the love poetry of Catullus. Diligere often implies \"to be affectionate for,\" \"to esteem,\" and rarely if ever is used for romantic love. This word would be appropriate to describe the friendship of two men. The corresponding noun diligentia, however, has the meaning of \"diligence\" or \"carefulness,\" and has little semantic overlap with the verb. Observare is a synonym for diligere; despite the cognate with English, this verb and its corresponding noun, observantia, often denote \"esteem\" or \"affection.\" Caritas is used in Latin translations of the Christian Bible to mean \"charitable love\"; this meaning, however, is not found in Classical pagan Roman literature. As it arises from a conflation with a Greek word, there is no corresponding verb.\\n\\n\\n=== Chinese and other Sinic ===\\nTwo philosophical underpinnings of love exist in the Chinese tradition, one from Confucianism which emphasized actions and duty while the other came from Mohism which championed a universal love. A core concept to Confucianism is 仁 (Ren, \"benevolent love\"), which focuses on duty, action, and attitude in a relationship rather than love itself. In Confucianism, one displays benevolent love by performing actions such as filial piety from children, kindness from parents, loyalty to the king and so forth.\\nThe concept of 愛 (Mandarin: ài) was developed by the Chinese philosopher Mozi in the 4th century BCE in reaction to Confucianism\\'s benevolent love. Mozi tried to replace what he considered to be the long-entrenched Chinese over-attachment to family and clan structures with the concept of \"universal love\" (兼愛, jiān\\'ài). In this, he argued directly against Confucians who believed that it was natural and correct for people to care about different people in different degrees. Mozi, by contrast, believed people in principle should care for all people equally. Mohism stressed that rather than adopting different attitudes towards different people, love should be unconditional and offered to everyone without regard to reciprocation; not just to friends, family, and other Confucian relations. Later in Chinese Buddhism, the term Ai (愛) was adopted to refer to a passionate, caring love and was considered a fundamental desire. In Buddhism, Ai was seen as capable of being either selfish or selfless, the latter being a key element towards enlightenment.\\nIn Mandarin Chinese, 愛 (ài) is often used as the equivalent of the Western concept of love. 愛 (ài) is used as both a verb (e.g. 我愛你, Wǒ ài nǐ, or \"I love you\") and a noun (such as 愛情 àiqíng, or \"romantic love\"). However, due to the influence of Confucian 仁 (rén), the phrase 我愛你 (Wǒ ài nǐ, I love you) carries with it a very specific sense of responsibility, commitment, and loyalty. Instead of frequently saying \"I love you\" as in some Western societies, the Chinese are more likely to express feelings of affection in a more casual way. Consequently, \"I like you\" (我喜欢你, Wǒ xǐhuan nǐ) is a more common way of expressing affection in Mandarin; it is more playful and less serious. This is also true in Japanese (suki da, 好きだ).\\n\\n\\n=== Japanese ===\\nThe Japanese language uses three words to convey the English equivalent of \"love\". Because \"love\" covers a wide range of emotions and behavioral phenomena, there are nuances distinguishing the three terms. The term ai (愛), which is often associated with maternal love or selfless love, originally referred to beauty and was often used in a religious context. Following the Meiji Restoration of 1868, the term became associated with \"love\" in order to translate Western literature.\\nPrior to Western influence, the term koi (恋 or 孤悲) generally represented romantic love, and was often the subject of the popular Man\\'yōshū Japanese poetry collection. Koi describes a longing for a member of the opposite sex and is typically interpreted as selfish and wanting. The term\\'s origins come from the concept of lonely solitude as a result of separation from a loved one. Though modern usage of koi focuses on sexual love and infatuation, the Manyō used the term to cover a wider range of situations, including tenderness, benevolence, and material desire.The third term, ren\\'ai (恋愛), is a more modern construction that combines the kanji characters for both ai and koi, though its usage more closely resembles that of koi in the form of romantic love.Amae (甘え), referring to the desire to be loved and cared for by an authority figure, is another important aspect of Japan\\'s cultural perspective on love, and has been analysed in detail in Takeo Doi\\'s The Anatomy of Dependence\\n\\n\\n=== Indian ===\\nIn contemporary literature, the Sanskrit words for love is sneha. Other terms include priya which refers to innocent love, prema refers to spiritual love, and kama refers usually to sexual desire. However, the term also refers to any sensory enjoyment, emotional attraction and aesthetic pleasure such as from arts, dance, music, painting, sculpture and nature.The concept of kama is found in some of the earliest known verses in Vedas. For example, Book 10 of Rig Veda describes the creation of the universe from nothing by the great heat. In hymn 129, it states:\\n\\n\\n=== Persian ===\\n\\nRumi, Hafiz, and Sa\\'di are icons of the passion and love that the Persian culture and language present. The Persian word for love is Ishq, which is derived from Arabic; however, it is considered by most to be too stalwart a term for interpersonal love and is more commonly substituted with \"doost dashtan\" (\"liking\"). In the Persian culture, everything is encompassed by love and all is for love, starting from loving friends and family, husbands and wives, and eventually reaching the divine love that is the ultimate goal in life.\\n\\n\\n== Religious views ==\\n\\n\\n=== Abrahamic ===\\n\\n\\n==== Judaism ====\\n\\nIn Hebrew, אהבה (ahava) is the most commonly used term for both interpersonal love and love between God and God\\'s creations. Chesed, often translated as loving-kindness, is used to describe many forms of love between human beings.\\nThe commandment to love other people is given in the Torah, which states, \"Love your neighbor like yourself\" (Leviticus 19:18). The Torah\\'s commandment to love God \"with all your heart, with all your soul and with all your might\" (Deuteronomy 6:5) is taken by the Mishnah (a central text of the Jewish oral law) to refer to good deeds, willingness to sacrifice one\\'s life rather than commit certain serious transgressions, willingness to sacrifice all of one\\'s possessions, and being grateful to the Lord despite adversity (tractate Berachoth 9:5). Rabbinic literature differs as to how this love can be developed, e.g., by contemplating divine deeds or witnessing the marvels of nature.\\nAs for love between marital partners, this is deemed an essential ingredient to life: \"See life with the wife you love\" (Ecclesiastes 9:9). Rabbi David Wolpe writes that \"love is not only about the feelings of the lover... It is when one person believes in another person and shows it.\" He further states that \"love... is a feeling that expresses itself in action. What we really feel is reflected in what we do.\" The biblical book Song of Solomon is considered a romantically phrased metaphor of love between God and his people, but in its plain reading it reads like a love song. The 20th-century rabbi Eliyahu Eliezer Dessler is frequently quoted as defining love from the Jewish point of view as \"giving without expecting to take\".\\n\\n\\n==== Christianity ====\\nThe Christian understanding is that love comes from God, who is himself love (1 John 4:8). The love of man and woman—eros in Greek—and the unselfish love of others (agape), are often contrasted as \"descending\" and \"ascending\" love, respectively, but are ultimately the same thing.There are several Greek words for \"love\" that are regularly referred to in Christian circles.\\n\\nagape\\nIn the New Testament, agapē is charitable, selfless, altruistic, and unconditional. It is parental love, seen as creating goodness in the world; it is the way God is seen to love humanity, and it is seen as the kind of love that Christians aspire to have for one another.\\nphileo\\nAlso used in the New Testament, phileo is a human response to something that is found to be delightful. Also known as \"brotherly love.\"Two other words for love in the Greek language, eros (sexual love) and storge (child-to-parent love), were never used in the New Testament.Christians believe that to love God with all your heart, mind, and strength and love your neighbor as yourself are the two most important things in life (the greatest commandment of the Jewish Torah, according to Jesus; cf. Gospel of Mark 12:28–34). Saint Augustine summarized this when he wrote \"Love God, and do as thou wilt.\"The Apostle Paul glorified love as the most important virtue of all. Describing love in the famous poetic interpretation in 1 Corinthians, he wrote, \"Love is patient, love is kind. It does not envy, it does not boast, it is not proud. It is not rude, it is not self-seeking, it is not easily angered, it keeps no record of wrongs. Love does not delight in evil but rejoices with the truth. It always protects, always trusts, always hopes, and always perseveres.\" (1 Corinthians 13:4–7)\\nThe Apostle John wrote, \"For God so loved the world that he gave his one and only Son, that whoever believes in him shall not perish but have eternal life. For God did not send his Son into the world to condemn the world, but to save the world through him.\" (John 3:16–17) John also wrote, \"Dear friends, let us love one another for love comes from God. Everyone who loves has been born of God and knows God. Whoever does not love does not know God, because God is love.\" (1 John 4:7–8)\\nSaint Augustine wrote that one must be able to decipher the difference between love and lust. Lust, according to Saint Augustine, is an overindulgence, but to love and be loved is what he has sought for his entire life. He even says, \"I was in love with love.\" Finally, he does fall in love and is loved back, by God. Saint Augustine says the only one who can love you truly and fully is God, because love with a human only allows for flaws such as \"jealousy, suspicion, fear, anger, and contention.\":\\u200aIII.1\\u200a According to Saint Augustine, to love God is \"to attain the peace which is yours.\":\\u200aX.27\\u200aAugustine regards the duplex commandment of love in Matthew 22 as the heart of Christian faith and the interpretation of the Bible. After the review of Christian doctrine, Augustine treats the problem of love in terms of use and enjoyment until the end of Book I of De Doctrina Christiana (1.22.21–1.40.44).Christian theologians see God as the source of love, which is mirrored in humans and their own loving relationships. Influential Christian theologian C. S. Lewis wrote a book called The Four Loves. Benedict XVI named his first encyclical God is love. He said that a human being, created in the image of God, who is love, is able to practice love; to give himself to God and others (agape) and by receiving and experiencing God\\'s love in contemplation (eros). This life of love, according to him, is the life of the saints such as Teresa of Calcutta and Mary, the mother of Jesus and is the direction Christians take when they believe that God loves them.\\nPope Francis asserts that the \"Cross (Jesus crucified) is the greatest meaning of the greatest love,\" and in the crucifixion is found everything, all knowledge and the entirety of God\\'s love. Pope Francis taught that \"True love is both loving and letting oneself be loved... what is important in love is not our loving, but allowing ourselves to be loved by God.\" And so, in the analysis of a Catholic theologian, for Pope Francis, \"the key to love... is not our activity. It is the activity of the greatest, and the source, of all the powers in the universe: God\\'s.\"In Christianity the practical definition of love is summarised by Thomas Aquinas, who defined love as \"to will the good of another,\" or to desire for another to succeed. This is an explanation of the Christian need to love others, including their enemies. Thomas Aquinas explains that Christian love is motivated by the need to see others succeed in life, to be good people.\\nRegarding love for enemies, Jesus is quoted in the Gospel of Matthew:\\n\\nYou have heard that it was said, \"Love your neighbor and hate your enemy.\" But I tell you, love your enemies and pray for those who persecute you, that you may be children of your Father in heaven. He causes his sun to rise on the evil and the good, and sends rain on the righteous and the unrighteous. If you love those who love you, what reward will you get? Are not even the tax collectors doing that? And if you greet only your own people, what are you doing more than others? Do not even pagans do that? Be perfect, therefore, as your heavenly Father is perfect.\\nTertullian wrote regarding love for enemies: \"Our individual, extraordinary, and perfect goodness consists in loving our enemies. To love one\\'s friends is common practice, to love one\\'s enemies only among Christians.\"\\n\\n\\n==== Islam ====\\nLove encompasses the Islamic view of life as universal brotherhood that applies to all who hold faith. Among the 99 names of God (Allah) is the name Al-Wadud, or \"the Loving One,\" which is found in Surah 11:90 and 85:14. God is also referenced at the beginning of every chapter in the Qur\\'an as Ar-Rahman and Ar-Rahim, or the \"Most Compassionate\" and the \"Most Merciful\", indicating that nobody is more loving, compassionate, and benevolent than God. The Qur\\'an refers to God as being \"full of loving kindness.\"\\nThe Qur\\'an exhorts Muslim believers to treat all people, those who have not persecuted them, with birr or \"deep kindness\" as stated in Surah 6:8-9. Birr is also used by the Qur\\'an to describe the love and kindness that children must show to their parents.\\nIshq, or divine love, is emphasized by Sufism in the Islamic tradition. Practitioners of Sufism believe that love is a projection of the essence of God into the universe. God desires to recognize beauty, and as if one looks at a mirror to see oneself, God \"looks\" at himself within the dynamics of nature. Since everything is a reflection of God, the school of Sufism practices seeing the beauty inside the apparently ugly. Sufism is often referred to as the religion of love. God in Sufism is referred to in three main terms—Lover, Loved, and Beloved—with the last of these terms often seen in Sufi poetry. A common viewpoint of Sufism is that through love, humankind can return to its inherent purity and grace. The saints of Sufism are infamous for being \"drunk\" due to their love of God; hence, the constant reference to wine in Sufi poetry and music.\\n\\n\\n==== Bahá\\'í Faith ====\\nIn his Paris Talks, `Abdu\\'l-Bahá described four types of love: the love that flows from God to human beings; the love that flows from human beings to God; the love of God towards the Self or Identity of God; and the love of human beings for human beings.\\n\\n\\n=== Dharmic ===\\n\\n\\n==== Buddhism ====\\nIn Buddhism, kāma is sensuous, sexual love. It is an obstacle on the path to enlightenment, since it is selfish. Karuṇā is compassion and mercy, which reduces the suffering of others. It is complementary to wisdom and is necessary for enlightenment. Adveṣa and mettā are benevolent love. This love is unconditional and requires considerable self-acceptance. This is quite different from ordinary love, which is usually about attachment and sex and which rarely occurs without self-interest. Instead, in Buddhism love refers to detachment and unselfish interest in others\\' welfare.\\nThe Bodhisattva ideal in Mahayana Buddhism involves the complete renunciation of oneself in order to take on the burden of a suffering world.\\n\\n\\n==== Hinduism ====\\n\\nIn Hinduism, kāma is pleasurable, sexual love, personified by the god Kamadeva. For many Hindu schools, it is the third end (Kama) in life. Kamadeva is often pictured holding a bow of sugar cane and an arrow of flowers; he may ride upon a great parrot. He is usually accompanied by his consort Rati and his companion Vasanta, lord of the spring season. Stone images of Kamadeva and Rati can be seen on the door of the Chennakeshava temple at Belur, in Karnataka, India. Maara is another name for kāma.In contrast to kāma, prema—or premefers to elevated love. Karuṇā is compassion and mercy, which impels one to help reduce the suffering of others. Bhakti is a Sanskrit term meaning \"loving devotion to the supreme God.\" A person who practices bhakti is called a bhakta. Hindu writers, theologians, and philosophers have distinguished nine forms of bhakti, which can be found in the Bhagavata Purana and works by Tulsidas. The philosophical work Narada Bhakti Sutra, written by an unknown author (presumed to be Narada), distinguishes eleven forms of love.\\nIn certain Vaishnava sects within Hinduism, attaining unadulterated, unconditional, and incessant love for the Godhead is considered the foremost goal of life. Gaudiya Vaishnavas who worship Krishna as the Supreme Personality of Godhead and the cause of all causes consider Love for Godhead (Prema) to act in two ways: sambhoga and vipralambha (union and separation)—two opposites.In the condition of separation, there is an acute yearning for being with the beloved and in the condition of union, there is supreme happiness and nectarean. Gaudiya Vaishnavas consider that Krishna-prema (Love for Godhead) burns away one\\'s material desires, pierces the heart, and washes away everything—one\\'s pride, one\\'s religious rules, and one\\'s shyness. Krishna-prema is considered to make one drown in the ocean of transcendental ecstasy and pleasure. The love of Radha, a cowherd girl, for Krishna is often cited as the supreme example of love for Godhead by Gaudiya Vaishnavas. Radha is considered to be the internal potency of Krishna, and is the supreme lover of Godhead. Her example of love is considered to be beyond the understanding of material realm as it surpasses any form of selfish love or lust that is visible in the material world. The reciprocal love between Radha (the supreme lover) and Krishna (God as the Supremely Loved) is the subject of many poetic compositions in India such as the Gita Govinda of Jayadeva and Hari Bhakti Shuddhodhaya.\\nIn the Bhakti tradition within Hinduism, it is believed that execution of devotional service to God leads to the development of Love for God (taiche bhakti-phale krsne prema upajaya), and as love for God increases in the heart, the more one becomes free from material contamination (krishna-prema asvada haile, bhava nasa paya). Being perfectly in love with God or Krishna makes one perfectly free from material contamination, and this is the ultimate way of salvation or liberation. In this tradition, salvation or liberation is considered inferior to love, and just an incidental by-product. Being absorbed in Love for God is considered to be the perfection of life.\\n\\n\\n== Political views ==\\n\\n\\n=== Free love ===\\n\\nThe term \"free love\" has been used to describe a social movement that rejects marriage, which is seen as a form of social bondage. The free love movement\\'s initial goal was to separate the state from sexual matters such as marriage, birth control, and adultery. It claimed that such issues were the concern of the people involved, and no one else.Many people in the early 19th century believed that marriage was an important aspect of life to \"fulfill earthly human happiness.\" Middle-class Americans wanted the home to be a place of stability in an uncertain world. This mentality created a vision of strongly defined gender roles, which provoked the advancement of the free love movement as a contrast.Advocates of free love had two strong beliefs: opposition to the idea of forceful sexual activity in a relationship and advocacy for a woman to use her body in any way that she pleases. These are also beliefs of feminism.\\n\\n\\n== Philosophical views ==\\n\\nThe philosophy of love is a field of social philosophy and ethics that attempts to explain the nature of love. The philosophical investigation of love includes the tasks of distinguishing between the various kinds of personal love, asking if and how love is or can be justified, asking what the value of love is, and what impact love has on the autonomy of both the lover and the beloved.\\n\\n\\n== Literature depictions ==\\n\\n\\n== See also ==\\nColor wheel theory of love – Idea created by psychologist John Alan LeePages displaying short descriptions of redirect targets\\nFinger heart – Hand gesture\\nHand heart – Affectionate hand gesture\\nHeart in hand – Symbol of charity\\nHuman bonding – Process of development of a close, interpersonal relationship\\nILY sign – American Sign Language gesture\\nLove at first sight – Falling in long-lasting love with someone on first sight\\nLove-in – Peaceful public gatheringPages displaying wikidata descriptions as a fallback\\nPair bond – Biological term\\nPolyamory – Intimacy for multiple partners\\nRelationship science – Field dedicated to the scientific study of interpersonal relationship processes\\nRomance (love) – Type of love that focuses on feelings\\nSelf-love – Concept in philosophy and psychology\\nSocial connection – Term in psychology referring to the experience of feeling close and connected to others\\nTraditional forms, Agape, Philia, Philautia, Storge, Eros: Greek terms for love\\n\\n\\n== References ==\\n\\n\\n== Sources ==\\n\\n\\n== Further reading ==\\nBayer, A, ed. (2008). Art and love in Renaissance Italy. New York: The Metropolitan Museum of Art.\\n\\n\\n== External links ==\\n\\nHistory of Love, Internet Encyclopedia of Philosophy\\nFriendship at Curlie\\nPhilanthropy at Curlie\\nRomance at Curlie',\n",
              " 'A plan is typically any diagram or list of steps with details of timing and resources, used to achieve an objective to do something. It is commonly understood as a temporal set of intended actions through which one expects to achieve a goal.\\nFor spatial or planar topologic or topographic sets see map.\\nPlans can be formal or informal:\\n\\nStructured and formal plans, used by multiple people, are more likely to occur in projects, diplomacy, careers, economic development, military campaigns, combat, sports, games, or in the conduct of other business. In most cases, the absence of a well-laid plan can have adverse effects: for example, a non-robust project plan can cost the organization time and money.\\nInformal or ad hoc plans are created by individuals in all of their pursuits.The most popular ways to describe plans are by their breadth, time frame, and specificity; however, these planning classifications are not independent of one another. For instance, there is a close relationship between the short- and long-term categories and the strategic and operational categories.\\nIt is common for less formal plans to be created as abstract ideas, and remain in that form as they are maintained and put to use. More formal plans as used for business and military purposes, while initially created with and as an abstract thought, are likely to be written down, drawn up or otherwise stored in a form that is accessible to multiple people across time and space. This allows more reliable collaboration in the execution of the plan.\\n\\n\\n== Topics ==\\n\\n\\n=== Planning ===\\nThe term planning implies the working out of sub-components in some degree of elaborate detail. Broader-brush enunciations of objectives may qualify as metaphorical roadmaps. Planning literally just means the creation of a plan; it can be as simple as making a list. It has not acquired a technical meaning, however, to cover the area of government legislation and regulations elated to the use of resources.\\nPlanning can refer to the planned use of any and all resources, as in the succession of Five-Year Plans through which the government of the Soviet Union sought to develop the country. However, the term is most frequently used in relation to planning for the use of land and related resources, for example in urban planning, transportation planning, etc.\\nIn a governmental context, \"planning\" without any qualification is most likely to mean the regulation of land use. See also zoning.\\n\\n\\n=== Planners ===\\nPlanners are the professionals that have the requisite training to take or make decisions that will help or balance the society in order to have a functional, aesthetic, and convenient environment.\\n\\n\\n=== Methodology ===\\nConcepts such as top-down planning (as opposed to bottom-up planning) reveal similarities with the systems thinking behind the top-down model.\\nThe subject touches such broad fields as psychology, game theory, communications and information theory, which inform the planning methods that people seek to use and refine; as well as logic and science (i.e. methodological naturalism) which serve as a means of testing different parts of a plan for reliability or consistency.\\nThe specific methods used to create and refine plans depend on who is to make it, who is to put it to use, and what resources are available for the task. The methods used by an individual in his or her mind or personal organizer, may be very different from the collection of planning techniques found in a corporate board-room, and the planning done by a project manager has different priorities and uses different tools to the planning done by an engineer or industrial designer.\\n\\n\\n== Examples of plans ==\\nArchitectural plan\\nBusiness plan\\nFragplan\\nFlight plan\\nHealth plan\\nMarketing plan\\nMilitary plan\\nProject plan\\nSite plan\\nThe Schlieffen Plan\\nThe Five-Year Plan system in the former Soviet Union\\nThe Marshall Plan\\n\\n\\n== See also ==\\nAutomated planning\\nCritical path method\\nPDCA (plan–do–check–act)\\nProgram evaluation and review technique (PERT)\\nRoadmap\\nStrategy\\n\\n\\n== References ==',\n",
              " 'Plants are the eukaryotes that form the kingdom Plantae; they are predominantly photosynthetic. This means that they obtain their energy from sunlight, using chloroplasts derived from endosymbiosis with cyanobacteria to produce sugars from carbon dioxide and water, using the green pigment chlorophyll. Exceptions are parasitic plants that have lost the genes for chlorophyll and photosynthesis, and obtain their energy from other plants or fungi.\\nHistorically, as in Aristotle\\'s biology, the plant kingdom encompassed all living things that were not animals, and included algae and fungi. Definitions have narrowed since then; current definitions exclude the fungi and some of the algae. By the definition used in this article, plants form the clade Viridiplantae (green plants), which consists of the green algae and the embryophytes or land plants (hornworts, liverworts, mosses, lycophytes, ferns, conifers and other gymnosperms, and flowering plants). A definition based on genomes includes the Viridiplantae, along with the red algae and the glaucophytes, in the clade Archaeplastida.\\nThere are about 380,000 known species of plants, of which the majority, some 260,000, produce seeds. They range in size from single cells to the tallest trees. Green plants provide a substantial proportion of the world\\'s molecular oxygen; the sugars they create supply the energy for most of Earth\\'s ecosystems; other organisms, including animals, either consume plants directly or rely on organisms which do so.\\nGrain, fruit, and vegetables are basic human foods and have been domesticated for millennia. People use plants for many purposes, such as building materials, ornaments, writing materials, and, in great variety, for medicines. The scientific study of plants is known as botany, a branch of biology.\\n\\n\\n== Definition ==\\n\\n\\n=== Taxonomic history ===\\n\\nAll living things were traditionally placed into one of two groups, plants and animals. This classification dates from Aristotle (384–322 BC), who distinguished different levels of beings in his biology, based on whether living things had a \"sensitive soul\" or like plants only a \"vegetative soul\". Theophrastus, Aristotle\\'s student, continued his work in plant taxonomy and classification. Much later, Linnaeus (1707–1778) created the basis of the modern system of scientific classification, but retained the animal and plant kingdoms, naming the plant kingdom the Vegetabilia.\\n\\n\\n=== Alternative concepts ===\\nWhen the name Plantae or plant is applied to a specific group of organisms or taxa, it usually refers to one of four concepts. From least to most inclusive, these four groupings are:\\n\\n\\n== Evolution ==\\n\\n\\n=== Diversity ===\\nThere are about 382,000 accepted species of plants, of which the great majority, some 283,000, produce seeds. The table below shows some species count estimates of different green plant (Viridiplantae) divisions. About 85–90% of all plants are flowering plants. Several projects are currently attempting to collect records on all plant species in online databases, e.g. the World Flora Online.Plants range in scale from single-celled organisms such as desmids (from 10 micrometres across) and picozoa (less than 3 micrometres across), to the largest trees (megaflora) such as the conifer Sequoia sempervirens (up to 380 feet (120 m) tall ) and the angiosperm Eucalyptus regnans (up to 325 feet (99 m) tall ).\\nThe naming of plants is governed by the International Code of Nomenclature for algae, fungi, and plants and the International Code of Nomenclature for Cultivated Plants.\\n\\n\\n=== Evolutionary history ===\\n\\nThe ancestors of land plants evolved in water. An algal scum formed on the land 1,200 million years ago, but it was not until the Ordovician, around 450 million years ago, that the first land plants appeared, with a level of organisation like that of bryophytes. However, evidence from carbon isotope ratios in Precambrian rocks suggests that complex plants developed over 1000 mya.Primitive land plants began to diversify in the late Silurian, around 420 million years ago. Bryophytes, club mosses, and ferns then appear in the fossil record. Early plant anatomy is preserved in cellular detail in an early Devonian fossil assemblage from the Rhynie chert. These early plants were preserved by being petrified in chert formed in silica-rich volcanic hot springs.By the end of the Devonian, most of the basic features of plants today were present, including roots, leaves and secondary wood in trees such as Archaeopteris. The Carboniferous Period saw the development of forests in swampy environments dominated by clubmosses and horsetails, including some as large as trees, and the appearance of early gymnosperms, the first seed plants. The Permo-Triassic extinction event radically changed the structures of communities. This may have set the scene for the evolution of flowering plants in the Triassic (~200 million years ago), with an adaptive radiation in the Cretaceous so rapid that Darwin called it an \"abominable mystery\". Conifers diversified from the Late Triassic onwards, and became a dominant part of floras in the Jurassic.\\n\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n=== Phylogeny ===\\nIn 2019, a phylogeny based on genomes and transcriptomes from 1,153 plant species was proposed. The placing of algal groups is supported by phylogenies based on genomes from the Mesostigmatophyceae and Chlorokybophyceae that have since been sequenced. Both the \"chlorophyte algae\" and the \"streptophyte algae\" are treated as paraphyletic (vertical bars beside phylogenetic tree diagram) in this analysis, as the land plants arose from within those groups. The classification of Bryophyta is supported both by Puttick et al. 2018, and by phylogenies involving the hornwort genomes that have also since been sequenced.\\n\\n\\n== Physiology ==\\n\\n\\n=== Plant cells ===\\n\\nPlant cells have distinctive features that other eukaryotic cells (such as those of animals) lack. These include the large water-filled central vacuole, chloroplasts, and the strong flexible cell wall, which is outside the cell membrane. Chloroplasts are derived from what was once a symbiosis of a non-photosynthetic cell and photosynthetic cyanobacteria. The cell wall, made mostly of cellulose, allows plant cells to swell up with water without bursting. The vacuole allows the cell to change in size while the amount of cytoplasm stays the same.\\n\\n\\n=== Plant structure ===\\n\\nMost plants are multicellular. Plant cells differentiate into multiple cell types, forming tissues such as the vascular tissue with specialized xylem and phloem of leaf veins and stems, and organs with different physiological functions such as roots to absorb water and minerals, stems for support and to transport water and synthesized molecules, leaves for photosynthesis, and flowers for reproduction.\\n\\n\\n=== Photosynthesis ===\\n\\nPlants photosynthesize, manufacturing food molecules (sugars) using energy obtained from light. Plant cells contain chlorophylls inside their chloroplasts, which are green pigments that are used to capture light energy. The end-to-end chemical equation for photosynthesis is:\\n\\n  \\n    \\n      \\n        \\n          6\\n          \\n          \\n            CO\\n            \\n              2\\n            \\n            \\n              \\n            \\n          \\n          \\n\\n          \\n          +\\n          6\\n          \\n          \\n            H\\n            \\n              2\\n            \\n            \\n              \\n            \\n          \\n          O\\n          \\n\\n          \\n          \\n            \\n              →\\n              \\n                \\n                  light\\n                \\n              \\n            \\n          \\n          \\n            C\\n            \\n              6\\n            \\n            \\n              \\n            \\n          \\n          \\n            H\\n            \\n              12\\n            \\n            \\n              \\n            \\n          \\n          \\n            O\\n            \\n              6\\n            \\n            \\n              \\n            \\n          \\n          \\n\\n          \\n          +\\n          6\\n          \\n          \\n            O\\n            \\n              2\\n            \\n            \\n              \\n            \\n          \\n          \\n\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\ce {6CO2{}+6H2O{}->[{\\\\text{light}}]C6H12O6{}+6O2{}}}}\\n  This causes plants to release oxygen into the atmosphere. Green plants provide a substantial proportion of the world\\'s molecular oxygen, alongside the contributions from photosynthetic algae and cyanobacteria.Plants that have secondarily adopted a parasitic lifestyle may lose the genes involved in photosynthesis and the production of chlorophyll.\\n\\n\\n=== Growth and repair ===\\nGrowth is determined by the interaction of a plant\\'s genome with its physical and biotic environment. Factors of the physical or abiotic environment include temperature, water, light, carbon dioxide, and nutrients in the soil. Biotic factors that affect plant growth include crowding, grazing, beneficial symbiotic bacteria and fungi, and attacks by insects or plant diseases.Frost and dehydration can damage or kill plants. Some plants have antifreeze proteins, heat-shock proteins and sugars in their cytoplasm that enable them to tolerate these stresses. Plants are continuously exposed to a range of physical and biotic stresses which cause DNA damage, but they can tolerate and repair much of this damage.\\n\\n\\n=== Reproduction ===\\n\\nPlants reproduce to generate offspring, whether sexually, involving gametes, or asexually, involving ordinary growth. Many plants use both mechanisms.\\n\\n\\n==== Sexual ====\\nWhen reproducing sexually, plants have complex lifecycles involving alternation of generations. One generation, the sporophyte, which is diploid (with 2 sets of chromosomes), gives rise to the next generation, the gametophyte, which is haploid (with one set of chromosomes). Some plants also reproduce asexually via spores. In some non-flowering plants such as mosses, the sexual gametophyte forms most of the visible plant. In seed plants (gymnosperms and flowering plants), the sporophyte forms most of the visible plant, and the gametophyte is very small. Flowering plants reproduce sexually using flowers, which contain male and female parts: these may be within the same (hermaphrodite) flower, on different flowers on the same plant, or on different plants. The pollen produces male gametes that enter the ovule to fertilize the egg cell of the female gametophyte. Fertilization takes place within the carpels or ovaries, which develop into fruits that contain seeds. Fruits may be dispersed whole, or they may split open and the seeds dispersed individually.\\n\\n\\n==== Asexual ====\\nPlants reproduce asexually by growing any of a wide variety of structures capable of growing into new plants. At the simplest, plants such as mosses or liverworts may be broken into pieces, each of which may regrow into whole plants. The propagation of flowering plants by cuttings is a similar process. Structures such as runners enable plants to grow to cover an area, forming a clone. Many plants grow food storage structures such as tubers or bulbs which may each develop into a new plant.Some non-flowering plants, such as many liverworts, mosses and some clubmosses, along with a few flowering plants, grow small clumps of cells called gemmae which can detach and grow.\\n\\n\\n=== Disease resistance ===\\n\\nPlants use pattern-recognition receptors to recognize pathogens such as bacteria that cause plant diseases. This recognition triggers a protective response. The first such plant receptors were identified in rice and in Arabidopsis thaliana.\\n\\n\\n=== Genomics ===\\n\\nPlants have some of the largest genomes among all organisms. The largest plant genome (in terms of gene number) is that of wheat (Triticum aestivum), predicted to encode ≈94,000 genes and thus almost 5 times as many as the human genome. The first plant genome sequenced was that of Arabidopsis thaliana which encodes about 25,500 genes. In terms of sheer DNA sequence, the smallest published genome is that of the carnivorous bladderwort (Utricularia gibba) at 82 Mb (although it still encodes 28,500 genes) while the largest, from the Norway spruce (Picea abies), extends over 19.6 Gb (encoding about 28,300 genes).\\n\\n\\n== Ecology ==\\n\\n\\n=== Distribution ===\\n\\nPlants are distributed almost worldwide. While they inhabit several biomes which can be divided into a multitude of ecoregions, only the hardy plants of the Antarctic flora, consisting of algae, mosses, liverworts, lichens, and just two flowering plants, have adapted to the prevailing conditions on that southern continent.Plants are often the dominant physical and structural component of the habitats where they occur. Many of the Earth\\'s biomes are named for the type of vegetation because plants are the dominant organisms in those biomes, such as grassland, savanna, and tropical rainforest.\\n\\n\\n=== Primary producers ===\\n\\nThe photosynthesis conducted by land plants and algae is the ultimate source of energy and organic material in nearly all ecosystems. Photosynthesis, at first by cyanobacteria and later by photosynthetic eukaryotes, radically changed the composition of the early Earth\\'s anoxic atmosphere, which as a result is now 21% oxygen. Animals and most other organisms are aerobic, relying on oxygen; those that do not are confined to relatively rare anaerobic environments. Plants are the primary producers in most terrestrial ecosystems and form the basis of the food web in those ecosystems. Plants form about 80% of the world biomass at about 450 gigatonnes (4.4×1011 long tons; 5.0×1011 short tons) of carbon.\\n\\n\\n=== Ecological relationships ===\\n\\nNumerous animals have coevolved with plants; flowering plants have evolved pollination syndromes, suites of flower traits that favour their reproduction. Many, including insect and bird partners, are pollinators, visiting flowers and accidentally transferring pollen in exchange for food in the form of pollen or nectar.Many animals disperse seeds that are adapted for such dispersal. Various mechanisms of dispersal have evolved. Some fruits offer nutritious outer layers attractive to animals, while the seeds are adapted to survive the passage through the animal\\'s gut; others have hooks that enable them to attach to a mammal\\'s fur.Myrmecophytes are plants that have coevolved with ants. The plant provides a home, and sometimes food, for the ants. In exchange, the ants defend the plant from herbivores and sometimes competing plants. Ant wastes serve as organic fertilizer.The majority of plant species have fungi associated with their root systems in a mutualistic symbiosis known as mycorrhiza. The fungi help the plants gain water and mineral nutrients from the soil, while the plant gives the fungi carbohydrates manufactured in photosynthesis.\\nSome plants serve as homes for endophytic fungi that protect the plant from herbivores by producing toxins. The fungal endophyte Neotyphodium coenophialum in tall fescue grass has pest status in the American cattle industry.Many legumes have Rhizobium nitrogen-fixing bacteria in nodules of their roots, which fix nitrogen from the air for the plant to use; in return, the plants supply sugars to the bacteria. Nitrogen fixed in this way can become available to other plants, and is important in agriculture; for example, farmers may grow a crop rotation of a legume such as beans, followed by a cereal such as wheat, to provide cash crops with a reduced input of nitrogen fertilizer.Some 1% of plants are parasitic. They range from the semi-parasitic mistletoe that merely takes some nutrients from its host, but still has photosynthetic leaves, to the fully-parasitic broomrape and toothwort that acquire all their nutrients through connections to the roots of other plants, and so have no chlorophyll. Full parasites can be extremely harmful to their plant hosts.Plants that grow on other plants, usually trees, without parasitizing them, are called epiphytes. These may support diverse arboreal ecosystems. Some may indirectly harm their host plant, such as by intercepting light. Hemiepiphytes like the strangler fig begin as epiphytes, but eventually set their own roots and overpower and kill their host. Many orchids, bromeliads, ferns, and mosses grow as epiphytes. Among the epiphytes, the bromeliads accumulate water in their leaf axils; these water-filled cavities can support complex aquatic food webs.Some 630 species of plants are carnivorous, such as the Venus flytrap (Dionaea muscipula) and sundew (Drosera species). They trap small animals and digest them to obtain mineral nutrients, especially nitrogen and phosphorus.\\n\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n=== Competition ===\\nCompetition for shared resources reduces a plant\\'s growth. Shared resources include sunlight, water and nutrients. Light is a critical resource because it is necessary for photosynthesis. Plants use their leaves to shade other plants from sunlight and grow quickly to maximize their own expose. Water too is essential for photosynthesis; roots compete to maximize water uptake from soil. Some plants have deep roots that are able to locate water stored deep underground, and others have shallower roots that are capable of extending longer distances to collect recent rainwater.\\nMinerals are important for plant growth and development. Common nutrients competed for amongst plants include nitrogen, phosphorus, and potassium.\\n\\n\\n== Importance to humans ==\\n\\n\\n=== Food ===\\n\\nHuman cultivation of plants is the core of agriculture, which in turn has played a key role in the history of world civilizations. Humans depend on plants for food, either directly or as feed in animal husbandry. Agriculture includes agronomy for arable crops, horticulture for vegetables and fruit, and forestry for timber. About 7,000 species of plant have been used for food, though most of today\\'s food is derived from only 30 species. The major staples include cereals such as rice and wheat, starchy roots and tubers such as cassava and potato, and legumes such as peas and beans. Vegetable oils such as olive oil and palm oil provide lipids, while fruit and vegetables contribute vitamins and minerals to the diet. Coffee, tea, and chocolate are major crops whose caffeine-containing products serve as mild stimulants. The study of plant uses by people is called economic botany or ethnobotany.\\n\\n\\n=== Medicines ===\\n\\nMedicinal plants are a primary source of organic compounds, both for their medicinal and physiological effects, and for the industrial synthesis of a vast array of organic chemicals. Many hundreds of medicines, as well as narcotics, are derived from plants, both traditional medicines used in herbalism and chemical substances purified from plants or first identified in them, sometimes by ethnobotanical search, and then synthesised for use in modern medicine. Modern medicines derived from plants include aspirin, taxol, morphine, quinine, reserpine, colchicine, digitalis and vincristine. Plants used in herbalism include ginkgo, echinacea, feverfew, and Saint John\\'s wort. The pharmacopoeia of Dioscorides, De materia medica, describing some 600 medicinal plants, was written between 50 and 70 CE and remained in use in Europe and the Middle East until around 1600 CE; it was the precursor of all modern pharmacopoeias.\\n\\n\\n=== Nonfood products ===\\n\\nPlants grown as industrial crops are the source of a wide range of products used in manufacturing. Nonfood products include essential oils, natural dyes, pigments, waxes, resins, tannins, alkaloids, amber and cork. Products derived from plants include soaps, shampoos, perfumes, cosmetics, paint, varnish, turpentine, rubber, latex, lubricants, linoleum, plastics, inks, and gums. Renewable fuels from plants include firewood, peat and other biofuels. The fossil fuels coal, petroleum and natural gas are derived from the remains of aquatic organisms including phytoplankton in geological time. Many of the coal fields date to the Carboniferous period of Earth\\'s history. Terrestrial plants also form type III kerogen, a source of natural gas.Structural resources and fibres from plants are used to construct dwellings and to manufacture clothing. Wood is used for buildings, boats, and furniture, and for smaller items such as musical instruments and sports equipment. Wood is pulped to make paper and cardboard. Cloth is often made from cotton, flax, ramie or synthetic fibres such as rayon, derived from plant cellulose. Thread used to sew cloth likewise comes in large part from cotton.\\n\\n\\n=== Ornamental plants ===\\n\\nThousands of plant species are cultivated for their beauty and to provide shade, modify temperatures, reduce wind, abate noise, provide privacy, and reduce soil erosion. Plants are the basis of a multibillion-dollar per year tourism industry, which includes travel to historic gardens, national parks, rainforests, forests with colourful autumn leaves, and festivals such as Japan\\'s and America\\'s cherry blossom festivals.Plants may be grown indoors as houseplants, or in specialized buildings such as greenhouses. Plants such as Venus flytrap, sensitive plant and resurrection plant are sold as novelties. Art forms specializing in the arrangement of cut or living plant include bonsai, ikebana, and the arrangement of cut or dried flowers. Ornamental plants have sometimes changed the course of history, as in tulipomania.\\n\\n\\n=== In science ===\\n\\nThe traditional study of plants is the science of botany. Basic biological research has often used plants as its model organisms. In genetics, the breeding of pea plants allowed Gregor Mendel to derive the basic laws governing inheritance, and examination of chromosomes in maize allowed Barbara McClintock to demonstrate their connection to inherited traits. The plant Arabidopsis thaliana is used in laboratories as a model organism to understand how genes control the growth and development of plant structures. Tree rings provide a method of dating in archeology, and a record of past climates. The study of plant fossils, or Paleobotany, provides information about the evolutions of plants, paleogeographical reconstructions, and past climate change. Plant fossils can also help determine the age of rocks.\\n\\n\\n=== In mythology, religion, and culture ===\\n\\nPlants including trees appear in mythology, religion, and literature. In multiple Indo-European, Siberian, and Native American religions, the world tree motif is depicted as a colossal tree growing on the earth, supporting the heavens, and with its roots reaching into the underworld. It may also appear as a cosmic tree or an eagle and serpent tree. Forms of the world tree include the archetypal tree of life, which is in turn connected to the Eurasian concept of the sacred tree. Another widespread ancient motif, found for example in Iran, has a tree of life flanked by a pair of confronted animals.Flowers are often used as memorials, gifts and to mark special occasions such as births, deaths, weddings and holidays. Flower arrangements may be used to send hidden messages. Plants and especially  flowers form the subjects of many paintings.\\n\\n\\n=== Negative effects ===\\nWeeds are commercially or aesthetically undesirable plants growing in managed environments such as in agriculture and gardens. People have spread many plants beyond their native ranges; some of these plants have become invasive, damaging existing ecosystems by displacing native species, and sometimes becoming serious weeds of cultivation.Some plants that produce windblown pollen, including grasses, invoke allergic reactions in people who suffer from hay fever. Many plants produce toxins to protect themselves from herbivores. Major classes of plant toxins include alkaloids, terpenoids, and phenolics. These can be harmful to humans and livestock by ingestion or, as with poison ivy, by contact. Some plants have negative effects on other plants, preventing seedling growth or the growth of nearby plants by releasing allopathic chemicals.\\n\\n\\n== See also ==\\nPlant identification\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nGeneral:\\n\\nEvans, L.T. (1998). Feeding the Ten Billion – Plants and Population Growth. Cambridge University Press. Paperback, 247 pages. ISBN 0-521-64685-5.\\nKenrick, Paul & Crane, Peter R. (1997). The Origin and Early Diversification of Land Plants: A Cladistic Study. Washington, D.C.: Smithsonian Institution Press. ISBN 1-56098-730-8.\\nRaven, Peter H.; Evert, Ray F.; & Eichhorn, Susan E. (2005). Biology of Plants (7th ed.). New York: W.H. Freeman and Company. ISBN 0-7167-1007-2.\\nTaylor, Thomas N. & Taylor, Edith L. (1993). The Biology and Evolution of Fossil Plants. Englewood Cliffs, NJ: Prentice Hall. ISBN 0-13-651589-4.Species estimates and counts:\\n\\nInternational Union for Conservation of Nature and Natural Resources (IUCN) Species Survival Commission (2004). IUCN Red List The IUCN Red List of Threatened Species.\\nPrance, G. T. (2001). \"Discovering the Plant World\". Taxon. 50 (2, Golden Jubilee Part 4): 345–359. doi:10.2307/1223885. JSTOR 1223885.\\n\\n\\n== External links ==\\n\\nIndex Nominum Algarum\\nInteractive Cronquist classification. Archived 10 February 2006.\\nPlant Resources of Tropical Africa. Archived 11 June 2010.\\nTree of Life. Archived 9 March 2022 at the Wayback Machine.Botanical and vegetation databasesAfrican Plants Initiative database\\nAustralia\\nChilean plants at Chilebosque\\ne-Floras (Flora of China, Flora of North America and others). Archived 19 February 2022 at the Wayback Machine.\\nFlora Europaea\\nFlora of Central Europe (in German)\\nFlora of North America. Archived 19 February 2022 at the Wayback Machine.\\nList of Japanese Wild Plants Online. Archived 16 March 2022 at the Wayback Machine.\\nMeet the Plants-National Tropical Botanical Garden. Archived 16 June 2007.\\nLady Bird Johnson Wildflower Center – Native Plant Information Network at University of Texas, Austin\\nUnited States Department of Agriculture not limited to continental US species.',\n",
              " 'A name is a term used for identification by an external observer. They can identify a class or category of things, or a single thing, either uniquely, or within a given context. The entity identified by a name is called its referent. A personal name identifies, not necessarily uniquely, a specific individual human. The name of a specific entity is sometimes called a proper name (although that term has a philosophical meaning as well) and is, when consisting of only one word, a proper noun. Other nouns are sometimes called \"common names\" or (obsolete) \"general names\". A name can be given to a person, place, or thing; for example, parents can give their child a name or a scientist can give an element a name.\\n\\n\\n== Etymology ==\\nThe word name comes from Old English nama; cognate with Old High German (OHG) namo, Sanskrit नामन् (nāman), Latin nomen, Greek ὄνομα (onoma), and Persian نام (nâm), from the Proto-Indo-European (PIE) *h₁nómn̥. Outside Indo-European, it can be connected to Proto-Uralic *nime.\\n\\n\\n== Naming conventions ==\\nA naming convention is a set of agreed, stipulated, or generally accepted standards, norms, social norms, or criteria for naming things.\\nParents may follow a naming convention when selecting names for their children. Some have chosen alphabetical names by birth order. In some East Asian cultures it is common for one syllable in a two-syllable given name to be a generation name which is the same for immediate siblings. In many cultures it is common for the son to be named after the father or a grandfather. In certain African cultures, such as in Cameroon, the eldest son gets the family name for his given name. In other cultures, the name may include the place of residence, or the place of birth.\\nMajor naming conventions include:\\n\\nIn astronomy, astronomical naming conventions\\nIn biology, binomial nomenclature\\nIn chemistry, chemical nomenclature\\nIn classics, Roman naming conventions\\nIn computer programming, identifier naming conventions\\nIn computer networking, computer naming schemes\\nIn planetary science, planetary nomenclature\\nIn sciences generally, systematic names for a variety of thingsProducts may follow a naming convention. Automobiles typically have a binomial name, a \"make\" (manufacturer) and a \"model\", in addition to a model year, such as a 2007 Chevrolet Corvette. Sometimes there is a name for the car\\'s \"decoration level\" or \"trim line\" as well: e.g., Cadillac Escalade EXT Platinum, after the precious metal. Computers often have increasing numbers in their names to signify the next generation.\\nCourses at schools typically follow a naming convention: an abbreviation for the subject area and then a number ordered by increasing level of difficulty.\\nMany numbers (e.g., bank accounts, government IDs, credit cards, etc.) are not random but have an internal structure and convention. Virtually all organizations that assign names or numbers will follow some convention in generating these identifiers. Airline flight numbers, Space Shuttle flight numbers, even phone numbers all have an internal convention.\\n\\n\\n== Personal name ==\\n\\nA personal name is an identifying word or words by which an individual is intimately known or designated. In many countries, it is traditional for individuals to have a personal name (also called a given name or first name) and a surname (also called a last name or family name because it is shared by members of the same family). Some people have two surnames, one inherited from each parent. In most of Europe and the Americas, the given name typically comes before the surname, whereas in parts of Asia and Hungary the surname comes before the given name. In some cultures it is traditional for a woman to take her husband\\'s surname when she gets married.\\nA common practice in many countries is patronym which means that a component of a personal name is based on the given name of one\\'s father. A less common practice in countries is matronym which means that a component of a personal name is based on the given name of one\\'s mother. In some East Asian cultures, it is traditional for given names to include a generation name, a syllable shared between siblings and cousins of the same generation.\\nMiddle names are also used by many people as a third identifier, and can be chosen for personal reasons including signifying relationships, preserving pre-marital/maiden names (a popular practice in the United States), and to perpetuate family names. The practice of using middle names dates back to ancient Rome, where it was common for members of the elite to have a praenomen (a personal name), a nomen (a family name, not exactly used the way middle names are used today), and a cognomen (a name representing an individual attribute or the specific branch of a person\\'s family). Middle names eventually fell out of use, but regained popularity in Europe during the nineteenth century.Besides first, middle, and last names, individuals may also have nicknames, aliases, or titles. Nicknames are informal names used by friends or family to refer to a person (\"Chris\" may be used as a short form of the personal name \"Christopher\"). A person may choose to use an alias, or a fake name, instead of their real name, possibly to protect or obscure their identity. People may also have titles designating their role in an institution or profession (members of royal families may use various terms such as king, Queen, duke, or duchess to signify their positions of authority or their relation to the throne).\\n\\n\\n== Names of names ==\\nIn onomastic terminology, personal names of men are called andronyms (from Ancient Greek ἀνήρ / man, and ὄνομα / name), while personal names of women are called gynonyms (from Ancient Greek γυνή / woman, and ὄνομα / name).\\n\\n\\n== Brand names ==\\n\\nDeveloping a name for a brand or product is heavily influenced by marketing research and strategy to be appealing and marketable. The brand name is often a neologism or pseudoword, such as Kodak or Sony.\\n\\n\\n== Religious names ==\\n\\nIn the ancient world, particularly in the ancient near-east (Israel, Mesopotamia, Egypt, Persia) names were thought to be extremely powerful and act, in some ways, as a separate manifestation of a person or deity. This viewpoint is responsible both for the reluctance to use the proper name of God in Hebrew writing or speech, as well as the common understanding in ancient magic that magical rituals had to be carried out \"in [someone\\'s] name\". By invoking a god or spirit by name, one was thought to be able to summon that spirit\\'s power for some kind of miracle or magic (see Luke 9:49, in which the disciples claim to have seen a man driving out demons using the name of Jesus). This understanding passed into later religious tradition, for example the stipulation in Catholic exorcism that the demon cannot be expelled until the exorcist has forced it to give up its name, at which point the name may be used in a stern command which will drive the demon away.\\n\\n\\n=== Biblical names ===\\n\\nIn the Old Testament, the names of individuals are meaningful, and a change of name indicates a change of status. For example, the patriarch Abram and his wife Sarai were renamed \"Abraham\" and \"Sarah\" at the institution of the Abrahamic covenant (Genesis 17:4, 17:15). Simon was renamed Peter when he was given the Keys to Heaven. This is recounted in the Gospel of Matthew chapter 16, which according to Roman Catholic teaching was when Jesus promised to Saint Peter the power to take binding actions. Proper names are \"saturated with meaning\".Throughout the Bible, characters are given names at birth that reflect something of significance or describe the course of their lives. For example: Solomon meant peace, and the king with that name was the first whose reign was without war. Likewise, Joseph named his firstborn son Manasseh (Hebrew: \"causing to forget\")(Genesis 41:51); when Joseph also said, \"God has made me forget all my troubles and everyone in my father\\'s family.\" Biblical Jewish people did not have surnames which were passed from generation to generation. However, they were typically known as the child of their father. For example: דוד בן ישי (David ben Yishay) meaning, David, son of Jesse (1 Samuel 17:12,58). Today, this style of name is still used in Jewish religious rites.\\n\\n\\n=== Indian name ===\\n\\nIndian names are based on a variety of systems and naming conventions, which vary from region to region. Names are also influenced by religion and caste and may come from epics. India\\'s population speaks a wide variety of languages and nearly every major religion in the world has a following in India. This variety makes for subtle, often confusing, differences in names and naming styles. Due to historical Indian cultural influences, several names across South and Southeast Asia are influenced by or adapted from Indian names or words.\\nFor some Indians, their birth name is different from their official name; the birth name starts with a randomly selected name from the person\\'s horoscope (based on the nakshatra or lunar mansion corresponding to the person\\'s birth).\\nMany children are given three names, sometimes as a part of religious teaching.\\n\\n\\n=== Quranic names (Arabic names) ===\\n\\nWe can see many Arabic names in the Quran and in Muslim people, such as Allah, Muhammad, Khwaja, Ismail, Mehboob, Suhelahmed, Shoheb Ameena, Aaisha, Sameena, Rumana, Swaleha, etc. The names Mohammed and Ahmed are the same, for example Suhel Ahmad or Mohammad Suhel are the same. There are many similar names in Islam and Christianity, such as Yosef (Islamic)/Joseph (Christian), Adam/Adam, Dawood/David, Rumana/Romana, Maryam/Mary, Nuh/Noah, etc.\\n\\n\\n== Name use by animals and plants ==\\n\\nThe use of personal names is not unique to humans. Dolphins and green-rumped parrotlets also use symbolic names to address contact calls to specific individuals. Individual dolphins have distinctive signature whistles, to which they will respond even when there is no other information to clarify which dolphin is being referred to.\\n\\n\\n== Named entities ==\\n\\n\\n== See also ==\\n\\n\\n== References ==\\n\\n\\n== Sources ==\\n\\n\\n== Further reading ==\\n\"Names\" by Sam Cumming, Stanford Encyclopedia of Philosophy (SEP), a philosophical dissertation on the syntax and semantics of names\\nPilcher, Jane (2017). \"Names, Bodies and Identities\". Sociology. 50 (4): 764–779. doi:10.1177/0038038515582157. S2CID 145136869.\\nMatthews, Elaine; Hornblower, Simon; Fraser, Peter Marshall, Greek Personal Names: Their Value as Evidence, Proceedings of the British Academy (104), Oxford University Press, 2000. ISBN 0-19-726216-3\\nName and Form – from Sacred Texts Buddhism\\n\\n\\n== External links ==\\n\\nLexicon of Greek Personal Names, Oxford (over 35,000 published names)\\nBehind The Name, The etymology of first names\\nThe Name Tradition In The Christian Culture\\nKate Monk\\'s Onomastikon Names over the world throughout the history\\n\"Name\" . Encyclopædia Britannica (11th ed.). 1911.']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Generate Embeddings"
      ],
      "metadata": {
        "id": "pSE8d91mw-Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvQOZFsVw9Qf",
        "outputId": "5688f56c-b880-43c7-8dc3-6d64adefadb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "7kCIK-mX247v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'  # You can choose different variations of BERT here\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "2bf9638be1d74a828a469e5121523e77",
            "5a2b9b3e03f44631b1f2410bb77a15ab",
            "cabad43eefb24bb58e67f214635cfae7",
            "d2dcb48375e34e4084f7f9c2bca8c31a",
            "8281d7a7a8704d26a706323ca8a423e3",
            "e3e43c9c1923490699677dff198d402c",
            "f34aa1af2d5f4dbe85d90680c7e23ef4",
            "ecba445d19ff4f4a90f81602989bfdf2",
            "b2e119f7902e4e4683b3f7cb008566c2",
            "b7e956b533c14861b8c808452c3494a4",
            "5c1316f15e7c4d5fa5c2b082578e422c",
            "ac6a3967bb9c4821951c17765d813f44",
            "fa6dd73422094ec98aa384fa0a8f1ea9",
            "cee121985a7f4717b3538b9d1ab08ba7",
            "a27aec7b67334a8fb7b3260541a965b7",
            "8aa958c7142740f9993e73bec992e6f4",
            "56c56763ff384598b12458500df684c7",
            "aab89a8cb45747aba990607e469e4b24",
            "d2b0eca2cc484c148e1bc11601207530",
            "816fcf0d57f34989963910aec51c66ff",
            "060489664ced4268a358c0012f1b43e7",
            "67c110c6540b43fabe4c4e2ebe902d79",
            "d81f4c752aed4cad8fbfa51d100373a4",
            "165dbceab6e84299bf0fe37650319a84",
            "059ba710a5564cd28b529c990ec84241",
            "54c7df1d2f9b412b867b5f04f191ed91",
            "fa5b8c1f2bbf483ca2654a6720e36a03",
            "71c7e5005c874bc895db73f72599c3df",
            "e7ff5a48c75b4231b294ab5ea486ad62",
            "7d223169e08542caaad03a7ccd1e4048",
            "c2a61b02abb8457e99967eb9c32f2beb",
            "002297d9dc334574a379a3a819707c9a",
            "3d346addb9d948abbee4c92724381310",
            "d9b9a045f54d478794ada90bfd742bdd",
            "5b52b1b31ab440399d8ab8cd8526800d",
            "db0aec260d45424bbd1dbd8af669733a",
            "8501f840d3b244aa99a1a104883bb127",
            "db52867f9f71481187a05f5459c91191",
            "d5b0461a3c784b929f0eded7292d9364",
            "1fe92344a5fd4a6d86962c0ce3b71370",
            "0f243e7bb05045229da57361f5de4a56",
            "127b4dceb9b042e2b71c73adfaf6a369",
            "3ff1c142e4e8422abd6e3c7ff3202309",
            "2f0566d138b5445da3117ad0f4e54967",
            "be98164834c143da837a6e0a977e618a",
            "7bdca7fc1b9545feb374b4d63ad890d6",
            "4d1e7f2951994e399c951f081cd4cb5b",
            "47c94da8ae21463cba5477553ddc4ccd",
            "e52c54cbf991404fad815ffe72d46168",
            "de2c69d45bc04d95a42c7f7168b253f6",
            "bae63fa01da34955b64bbae6fa260847",
            "81c4484b5cbe4f87b23dcae0089a0bd3",
            "77d84fe2a82146648b2436d1f0ef1ca2",
            "1349c97f5bd44218a21a5123e9265990",
            "15e5de95fce1483ca1bc002669298212"
          ]
        },
        "id": "dF9zOtIB209T",
        "outputId": "d062d9d8-0ac2-4df0-8d00-fc0a7452b001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bf9638be1d74a828a469e5121523e77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac6a3967bb9c4821951c17765d813f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d81f4c752aed4cad8fbfa51d100373a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9b9a045f54d478794ada90bfd742bdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be98164834c143da837a6e0a977e618a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RQt-zQEJ3zPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and generate embeddings for each sentence\n",
        "embeddings = []\n",
        "for sentence in Sentences:\n",
        "    # Tokenize the sentence\n",
        "    tokenized_sentence = tokenizer.tokenize(sentence)\n",
        "\n",
        "    # Split sentence into chunks of maximum sequence length\n",
        "    max_chunk_len = 512  # Maximum sequence length for BERT base\n",
        "    chunked_tokens = [\n",
        "        tokenized_sentence[i:i + max_chunk_len] for i in range(0, len(tokenized_sentence), max_chunk_len)\n",
        "    ]\n",
        "\n",
        "    # Generate embeddings for each chunk\n",
        "    chunk_embeddings = []\n",
        "    for chunk in chunked_tokens:\n",
        "        indexed_tokens = tokenizer.convert_tokens_to_ids(chunk)\n",
        "        tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "        # Get the BERT model output (hidden states)\n",
        "        with torch.no_grad():\n",
        "            model_output = model(tokens_tensor)\n",
        "\n",
        "        # Extract the output embeddings (last hidden states)\n",
        "        last_hidden_states = model_output.last_hidden_state\n",
        "\n",
        "        # Average pooling of the hidden states to get a single vector representation of the chunk\n",
        "        chunk_embedding = torch.mean(last_hidden_states, dim=1).squeeze().numpy()\n",
        "        chunk_embeddings.append(chunk_embedding)\n",
        "\n",
        "    # Concatenate chunk embeddings to represent the full sentence\n",
        "    sentence_embedding = np.concatenate(chunk_embeddings)\n",
        "    embeddings.append(sentence_embedding)\n",
        "\n",
        "# Now 'embeddings' contains the BERT embeddings for each sentence in your list\n",
        "# You can use these embeddings for further downstream tasks or analysis"
      ],
      "metadata": {
        "id": "v0HXuW6f2r0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming 'embeddings' is your list of embeddings\n",
        "with open('embeddings.pkl', 'wb') as file:\n",
        "    pickle.dump(embeddings, file)\n"
      ],
      "metadata": {
        "id": "4xUf4niz6vdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "Jzq1JqjxiTd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('embeddings.pkl', 'rb') as file:\n",
        "    loaded_embeddings = pickle.load(file)"
      ],
      "metadata": {
        "id": "gNDohffphyVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_embeddings[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEEBAiQH60t7",
        "outputId": "9942d36d-3e97-4d97-9a20-6389bec5ec98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.23525506,  0.55807006,  0.17506835, ..., -0.0083645 ,\n",
              "        0.01382213,  0.4041682 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Question Answering of docs"
      ],
      "metadata": {
        "id": "wH_KE7aE7CH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain chromadb langchainhub --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJSwS_XamYyH",
        "outputId": "36e508d2-d429-4d0a-ee6e-0a356c46b05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.4/502.4 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.4/699.4 kB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XToKaUiQrxeu",
        "outputId": "c2be2659-af50-47e6-b09c-b8257ec8fe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WikipediaLoader"
      ],
      "metadata": {
        "id": "t9YCPnz_qoly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "Cq-h6CAkvPq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")"
      ],
      "metadata": {
        "id": "_ud1JNPSvUku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [\n",
        "    'Computer Science',\n",
        "    'Artificial Intelligence',\n",
        "    'Deep learning',\n",
        "    'Data Science',\n",
        "    'Algorithms',\n",
        "    'Programming Languages',\n",
        "    'Operating Systems',\n",
        "    'Computer Vision',\n",
        "    'Cryptography',\n",
        "    'Human-Computer Interaction',\n",
        "    'Software Engineering',\n",
        "    'Internet of Things',\n",
        "    'Computer Networks',\n",
        "    'Databases',\n",
        "    'Cybersecurity',\n",
        "    'Cricket' ,\n",
        "    'Rose' ,\n",
        "    'Plant' ,\n",
        "    'Planet' ,\n",
        "    'Name'\n",
        "]"
      ],
      "metadata": {
        "id": "Xzj1tcTHrrTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers > /dev/null"
      ],
      "metadata": {
        "id": "Mg2iP61twcve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "upTfKypwwd-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"bert-base-uncased\")\n",
        "# Equivalent to SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471,
          "referenced_widgets": [
            "e9e01dec418b4ab68bba1eedc2d20831",
            "33a9191d161041af87c373de8e91e60f",
            "c24cacc56bcd4347afa44fb9cf7f55da",
            "0408dd4c89ea4fd9be8d29f8091af13e",
            "8b3370be27964307a0dae24da416bc15",
            "8fc1692f2e4a44009c694422c95c62c1",
            "58cd6122eae245548934e63f6ca15f0f",
            "9eba8f6725484e79af1d02d5fc450a10",
            "0e8d1dc75fb74e5bbcc5204070d3ad18",
            "348fb0db82154b0289560294bbe22b27",
            "f6a129489743421784ea8c01b07250fe",
            "6fe7c3bc57b34a07a9496e8738fc4b3b",
            "4ec74561c0c64bc08808ffd3644b77e7",
            "79298e7ac3c344f29cbab53005e8ccd6",
            "6bdc71ffe9ab4af28732c9d7700828f1",
            "4f4e8bd64d674b5a9cf541010ae38040",
            "2b48c743696f4c61a4f0d138a59e1ef7",
            "85ad10d0812d484bb50c3f2e3fb79a82",
            "4da1f990dbdc4274b3e3366cfb3f0539",
            "e2371db566fe40d98cc3150c42d3b715",
            "bee9f7fd960f491d89784e65688748f3",
            "b1acfa20f09f4db583b67a25dc9a37db",
            "932b8216f9804641a3801f3b499a0388",
            "59b28708244f40329b8f00f045716073",
            "2dbe5cfab23e46a8837ecdedc9c1111d",
            "1baad3de9df34ff19fe1270f39310663",
            "d5a89fe36a3140dbbf566dc1bdf406da",
            "79b37527b3874f6f828091cfa4dbac1d",
            "5525d0c914694d318269ef6f3f97868f",
            "e037c96116b643339137b176c60741c6",
            "1be1bea91348422eb465068a41c7dc6d",
            "b6f5531fa2994c1eb1346b5405d3a5bf",
            "bd7dea4edeec4d2eafb6842f19fa951f",
            "9d9b1b5b4790487b894fd6ad0f44fec9",
            "da907327dd4e4882a6449f899c1efb5d",
            "53d3cf974e6044c3b15b12552978e7cd",
            "86428fb30c0c4b7dbe0a4783f81e0936",
            "f02728bea1db46d68edd9d66fe24021a",
            "07a2012e4563465891bcf00394391459",
            "072b7fd7db75449fa0992b145db22ca6",
            "155cab89f1904e37902b57f943170e67",
            "90deb757fcf74182963734791c763675",
            "820217eba92d4968bb5ee16ae12abd59",
            "5724ef6e30f24dcabfe7cafa8d96c151",
            "2b919792a8b443c7891c5b8b8d22a19b",
            "ac2e6f76cc7d457f9ae44dfde59e93ce",
            "39488c41c59f4536aec0aa414e94ade0",
            "8bb5358736ba4eefb248f1ceabca9fa3",
            "da61caef6eb848b6acf75d6e43409440",
            "7847a32772974a4196e7cd76e085f01f",
            "2eee880577b948e78b30b76e2c91cc81",
            "80072e6e30214157978153e1e8283602",
            "01ecf5b4bf1847388476394c76dd9576",
            "d99e3a3bda504caeb883452e49c95234",
            "c7d2f051e2c64faa9cd3a3031f3f8f45",
            "37a1ec500d334adfb6c811bc990f8030",
            "5d4983407aa146a6afb5acbc67de2f0a",
            "ab1e63b1fe564b1995093327a1176340",
            "30075978f75e42c998fa4f3e8168aedf",
            "4677a22eb52943bdaf7cb59855d688db",
            "729d86ea456a47bfbed8f0e9a31fa1d3",
            "a14aee3c566546c7b70451b51bb5b11c",
            "bb9a9bca920d4c579423aba0a80232c3",
            "ef81307de4594a32879ce658b863b160",
            "4be51057730f4f959f91fb6c49304b6f",
            "0176649e428f42329ed21bf7ba1b979a",
            "07eff2e86876403ebbd454695d9d37ad",
            "4e5e73f7d69d47dda8ac56dbe5f3543a",
            "e29d1234c49f4dd4bd4a5dc3f9b117c9",
            "fe62231902b64597b0907ae8305e7b62",
            "87b9a37c4a9d4537b81afd100e05004e",
            "1745db7cdaac4b9dad78a036c49e9f5e",
            "87e60351e5b040df9ce68fcdde28f72a",
            "68d048b4d3d948edb70d08238b1ab6c4",
            "c2976ca4f5f943fbbfa7a8d3e0ae2666",
            "c8e792330b1c4380a7fe83b8130cdb0a",
            "46ab7eea93764b8db33c43e3048cf75c",
            "2e3d58929eed497d8b0015fa598745f4",
            "8ed1e72ac97b488d8ea0e9f653d62861",
            "1e3c24c9cd904fbcb171b47c69759150",
            "1848e6ff3e62409a9570a4b2403873e6",
            "2cfd71cc139d4158a84fab35ac47cda8",
            "4e4266b5828e4f318da8a66b3378d90d",
            "25d5e704e727427ea6aa80df63a851a3",
            "f2e67159b0054994ac27d91797267262",
            "3e59b65fff0d487cbbe9a3b74cc1bf08",
            "61a1afd024c74e77bfac4753c6432055",
            "2dd6978fd55c4f57831d2f6ffd4d7a9c",
            "7ea07d545bee4217a324da0106c1c639",
            "d8bb82b7e49d43cf9b33d8e7fc2f21e5",
            "7492d3fdc2c644c49338e53c896332d1",
            "b0069b11a84b48a490dd5fa0f7ffae05",
            "c7e755cb1c2942e99e52a18f7fe9f0e3",
            "9b47149eb10a41e9b08b828b2fb8808e",
            "afe79dc613664db6b5bec7ed6f8f8fe1",
            "758f680037c84a4f85991d285642afc9",
            "a9922b72ccdf404a9731b567041479e6",
            "ebd1a9ee935844d0b8c293f9fac775c0",
            "9e045313d48147eaafbb8078292e9879",
            "6d036de511ec419ea2065e428da3cccf",
            "614356073dc643a2af0141d79089e3bd",
            "f75aeeae9c794374bf589d6cf13fd9e1",
            "90d459428eed4326b7eba1afa1822684",
            "957fd9bdd2404c7682cb000a1957bed2",
            "d9ec06115959466f877a86a5826c8dd7",
            "30b2f1f428a14d3bbd214e1b4d56232e",
            "54d0fcc812bd45ad82c44e9f5be72df4",
            "4751022230ed4f76b0c6c95ba6e52c48",
            "bcbb97ce96a442b48036fc8d05254c07",
            "064a85c6eb99492590774d98a061c4fe",
            "3f4a65b97cc346469356e6649be0ff89",
            "2027f7c3f6314e0c94884f4ed4ecbcb4",
            "de30b7bcb8e54298b63b68e2ef162138",
            "f0e66c98927e4680a002eb64a8d0d8f3",
            "beff2aaa198a484b83ccf1ec74a797ec",
            "2f7975f71d5e4abb9daeacc0e89de384",
            "33da93679d4f4d8192c359e21a21b681",
            "d657d333d46f43be8a3b105199d42ec6",
            "77dd3359f4e947e99e38e985b79426dc",
            "142587252f6d44829c8b64985358dcf7",
            "ee4db58056e845bd8e6006ecea3a2a51",
            "30eae81f318f4ab49a940e116951be3c",
            "0fb65c9eb97c403696dd53084a3fe7db",
            "9b0b2fcc69904541b86f2046fc64e18c",
            "99dbfb1e3d4641cb9d5f7c43594a4fc2",
            "5018f5f464714fdd9a64c976285dc82c",
            "48dc3b67caf3457693d28c1b23237c70",
            "eddc8742a5824d0abac0f5961f8c0031",
            "0e445cbb56e34b1f805066079e099b7b",
            "33b7524e2a424038959bb668f77b4b77",
            "2a14aee1a26c45e5a7eec5c5e0f24839",
            "848bf8779dec437ba6e6e3a7d5d6f8a5",
            "0efe12604df04b04bc019604fe2866dc",
            "615fbd2dd2434590be38ab082fddb696",
            "3d447735e1d447b49a88bbfc63288f59",
            "6c8b49ea662d425780d3f414d7bca675",
            "10522865624641d291ac68c056f0130d",
            "b38286de97a34c94ad5fd33215d2899c",
            "51229f16589d4544b69a15f4ccad4b8d",
            "cbc9e127fc21437085e20b14c9119dd2",
            "7ef75f246c2e4b52bc0d379dccf2be42",
            "d665ff349cf549669691b3170b4826cc",
            "7e7639bd2d414beb91eeaaebbffdc978"
          ]
        },
        "id": "gOwjlUH-whTT",
        "outputId": "3fb7a597-8a87-4387-e0de-f97d145ae125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/491 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9e01dec418b4ab68bba1eedc2d20831"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LICENSE:   0%|          | 0.00/11.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fe7c3bc57b34a07a9496e8738fc4b3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "932b8216f9804641a3801f3b499a0388"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d9b1b5b4790487b894fd6ad0f44fec9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)kage/Data/com.apple.CoreML/model.mlmodel:   0%|          | 0.00/165k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b919792a8b443c7891c5b8b8d22a19b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "weight.bin:   0%|          | 0.00/532M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37a1ec500d334adfb6c811bc990f8030"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)sk/float32_model.mlpackage/Manifest.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07eff2e86876403ebbd454695d9d37ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.onnx:   0%|          | 0.00/532M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e3d58929eed497d8b0015fa598745f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ea07d545bee4217a324da0106c1c639"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d036de511ec419ea2065e428da3cccf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f4a65b97cc346469356e6649be0ff89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30eae81f318f4ab49a940e116951be3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0efe12604df04b04bc019604fe2866dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "MCO5u_rnxecJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic in topics:\n",
        "    # Fetch Wikipedia pages for each topic\n",
        "    docs = WikipediaLoader(query=topic, load_max_docs=1).load()  # Fetching 1 page per topic\n",
        "    all_splits = text_splitter.split_documents(docs)\n",
        "    vectorstore = Chroma.from_documents(documents=all_splits, embedding= embeddings)"
      ],
      "metadata": {
        "id": "_2idY9VxvZT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
      ],
      "metadata": {
        "id": "7-_k1tUcvrs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs = retriever.get_relevant_documents(\n",
        "    \"Who is Rajan?\"\n",
        ")"
      ],
      "metadata": {
        "id": "iP8-clcAx7j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(retrieved_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnKX7yu3x_9m",
        "outputId": "4f051c78-3c71-4eae-92ab-6f1daa531e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(retrieved_docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpHifOHCyG0q",
        "outputId": "6df05d44-eda7-4f16-bb23-35a4fdc28bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== History ==\n",
            "\n",
            "\n",
            "=== Ancient algorithms ===\n",
            "Since antiquity, step-by-step procedures for solving mathematical problems have been attested. This includes Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later; e.g. Shulba Sutras, Kerala School, and Brāhmasphuṭasiddhānta), The Ifa Oracle (around 500 BC), Greek mathematics (around 240 BC, e.g. sieve of Eratosthenes and Euclidean algorithm), and Arabic mathematics (9th century, e.g. cryptographic algorithms for code-breaking based on frequency analysis).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.chatbot"
      ],
      "metadata": {
        "id": "pksuU2qiy5GV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using Basic Python"
      ],
      "metadata": {
        "id": "VQO6YoS8zWfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Use Langchain retriever to get an answer based on the user input\n",
        "    retrieved_docs = retriever.get_relevant_documents(user_input)\n",
        "\n",
        "    # Display retrieved answer\n",
        "    print(f\"Bot: {retrieved_docs[0]}\")\n",
        "\n",
        "    # Ask a follow-up question or continue the conversation\n",
        "    user_response = input(\"Bot: What else would you like to know? (Press Enter to exit)\")\n",
        "    if user_response.lower() == \"\":\n",
        "        break  # Exit the conversation loop if the user chooses to exit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2h7YTZRzHUT",
        "outputId": "729ffa02-a33d-48b9-fed7-c0ae5ceaec3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: what is machine learning?\n",
            "Bot: page_content='The fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.' metadata={'source': 'https://en.wikipedia.org/wiki/Computer_science', 'start_index': 1794, 'summary': 'Computer science is the study of computation, information, and automation. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). Though more often considered an academic discipline, computer science is closely related to computer programming.Algorithms and data structures are central to computer science.\\nThe theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.\\nThe fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.', 'title': 'Computer science'}\n",
            "Bot: What else would you like to know? (Press Enter to exit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using OpenAI"
      ],
      "metadata": {
        "id": "-eiHHr0IzbF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "gGkKpuPA4p5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-ggZa8EzSId6MFdQxCWtXT3BlLHYp8uIskTobqR9xbZJ\""
      ],
      "metadata": {
        "id": "VgDvOvG-qy5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "5MWHRtwRq-U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_template = \"\"\"Answer the question based on the context below. If the\n",
        "question cannot be answered using the information provided answer\n",
        "with \"I don't know\".\n",
        "\n",
        "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
        "Their superior performance over smaller models has made them incredibly\n",
        "useful for developers building NLP enabled applications. These models\n",
        "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
        "using the `openai` library, and via Cohere using the `cohere` library.\n",
        "\n",
        "Question: Which libraries and model providers offer LLMs?\n",
        "\n",
        "\n",
        "Answer:\n",
        "\n",
        "Answer the Question asked by user\n",
        "{Question}. \"\"\""
      ],
      "metadata": {
        "id": "V3CtrRX6uklP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.format(Question='what is capital of india?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uBFgOJqztkS7",
        "outputId": "7c9baac4-4f28-47ab-b8d8-f751dba77f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer the Question asked by user what is capital of india?. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenAI --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyPGV7JKxS6q",
        "outputId": "1be1fba6-d489-421e-a61e-69e005e21f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/221.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/221.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm=OpenAI(temperature=0.7)\n",
        "chain1=LLMChain(llm=llm,prompt=prompt)"
      ],
      "metadata": {
        "id": "0PN8jLD4tk2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.run('GDP')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ijDJK5VqxcBr",
        "outputId": "1d758148-3076-4e62-c42c-8d177898e3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-3a5fa2470341>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchain1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GDP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    508\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    515\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 )\n\u001b[1;32m    665\u001b[0m             ]\n\u001b[0;32m--> 666\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             output = (\n\u001b[0;32m--> 540\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    541\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 )\n\u001b[1;32m    454\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 response = completion_with_retry(\n\u001b[0m\u001b[1;32m    456\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;34m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_openai_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mretry_decorator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_retry_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[0;32m--> 559\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0;34m\"/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         )\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 846\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    885\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    885\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using developed qa system"
      ],
      "metadata": {
        "id": "AYWbwZdF1nGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "### Instruction: You're a travelling support agent that is talking to a customer. Use only the chat history and the following information\n",
        "{context}\n",
        "to answer in a helpful manner to the question. If you don't know the answer - say that you don't know.\n",
        "Keep your replies short, compassionate and informative.\n",
        "{chat_history}\n",
        "### Input: {question}\n",
        "### Response:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "w0f_zK0zxer9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\", \"chat_history\"], template=template\n",
        ")"
      ],
      "metadata": {
        "id": "4ky-VwEJ1mht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "raQsoFnl6zJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    human_prefix=\"### Input\",\n",
        "    ai_prefix=\"### Response\",\n",
        "    output_key=\"answer\",\n",
        "    return_messages=True,\n",
        ")"
      ],
      "metadata": {
        "id": "nj49q0e56FDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "VJBm4-3-7EQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'vectorstore' is an instance of VectorStore or a retriever object\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
        "# retrieved_docs = retriever.get_relevant_documents(question)"
      ],
      "metadata": {
        "id": "WYO-W8aE8jJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## retriever=vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
      ],
      "metadata": {
        "id": "jJAOn74J9x97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1}),\n",
        "    memory=memory,\n",
        "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
        "    return_source_documents=True,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "GRkl-9qv6L7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what is capital of india?\"\n",
        "answer = chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "LY983Zib80vi",
        "outputId": "71ec9bf5-dc9b-4a04-a7dd-d1d3c29dde1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m### Instruction: You're a travelling support agent that is talking to a customer. Use only the chat history and the following information\n",
            "Haec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris.\n",
            "which translates to:\n",
            "\n",
            "Algorism is the art by which at present we use those Indian figures, which number two times five.\n",
            "The poem is a few hundred lines long and summarizes the art of calculating with the new styled Indian dice (Tali Indorum), or Hindu numerals.\n",
            "\n",
            "\n",
            "=== English evolution of the word ===\n",
            "Around 1230, the English word algorism is attested and then by Chaucer in 1391. English adopted the French term.In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, \"number\"; cf. \"arithmetic\"), the Latin word was altered to algorithmus.\n",
            "In 1656, in the English dictionary Glossographia, it says:\n",
            "\n",
            "Algorism ([Latin] algorismus) the Art or use of Cyphers, or of numbering by Cyphers; skill in accounting.\n",
            "Augrime ([Latin] algorithmus) skil in accounting or numbring.\n",
            "\n",
            "In 1658, in the first edition of The New World of English Words, it says:\n",
            "to answer in a helpful manner to the question. If you don't know the answer - say that you don't know.\n",
            "Keep your replies short, compassionate and informative.\n",
            "\n",
            "### Input: what is capital of india?\n",
            "### Response:\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-0d24a3376d68>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"what is capital of india?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/conversational_retrieval/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mnew_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mnew_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"chat_history\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_history_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             answer = self.combine_docs_chain.run(\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mother_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     async def acombine_docs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    515\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 )\n\u001b[1;32m    665\u001b[0m             ]\n\u001b[0;32m--> 666\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             output = (\n\u001b[0;32m--> 540\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    541\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 )\n\u001b[1;32m    454\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 response = completion_with_retry(\n\u001b[0m\u001b[1;32m    456\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;34m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_openai_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mretry_decorator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_retry_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[0;32m--> 559\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0;34m\"/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         )\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 846\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    885\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    885\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    human_prefix=\"### Input\",\n",
        "    ai_prefix=\"### Response\",\n",
        "    input_key=\"question\",\n",
        "    output_key=\"output_text\",\n",
        "    return_messages=False,\n",
        ")"
      ],
      "metadata": {
        "id": "muUnzesB8491"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "8WGjv22l-NJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(\n",
        "    llm, chain_type=\"stuff\", prompt=prompt, memory=memory, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "4Uornznu-Djz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How flight search works?\"\n",
        "answer = chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pZnmYqwg-Gd5",
        "outputId": "12519665-fb41-44ac-80c7-83c02e8aa013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-68fb6bc06701>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"How flight search works?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0mChain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         callback_manager = CallbackManager.configure(\n\u001b[1;32m    290\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mprep_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0m_input_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    436\u001b[0m                     \u001b[0;34mf\"A single string input was passed in, but this chain expects \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;34mf\"multiple inputs ({_input_keys}). When a chain expects \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A single string input was passed in, but this chain expects multiple inputs ({'question', 'input_documents'}). When a chain expects multiple inputs, please call it by passing in a dictionary, eg `chain({'foo': 1, 'bar': 2})`"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using Huggingface"
      ],
      "metadata": {
        "id": "utQ_vcA7C3qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "81wmMPjpDCZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "5XXK-FyqC6LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0, \"max_length\":512})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K1SjbvIC7aB",
        "outputId": "1abb31c6-9f95-4092-fc7c-5dc1e2c65218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "z7Gp3lGZC_Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is computer science?\"\n",
        "docs = retriever.get_relevant_documents(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "sLxDsm_zDsv_",
        "outputId": "470a288d-8eee-4f00-99e6-c9a5231fad65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-abc8aa81a639>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is computer science?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mother_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     async def acombine_docs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    515\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 )\n\u001b[1;32m    665\u001b[0m             ]\n\u001b[0;32m--> 666\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             output = (\n\u001b[0;32m--> 540\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    541\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             text = (\n\u001b[0;32m-> 1069\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/huggingface_hub.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error raised by inference API: {response['error']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Text generation return includes the starter text.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error raised by inference API: Authorization header is correct, but the token seems invalid"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## new start"
      ],
      "metadata": {
        "id": "ArYZkXbeHZsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub --quiet"
      ],
      "metadata": {
        "id": "_It68eqtH-fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghfvKEf1IFWV",
        "outputId": "55713038-7a37-4308-b108-e0daa95dabc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "XG7YeRbOHb9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "H0zGIQZKIKn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "kDqeb2DnIOiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "kUFoNUZKIQwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"google/flan-t5-xxl\"  # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options"
      ],
      "metadata": {
        "id": "VuF28nWCIU2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 64}\n",
        ")\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8chMPTWZJNE2",
        "outputId": "6bede4eb-523b-4948-bb8a-fa48321525bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The FIFA World Cup is an international football tournament held every two years. The FIFA World Cup in the year 1994 was won by West Germany. The answer: West Germany.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "HnbY2I7PJPvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    prompt.invoke(\n",
        "        {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
        "    ).to_string()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1cg_V81J0YX",
        "outputId": "0a5f58fb-a369-4f23-dbbe-0aab5dcc4a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: filler question \n",
            "Context: filler context \n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "mciBVtXDJ29C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in rag_chain.stream(\"What is Computer Science?\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tEEXDLAJ8F-",
        "outputId": "87e8612a-d670-40e5-f64c-3285b68ac45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what can and cannot be automated"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in rag_chain.stream(\"What is CyberSecurity?\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C29mfcIFLuoU",
        "outputId": "b0b47561-e8dc-4c6a-8210-5172f56e6f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To secure a computer system, it is important to understand the attacks that can be made against it, and these threats can typically be classified into one of the following categories:"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Use the provided context to answer the initial question. After your response, encourage follow-up questions by inviting more discussion.\n",
        "If uncertain, feel free to mention you're open to more queries.\n",
        "Keep your response within three concise sentences and end by expressing gratitude: \"Thanks for asking!\"\n",
        "{context}\n",
        "Initial Question: {question}\n",
        "Answer:\"\"\"\n",
        "follow_up_prompt_custom = PromptTemplate.from_template(template)\n",
        "\n",
        "follow_up_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | follow_up_prompt_custom\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "follow_up_chain.invoke(\"What is Computer Science?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B4Va5j0KJ_6D",
        "outputId": "075c190b-1a09-4387-9d0a-b819ec773f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The fundamental concern of computer science is determining what can and cannot be automated.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## new start 2"
      ],
      "metadata": {
        "id": "FbhTqIkoOX-i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3346EYm4Oaky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}